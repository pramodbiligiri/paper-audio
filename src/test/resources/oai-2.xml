<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2021-06-04T13:00:43Z</responseDate>
<request verb="ListRecords" resumptionToken="5392151|1001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13353</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13353</id><submitter>Quoc-Huy Tran</submitter><version version="v1"><date>Thu, 27 May 2021 17:57:37 GMT</date><size>617kb</size><source_type>D</source_type></version><version version="v2"><date>Fri, 28 May 2021 21:06:22 GMT</date><size>951kb</size><source_type>D</source_type></version><title>Unsupervised Activity Segmentation by Joint Representation Learning and
  Online Clustering</title><authors>Sateesh Kumar, Sanjay Haresh, Awais Ahmed, Andrey Konin, M. Zeeshan
  Zia, Quoc-Huy Tran</authors><categories>cs.CV</categories><comments>Preprint. Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach for unsupervised activity segmentation, which
uses video frame clustering as a pretext task and simultaneously performs
representation learning and online clustering. This is in contrast with prior
works where representation learning and clustering are often performed
sequentially. We leverage temporal information in videos by employing temporal
optimal transport and temporal coherence loss. In particular, we incorporate a
temporal regularization term into the standard optimal transport module, which
preserves the temporal order of the activity, yielding the temporal optimal
transport module for computing pseudo-label cluster assignments. Next, the
temporal coherence loss encourages neighboring video frames to be mapped to
nearby points while distant video frames are mapped to farther away points in
the embedding space. The combination of these two components results in
effective representations for unsupervised activity segmentation. Furthermore,
previous methods require storing learned features for the entire dataset before
clustering them in an offline manner, whereas our approach processes one
mini-batch at a time in an online manner. Extensive evaluations on three public
datasets, i.e. 50-Salads, YouTube Instructions, and Breakfast, and our dataset,
i.e., Desktop Assembly, show that our approach performs on par or better than
previous methods for unsupervised activity segmentation, despite having
significantly less memory constraints.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13396</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13396</id><submitter>Zachary Neal</submitter><version version="v1"><date>Thu, 27 May 2021 18:56:04 GMT</date><size>1064kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 12:24:53 GMT</date><size>1064kb</size><source_type>D</source_type></version><title>Comparing Models for Extracting the Backbone of Bipartite Projections</title><authors>Zachary P. Neal, Rachel Domagalski, and Bruce Sagan</authors><categories>cs.SI stat.AP</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Projections of bipartite or two-mode networks capture co-occurrences, and are
used in diverse fields (e.g., ecology, economics, bibliometrics, politics) to
represent unipartite networks that would otherwise be difficult or impossible
to measure directly. A key challenge in analyzing such networks is determining
whether an observed number of co-occurrences is significant. Several models now
exist for doing so and thus for extracting the backbone of bipartite
projections, but they have not been directly compared to each other. In this
paper, we compare five such models -- fixed fill model (FFM) fixed row model
(FRM), fixed column model (FCM), fixed degree sequence model (FDSM), and
stochastic degree sequence model (SDSM) -- in terms of accuracy, speed,
statistical power, similarity, and community detection. We find that the
computationally-fast SDSM offers a statistically conservative but close
approximation of the computationally-impractical FDSM under a wide range of
conditions, and that it correctly recovers a known community structure even
when the signal is weak. Therefore, although each backbone model may have
particular applications, we recommend SDSM for extracting the backbone of most
bipartite projections.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13456</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13456</id><submitter>Tuan Manh Lai</submitter><version version="v1"><date>Thu, 27 May 2021 21:33:34 GMT</date><size>5598kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 01:46:40 GMT</date><size>5598kb</size><source_type>D</source_type></version><title>Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced
  Collective Inference</title><authors>Tuan Lai, Heng Ji, ChengXiang Zhai, and Quan Hung Tran</authors><categories>cs.CL</categories><comments>Accepted by ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compared to the general news domain, information extraction (IE) from
biomedical text requires much broader domain knowledge. However, many previous
IE methods do not utilize any external knowledge during inference. Due to the
exponential growth of biomedical publications, models that do not go beyond
their fixed set of parameters will likely fall behind. Inspired by how humans
look up relevant information to comprehend a scientific text, we present a
novel framework that utilizes external knowledge for joint entity and relation
extraction named KECI (Knowledge-Enhanced Collective Inference). Given an input
text, KECI first constructs an initial span graph representing its initial
understanding of the text. It then uses an entity linker to form a knowledge
graph containing relevant background knowledge for the the entity mentions in
the text. To make the final predictions, KECI fuses the initial span graph and
the knowledge graph into a more refined graph using an attention mechanism.
KECI takes a collective approach to link mention spans to entities by
integrating global relational information into local representations using
graph convolutional networks. Our experimental results show that the framework
is highly effective, achieving new state-of-the-art results in two different
benchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse
drug event extraction). For example, KECI achieves absolute improvements of
4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity
and relation extraction tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13471</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13471</id><submitter>Carlos Aspillaga</submitter><version version="v1"><date>Thu, 27 May 2021 22:19:19 GMT</date><size>2118kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 13:29:09 GMT</date><size>2132kb</size><source_type>D</source_type></version><title>Inspecting the concept knowledge graph encoded by modern language models</title><authors>Carlos Aspillaga, Marcelo Mendoza, Alvaro Soto</authors><categories>cs.AI cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The field of natural language understanding has experienced exponential
progress in the last few years, with impressive results in several tasks. This
success has motivated researchers to study the underlying knowledge encoded by
these models. Despite this, attempts to understand their semantic capabilities
have not been successful, often leading to non-conclusive, or contradictory
conclusions among different works. Via a probing classifier, we extract the
underlying knowledge graph of nine of the most influential language models of
the last years, including word embeddings, text generators, and context
encoders. This probe is based on concept relatedness, grounded on WordNet. Our
results reveal that all the models encode this knowledge, but suffer from
several inaccuracies. Furthermore, we show that the different architectures and
training strategies lead to different model biases. We conduct a systematic
evaluation to discover specific factors that explain why some concepts are
challenging. We hope our insights will motivate the development of models that
capture concepts more precisely.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13480</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13480</id><submitter>Rui Li</submitter><version version="v1"><date>Thu, 27 May 2021 22:25:38 GMT</date><size>144kb</size></version><version version="v2"><date>Mon, 31 May 2021 00:34:48 GMT</date><size>144kb</size></version><title>Efficient distributed algorithms for Convolutional Neural Networks</title><authors>Rui Li, Yufan Xu, Aravind Sukumaran-Rajam, Atanas Rountev and P
  Sadayappan</authors><categories>cs.DC</categories><comments>Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms
  and Architectures (SPAA '21), July 6--8, 2021, Virtual Event, USA</comments><doi>10.1145/3409964.3461828</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Several efficient distributed algorithms have been developed for
matrix-matrix multiplication: the 3D algorithm, the 2D SUMMA algorithm, and the
2.5D algorithm. Each of these algorithms was independently conceived and they
trade-off memory needed per node and the inter-node data communication volume.
  The convolutional neural network (CNN) computation may be viewed as a
generalization of matrix-multiplication combined with neighborhood stencil
computations. We develop communication-efficient distributed-memory algorithms
for CNNs that are analogous to the 2D/2.5D/3D algorithms for matrix-matrix
multiplication.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13482</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13482</id><submitter>Grzegorz Sarwas</submitter><version version="v1"><date>Thu, 27 May 2021 22:31:40 GMT</date><size>4514kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 09:45:52 GMT</date><size>2665kb</size><source_type>D</source_type></version><title>FastRIFE: Optimization of Real-Time Intermediate Flow Estimation for
  Video Frame Interpolation</title><authors>Malwina Kubas and Grzegorz Sarwas</authors><categories>cs.CV</categories><comments>WSCG 2021 29. International Conference in Central Europe on Computer
  Graphics, Visualization and Computer Vision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of video inter-frame interpolation is an essential task in the
field of image processing. Correctly increasing the number of frames in the
recording while maintaining smooth movement allows to improve the quality of
played video sequence, enables more effective compression and creating a
slow-motion recording. This paper proposes the FastRIFE algorithm, which is
some speed improvement of the RIFE (Real-Time Intermediate Flow Estimation)
model. The novel method was examined and compared with other recently published
algorithms. All source codes are available at
https://gitlab.com/malwinq/interpolation-of-images-for-slow-motion-videos
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13538</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13538</id><submitter>Junxian Wang</submitter><version version="v1"><date>Fri, 28 May 2021 01:58:16 GMT</date><size>3145kb</size></version><version version="v2"><date>Thu, 3 Jun 2021 12:00:50 GMT</date><size>3212kb</size></version><title>Two-level overlapping Schwarz methods based on local generalized
  eigenproblems for Hermitian variational problems</title><authors>Qing Lu, Junxian Wang, Shi Shu, Jie Peng</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research of two-level overlapping Schwarz (TL-OS) method based on
constrained energy minimizing coarse space is still in its infancy, and there
exist some defects, e.g. mainly for second order elliptic problem and too heavy
computational cost of coarse space construction. In this paper, by introducing
appropriate assumptions, we propose more concise coarse basis functions for
general Hermitian positive and definite discrete systems, and establish the
algorithmic and theoretical frameworks of the corresponding TL-OS methods.
Furthermore, to enhance the practicability of the algorithm, we design two
economical TL-OS preconditioners and prove the condition number estimate. As
the first application of the frameworks, we prove that the assumptions hold for
the linear finite element discretization of second order elliptic problem with
high contrast and oscillatory coefficient and the condition number of the TL-OS
preconditioned system is robust with respect to the model and mesh parameters.
In particular, we also prove that the condition number of the economically
preconditioned system is independent of the jump range under a certain jump
distribution. Experimental results show that the first kind of economical
preconditioner is more efficient and stable than the existed one. Secondly, we
construct TL-OS and the economical TL-OS preconditioners for the plane wave
least squares discrete system of Helmholtz equation by using the frameworks.
The numerical results for homogeneous and non-homogeneous cases illustrate that
the PCG method based on the proposed preconditioners have good stability in
terms of the angular frequency, mesh parameters and the number of degrees of
freedom in each element.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13562</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13562</id><submitter>Ashutosh Modi</submitter><version version="v1"><date>Fri, 28 May 2021 03:07:32 GMT</date><size>871kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 11:17:43 GMT</date><size>871kb</size><source_type>D</source_type></version><title>ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment
  Prediction and Explanation</title><authors>Vijit Malik and Rishabh Sanjay and Shubham Kumar Nigam and Kripa Ghosh
  and Shouvik Kumar Guha and Arnab Bhattacharya and Ashutosh Modi</authors><categories>cs.CL cs.AI</categories><comments>Accepted at ACL 2021, 17 Pages (9 Pages main paper, 4 pages
  references, 4 pages appendix)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  An automated system that could assist a judge in predicting the outcome of a
case would help expedite the judicial process. For such a system to be
practically useful, predictions by the system should be explainable. To promote
research in developing such a system, we introduce ILDC (Indian Legal Documents
Corpus). ILDC is a large corpus of 35k Indian Supreme Court cases annotated
with original court decisions. A portion of the corpus (a separate test set) is
annotated with gold standard explanations by legal experts. Based on ILDC, we
propose the task of Court Judgment Prediction and Explanation (CJPE). The task
requires an automated system to predict an explainable outcome of a case. We
experiment with a battery of baseline models for case predictions and propose a
hierarchical occlusion based model for explainability. Our best prediction
model has an accuracy of 78% versus 94% for human legal experts, pointing
towards the complexity of the prediction task. The analysis of explanations by
the proposed algorithm reveals a significant difference in the point of view of
the algorithm and legal experts for explaining the judgments, pointing towards
scope for future research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13574</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13574</id><submitter>Youry Khmelevsky</submitter><version version="v1"><date>Fri, 28 May 2021 03:50:57 GMT</date><size>13kb</size></version><version version="v2"><date>Mon, 31 May 2021 01:05:38 GMT</date><size>13kb</size></version><title>Parallel Programming Applied Research Projects for Teaching Parallel
  Programming to Beginner Students</title><authors>Youry Khmelevsky and Gaetan J.D.R. Hains</authors><categories>cs.DC</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this paper, we discuss the educational value of a few mid-size and one
large applied research projects at the Computer Science Department of Okanagan
College (OC) and at the Universities of Paris East Creteil (LACL) and Orleans
(LIFO) in France. We found, that some freshmen students are very active and
eager to be involved in applied research projects starting from the second
semester. They are actively participating in programming competitions and want
to be involved in applied research projects to compete with sophomore and older
students. Our observation is based on five NSERC Engage College and Applied
Research and Development (ARD) grants, and several small applied projects.
Student involvement in applied research is a key motivation and success factor
in our activities, but we are also involved in transferring some results of
applied research, namely programming techniques, into the parallel programming
courses for beginners at the senior- and first-year MSc levels. We illustrate
this feedback process with programming notions for beginners, practical tools
to acquire them and the overall success/failure of students as experienced for
more than 10 years in our French University courses.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13607</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13607</id><submitter>Yi Zhang</submitter><version version="v1"><date>Fri, 28 May 2021 06:26:19 GMT</date><size>8466kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 13:09:19 GMT</date><size>8463kb</size><source_type>D</source_type></version><title>Alleviating the Knowledge-Language Inconsistency: A Study for Deep
  Commonsense Knowledge</title><authors>Yi Zhang, Lei Li, Yunfang Wu, Qi Su, Xu Sun</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Knowledge facts are typically represented by relational triples, while we
observe that some commonsense facts are represented by the triples whose forms
are inconsistent with the expression of language. This inconsistency puts
forward a challenge for pre-trained language models to deal with these
commonsense knowledge facts. In this paper, we term such knowledge as deep
commonsense knowledge and conduct extensive exploratory experiments on it. We
show that deep commonsense knowledge occupies a significant part of commonsense
knowledge while conventional methods fail to capture it effectively. We further
propose a novel method to mine the deep commonsense knowledge distributed in
sentences, alleviating the reliance of conventional methods on the triple
representation form of knowledge. Experiments demonstrate that the proposal
significantly improves the performance in mining deep commonsense knowledge.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13608</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13608</id><submitter>Ehsan Kamalloo</submitter><version version="v1"><date>Fri, 28 May 2021 06:32:32 GMT</date><size>128kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 15:18:33 GMT</date><size>1021kb</size><source_type>D</source_type></version><title>Not Far Away, Not So Close: Sample Efficient Nearest Neighbour Data
  Augmentation via MiniMax</title><authors>Ehsan Kamalloo, Mehdi Rezagholizadeh, Peyman Passban, Ali Ghodsi</authors><categories>cs.CL cs.LG</categories><comments>Findings of ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Natural Language Processing (NLP), finding data augmentation techniques
that can produce high-quality human-interpretable examples has always been
challenging. Recently, leveraging kNN such that augmented examples are
retrieved from large repositories of unlabelled sentences has made a step
toward interpretable augmentation. Inspired by this paradigm, we introduce
Minimax-kNN, a sample efficient data augmentation strategy tailored for
Knowledge Distillation (KD). We exploit a semi-supervised approach based on KD
to train a model on augmented data. In contrast to existing kNN augmentation
techniques that blindly incorporate all samples, our method dynamically selects
a subset of augmented samples that maximizes KL-divergence between the teacher
and student models. This step aims to extract the most efficient samples to
ensure our augmented data covers regions in the input space with maximum loss
value. We evaluated our technique on several text classification tasks and
demonstrated that Minimax-kNN consistently outperforms strong baselines. Our
results show that Minimax-kNN requires fewer augmented examples and less
computation to achieve superior performance over the state-of-the-art kNN-based
augmentation techniques.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13636</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13636</id><submitter>Akinori F Ebihara</submitter><version version="v1"><date>Fri, 28 May 2021 07:21:58 GMT</date><size>3490kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 01:44:50 GMT</date><size>3494kb</size><source_type>D</source_type></version><title>The Power of Log-Sum-Exp: Sequential Density Ratio Matrix Estimation for
  Speed-Accuracy Optimization</title><authors>Taiki Miyagawa and Akinori F. Ebihara</authors><categories>cs.LG</categories><comments>Accepted to International Conference on Machine Learning (ICML) 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a model for multiclass classification of time series to make a
prediction as early and as accurate as possible. The matrix sequential
probability ratio test (MSPRT) is known to be asymptotically optimal for this
setting, but contains a critical assumption that hinders broad real-world
applications; the MSPRT requires the underlying probability density. To address
this problem, we propose to solve density ratio matrix estimation (DRME), a
novel type of density ratio estimation that consists of estimating matrices of
multiple density ratios with constraints and thus is more challenging than the
conventional density ratio estimation. We propose a log-sum-exp-type loss
function (LSEL) for solving DRME and prove the following: (i) the LSEL provides
the true density ratio matrix as the sample size of the training set increases
(consistency); (ii) it assigns larger gradients to harder classes (hard class
weighting effect); and (iii) it provides discriminative scores even on
class-imbalanced datasets (guess-aversion). Our overall architecture for early
classification, MSPRT-TANDEM, statistically significantly outperforms baseline
models on four datasets including action recognition, especially in the early
stage of sequential observations. Our code and datasets are publicly available
at: https://github.com/TaikiMiyagawa/MSPRT-TANDEM.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13647</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13647</id><submitter>Sung Hyuck Hong</submitter><version version="v1"><date>Fri, 28 May 2021 07:51:16 GMT</date><size>608kb</size></version><title>Hybrid Beamforming for Intelligent Reflecting Surface Aided Millimeter
  Wave MIMO Systems</title><authors>Sung Hyuck Hong, Jaeyong Park, Sung-Jin Kim, and Junil Choi</authors><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While communication systems that employ millimeter wave (mmWave) frequency
bands can support extremely high data rates, they must use large antenna arrays
in order to overcome the severe propagation loss of mmWave signals. As the cost
of traditional fully-digital beamforming at baseband increases rapidly with the
number of antennas, hybrid beamforming that requires only a small number of
radio frequency (RF) chains has been considered as a key enabling technology
for mmWave communications. Intelligent reflecting surface (IRS) is another
innovative technology that has been proposed as an integral element of future
communication systems, establishing the favorable propagation environment in a
timely manner through the use of low-cost passive reflecting elements. In this
paper, we study IRS-aided mmWave multiple-input multiple-output (MIMO) systems
with hybrid beamforming architectures. We first propose the joint design of IRS
reflection pattern and hybrid beamformer for narrowband MIMO systems. Then, by
exploiting the sparsity of frequency-selective mmWave channels in the angular
domain, we generalize the proposed joint design to broadband MIMO systems with
orthogonal frequency division multiplexing (OFDM) modulation. Simulation
results demonstrate that the proposed joint designs can significantly enhance
the spectral efficiency of the systems of interest and achieve superior
performance over the existing designs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13648</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13648</id><submitter>Yu Bai</submitter><version version="v1"><date>Fri, 28 May 2021 07:51:42 GMT</date><size>15279kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 03:26:58 GMT</date><size>15279kb</size><source_type>D</source_type></version><title>Cross-Lingual Abstractive Summarization with Limited Parallel Resources</title><authors>Yu Bai, Yang Gao, Heyan Huang</authors><categories>cs.CL</categories><comments>Accepted by ACL2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel cross-lingual summarization data is scarce, requiring models to
better use the limited available cross-lingual resources. Existing methods to
do so often adopt sequence-to-sequence networks with multi-task frameworks.
Such approaches apply multiple decoders, each of which is utilized for a
specific task. However, these independent decoders share no parameters, hence
fail to capture the relationships between the discrete phrases of summaries in
different languages, breaking the connections in order to transfer the
knowledge of the high-resource languages to low-resource languages. To bridge
these connections, we propose a novel Multi-Task framework for Cross-Lingual
Abstractive Summarization (MCLAS) in a low-resource setting. Employing one
unified decoder to generate the sequential concatenation of monolingual and
cross-lingual summaries, MCLAS makes the monolingual summarization task a
prerequisite of the cross-lingual summarization (CLS) task. In this way, the
shared decoder learns interactions involving alignments and summary patterns
across languages, which encourages attaining knowledge transfer. Experiments on
two CLS datasets demonstrate that our model significantly outperforms three
baseline models in both low-resource and full-dataset scenarios. Moreover,
in-depth analysis on the generated summaries and attention heads verifies that
interactions are learned well using MCLAS, which benefits the CLS task under
limited parallel resources.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13677</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13677</id><submitter>Qing-Long Zhang</submitter><version version="v1"><date>Fri, 28 May 2021 08:53:54 GMT</date><size>226kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 13:16:31 GMT</date><size>6065kb</size><source_type>D</source_type></version><title>ResT: An Efficient Transformer for Visual Recognition</title><authors>Qinglong Zhang and Yubin Yang</authors><categories>cs.CV</categories><comments>ResT is an efficient multi-scale vision Transformer that can tackle
  input images with arbitrary size. arXiv admin note: text overlap with
  arXiv:2103.14030 by other authors</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents an efficient multi-scale vision Transformer, called ResT,
that capably served as a general-purpose backbone for image recognition. Unlike
existing Transformer methods, which employ standard Transformer blocks to
tackle raw images with a fixed resolution, our ResT have several advantages:
(1) A memory-efficient multi-head self-attention is built, which compresses the
memory by a simple depth-wise convolution, and projects the interaction across
the attention-heads dimension while keeping the diversity ability of
multi-heads; (2) Position encoding is constructed as spatial attention, which
is more flexible and can tackle with input images of arbitrary size without
interpolation or fine-tune; (3) Instead of the straightforward tokenization at
the beginning of each stage, we design the patch embedding as a stack of
overlapping convolution operation with stride on the 2D-reshaped token map. We
comprehensively validate ResT on image classification and downstream tasks.
Experimental results show that the proposed ResT can outperform the recently
state-of-the-art backbones by a large margin, demonstrating the potential of
ResT as strong backbones. The code and models will be made publicly available
at https://github.com/wofmanaf/ResT.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13699</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13699</id><submitter>Jihyeok Park</submitter><version version="v1"><date>Fri, 28 May 2021 09:48:53 GMT</date><size>4442kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 05:35:04 GMT</date><size>4425kb</size><source_type>D</source_type></version><title>Accelerating JavaScript Static Analysis via Dynamic Shortcuts (Extended
  Version)</title><authors>Joonyoung Park, Jihyeok Park, Dongjun Youn, Sukyoung Ryu</authors><categories>cs.SE</categories><comments>16 pages, 11 figures, 1 table, In Proceedings of the 29th ACM Joint
  European Software Engineering Conference and Symposium on the Foundations of
  Software Engineering (ESEC/FSE'21)</comments><doi>10.1145/3468264.3468556</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  JavaScript has become one of the most widely used programming languages for
web development, server-side programming, and even micro-controllers for IoT.
However, its extremely functional and dynamic features degrade the performance
and precision of static analysis. Moreover, the variety of built-in functions
and host environments requires excessive manual modeling of their behaviors. To
alleviate these problems, researchers have proposed various ways to leverage
dynamic analysis during JavaScript static analysis. However, they do not fully
utilize the high performance of dynamic analysis and often sacrifice the
soundness of static analysis.
  In this paper, we present dynamic shortcuts, a new technique to flexibly
switch between abstract and concrete execution during JavaScript static
analysis in a sound way. It can significantly improve the analysis performance
and precision by using highly-optimized commercial JavaScript engines and
lessen the modeling efforts for opaque code. We actualize the technique via
$\text{SAFE}_\textsf{DS}$, an extended combination of $\text{SAFE}$ and
Jalangi, a static analyzer and a dynamic analyzer, respectively. We evaluated
$\text{SAFE}_\textsf{DS}$ using 269 official tests of Lodash 4 library. Our
experiment shows that $\text{SAFE}_\textsf{DS}$ is 7.81x faster than the
baseline static analyzer, and it improves the precision to reduce failed
assertions by 12.31% on average for 22 opaque functions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13718</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13718</id><submitter>Amin Honarmandi Shandiz</submitter><version version="v1"><date>Fri, 28 May 2021 10:33:22 GMT</date><size>216kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 11:40:48 GMT</date><size>216kb</size><source_type>D</source_type></version><title>Voice Activity Detection for Ultrasound-based Silent Speech Interfaces
  using Convolutional Neural Networks</title><authors>Amin Honarmandi Shandiz and L\'aszl\'o T\'oth</authors><categories>cs.SD eess.AS</categories><comments>12 pages, 7 tables, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Voice Activity Detection (VAD) is not easy task when the input audio signal
is noisy, and it is even more complicated when the input is not even an audio
recording. This is the case with Silent Speech Interfaces (SSI) where we record
the movement of the articulatory organs during speech, and we aim to
reconstruct the speech signal from this recording. Our SSI system synthesizes
speech from ultrasonic videos of the tongue movement, and the quality of the
resulting speech signals are evaluated by metrics such as the mean squared
error loss function of the underlying neural network and the Mel-Cepstral
Distortion (MCD) of the reconstructed speech compared to the original. Here, we
first demonstrate that the amount of silence in the training data can have an
influence both on the MCD evaluation metric and on the performance of the
neural network model. Then, we train a convolutional neural network classifier
to separate silent and speech-containing ultrasound tongue images, using a
conventional VAD algorithm to create the training labels from the corresponding
speech signal. In the experiments our ultrasound-based speech/silence separator
achieved a classification accuracy of about 85\% and an AUC score around 86\%.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13719</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13719</id><submitter>Dominik Schr\&quot;oder</submitter><version version="v1"><date>Fri, 28 May 2021 10:36:54 GMT</date><size>167kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 07:53:21 GMT</date><size>167kb</size><source_type>D</source_type></version><title>On the condition number of the shifted real Ginibre ensemble</title><authors>Giorgio Cipolloni, L\'aszl\'o Erd\H{o}s, Dominik Schr\&quot;oder</authors><categories>math.NA cs.NA math.PR</categories><comments>10 pages, 3 figures. Updated references</comments><msc-class>60B20, 68W40, 65F35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive an accurate lower tail estimate on the lowest singular value
$\sigma_1(X-z)$ of a real Gaussian (Ginibre) random matrix $X$ shifted by a
complex parameter $z$. Such shift effectively changes the upper tail behaviour
of the condition number $\kappa(X-z)$ from the slower
$\mathbf{P}(\kappa(X-z)\ge t)\lesssim 1/t$ decay typical for real Ginibre
matrices to the faster $1/t^2$ decay seen for complex Ginibre matrices as long
as $z$ is away from the real axis. This sharpens and resolves a recent
conjecture in [arXiv:2005.08930] on the regularizing effect of the real Ginibre
ensemble with a genuinely complex shift. As a consequence we obtain an improved
upper bound on the eigenvalue condition numbers (known also as the eigenvector
overlaps) for real Ginibre matrices. The main technical tool is a rigorous
supersymmetric analysis from our earlier work [arXiv:1908.01653].
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13728</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13728</id><submitter>Oana Cocarascu</submitter><version version="v1"><date>Fri, 28 May 2021 10:48:08 GMT</date><size>132kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 10:46:56 GMT</date><size>132kb</size><source_type>D</source_type></version><title>An Explanatory Query-Based Framework for Exploring Academic Expertise</title><authors>Oana Cocarascu, Andrew McLean, Paul French, Francesca Toni</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The success of research institutions heavily relies upon identifying the
right researchers &quot;for the job&quot;: researchers may need to identify appropriate
collaborators, often from across disciplines; students may need to identify
suitable supervisors for projects of their interest; administrators may need to
match funding opportunities with relevant researchers, and so on. Usually,
finding potential collaborators in institutions is a time-consuming manual
search task prone to bias. In this paper, we propose a novel query-based
framework for searching, scoring, and exploring research expertise
automatically, based upon processing abstracts of academic publications. Given
user queries in natural language, our framework finds researchers with relevant
expertise, making use of domain-specific knowledge bases and word embeddings.
It also generates explanations for its recommendations. We evaluate our
framework with an institutional repository of papers from a leading university,
using, as baselines, artificial neural networks and transformer-based models
for a multilabel classification task to identify authors of publication
abstracts. We also assess the cross-domain effectiveness of our framework with
a (separate) research funding repository for the same institution. We show that
our simple method is effective in identifying matches, while satisfying
desirable properties and being efficient.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13753</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13753</id><submitter>Chang-Hwan Son</submitter><version version="v1"><date>Fri, 28 May 2021 11:40:40 GMT</date><size>1578kb</size></version><version version="v2"><date>Mon, 31 May 2021 03:03:21 GMT</date><size>1578kb</size></version><title>New Image Captioning Encoder via Semantic Visual Feature Matching for
  Heavy Rain Images</title><authors>Chang-Hwan Son, Pung-Hwi Ye</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Image captioning generates text that describes scenes from input images. It
has been developed for high quality images taken in clear weather. However, in
bad weather conditions, such as heavy rain, snow, and dense fog, the poor
visibility owing to rain streaks, rain accumulation, and snowflakes causes a
serious degradation of image quality. This hinders the extraction of useful
visual features and results in deteriorated image captioning performance. To
address practical issues, this study introduces a new encoder for captioning
heavy rain images. The central idea is to transform output features extracted
from heavy rain input images into semantic visual features associated with
words and sentence context. To achieve this, a target encoder is initially
trained in an encoder-decoder framework to associate visual features with
semantic words. Subsequently, the objects in a heavy rain image are rendered
visible by using an initial reconstruction subnetwork (IRS) based on a heavy
rain model. The IRS is then combined with another semantic visual feature
matching subnetwork (SVFMS) to match the output features of the IRS with the
semantic visual features of the pretrained target encoder. The proposed encoder
is based on the joint learning of the IRS and SVFMS. It is is trained in an
end-to-end manner, and then connected to the pretrained decoder for image
captioning. It is experimentally demonstrated that the proposed encoder can
generate semantic visual features associated with words even from heavy rain
images, thereby increasing the accuracy of the generated captions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13762</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13762</id><submitter>Ioannis Kontoyiannis</submitter><version version="v1"><date>Fri, 28 May 2021 12:07:10 GMT</date><size>5013kb</size><source_type>D</source_type></version><title>Inferring community characteristics in labelled networks</title><authors>Ioannis Kontoyiannis and Lawrence Tray</authors><categories>cs.LG cs.SI stat.AP</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Labelled networks form a very common and important class of data, naturally
appearing in numerous applications in science and engineering. A typical
inference goal is to determine how the vertex labels(or {\em features}) affect
the network's graph structure. A standard approach has been to partition the
network into blocks grouped by distinct values of the feature of interest. A
block-based random graph model -- typically a variant of the stochastic block
model -- is then used to test for evidence of asymmetric behaviour within these
feature-based communities. Nevertheless, the resulting communities often do not
produce a natural partition of the graph. In this work, we introduce a new
generative model, the feature-first block model (FFBM), which is more effective
at describing vertex-labelled undirected graphs and also facilitates the use of
richer queries on labelled networks. We develop a Bayesian framework for
inference with this model, and we present a method to efficiently sample from
the posterior distribution of the FFBM parameters. The FFBM's structure is kept
deliberately simple to retain easy interpretability of the parameter values. We
apply the proposed methods to a variety of network data to extract the most
important features along which the vertices are partitioned. The main
advantages of the proposed approach are that the whole feature-space is used
automatically, and features can be rank-ordered implicitly according to impact.
Any features that do not significantly impact the high-level structure can be
discarded to reduce the problem dimension. In cases where the vertex features
available do not readily explain the community structure in the resulting
network, the approach detects this and is protected against over-fitting.
Results on several real-world datasets illustrate the performance of the
proposed methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13863</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13863</id><submitter>Hakop Hakopian</submitter><version version="v1"><date>Fri, 28 May 2021 14:16:54 GMT</date><size>18kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 07:15:09 GMT</date><size>18kb</size></version><title>On plane algebraic curves passing through $n$-independent nodes</title><authors>Hakop Hakopian, Harutyun Kloyan, Davit Voskanyan</authors><categories>math.AG cs.NA math.NA</categories><comments>24 pages. arXiv admin note: substantial text overlap with
  arXiv:1903.10874</comments><msc-class>14H50</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Let a set of nodes $\mathcal X$ in the plane be $n$-independent, i.e., each
node has a fundamental polynomial of degree $n.$ Assume that $\#\mathcal
X=d(n,k)+3= (n+1)+n+\cdots+(n-k+5)+3$ and $4 \le k\le n-1.$ In this paper we
prove that there are at most seven linearly independent curves of degree less
than or equal to $k$ that pass through all the nodes of $\mathcal X.$ We
provide a characterization of the case when there are exactly seven such
curves. Namely, we prove that then the set $\mathcal X$ has a very special
construction: all its nodes but three belong to a (maximal) curve of degree
$k-3.$ Let us mention that in a series of such results this is the third one.
In the end, an important application to the bivariate polynomial interpolation
is provided, which is essential also for the study of the Gasca-Maeztu
conjecture.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13865</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13865</id><submitter>Yi Ke Yun</submitter><version version="v1"><date>Fri, 28 May 2021 14:19:54 GMT</date><size>11294kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 02:43:47 GMT</date><size>11294kb</size><source_type>D</source_type></version><title>Recursive Contour Saliency Blending Network for Accurate Salient Object
  Detection</title><authors>Yi Ke Yun, Chun Wei Tan, Takahiro Tsubono</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Contour information plays a vital role in salient object detection. However,
excessive false positives remain in predictions from existing contour-based
models due to insufficient contour-saliency fusion. In this work, we designed a
network for better edge quality in salient object detection. We proposed a
contour-saliency blending module to exchange information between contour and
saliency. We adopted recursive CNN to increase contour-saliency fusion while
keeping the total trainable parameters the same. Furthermore, we designed a
stage-wise feature extraction module to help the model pick up the most helpful
features from previous intermediate saliency predictions. Besides, we proposed
two new loss functions, namely Dual Confinement Loss and Confidence Loss, for
our model to generate better boundary predictions. Evaluation results on five
common benchmark datasets reveal that our model achieves competitive
state-of-the-art performance. Last but not least, our model is lightweight and
fast, with only 27.9 million parameters and real-time inferencing at 31 FPS.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13868</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13868</id><submitter>Shuhuai Ren</submitter><version version="v1"><date>Fri, 28 May 2021 14:25:49 GMT</date><size>7904kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 05:16:22 GMT</date><size>7905kb</size><source_type>D</source_type></version><title>Learning Relation Alignment for Calibrated Cross-modal Retrieval</title><authors>Shuhuai Ren, Junyang Lin, Guangxiang Zhao, Rui Men, An Yang, Jingren
  Zhou, Xu Sun, Hongxia Yang</authors><categories>cs.CL cs.CV</categories><comments>Accepted by ACL-IJCNLP 2021 main conference (Long Paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the achievements of large-scale multimodal pre-training approaches,
cross-modal retrieval, e.g., image-text retrieval, remains a challenging task.
To bridge the semantic gap between the two modalities, previous studies mainly
focus on word-region alignment at the object level, lacking the matching
between the linguistic relation among the words and the visual relation among
the regions. The neglect of such relation consistency impairs the
contextualized representation of image-text pairs and hinders the model
performance and the interpretability. In this paper, we first propose a novel
metric, Intra-modal Self-attention Distance (ISD), to quantify the relation
consistency by measuring the semantic distance between linguistic and visual
relations. In response, we present Inter-modal Alignment on Intra-modal
Self-attentions (IAIS), a regularized training method to optimize the ISD and
calibrate intra-modal self-attentions from the two modalities mutually via
inter-modal alignment. The IAIS regularizer boosts the performance of
prevailing models on Flickr30k and MS COCO datasets by a considerable margin,
which demonstrates the superiority of our approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13913</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13913</id><submitter>Mathieu Besan\c{c}on</submitter><version version="v1"><date>Fri, 28 May 2021 15:26:36 GMT</date><size>20870kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 07:18:01 GMT</date><size>20873kb</size><source_type>D</source_type></version><title>Simple steps are all you need: Frank-Wolfe and generalized
  self-concordant functions</title><authors>Alejandro Carderera and Mathieu Besan\c{c}on and Sebastian Pokutta</authors><categories>math.OC cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized self-concordance is a key property present in the objective
function of many important learning problems. We establish the convergence rate
of a simple Frank-Wolfe variant that uses the open-loop step size strategy
$\gamma_t = 2/(t+2)$, obtaining a $\mathcal{O}(1/t)$ convergence rate for this
class of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the
iteration count. This avoids the use of second-order information or the need to
estimate local smoothness parameters of previous work. We also show improved
convergence rates for various common cases, e.g., when the feasible region
under consideration is uniformly convex or polyhedral.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.13945</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.13945</id><submitter>Michael Spannowsky</submitter><version version="v1"><date>Fri, 28 May 2021 16:08:48 GMT</date><size>7757kb</size><source_type>D</source_type></version><version version="v2"><date>Mon, 31 May 2021 11:58:57 GMT</date><size>8193kb</size><source_type>D</source_type></version><title>Quantum Optimisation of Complex Systems with a Quantum Annealer</title><authors>Steve Abel, Andrew Blance and Michael Spannowsky</authors><categories>quant-ph cond-mat.stat-mech cs.LG hep-ph physics.comp-ph</categories><comments>24 pages, 19 figures, V2 (replaced fig. 13 b)</comments><report-no>IPPP/20/106</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform an in-depth comparison of quantum annealing with several classical
optimisation techniques, namely thermal annealing, Nelder-Mead, and gradient
descent. We begin with a direct study of the 2D Ising model on a quantum
annealer, and compare its properties directly with those of the thermal 2D
Ising model. These properties include an Ising-like phase transition that can
be induced by either a change in 'quantum-ness' of the theory, or by a scaling
the Ising couplings up or down. This behaviour is in accord with what is
expected from the physical understanding of the quantum system. We then go on
to demonstrate the efficacy of the quantum annealer at minimising several
increasingly hard two dimensional potentials. For all the potentials we find
the general behaviour that Nelder-Mead and gradient descent methods are very
susceptible to becoming trapped in false minima, while the thermal anneal
method is somewhat better at discovering the true minimum. However, and despite
current limitations on its size, the quantum annealer performs a minimisation
very markedly better than any of these classical techniques. A quantum anneal
can be designed so that the system almost never gets trapped in a false
minimum, and rapidly and successfully minimises the potentials.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14024</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14024</id><submitter>Scott Sussex</submitter><version version="v1"><date>Fri, 28 May 2021 18:00:00 GMT</date><size>478kb</size><source_type>D</source_type></version><title>Near-Optimal Multi-Perturbation Experimental Design for Causal Structure
  Learning</title><authors>Scott Sussex (1), Andreas Krause (1), Caroline Uhler (2) ((1)
  Department of Computer Science, ETH Z\&quot;urich, (2) Laboratory for Information
  &amp; Decision Systems, Massachusetts Institute of Technology)</authors><categories>cs.LG</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causal structure learning is a key problem in many domains. Causal structures
can be learnt by performing experiments on the system of interest. We address
the largely unexplored problem of designing experiments that simultaneously
intervene on multiple variables. While potentially more informative than the
commonly considered single-variable interventions, selecting such interventions
is algorithmically much more challenging, due to the doubly-exponential
combinatorial search space over sets of composite interventions. In this paper,
we develop efficient algorithms for optimizing different objective functions
quantifying the informativeness of experiments. By establishing novel
submodularity properties of these objectives, we provide approximation
guarantees for our algorithms. Our algorithms empirically perform superior to
both random interventions and algorithms that only select single-variable
interventions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14033</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14033</id><submitter>Heng Yang</submitter><version version="v1"><date>Fri, 28 May 2021 18:07:16 GMT</date><size>1743kb</size><source_type>D</source_type></version><title>STRIDE along Spectrahedral Vertices for Solving Large-Scale Rank-One
  Semidefinite Relaxations</title><authors>Heng Yang, Ling Liang, Kim-Chuan Toh, Luca Carlone</authors><categories>math.OC cs.CV cs.LG</categories><comments>9 pages main context, 2 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider solving high-order semidefinite programming (SDP) relaxations of
nonconvex polynomial optimization problems (POPs) that admit rank-one optimal
solutions. Existing approaches, which solve the SDP independently from the POP,
either cannot scale to large problems or suffer from slow convergence due to
the typical degeneracy of such SDPs. We propose a new algorithmic framework,
called SpecTrahedral pRoximal gradIent Descent along vErtices (STRIDE), that
blends fast local search on the nonconvex POP with global descent on the convex
SDP. Specifically, STRIDE follows a globally convergent trajectory driven by a
proximal gradient method (PGM) for solving the SDP, while simultaneously
probing long, but safeguarded, rank-one &quot;strides&quot;, generated by fast nonlinear
programming algorithms on the POP, to seek rapid descent. We prove STRIDE has
global convergence. To solve the subproblem of projecting a given point onto
the feasible set of the SDP, we reformulate the projection step as a
continuously differentiable unconstrained optimization and apply a
limited-memory BFGS method to achieve both scalability and accuracy. We conduct
numerical experiments on solving second-order SDP relaxations arising from two
important applications in machine learning and computer vision. STRIDE
dominates a diverse set of five existing SDP solvers and is the only solver
that can solve degenerate rank-one SDPs to high accuracy (e.g., KKT residuals
below 1e-9), even in the presence of millions of equality constraints.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14035</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14035</id><submitter>Shih-Ting Huang</submitter><version version="v1"><date>Fri, 28 May 2021 18:07:32 GMT</date><size>4802kb</size><source_type>D</source_type></version><title>DeepMoM: Robust Deep Learning With Median-of-Means</title><authors>Shih-Ting Huang and Johannes Lederer</authors><categories>stat.ML cs.LG stat.CO</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Data used in deep learning is notoriously problematic. For example, data are
usually combined from diverse sources, rarely cleaned and vetted thoroughly,
and sometimes corrupted on purpose. Intentional corruption that targets the
weak spots of algorithms has been studied extensively under the label of
&quot;adversarial attacks.&quot; In contrast, the arguably much more common case of
corruption that reflects the limited quality of data has been studied much
less. Such &quot;random&quot; corruptions are due to measurement errors, unreliable
sources, convenience sampling, and so forth. These kinds of corruption are
common in deep learning, because data are rarely collected according to strict
protocols -- in strong contrast to the formalized data collection in some parts
of classical statistics. This paper concerns such corruption. We introduce an
approach motivated by very recent insights into median-of-means and Le Cam's
principle, we show that the approach can be readily implemented, and we
demonstrate that it performs very well in practice. In conclusion, we believe
that our approach is a very promising alternative to standard parameter
training based on least-squares and cross-entropy loss.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14038</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14038</id><submitter>Xuechen Li</submitter><version version="v1"><date>Fri, 28 May 2021 18:12:22 GMT</date><size>744kb</size><source_type>D</source_type></version><title>Learning to Extend Program Graphs to Work-in-Progress Code</title><authors>Xuechen Li, Chris J. Maddison, Daniel Tarlow</authors><categories>cs.LG cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Source code spends most of its time in a broken or incomplete state during
software development. This presents a challenge to machine learning for code,
since high-performing models typically rely on graph structured representations
of programs derived from traditional program analyses. Such analyses may be
undefined for broken or incomplete code. We extend the notion of program graphs
to work-in-progress code by learning to predict edge relations between tokens,
training on well-formed code before transferring to work-in-progress code. We
consider the tasks of code completion and localizing and repairing variable
misuse in a work-in-process scenario. We demonstrate that training
relation-aware models with fine-tuned edges consistently leads to improved
performance on both tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14039</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14039</id><submitter>Andrew Lampinen</submitter><version version="v1"><date>Fri, 28 May 2021 18:12:28 GMT</date><size>14288kb</size><source_type>D</source_type></version><title>Towards mental time travel: a hierarchical memory for reinforcement
  learning agents</title><authors>Andrew Kyle Lampinen, Stephanie C.Y. Chan, Andrea Banino, Felix Hill</authors><categories>cs.LG cs.AI cs.NE</categories><comments>10 pages main text; 22 pages total</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement learning agents often forget details of the past, especially
after delays or distractor tasks. Agents with common memory architectures
struggle to recall and integrate across multiple timesteps of a past event, or
even to recall the details of a single timestep that is followed by distractor
tasks. To address these limitations, we propose a Hierarchical Transformer
Memory (HTM), which helps agents to remember the past in detail. HTM stores
memories by dividing the past into chunks, and recalls by first performing
high-level attention over coarse summaries of the chunks, and then performing
detailed attention within only the most relevant chunks. An agent with HTM can
therefore &quot;mentally time-travel&quot; -- remember past events in detail without
attending to all intervening events. We show that agents with HTM substantially
outperform agents with other memory architectures at tasks requiring long-term
recall, retention, or reasoning over memory. These include recalling where an
object is hidden in a 3D environment, rapidly learning to navigate efficiently
in a new neighborhood, and rapidly learning and retaining new object names.
Agents with HTM can extrapolate to task sequences an order of magnitude longer
than they were trained on, and can even generalize zero-shot from a
meta-learning setting to maintaining knowledge across episodes. HTM improves
agent sample efficiency, generalization, and generality (by solving tasks that
previously required specialized architectures). Our work is a step towards
agents that can learn, interact, and adapt in complex and temporally-extended
environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14044</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14044</id><submitter>Xavier Gitiaux</submitter><version version="v1"><date>Fri, 28 May 2021 18:22:07 GMT</date><size>10895kb</size><source_type>D</source_type></version><title>Fair Representations by Compression</title><authors>Xavier Gitiaux, Huzefa Rangwala</authors><categories>cs.LG cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Organizations that collect and sell data face increasing scrutiny for the
discriminatory use of data. We propose a novel unsupervised approach to
transform data into a compressed binary representation independent of sensitive
attributes. We show that in an information bottleneck framework, a parsimonious
representation should filter out information related to sensitive attributes if
they are provided directly to the decoder. Empirical results show that the
proposed method, \textbf{FBC}, achieves state-of-the-art accuracy-fairness
trade-off. Explicit control of the entropy of the representation bit stream
allows the user to move smoothly and simultaneously along both rate-distortion
and rate-fairness curves. \end{abstract}
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14047</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14047</id><submitter>Xiaoning Bian</submitter><version version="v1"><date>Fri, 28 May 2021 18:26:23 GMT</date><size>38kb</size></version><title>Generators and relations for $U_n(\mathbb Z [\frac{1}{2}, i])$</title><authors>Xiaoning Bian and Peter Selinger</authors><categories>quant-ph cs.ET cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the universal gate set for quantum computing consisting of the gates
X, CX, CCX, ${\omega}{\dagger}H$ and S. All of these gates have matrix entries
in the ring $\mathbb Z [\frac{1}{2}, i]$, the smallest subring of the complex
numbers containing $\frac{1}{2}$ and $i$. Amy, Glaudell, and Ross proved the
converse, i.e., any unitary matrix with entries in $\mathbb Z [\frac{1}{2}, i]$
can be realized by a quantum circuit over the above gate set using at most one
ancilla. In this paper, we give a finite presentation by generators and
relations of $U_n(\mathbb Z [\frac{1}{2}, i])$, the group of unitary $n\times
n$-matrices with entries in $\mathbb Z [\frac{1}{2}, i]$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14052</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14052</id><submitter>Shih-Ting Huang</submitter><version version="v1"><date>Fri, 28 May 2021 18:37:12 GMT</date><size>1498kb</size><source_type>D</source_type></version><title>Targeted Deep Learning: Framework, Methods, and Applications</title><authors>Shih-Ting Huang and Johannes Lederer</authors><categories>cs.LG stat.CO</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Deep learning systems are typically designed to perform for a wide range of
test inputs. For example, deep learning systems in autonomous cars are supposed
to deal with traffic situations for which they were not specifically trained.
In general, the ability to cope with a broad spectrum of unseen test inputs is
called generalization. Generalization is definitely important in applications
where the possible test inputs are known but plentiful or simply unknown, but
there are also cases where the possible inputs are few and unlabeled but known
beforehand. For example, medicine is currently interested in targeting
treatments to individual patients; the number of patients at any given time is
usually small (typically one), their diagnoses/responses/... are still unknown,
but their general characteristics (such as genome information, protein levels
in the blood, and so forth) are known before the treatment. We propose to call
deep learning in such applications targeted deep learning. In this paper, we
introduce a framework for targeted deep learning, and we devise and test an
approach for adapting standard pipelines to the requirements of targeted deep
learning. The approach is very general yet easy to use: it can be implemented
as a simple data-preprocessing step. We demonstrate on a variety of real-world
data that our approach can indeed render standard deep learning faster and more
accurate when the test inputs are known beforehand.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14058</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14058</id><submitter>Francesco Farina</submitter><version version="v1"><date>Fri, 28 May 2021 18:54:12 GMT</date><size>4143kb</size><source_type>D</source_type></version><title>Symmetry-driven graph neural networks</title><authors>Francesco Farina, Emma Slade</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Exploiting symmetries and invariance in data is a powerful, yet not fully
exploited, way to achieve better generalisation with more efficiency. In this
paper, we introduce two graph network architectures that are equivariant to
several types of transformations affecting the node coordinates. First, we
build equivariance to any transformation in the coordinate embeddings that
preserves the distance between neighbouring nodes, allowing for equivariance to
the Euclidean group. Then, we introduce angle attributes to build equivariance
to any angle preserving transformation - thus, to the conformal group. Thanks
to their equivariance properties, the proposed models can be vastly more data
efficient with respect to classical graph architectures, intrinsically equipped
with a better inductive bias and better at generalising. We demonstrate these
capabilities on a synthetic dataset composed of $n$-dimensional geometric
objects. Additionally, we provide examples of their limitations when (the
right) symmetries are not present in the data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14059</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14059</id><submitter>Kleinner Farias</submitter><version version="v1"><date>Fri, 28 May 2021 18:57:40 GMT</date><size>3288kb</size><source_type>D</source_type></version><title>On the Usage of Psychophysiological Data in Software Engineering: An
  Extended Systematic Mapping Study</title><authors>Roger Vieira, Kleinner Farias</authors><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, many studies have applied wearable devices to capture
psychophysiological data from software developers. However, the current
literature lacks investigations that classify the studies and point out gaps to
be explored. This article, therefore, seeks to present a comprehensive overview
of the literature by classifying and creating a systematic map of the works.
Besides, it seeks to pinpoint research gaps, challenges, and trends. Based on
widely known guidelines, a systematic mapping of the literature was designed
and run to answer eight research questions. After applying a careful filtering
process, we selected 27 representative studies from a sample of 2,084
potentially relevant works retrieved from seven digital libraries. The main
results are: a classification scheme of the published studies was produced;
there is no predominance of the devices used to capture psychophysiological
data; over 50% of the studies have explored indicators related to mental states
and neural activity; and 80% have analyzed composite data to understand the
cognitive load and in the context of understanding debugging programs and
strategies. Our findings can benefit researchers and students by creating a
systematic map of the literature, being a starting point for future research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14060</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14060</id><submitter>Yongji Wu</submitter><version version="v1"><date>Fri, 28 May 2021 18:58:11 GMT</date><size>1021kb</size><source_type>D</source_type></version><title>Rethinking Lifelong Sequential Recommendation with Incremental
  Multi-Interest Attention</title><authors>Yongji Wu, Lu Yin, Defu Lian, Mingyang Yin, Neil Zhenqiang Gong,
  Jingren Zhou, Hongxia Yang</authors><categories>cs.IR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential recommendation plays an increasingly important role in many
e-commerce services such as display advertisement and online shopping. With the
rapid development of these services in the last two decades, users have
accumulated a massive amount of behavior data. Richer sequential behavior data
has been proven to be of great value for sequential recommendation. However,
traditional sequential models fail to handle users' lifelong sequences, as
their linear computational and storage cost prohibits them from performing
online inference. Recently, lifelong sequential modeling methods that borrow
the idea of memory networks from NLP are proposed to address this issue.
However, the RNN-based memory networks built upon intrinsically suffer from the
inability to capture long-term dependencies and may instead be overwhelmed by
the noise on extremely long behavior sequences. In addition, as the user's
behavior sequence gets longer, more interests would be demonstrated in it. It
is therefore crucial to model and capture the diverse interests of users. In
order to tackle these issues, we propose a novel lifelong incremental
multi-interest self attention based sequential recommendation model, namely
LimaRec. Our proposed method benefits from the carefully designed
self-attention to identify relevant information from users' behavior sequences
with different interests. It is still able to incrementally update users'
representations for online inference, similarly to memory network based
approaches. We extensively evaluate our method on four real-world datasets and
demonstrate its superior performances compared to the state-of-the-art
baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14064</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14064</id><submitter>Chien-Sheng Wu</submitter><version version="v1"><date>Fri, 28 May 2021 19:05:36 GMT</date><size>7303kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 05:16:05 GMT</date><size>7519kb</size><source_type>D</source_type></version><title>Controllable Abstractive Dialogue Summarization with Sketch Supervision</title><authors>Chien-Sheng Wu and Linqing Liu and Wenhao Liu and Pontus Stenetorp and
  Caiming Xiong</authors><categories>cs.CL cs.AI</categories><comments>ACL-Findings 2021. Code is released at
  https://github.com/salesforce/ConvSumm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim to improve abstractive dialogue summarization quality
and, at the same time, enable granularity control. Our model has two primary
components and stages: 1) a two-stage generation strategy that generates a
preliminary summary sketch serving as the basis for the final summary. This
summary sketch provides a weakly supervised signal in the form of
pseudo-labeled interrogative pronoun categories and key phrases extracted using
a constituency parser. 2) A simple strategy to control the granularity of the
final summary, in that our model can automatically determine or control the
number of generated summary sentences for a given dialogue by predicting and
highlighting different text spans from the source text. Our model achieves
state-of-the-art performance on the largest dialogue summarization corpus
SAMSum, with as high as 50.79 in ROUGE-L score. In addition, we conduct a case
study and show competitive human evaluation results and controllability to
human-annotated summaries.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14065</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14065</id><submitter>Xinyi Li</submitter><version version="v1"><date>Fri, 28 May 2021 19:08:43 GMT</date><size>2921kb</size><source_type>D</source_type></version><title>TransCamP: Graph Transformer for 6-DoF Camera Pose Estimation</title><authors>Xinyi Li, Haibin Ling</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Camera pose estimation or camera relocalization is the centerpiece in
numerous computer vision tasks such as visual odometry, structure from motion
(SfM) and SLAM. In this paper we propose a neural network approach with a graph
transformer backbone, namely TransCamP, to address the camera relocalization
problem. In contrast with prior work where the pose regression is mainly guided
by photometric consistency, TransCamP effectively fuses the image features,
camera pose information and inter-frame relative camera motions into encoded
graph attributes and is trained towards the graph consistency and accuracy
instead, yielding significantly higher computational efficiency. By leveraging
graph transformer layers with edge features and enabling tensorized adjacency
matrix, TransCamP dynamically captures the global attention and thus endows the
pose graph with evolving structures to achieve improved robustness and
accuracy. In addition, optional temporal transformer layers actively enhance
the spatiotemporal inter-frame relation for sequential inputs. Evaluation of
the proposed network on various public benchmarks demonstrates that TransCamP
outperforms state-of-the-art approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14066</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14066</id><submitter>Florian M. Farke</submitter><version version="v1"><date>Fri, 28 May 2021 19:08:43 GMT</date><size>1894kb</size><source_type>D</source_type></version><title>Are Privacy Dashboards Good for End Users? Evaluating User Perceptions
  and Reactions to Google's My Activity (Extended Version)</title><authors>Florian M. Farke (1), David G. Balash (2), Maximilian Golla (3),
  Markus D\&quot;urmuth (1), Adam J. Aviv (2) ((1) Ruhr University Bochum, (2) The
  George Washington University, (3) Max Planck Institute for Security and
  Privacy)</authors><categories>cs.CY cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy dashboards and transparency tools help users review and manage the
data collected about them online. Since 2016, Google has offered such a tool,
My Activity, which allows users to review and delete their activity data from
Google services. We conducted an online survey with $n = 153$ participants to
understand if Google's My Activity, as an example of a privacy transparency
tool, increases or decreases end-users' concerns and benefits regarding data
collection. While most participants were aware of Google's data collection, the
volume and detail was surprising, but after exposure to My Activity,
participants were significantly more likely to be both less concerned about
data collection and to view data collection more beneficially. Only $25\,\%$
indicated that they would change any settings in the My Activity service or
change any behaviors. This suggests that privacy transparency tools are quite
beneficial for online services as they garner trust with their users and
improve their perceptions without necessarily changing users' behaviors. At the
same time, though, it remains unclear if such transparency tools actually
improve end user privacy by sufficiently assisting or motivating users to
change or review data collection settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14068</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14068</id><submitter>Yongji Wu</submitter><version version="v1"><date>Fri, 28 May 2021 19:16:51 GMT</date><size>2750kb</size><source_type>D</source_type></version><title>Linear-Time Self Attention with Codeword Histogram for Efficient
  Recommendation</title><authors>Yongji Wu, Defu Lian, Neil Zhenqiang Gong, Lu Yin, Mingyang Yin,
  Jingren Zhou, Hongxia Yang</authors><categories>cs.IR</categories><comments>11 pages. Accepted by the Web Conference 2021 (WWW '21)</comments><doi>10.1145/3442381.3449946</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-attention has become increasingly popular in a variety of sequence
modeling tasks from natural language processing to recommendation, due to its
effectiveness. However, self-attention suffers from quadratic computational and
memory complexities, prohibiting its applications on long sequences. Existing
approaches that address this issue mainly rely on a sparse attention context,
either using a local window, or a permuted bucket obtained by
locality-sensitive hashing (LSH) or sorting, while crucial information may be
lost. Inspired by the idea of vector quantization that uses cluster centroids
to approximate items, we propose LISA (LInear-time Self Attention), which
enjoys both the effectiveness of vanilla self-attention and the efficiency of
sparse attention. LISA scales linearly with the sequence length, while enabling
full contextual attention via computing differentiable histograms of codeword
distributions. Meanwhile, unlike some efficient attention methods, our method
poses no restriction on casual masking or sequence length. We evaluate our
method on four real-world datasets for sequential recommendation. The results
show that LISA outperforms the state-of-the-art efficient attention methods in
both performance and speed; and it is up to 57x faster and 78x more memory
efficient than vanilla self-attention.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14069</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14069</id><submitter>Arman Dehpanah</submitter><version version="v1"><date>Fri, 28 May 2021 19:22:07 GMT</date><size>642kb</size><source_type>D</source_type></version><title>The Evaluation of Rating Systems in Team-based Battle Royale Games</title><authors>Arman Dehpanah, Muheeb Faizan Ghori, Jonathan Gemmell, Bamshad
  Mobasher</authors><categories>cs.IR cs.AI cs.PF</categories><comments>11 pages, 1 figure, Accepted in the 23rd International Conference on
  Artificial Intelligence (ICAI'21)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online competitive games have become a mainstream entertainment platform. To
create a fair and exciting experience, these games use rating systems to match
players with similar skills. While there has been an increasing amount of
research on improving the performance of these systems, less attention has been
paid to how their performance is evaluated. In this paper, we explore the
utility of several metrics for evaluating three popular rating systems on a
real-world dataset of over 25,000 team battle royale matches. Our results
suggest considerable differences in their evaluation patterns. Some metrics
were highly impacted by the inclusion of new players. Many could not capture
the real differences between certain groups of players. Among all metrics
studied, normalized discounted cumulative gain (NDCG) demonstrated more
reliable performance and more flexibility. It alleviated most of the challenges
faced by the other metrics while adding the freedom to adjust the focus of the
evaluations on different groups of players.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14070</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14070</id><submitter>Mikko Lehtimaki</submitter><version version="v1"><date>Fri, 28 May 2021 19:27:09 GMT</date><size>375kb</size><source_type>D</source_type></version><title>Accelerating Neural ODEs Using Model Order Reduction</title><authors>Mikko Lehtim\&quot;aki, Lassi Paunonen, Marja-Leena Linne</authors><categories>cs.LG math.DS</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><msc-class>34C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedding nonlinear dynamical systems into artificial neural networks is a
powerful new formalism for machine learning. By parameterizing ordinary
differential equations (ODEs) as neural network layers, these Neural ODEs are
memory-efficient to train, process time-series naturally and incorporate
knowledge of physical systems into deep learning models. However, the practical
applications of Neural ODEs are limited due to long inference times, because
the outputs of the embedded ODE layers are computed numerically with
differential equation solvers that can be computationally demanding. Here we
show that mathematical model order reduction methods can be used for
compressing and accelerating Neural ODEs by accurately simulating the
continuous nonlinear dynamics in low-dimensional subspaces. We implement our
novel compression method by developing Neural ODEs that integrate the necessary
subspace-projection and interpolation operations as layers of the neural
network. We validate our model reduction approach by comparing it to two
established acceleration methods from the literature in two classification
asks. In compressing convolutional and recurrent Neural ODE architectures, we
achieve the best balance between speed and accuracy when compared to the other
two acceleration methods. Based on our results, our integration of model order
reduction with Neural ODEs can facilitate efficient, dynamical system-driven
deep learning in resource-constrained applications.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14071</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14071</id><submitter>Soumick Chatterjee</submitter><version version="v1"><date>Fri, 28 May 2021 19:27:51 GMT</date><size>1433kb</size><source_type>D</source_type></version><title>Classification of Brain Tumours in MR Images using Deep Spatiospatial
  Models</title><authors>Soumick Chatterjee, Faraz Ahmed Nizamani, Andreas N\&quot;urnberger and
  Oliver Speck</authors><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A brain tumour is a mass or cluster of abnormal cells in the brain, which has
the possibility of becoming life-threatening because of its ability to invade
neighbouring tissues and also form metastases. An accurate diagnosis is
essential for successful treatment planning and magnetic resonance imaging is
the principal imaging modality for diagnostic of brain tumours and their
extent. Deep Learning methods in computer vision applications have shown
significant improvement in recent years, most of which can be credited to the
fact that a sizeable amount of data is available to train models on, and the
improvements in the model architectures yielding better approximations in a
supervised setting. Classifying tumours using such deep learning methods has
made significant progress with the availability of open datasets with reliable
annotations. Typically those methods are either 3D models, which use 3D
volumetric MRIs or even 2D models considering each slice separately. However,
by treating the slice spatial dimension separately, spatiotemporal models can
be employed as spatiospatial models for this task. These models have the
capabilities of learning specific spatial and temporal relationship, while
reducing computational costs. This paper uses two spatiotemporal models, ResNet
(2+1)D and ResNet Mixed Convolution, to classify different types of brain
tumours. It was observed that both these models performed superior to the pure
3D convolutional model, ResNet18. Furthermore, it was also observed that
pre-training the models on a different, even unrelated dataset before training
them for the task of tumour classification improves the performance. Finally,
Pre-trained ResNet Mixed Convolution was observed to be the best model in these
experiments, achieving a macro F1-score of 0.93 and a test accuracy of 96.98\%,
while at the same time being the model with the least computational cost.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14073</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14073</id><submitter>Murat Cubuktepe</submitter><version version="v1"><date>Fri, 28 May 2021 19:36:54 GMT</date><size>172kb</size></version><title>Task-Guided Inverse Reinforcement Learning Under Partial Information</title><authors>Franck Djeumou, Murat Cubuktepe, Craig Lennon, Ufuk Topcu</authors><categories>cs.LG cs.AI math.OC</categories><comments>Submitted to NeurIPS 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of inverse reinforcement learning (IRL), where the
learning agent recovers a reward function using expert demonstrations. Most of
the existing IRL techniques make the often unrealistic assumption that the
agent has access to full information about the environment. We remove this
assumption by developing an algorithm for IRL in partially observable Markov
decision processes (POMDPs), where an agent cannot directly observe the current
state of the POMDP. The algorithm addresses several limitations of existing
techniques that do not take the \emph{information asymmetry} between the expert
and the agent into account. First, it adopts causal entropy as the measure of
the likelihood of the expert demonstrations as opposed to entropy in most
existing IRL techniques and avoids a common source of algorithmic complexity.
Second, it incorporates task specifications expressed in temporal logic into
IRL. Such specifications may be interpreted as side information available to
the learner a priori in addition to the demonstrations, and may reduce the
information asymmetry between the expert and the agent. Nevertheless, the
resulting formulation is still nonconvex due to the intrinsic nonconvexity of
the so-called \emph{forward problem}, i.e., computing an optimal policy given a
reward function, in POMDPs. We address this nonconvexity through sequential
convex programming and introduce several extensions to solve the forward
problem in a scalable manner. This scalability allows computing policies that
incorporate memory at the expense of added computational cost yet also achieves
higher performance compared to memoryless policies. We demonstrate that, even
with severely limited data, the algorithm learns reward functions and policies
that satisfy the task and induce a similar behavior to the expert by leveraging
the side information and incorporating memory into the policy.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14074</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14074</id><submitter>Rohan Chitnis</submitter><version version="v1"><date>Fri, 28 May 2021 19:37:18 GMT</date><size>2405kb</size><source_type>D</source_type></version><title>Learning Neuro-Symbolic Relational Transition Models for Bilevel
  Planning</title><authors>Rohan Chitnis, Tom Silver, Joshua B. Tenenbaum, Tomas Lozano-Perez,
  Leslie Pack Kaelbling</authors><categories>cs.AI cs.LG cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite recent, independent progress in model-based reinforcement learning
and integrated symbolic-geometric robotic planning, synthesizing these
techniques remains challenging because of their disparate assumptions and
strengths. In this work, we take a step toward bridging this gap with
Neuro-Symbolic Relational Transition Models (NSRTs), a novel class of
transition models that are data-efficient to learn, compatible with powerful
robotic planning methods, and generalizable over objects. NSRTs have both
symbolic and neural components, enabling a bilevel planning scheme where
symbolic AI planning in an outer loop guides continuous planning with neural
models in an inner loop. Experiments in four robotic planning domains show that
NSRTs can be learned after only tens or hundreds of training episodes, and then
used for fast planning in new tasks that require up to 60 actions to reach the
goal and involve many more objects than were seen during training. Video:
https://tinyurl.com/chitnis-nsrts
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14077</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14077</id><submitter>George Cazenavette V</submitter><version version="v1"><date>Fri, 28 May 2021 19:41:48 GMT</date><size>2710kb</size><source_type>D</source_type></version><title>On the Bias Against Inductive Biases</title><authors>George Cazenavette, Simon Lucey</authors><categories>cs.CV cs.LG</categories><comments>Under Review at NeurIPS 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Borrowing from the transformer models that revolutionized the field of
natural language processing, self-supervised feature learning for visual tasks
has also seen state-of-the-art success using these extremely deep, isotropic
networks. However, the typical AI researcher does not have the resources to
evaluate, let alone train, a model with several billion parameters and
quadratic self-attention activations. To facilitate further research, it is
necessary to understand the features of these huge transformer models that can
be adequately studied by the typical researcher. One interesting characteristic
of these transformer models is that they remove most of the inductive biases
present in classical convolutional networks. In this work, we analyze the
effect of these and more inductive biases on small to moderately-sized
isotropic networks used for unsupervised visual feature learning and show that
their removal is not always ideal.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14078</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14078</id><submitter>Xiaotao Gu</submitter><version version="v1"><date>Fri, 28 May 2021 19:44:24 GMT</date><size>3234kb</size><source_type>D</source_type></version><title>UCPhrase: Unsupervised Context-aware Quality Phrase Tagging</title><authors>Xiaotao Gu, Zihan Wang, Zhenyu Bi, Yu Meng, Liyuan Liu, Jiawei Han,
  Jingbo Shang</authors><categories>cs.CL</categories><comments>KDD 2021</comments><doi>10.1145/3447548.3467397</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Identifying and understanding quality phrases from context is a fundamental
task in text mining. The most challenging part of this task arguably lies in
uncommon, emerging, and domain-specific phrases. The infrequent nature of these
phrases significantly hurts the performance of phrase mining methods that rely
on sufficient phrase occurrences in the input corpus. Context-aware tagging
models, though not restricted by frequency, heavily rely on domain experts for
either massive sentence-level gold labels or handcrafted gazetteers. In this
work, we propose UCPhrase, a novel unsupervised context-aware quality phrase
tagger. Specifically, we induce high-quality phrase spans as silver labels from
consistently co-occurring word sequences within each document. Compared with
typical context-agnostic distant supervision based on existing knowledge bases
(KBs), our silver labels root deeply in the input domain and context, thus
having unique advantages in preserving contextual completeness and capturing
emerging, out-of-KB phrases. Training a conventional neural tagger based on
silver labels usually faces the risk of overfitting phrase surface names.
Alternatively, we observe that the contextualized attention maps generated from
a transformer-based neural language model effectively reveal the connections
between words in a surface-agnostic way. Therefore, we pair such attention maps
with the silver labels to train a lightweight span prediction model, which can
be applied to new input to recognize (unseen) quality phrases regardless of
their surface names or frequency. Thorough experiments on various tasks and
datasets, including corpus-level phrase ranking, document-level keyphrase
extraction, and sentence-level phrase tagging, demonstrate the superiority of
our design over state-of-the-art pre-trained, unsupervised, and distantly
supervised methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14080</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14080</id><submitter>Alexia Jolicoeur-Martineau</submitter><version version="v1"><date>Fri, 28 May 2021 19:48:51 GMT</date><size>26742kb</size><source_type>D</source_type></version><title>Gotta Go Fast When Generating Data with Score-Based Models</title><authors>Alexia Jolicoeur-Martineau, Ke Li, R\'emi Pich\'e-Taillefer, Tal
  Kachman, Ioannis Mitliagkas</authors><categories>cs.LG cs.CV math.OC stat.ML</categories><comments>Code is available on
  https://github.com/AlexiaJM/score_sde_fast_sampling</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Score-based (denoising diffusion) generative models have recently gained a
lot of success in generating realistic and diverse data. These approaches
define a forward diffusion process for transforming data to noise and generate
data by reversing it (thereby going from noise to data). Unfortunately, current
score-based models generate data very slowly due to the sheer number of score
network evaluations required by numerical SDE solvers.
  In this work, we aim to accelerate this process by devising a more efficient
SDE solver. Existing approaches rely on the Euler-Maruyama (EM) solver, which
uses a fixed step size. We found that naively replacing it with other SDE
solvers fares poorly - they either result in low-quality samples or become
slower than EM. To get around this issue, we carefully devise an SDE solver
with adaptive step sizes tailored to score-based generative models piece by
piece. Our solver requires only two score function evaluations, rarely rejects
samples, and leads to high-quality samples. Our approach generates data 2 to 10
times faster than EM while achieving better or equal sample quality. For
high-resolution images, our method leads to significantly higher quality
samples than all other methods tested. Our SDE solver has the benefit of
requiring no step size tuning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14082</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14082</id><submitter>Aryaman Arora</submitter><version version="v1"><date>Fri, 28 May 2021 19:52:42 GMT</date><size>2639kb</size><source_type>D</source_type></version><title>Bh\=a$\unicode{x1E63}$\=acitra: Visualising the dialect geography of
  South Asia</title><authors>Aryaman Arora, Adam Farris, Gopalakrishnan R, Samopriya Basu</authors><categories>cs.CL</categories><comments>4 + 2 pages, 3 figures. To appear at LChange'21 workshop located at
  ACL 2021</comments><acm-class>I.2.7</acm-class><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present Bh\=a$\unicode{x1E63}$\=acitra, a dialect mapping system for South
Asia built on a database of linguistic studies of languages of the region
annotated for topic and location data. We analyse language coverage and look
towards applications to typology by visualising example datasets. The
application is not only meant to be useful for feature mapping, but also serves
as a new kind of interactive bibliography for linguists of South Asian
languages.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14083</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14083</id><submitter>Glenn Dawson</submitter><version version="v1"><date>Fri, 28 May 2021 19:58:18 GMT</date><size>2300kb</size><source_type>D</source_type></version><title>Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial
  Awareness</title><authors>Glenn Dawson, Robi Polikar</authors><categories>cs.LG cs.AI cs.HC</categories><comments>9 pages, 3 figures, 3 algorithms. Currently under blind review at
  NeurIPS 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most studies on learning from noisy labels rely on unrealistic models of
i.i.d. label noise, such as class-conditional transition matrices. More recent
work on instance-dependent noise models are more realistic, but assume a single
generative process for label noise across the entire dataset. We propose a more
principled model of label noise that generalizes instance-dependent noise to
multiple labelers, based on the observation that modern datasets are typically
annotated using distributed crowdsourcing methods. Under our labeler-dependent
model, label noise manifests itself under two modalities: natural error of
good-faith labelers, and adversarial labels provided by malicious actors. We
present two adversarial attack vectors that more accurately reflect the label
noise that may be encountered in real-world settings, and demonstrate that
under our multimodal noisy labels model, state-of-the-art approaches for
learning from noisy labels are defeated by adversarial label attacks. Finally,
we propose a multi-stage, labeler-aware, model-agnostic framework that reliably
filters noisy labels by leveraging knowledge about which data partitions were
labeled by which labeler, and show that our proposed framework remains robust
even in the presence of extreme adversarial label noise.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14084</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14084</id><submitter>Clayton Sanford</submitter><version version="v1"><date>Fri, 28 May 2021 20:06:21 GMT</date><size>4835kb</size><source_type>D</source_type></version><title>Support vector machines and linear regression coincide with very
  high-dimensional features</title><authors>Navid Ardeshir, Clayton Sanford, Daniel Hsu</authors><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>32 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The support vector machine (SVM) and minimum Euclidean norm least squares
regression are two fundamentally different approaches to fitting linear models,
but they have recently been connected in models for very high-dimensional data
through a phenomenon of support vector proliferation, where every training
example used to fit an SVM becomes a support vector. In this paper, we explore
the generality of this phenomenon and make the following contributions. First,
we prove a super-linear lower bound on the dimension (in terms of sample size)
required for support vector proliferation in independent feature models,
matching the upper bounds from previous works. We further identify a sharp
phase transition in Gaussian feature models, bound the width of this
transition, and give experimental support for its universality. Finally, we
hypothesize that this phase transition occurs only in much higher-dimensional
settings in the $\ell_1$ variant of the SVM, and we present a new geometric
characterization of the problem that may elucidate this phenomenon for the
general $\ell_p$ case.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14086</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14086</id><submitter>Xiaopei Wan</submitter><version version="v1"><date>Fri, 28 May 2021 20:11:08 GMT</date><size>943kb</size><source_type>D</source_type></version><title>Augmenting Anchors by the Detector Itself</title><authors>Xiaopei Wan, Shengjie Chen, Yujiu Yang, Zhenhua Guo, Fangbo Tao</authors><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  It is difficult to determine the scale and aspect ratio of anchors for
anchor-based object detection methods. Current state-of-the-art object
detectors either determine anchor parameters according to objects' shape and
scale in a dataset, or avoid this problem by utilizing anchor-free method. In
this paper, we propose a gradient-free anchor augmentation method named AADI,
which means Augmenting Anchors by the Detector Itself. AADI is not an
anchor-free method, but it converts the scale and aspect ratio of anchors from
a continuous space to a discrete space, which greatly alleviates the problem of
anchors' designation. Furthermore, AADI does not add any parameters or
hyper-parameters, which is beneficial for future research and downstream tasks.
Extensive experiments on COCO dataset show that AADI has obvious advantages for
both two-stage and single-stage methods, specifically, AADI achieves at least
2.1 AP improvements on Faster R-CNN and 1.6 AP improvements on RetinaNet, using
ResNet-50 model. We hope that this simple and cost-efficient method can be
widely used in object detection.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14088</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14088</id><submitter>Liang Luo</submitter><version version="v1"><date>Fri, 28 May 2021 20:14:38 GMT</date><size>407kb</size><source_type>D</source_type></version><title>Cloud Collectives: Towards Cloud-aware Collectives forML Workloads with
  Rank Reordering</title><authors>Liang Luo, Jacob Nelson, Arvind Krishnamurthy, Luis Ceze</authors><categories>cs.DC cs.AI cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  ML workloads are becoming increasingly popular in the cloud. Good cloud
training performance is contingent on efficient parameter exchange among VMs.
We find that Collectives, the widely used distributed communication algorithms,
cannot perform optimally out of the box due to the hierarchical topology of
datacenter networks and multi-tenancy nature of the cloudenvironment.In this
paper, we present Cloud Collectives , a prototype that accelerates collectives
by reordering theranks of participating VMs such that the communication pattern
dictated by the selected collectives operation best exploits the locality in
the network.Collectives is non-intrusive, requires no code changes nor rebuild
of an existing application, and runs without support from cloud providers. Our
preliminary application of Cloud Collectives on allreduce operations in public
clouds results in a speedup of up to 3.7x in multiple microbenchmarks and 1.3x
in real-world workloads of distributed training of deep neural networks and
gradient boosted decision trees using state-of-the-art frameworks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14089</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14089</id><submitter>Marcos M. Vasconcelos</submitter><version version="v1"><date>Fri, 28 May 2021 20:19:15 GMT</date><size>1149kb</size><source_type>D</source_type></version><title>Improved Convergence Rate for a Distributed Two-Time-Scale Gradient
  Method under Random Quantization</title><authors>Marcos M. Vasconcelos, Thinh T. Doan and Urbashi Mitra</authors><categories>eess.SY cs.SY</categories><comments>Submitted to IEEE Conference on Decision and Control (CDC) 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We study the so-called distributed two-time-scale gradient method for solving
convex optimization problems over a network of agents when the communication
bandwidth between the nodes is limited, and so information that is exchanged
between the nodes must be quantized. Our main contribution is to provide a
novel analysis, resulting to an improved convergence rate of this method as
compared to the existing works. In particular, we show that the method
converges at a rate $O(log_2 k/\sqrt k)$ to the optimal solution, when the
underlying objective function is strongly convex and smooth. The key technique
in our analysis is to consider a Lyapunov function that simultaneously captures
the coupling of the consensus and optimality errors generated by the method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14091</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14091</id><submitter>Virginie Ehrlacher</submitter><version version="v1"><date>Fri, 28 May 2021 20:21:31 GMT</date><size>3895kb</size></version><title>Influence of sampling on the convergence rates of greedy algorithms for
  parameter-dependent random variables</title><authors>Mohamed-Raed Blel, Virginie Ehrlacher, Tony Leli\`evre</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main focus of this article is to provide a mathematical study of the
algorithm proposed in~\cite{boyaval2010variance} where the authors proposed a
variance reduction technique for the computation of parameter-dependent
expectations using a reduced basis paradigm. We study the effect of Monte-Carlo
sampling on the theoretical properties of greedy algorithms. In particular,
using concentration inequalities for the empirical measure in Wasserstein
distance proved in~\cite{fournier2015rate}, we provide sufficient conditions on
the number of samples used for the computation of empirical variances at each
iteration of the greedy procedure to guarantee that the resulting method
algorithm is a weak greedy algorithm with high probability. These theoretical
results are not fully practical and we therefore propose a heuristic procedure
to choose the number of Monte-Carlo samples at each iteration, inspired from
this theoretical study, which provides satisfactory results on several
numerical test cases.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14092</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14092</id><submitter>Pawel Wawrzynski</submitter><version version="v1"><date>Fri, 28 May 2021 20:24:00 GMT</date><size>135kb</size><source_type>D</source_type></version><title>Deep Memory Update</title><authors>{\L}ukasz Neumann, Pawe{\l} Wawrzy\'nski</authors><categories>cs.NE</categories><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks are key tools for sequential data processing.
Existing architectures support only a limited class of operations that these
networks can apply to their memory state. In this paper, we address this issue
and introduce a recurrent neural module called Deep Memory Update (DMU). This
module is an alternative to well-established LSTM and GRU. However, it uses a
universal function approximator to process its lagged memory state. In
addition, the module normalizes the lagged memory to avoid gradient exploding
or vanishing in backpropagation through time. The subnetwork that transforms
the memory state of DMU can be arbitrary. Experimental results presented here
confirm that the previously mentioned properties of the network allow it to
compete with and often outperform state-of-the-art architectures such as LSTM
and GRU.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14094</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14094</id><submitter>Justin Dong</submitter><version version="v1"><date>Fri, 28 May 2021 20:25:40 GMT</date><size>14479kb</size><source_type>D</source_type></version><title>Galerkin Neural Networks: A Framework for Approximating Variational
  Equations with Error Control</title><authors>Mark Ainsworth and Justin Dong</authors><categories>cs.LG cs.NA math.NA</categories><msc-class>68T07 (primary), 35A15 (secondary)</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We present a new approach to using neural networks to approximate the
solutions of variational equations, based on the adaptive construction of a
sequence of finite-dimensional subspaces whose basis functions are realizations
of a sequence of neural networks. The finite-dimensional subspaces are then
used to define a standard Galerkin approximation of the variational equation.
This approach enjoys a number of advantages, including: the sequential nature
of the algorithm offers a systematic approach to enhancing the accuracy of a
given approximation; the sequential enhancements provide a useful indicator for
the error that can be used as a criterion for terminating the sequential
updates; the basic approach is largely oblivious to the nature of the partial
differential equation under consideration; and, some basic theoretical results
are presented regarding the convergence (or otherwise) of the method which are
used to formulate basic guidelines for applying the method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14095</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14095</id><submitter>Shuxiao Chen</submitter><version version="v1"><date>Fri, 28 May 2021 20:27:02 GMT</date><size>469kb</size><source_type>D</source_type></version><title>Weighted Training for Cross-Task Learning</title><authors>Shuxiao Chen, Koby Crammer, Hangfeng He, Dan Roth, Weijie J. Su</authors><categories>cs.LG cs.CL stat.ML</categories><comments>21 pages, 3 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted
training algorithm for cross-task learning based on minimizing a
representation-based task distance between the source and target tasks. We show
that TAWT is easy to implement, is computationally efficient, requires little
hyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees.
The effectiveness of TAWT is corroborated through extensive experiments with
BERT on four sequence tagging tasks in natural language processing (NLP),
including part-of-speech (PoS) tagging, chunking, predicate detection, and
named entity recognition (NER). As a byproduct, the proposed
representation-based task distance allows one to reason in a theoretically
principled way about several critical aspects of cross-task learning, such as
the choice of the source data and the impact of fine-tuning
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14097</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14097</id><submitter>Pawe{\l} Wawrzy\'nski</submitter><version version="v1"><date>Fri, 28 May 2021 20:31:25 GMT</date><size>76kb</size><source_type>D</source_type></version><title>Reinforcement Learning for on-line Sequence Transformation</title><authors>Grzegorz Rype\'s\'c, {\L}ukasz Lepak, Pawe{\l} Wawrzy\'nski</authors><categories>cs.LG cs.CL</categories><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of problems in the processing of sound and natural language, as well
as in other areas, can be reduced to simultaneously reading an input sequence
and writing an output sequence of generally different length. There are well
developed methods that produce the output sequence based on the entirely known
input. However, efficient methods that enable such transformations on-line do
not exist. In this paper we introduce an architecture that learns with
reinforcement to make decisions about whether to read a token or write another
token. This architecture is able to transform potentially infinite sequences
on-line. In an experimental study we compare it with state-of-the-art methods
for neural machine translation. While it produces slightly worse translations
than Transformer, it outperforms the autoencoder with attention, even though
our architecture translates texts on-line thereby solving a more difficult
problem than both reference methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14098</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14098</id><submitter>Ashkan Javaherian</submitter><version version="v1"><date>Fri, 28 May 2021 20:36:27 GMT</date><size>1109kb</size><source_type>D</source_type></version><title>Ray-based inversion accounting for scattering for biomedical ultrasound
  computed tomography</title><authors>Ashkan Javaherian, Ben Cox</authors><categories>math.NA cs.NA</categories><msc-class>34A55, 45Q05, 65L09, 86A22</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An efficient and accurate image reconstruction algorithm for ultrasound
tomography (UST) is described and demonstrated, which can recover accurate
sound speed distribution from acoustic time series measurements made in soft
tissue. The approach is based on a second-order iterative minimisation of the
difference between the measurements and a model based on a ray-approximation to
the heterogeneous Green's function. It overcomes the computational burden of
full-wave solvers while avoiding the drawbacks of time-of-flight methods.
Through the use of a second-order iterative minimisation scheme, applied
stepwise from low to high frequencies, the effects of scattering are
incorporated into the inversion.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14099</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14099</id><submitter>Nan Ding</submitter><version version="v1"><date>Fri, 28 May 2021 20:40:40 GMT</date><size>1552kb</size><source_type>D</source_type></version><title>Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot
  Meta-Learning</title><authors>Nan Ding, Xi Chen, Tomer Levinboim, Sebastian Goodman, Radu Soricut</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Despite recent advances in its theoretical understanding, there still remains
a significant gap in the ability of existing PAC-Bayesian theories on
meta-learning to explain performance improvements in the few-shot learning
setting, where the number of training examples in the target tasks is severely
limited. This gap originates from an assumption in the existing theories which
supposes that the number of training examples in the observed tasks and the
number of training examples in the target tasks follow the same distribution,
an assumption that rarely holds in practice. By relaxing this assumption, we
develop two PAC-Bayesian bounds tailored for the few-shot learning setting and
show that two existing meta-learning algorithms (MAML and Reptile) can be
derived from our bounds, thereby bridging the gap between practice and
PAC-Bayesian theories. Furthermore, we derive a new computationally-efficient
PACMAML algorithm, and show it outperforms existing meta-learning algorithms on
several few-shot benchmark datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14100</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14100</id><submitter>Kevin Batz</submitter><version version="v1"><date>Fri, 28 May 2021 20:40:44 GMT</date><size>196kb</size></version><title>Latticed $k$-Induction with an Application to Probabilistic Programs</title><authors>Kevin Batz, Mingshuai Chen, Benjamin Lucien Kaminski, Joost-Pieter
  Katoen, Christoph Matheja, Philipp Schr\&quot;oer</authors><categories>cs.LO</categories><comments>to be published in: CAV (2021)</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We revisit two well-established verification techniques, $k$-induction and
bounded model checking (BMC), in the more general setting of fixed point theory
over complete lattices. Our main theoretical contribution is latticed
$k$-induction, which (i) generalizes classical $k$-induction for verifying
transition systems, (ii) generalizes Park induction for bounding fixed points
of monotonic maps on complete lattices, and (iii) extends from naturals $k$ to
transfinite ordinals $\kappa$, thus yielding $\kappa$-induction. The
lattice-theoretic understanding of $k$-induction and BMC enables us to apply
both techniques to the fully automatic verification of infinite-state
probabilistic programs. Our prototypical implementation manages to
automatically verify non-trivial specifications for probabilistic programs
taken from the literature that - using existing techniques - cannot be verified
without synthesizing a stronger inductive invariant first.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14103</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14103</id><submitter>Hanlin Goh</submitter><version version="v1"><date>Fri, 28 May 2021 20:45:30 GMT</date><size>6873kb</size><source_type>D</source_type></version><title>An Attention Free Transformer</title><authors>Shuangfei Zhai, Walter Talbott, Nitish Srivastava, Chen Huang, Hanlin
  Goh, Ruixiang Zhang, Josh Susskind</authors><categories>cs.LG cs.CL cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Attention Free Transformer (AFT), an efficient variant of
Transformers that eliminates the need for dot product self attention. In an AFT
layer, the key and value are first combined with a set of learned position
biases, the result of which is multiplied with the query in an element-wise
fashion. This new operation has a memory complexity linear w.r.t. both the
context size and the dimension of features, making it compatible to both large
input and model sizes. We also introduce AFT-local and AFT-conv, two model
variants that take advantage of the idea of locality and spatial weight sharing
while maintaining global connectivity. We conduct extensive experiments on two
autoregressive modeling tasks (CIFAR10 and Enwik8) as well as an image
recognition task (ImageNet-1K classification). We show that AFT demonstrates
competitive performance on all the benchmarks, while providing excellent
efficiency at the same time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14105</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14105</id><submitter>Dominik Schildknecht</submitter><version version="v1"><date>Fri, 28 May 2021 21:04:55 GMT</date><size>651kb</size><source_type>D</source_type></version><title>Reinforcement Learning reveals fundamental limits on the mixing of
  active particles</title><authors>Dominik Schildknecht, Anastasia N. Popova, Jack Stellwagen, Matt
  Thomson</authors><categories>cs.LG cs.SY eess.SY nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control of far-from-equilibrium physical systems, including active
materials, has emerged as an important area for the application of
reinforcement learning (RL) strategies to derive control policies for physical
systems. In active materials, non-linear dynamics and long-range interactions
between particles prohibit closed-form descriptions of the system's dynamics
and prevent explicit solutions to optimal control problems. Due to fundamental
challenges in solving for explicit control strategies, RL has emerged as an
approach to derive control strategies for far-from-equilibrium active matter
systems. However, an important open question is how the mathematical structure
and the physical properties of the active matter systems determine the
tractability of RL for learning control policies. In this work, we show that RL
can only find good strategies to the canonical active matter task of mixing for
systems that combine attractive and repulsive particle interactions. Using
mathematical results from dynamical systems theory, we relate the availability
of both interaction types with the existence of hyperbolic dynamics and the
ability of RL to find homogeneous mixing strategies. In particular, we show
that for drag-dominated translational-invariant particle systems, hyperbolic
dynamics and, therefore, mixing requires combining attractive and repulsive
interactions. Broadly, our work demonstrates how fundamental physical and
mathematical properties of dynamical systems can enable or constrain
reinforcement learning-based control.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14106</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14106</id><submitter>Francesco Pelosin</submitter><version version="v1"><date>Fri, 28 May 2021 21:05:51 GMT</date><size>616kb</size><source_type>D</source_type></version><title>More Is Better: An Analysis of Instance Quantity/Quality Trade-off in
  Rehearsal-based Continual Learning</title><authors>Francesco Pelosin and Andrea Torsello</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The design of machines and algorithms capable of learning in a dynamically
changing environment has become an increasingly topical problem with the
increase of the size and heterogeneity of data available to learning systems.
As a consequence, the key issue of Continual Learning has become that of
addressing the stability-plasticity dilemma of connectionist systems, as they
need to adapt their model without forgetting previously acquired knowledge.
Within this context, rehearsal-based methods i.e., solutions in where the
learner exploits memory to revisit past data, has proven to be very effective,
leading to performance at the state-of-the-art. In our study, we propose an
analysis of the memory quantity/quality trade-off adopting various data
reduction approaches to increase the number of instances storable in memory. In
particular, we investigate complex instance compression techniques such as deep
encoders, but also trivial approaches such as image resizing and linear
dimensionality reduction. Our findings suggest that the optimal trade-off is
severely skewed toward instance quantity, where rehearsal approaches with
several heavily compressed instances easily outperform state-of-the-art
approaches with the same amount of memory at their disposal. Further, in high
memory configurations, deep approaches extracting spatial structure combined
with extreme resizing (of the order of $8\times8$ images) yield the best
results, while in memory-constrained configurations where deep approaches
cannot be used due to their memory requirement in training, Extreme Learning
Machines (ELM) offer a clear advantage.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14107</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14107</id><submitter>Yifan Li</submitter><version version="v1"><date>Fri, 28 May 2021 21:06:05 GMT</date><size>203kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 13:50:52 GMT</date><size>203kb</size></version><title>Data Acquisition for Improving Machine Learning Models</title><authors>Yifan Li, Xiaohui Yu, Nick Koudas</authors><categories>cs.DB</categories><comments>Accepted by VLDB 2021</comments><acm-class>E.5</acm-class><doi>10.14778/3467861.3467872</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast advances in Machine Learning over the last ten years have been
powered by the availability of suitably prepared data for training purposes.
The future of ML-enabled enterprise hinges on data. As such, there is already a
vibrant market offering data annotation services to tailor sophisticated ML
models. In this paper, we present research on the practical problem of
obtaining data in order to improve the accuracy of ML models. We consider an
environment in which consumers query for data to enhance the accuracy of their
models and data providers who possess data make them available for training
purposes. We first formalize this interaction process laying out the suitable
framework and associated parameters for data exchange. We then propose two data
acquisition strategies that consider a trade-off between exploration during
which we obtain data to learn about the distribution of a provider's data and
exploitation during which we optimize our data inquiries utilizing the gained
knowledge. In the first strategy, Estimation and Allocation, we utilize queries
to estimate the utilities of various predicates while learning about the
distribution of the provider's data; then we proceed to the allocation stage in
which we utilize those learned utility estimates to inform our data acquisition
decisions. The second algorithmic proposal, named Sequential Predicate
Selection, utilizes a sampling strategy to explore the distribution of the
provider's data, adaptively investing more resources to parts of the data space
that are statistically more promising to improve overall model accuracy. We
present a detailed experimental evaluation of our proposals utilizing a variety
of ML models and associated real data sets exploring all applicable parameters
of interest. We identify trade-offs and highlight the relative benefits of each
algorithm to further optimize model accuracy.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14108</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14108</id><submitter>Christian David Marton</submitter><version version="v1"><date>Fri, 28 May 2021 21:07:54 GMT</date><size>9013kb</size><source_type>D</source_type></version><title>Efficient and robust multi-task learning in the brain with modular task
  primitives</title><authors>Christian David Marton, Guillaume Lajoie, Kanaka Rajan</authors><categories>cs.AI q-bio.NC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In a real-world setting biological agents do not have infinite resources to
learn new things. It is thus useful to recycle previously acquired knowledge in
a way that allows for faster, less resource-intensive acquisition of multiple
new skills. Neural networks in the brain are likely not entirely re-trained
with new tasks, but how they leverage existing computations to learn new tasks
is not well understood. In this work, we study this question in artificial
neural networks trained on commonly used neuroscience paradigms. Building on
recent work from the multi-task learning literature, we propose two
ingredients: (1) network modularity, and (2) learning task primitives.
Together, these ingredients form inductive biases we call structural and
functional, respectively. Using a corpus of nine different tasks, we show that
a modular network endowed with task primitives allows for learning multiple
tasks well while keeping parameter counts, and updates, low. We also show that
the skills acquired with our approach are more robust to a broad range of
perturbations compared to those acquired with other multi-task learning
strategies. This work offers a new perspective on achieving efficient
multi-task learning in the brain, and makes predictions for novel neuroscience
experiments in which targeted perturbations are employed to explore solution
spaces.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14110</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14110</id><submitter>George Cazenavette V</submitter><version version="v1"><date>Fri, 28 May 2021 21:12:52 GMT</date><size>3954kb</size><source_type>D</source_type></version><title>MixerGAN: An MLP-Based Architecture for Unpaired Image-to-Image
  Translation</title><authors>George Cazenavette, Manuel Ladron De Guevara</authors><categories>cs.CV</categories><comments>Under Review for NeurIPS 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While attention-based transformer networks achieve unparalleled success in
nearly all language tasks, the large number of tokens coupled with the
quadratic activation memory usage makes them prohibitive for visual tasks. As
such, while language-to-language translation has been revolutionized by the
transformer model, convolutional networks remain the de facto solution for
image-to-image translation. The recently proposed MLP-Mixer architecture
alleviates some of the speed and memory issues associated with attention-based
networks while still retaining the long-range connections that make transformer
models desirable. Leveraging this efficient alternative to self-attention, we
propose a new unpaired image-to-image translation model called MixerGAN: a
simpler MLP-based architecture that considers long-distance relationships
between pixels without the need for expensive attention mechanisms.
Quantitative and qualitative analysis shows that MixerGAN achieves competitive
results when compared to prior convolutional-based methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14111</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14111</id><submitter>Jack Koch</submitter><version version="v1"><date>Fri, 28 May 2021 21:13:34 GMT</date><size>995kb</size><source_type>D</source_type></version><title>Objective Robustness in Deep Reinforcement Learning</title><authors>Jack Koch, Lauro Langosco, Jacob Pfau, James Le, Lee Sharkey</authors><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study objective robustness failures, a type of out-of-distribution
robustness failure in reinforcement learning (RL). Objective robustness
failures occur when an RL agent retains its capabilities off-distribution yet
pursues the wrong objective. We provide the first explicit empirical
demonstrations of objective robustness failures and argue that this type of
failure is critical to address.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14113</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14113</id><submitter>Weiming Xiang</submitter><version version="v1"><date>Fri, 28 May 2021 21:21:01 GMT</date><size>218kb</size></version><title>Necessary and Sufficient Conditions for Stability of Discrete-Time
  Switched Linear Systems with Ranged Dwell Time</title><authors>Weiming Xiang</authors><categories>math.OC cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper deals with the stability analysis problem of discrete-time
switched linear systems with ranged dwell time. A novel concept called
L-switching-cycle is proposed, which contains sequences of multiple activation
cycles satisfying the prescribed ranged dwell time constraint. Based on
L-switching-cycle, two sufficient conditions are proposed to ensure the global
uniform asymptotic stability of discrete-time switched linear systems. It is
noted that two conditions are equivalent in stability analysis with the same
$L$-switching-cycle. These two sufficient conditions can be viewed as
generalizations of the clock-dependent Lyapunov and multiple Lyapunov function
methods, respectively. Furthermore, it has been proven that the proposed
L-switching-cycle can eventually achieve the nonconservativeness in stability
analysis as long as a sufficiently long L-switching-cycle is adopted. A
numerical example is provided to illustrate our theoretical results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14114</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14114</id><submitter>Matias M\&quot;uller</submitter><version version="v1"><date>Fri, 28 May 2021 21:28:44 GMT</date><size>2291kb</size><source_type>D</source_type></version><title>Asymptotically Optimal Bandits under Weighted Information</title><authors>Matias I. M\&quot;uller and Cristian R. Rojas</authors><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>9 content pages, 3 references pages, 22 appendix pages, 4 figures, 34
  total pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We study the problem of regret minimization in a multi-armed bandit setup
where the agent is allowed to play multiple arms at each round by spreading the
resources usually allocated to only one arm. At each iteration the agent
selects a normalized power profile and receives a Gaussian vector as outcome,
where the unknown variance of each sample is inversely proportional to the
power allocated to that arm. The reward corresponds to a linear combination of
the power profile and the outcomes, resembling a linear bandit. By spreading
the power, the agent can choose to collect information much faster than in a
traditional multi-armed bandit at the price of reducing the accuracy of the
samples. This setup is fundamentally different from that of a linear bandit --
the regret is known to scale as $\Theta(\sqrt{T})$ for linear bandits, while in
this setup the agent receives a much more detailed feedback, for which we
derive a tight $\log(T)$ problem-dependent lower-bound. We propose a
Thompson-Sampling-based strategy, called Weighted Thompson Sampling (\WTS),
that designs the power profile as its posterior belief of each arm being the
best arm, and show that its upper bound matches the derived logarithmic lower
bound. Finally, we apply this strategy to a problem of control and system
identification, where the goal is to estimate the maximum gain (also called
$\mathcal{H}_\infty$-norm) of a linear dynamical system based on batches of
input-output samples.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14115</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14115</id><submitter>Antonios Anastasopoulos</submitter><version version="v1"><date>Fri, 28 May 2021 21:32:04 GMT</date><size>9261kb</size></version><title>Towards More Equitable Question Answering Systems: How Much More Data Do
  You Need?</title><authors>Arnab Debnath, Navid Rajabi, Fardina Fathmiul Alam, Antonios
  Anastasopoulos</authors><categories>cs.CL</categories><comments>Accepted at ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Question answering (QA) in English has been widely explored, but multilingual
datasets are relatively new, with several methods attempting to bridge the gap
between high- and low-resourced languages using data augmentation through
translation and cross-lingual transfer. In this project, we take a step back
and study which approaches allow us to take the most advantage of existing
resources in order to produce QA systems in many languages. Specifically, we
perform extensive analysis to measure the efficacy of few-shot approaches
augmented with automatic translations and permutations of
context-question-answer pairs. In addition, we make suggestions for future
dataset development efforts that make better use of a fixed annotation budget,
with a goal of increasing the language coverage of QA datasets and systems.
Code and data for reproducing our experiments are available here:
https://github.com/NavidRajabi/EMQA.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14116</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14116</id><submitter>Daniel Steinberg</submitter><version version="v1"><date>Fri, 28 May 2021 21:34:02 GMT</date><size>2477kb</size><source_type>D</source_type></version><title>Visualizing Representations of Adversarially Perturbed Inputs</title><authors>Daniel Steinberg, Paul Munro</authors><categories>cs.LG cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown that deep learning models are vulnerable to adversarial
attacks. We seek to further understand the consequence of such attacks on the
intermediate activations of neural networks. We present an evaluation metric,
POP-N, which scores the effectiveness of projecting data to N dimensions under
the context of visualizing representations of adversarially perturbed inputs.
We conduct experiments on CIFAR-10 to compare the POP-2 score of several
dimensionality reduction algorithms across various adversarial attacks.
Finally, we utilize the 2D data corresponding to high POP-2 scores to generate
example visualizations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14117</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14117</id><submitter>Dmitrii Shubin</submitter><version version="v1"><date>Fri, 28 May 2021 21:34:04 GMT</date><size>4277kb</size><source_type>D</source_type></version><title>About Explicit Variance Minimization: Training Neural Networks for
  Medical Imaging With Limited Data Annotations</title><authors>Dmitrii Shubin, Danny Eytan, Sebastian D. Goodfellow</authors><categories>cs.CV</categories><msc-class>68T07 (Primary) 68T45 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-supervised learning methods for computer vision have demonstrated the
effectiveness of pre-training feature representations, resulting in
well-generalizing Deep Neural Networks, even if the annotated data are limited.
However, representation learning techniques require a significant amount of
time for model training, with most of it time spent on precise hyper-parameter
optimization and selection of augmentation techniques. We hypothesized that if
the annotated dataset has enough morphological diversity to capture the general
population's as is common in medical imaging, for example, due to conserved
similarities of tissue mythologies, the variance error of the trained model is
the prevalent component of the Bias-Variance Trade-off. We propose the Variance
Aware Training (VAT) method that exploits this property by introducing the
variance error into the model loss function, i.e., enabling minimizing the
variance explicitly. Additionally, we provide the theoretical formulation and
proof of the proposed method to aid in interpreting the approach. Our method
requires selecting only one hyper-parameter and was able to match or improve
the state-of-the-art performance of self-supervised methods while achieving an
order of magnitude reduction in the GPU training time. We validated VAT on
three medical imaging datasets from diverse domains and various learning
objectives. These included a Magnetic Resonance Imaging (MRI) dataset for the
heart semantic segmentation (MICCAI 2017 ACDC challenge), fundus photography
dataset for ordinary regression of diabetic retinopathy progression (Kaggle
2019 APTOS Blindness Detection challenge), and classification of
histopathologic scans of lymph node sections (PatchCamelyon dataset).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14118</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14118</id><submitter>Mahroo Bahreinian</submitter><version version="v1"><date>Fri, 28 May 2021 21:35:57 GMT</date><size>2933kb</size><source_type>D</source_type></version><title>Robust Sample-Based Output-Feedback Path Planning</title><authors>Mahroo Bahreinian, Marc Mitjans, and Roberto Tron</authors><categories>cs.RO</categories><comments>submitted to IROS2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel approach for sampling-based and control-based motion
planning that combines a representation of the environment obtained via a
modified version of optimal Rapidly-exploring Random Trees (RRT*), with
landmark-based output-feedback controllers obtained via Control Lyapunov
Functions, Control Barrier Functions, and robust Linear Programming. Our
solution inherits many benefits of RRT*-like algorithms, such as the ability to
implicitly handle arbitrarily complex obstacles, and asymptotic optimality.
Additionally, it extends planning beyond the discrete nominal paths, as
feedback controllers can correct deviations from such paths, and are robust to
discrepancies between the map used for planning and the real environment.
  We test our algorithms first in simulations and then in experiments, testing
the robustness of the approach to practical conditions, such as deformations of
the environment, mismatches in the dynamical model of the robot, and
measurements acquired with a camera with a limited field of view.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14119</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14119</id><submitter>Adam Kalai</submitter><version version="v1"><date>Fri, 28 May 2021 21:44:48 GMT</date><size>304kb</size><source_type>D</source_type></version><title>Towards optimally abstaining from prediction</title><authors>Adam Tauman Kalai, Varun Kanade</authors><categories>cs.LG cs.AI cs.DS stat.ML</categories><comments>23 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A common challenge across all areas of machine learning is that training data
is not distributed like test data, due to natural shifts, &quot;blind spots,&quot; or
adversarial examples. We consider a model where one may abstain from
predicting, at a fixed cost. In particular, our transductive abstention
algorithm takes labeled training examples and unlabeled test examples as input,
and provides predictions with optimal prediction loss guarantees. The loss
bounds match standard generalization bounds when test examples are i.i.d. from
the training distribution, but add an additional term that is the cost of
abstaining times the statistical distance between the train and test
distribution (or the fraction of adversarial examples). For linear regression,
we give a polynomial-time algorithm based on Celis-Dennis-Tapia optimization
algorithms. For binary classification, we show how to efficiently implement it
using a proper agnostic learner (i.e., an Empirical Risk Minimizer) for the
class of interest. Our work builds on a recent abstention algorithm of
Goldwasser, Kalais, and Montasser (2020) for transductive binary
classification.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14120</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14120</id><submitter>Kevin Chu</submitter><version version="v1"><date>Fri, 28 May 2021 21:53:52 GMT</date><size>576kb</size></version><title>Assessing the intelligibility of vocoded speech using a remote testing
  framework</title><authors>Kevin M. Chu, Leslie M. Collins, Boyla O. Mainsah</authors><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past year, remote speech intelligibility testing has become a
popular and necessary alternative to traditional in-person experiments due to
the need for physical distancing during the COVID-19 pandemic. A remote
framework was developed for conducting speech intelligibility tests with normal
hearing listeners. In this study, subjects used their personal computers to
complete sentence recognition tasks in anechoic and reverberant listening
environments. The results obtained using this remote framework were compared
with previously collected in-lab results, and showed higher levels of speech
intelligibility among remote study participants than subjects who completed the
test in the laboratory.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14125</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14125</id><submitter>Vaneet Aggarwal</submitter><version version="v1"><date>Fri, 28 May 2021 22:20:54 GMT</date><size>238kb</size><source_type>D</source_type></version><title>Joint Optimization of Multi-Objective Reinforcement Learning with Policy
  Gradient Based Algorithm</title><authors>Qinbo Bai and Mridul Agarwal and Vaneet Aggarwal</authors><categories>cs.LG cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many engineering problems have multiple objectives, and the overall aim is to
optimize a non-linear function of these objectives. In this paper, we formulate
the problem of maximizing a non-linear concave function of multiple long-term
objectives. A policy-gradient based model-free algorithm is proposed for the
problem. To compute an estimate of the gradient, a biased estimator is
proposed. The proposed algorithm is shown to achieve convergence to within an
$\epsilon$ of the global optima after sampling
$\mathcal{O}(\frac{M^4\sigma^2}{(1-\gamma)^8\epsilon^4})$ trajectories where
$\gamma$ is the discount factor and $M$ is the number of the agents, thus
achieving the same dependence on $\epsilon$ as the policy gradient algorithm
for the standard reinforcement learning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14127</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14127</id><submitter>Michael Gimelfarb Mr.</submitter><version version="v1"><date>Fri, 28 May 2021 22:22:03 GMT</date><size>3114kb</size><source_type>D</source_type></version><title>Risk-Aware Transfer in Reinforcement Learning using Successor Features</title><authors>Michael Gimelfarb, Andr\'e Barreto, Scott Sanner, Chi-Guhn Lee</authors><categories>cs.LG cs.AI cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sample efficiency and risk-awareness are central to the development of
practical reinforcement learning (RL) for complex decision-making. The former
can be addressed by transfer learning and the latter by optimizing some utility
function of the return. However, the problem of transferring skills in a
risk-aware manner is not well-understood. In this paper, we address the problem
of risk-aware policy transfer between tasks in a common domain that differ only
in their reward functions, in which risk is measured by the variance of reward
streams. Our approach begins by extending the idea of generalized policy
improvement to maximize entropic utilities, thus extending policy improvement
via dynamic programming to sets of policies and levels of risk-aversion. Next,
we extend the idea of successor features (SF), a value function representation
that decouples the environment dynamics from the rewards, to capture the
variance of returns. Our resulting risk-aware successor features (RaSF)
integrate seamlessly within the RL framework, inherit the superior task
generalization ability of SFs, and incorporate risk-awareness into the
decision-making. Experiments on a discrete navigation domain and control of a
simulated robotic arm demonstrate the ability of RaSFs to outperform
alternative methods including SFs, when taking the risk of the learned policies
into account.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14130</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14130</id><submitter>Doga Gunduzalp</submitter><version version="v1"><date>Fri, 28 May 2021 22:37:50 GMT</date><size>862kb</size><source_type>D</source_type></version><title>3D U-NetR: Low Dose Computed Tomography Reconstruction via Deep Learning
  and 3 Dimensional Convolutions</title><authors>Doga Gunduzalp, Batuhan Cengiz, Mehmet Ozan Unal, Isa Yildirim</authors><categories>cs.CV eess.IV</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduced a novel deep learning based reconstruction
technique using the correlations of all 3 dimensions with each other by taking
into account the correlation between 2-dimensional low-dose CT images. Sparse
or noisy sinograms are back projected to the image domain with FBP operation,
then denoising process is applied with a U-Net like 3 dimensional network
called 3D U-NetR. Proposed network is trained with synthetic and real chest CT
images, and 2D U-Net is also trained with the same dataset to prove the
importance of the 3rd dimension. Proposed network shows better quantitative
performance on SSIM and PSNR. More importantly, 3D U-NetR captures medically
critical visual details that cannot be visualized by 2D network.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14134</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14134</id><submitter>Sudarshan Lamkhede</submitter><version version="v1"><date>Fri, 28 May 2021 23:01:30 GMT</date><size>2551kb</size><source_type>D</source_type></version><title>Recommendations and Results Organization in Netflix Search</title><authors>Sudarshan Lamkhede and Christoph Kofler</authors><categories>cs.IR cs.HC</categories><comments>Extended abstract submitted to RecSys 2021 Industry Track. 5 pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Personalized recommendations on the Netflix Homepage are based on a user's
viewing habits and the behavior of similar users. These recommendations,
organized for efficient browsing, enable users to discover the next great video
to watch and enjoy without additional input or an explicit expression of their
intents or goals. The Netflix Search experience, on the other hand, allows
users to take active control of discovering new videos by explicitly expressing
their entertainment needs via search queries.
  In this talk, we discuss the importance of producing search results that go
beyond traditional keyword-matches to effectively satisfy users' search needs
in the Netflix entertainment setting. Motivated by users' various search
intents, we highlight the necessity to improve Search by applying approaches
that have historically powered the Homepage. Specifically, we discuss our
approach to leverage recommendations in the context of Search and to
effectively organize search results to provide a product experience that
meaningfully adds value for our users.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14135</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14135</id><submitter>Kevin Chu</submitter><version version="v1"><date>Fri, 28 May 2021 23:02:14 GMT</date><size>1344kb</size></version><title>Phoneme-Based Ratio Mask Estimation for Reverberant Speech Enhancement
  in Cochlear Implant Processors</title><authors>Kevin M. Chu, Leslie M. Collins, and Boyla O. Mainsah</authors><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cochlear implant (CI) users have considerable difficulty in understanding
speech in reverberant listening environments. Time-frequency (T-F) masking is a
common technique that aims to improve speech intelligibility by multiplying
reverberant speech by a matrix of gain values to suppress T-F bins dominated by
reverberation. Recently proposed mask estimation algorithms leverage machine
learning approaches to distinguish between target speech and reverberant
reflections. However, the spectro-temporal structure of speech is highly
variable and dependent on the underlying phoneme. One way to potentially
overcome this variability is to leverage explicit knowledge of phonemic
information during mask estimation. This study proposes a phoneme-based mask
estimation algorithm, where separate mask estimation models are trained for
each phoneme. Sentence recognition tests were conducted in normal hearing
listeners to determine whether a phoneme-based mask estimation algorithm is
beneficial in the ideal scenario where perfect knowledge of the phoneme is
available. The results showed that the phoneme-based masks improved the
intelligibility of vocoded speech when compared to conventional
phoneme-independent masks. The results suggest that a phoneme-based speech
enhancement strategy may potentially benefit CI users in reverberant listening
environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14136</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14136</id><submitter>Felicien Ihirwe</submitter><version version="v1"><date>Fri, 28 May 2021 23:03:21 GMT</date><size>2579kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 09:50:41 GMT</date><size>2575kb</size><source_type>D</source_type></version><title>Towards a modeling and analysis environment for industrial IoT systems</title><authors>Felicien Ihirwe, Davide Di Ruscio, Silvia Mazzini, Alfonso Pierantonio</authors><categories>cs.SE cs.PL</categories><comments>7 figures, 10 pages</comments><acm-class>D.2.2; D.2.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The development of Industrial Internet of Things systems (IIoT) requires
tools robust enough to cope with the complexity and heterogeneity of such
systems, which are supposed to work in safety-critical conditions. The
availability of methodologies to support early analysis, verification, and
validation is still an open issue in the research community. The early
real-time schedulability analysis can help quantify to what extent the desired
system's timing performance can eventually be achieved. In this paper, we
present CHESSIoT, a model-driven environment to support the design and analysis
of industrial IoT systems. CHESSIoT follows a multi-view, component-based
modelling approach with a comprehensive way to perform event-based modelling on
system components for code generation purposes employing an intermediate
ThingML model. To showcase the capability of the extension, we have designed
and analysed an Industrial real-time safety use case.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14137</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14137</id><submitter>Gabriel Ullmann</submitter><version version="v1"><date>Fri, 28 May 2021 23:05:35 GMT</date><size>279kb</size><source_type>D</source_type></version><title>Aspects of High-Rated Games</title><authors>Gabriel Ullmann, Cristiano Politowski, Fabio Petrillo, Yann-G\&quot;ael
  Gu\'eh\'eneuc</authors><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the video game market grows larger, it becomes harder to stand out from
the crowd. Launching a successful game involves different aspects. But what are
they? In this paper, we investigate some aspects of the high-rated games from a
dataset of 200 projects. The results show that the none of the aspects of this
study have a strong relationship with the game's success. A further analysis on
the high-rated games shows that team, technical, and game-design aspects should
be the main focus of the game developers.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14138</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14138</id><submitter>Hao Tang</submitter><version version="v1"><date>Fri, 28 May 2021 23:06:26 GMT</date><size>5147kb</size><source_type>D</source_type></version><title>Transformer-Based Source-Free Domain Adaptation</title><authors>Guanglei Yang, Hao Tang, Zhun Zhong, Mingli Ding, Ling Shao, Nicu
  Sebe, Elisa Ricci</authors><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the task of source-free domain adaptation (SFDA),
where the source data are not available during target adaptation. Previous
works on SFDA mainly focus on aligning the cross-domain distributions. However,
they ignore the generalization ability of the pretrained source model, which
largely influences the initial target outputs that are vital to the target
adaptation stage. To address this, we make the interesting observation that the
model accuracy is highly correlated with whether or not attention is focused on
the objects in an image. To this end, we propose a generic and effective
framework based on Transformer, named TransDA, for learning a generalized model
for SFDA. Specifically, we apply the Transformer as the attention module and
inject it into a convolutional network. By doing so, the model is encouraged to
turn attention towards the object regions, which can effectively improve the
model's generalization ability on the target domains. Moreover, a novel
self-supervised knowledge distillation approach is proposed to adapt the
Transformer with target pseudo-labels, thus further encouraging the network to
focus on the object regions. Experiments on three domain adaptation tasks,
including closed-set, partial-set, and open-set adaption, demonstrate that
TransDA can greatly improve the adaptation accuracy and produce
state-of-the-art results. The source code and trained models are available at
https://github.com/ygjwd12345/TransDA.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14139</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14139</id><submitter>Sergey Ketkov</submitter><version version="v1"><date>Fri, 28 May 2021 23:17:35 GMT</date><size>744kb</size><source_type>D</source_type></version><title>Data-Driven Combinatorial Optimization with Incomplete Information: a
  Distributionally Robust Optimization Approach</title><authors>Sergey S. Ketkov, Andrei S. Shilov, Oleg A. Prokopyev</authors><categories>math.OC cs.LG stat.AP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this study we analyze linear combinatorial optimization problems where the
cost vector is not known a priori, but is only observable through a finite data
set. In contrast to the related studies, we presume that the number of
observations with respect to particular components of the cost vector may vary.
The goal is to find a procedure that transforms the data set into an estimate
of the expected value of the objective function (which is referred to as a
prediction rule) and a procedure that retrieves a candidate decision (which is
referred to as a prescription rule). We aim at finding the least conservative
prediction and prescription rules, which satisfy some specified asymptotic
guarantees. We demonstrate that the resulting vector optimization problems
admit a weakly optimal solution, which can be obtained by solving a particular
distributionally robust optimization problem. Specifically, the decision-maker
may optimize the worst-case expected loss across all probability distributions
with given component-wise relative entropy distances from the empirical
marginal distributions. Finally, we perform numerical experiments to analyze
the out-of-sample performance of the proposed solution approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14141</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14141</id><submitter>Alek Dimitriev</submitter><version version="v1"><date>Fri, 28 May 2021 23:19:54 GMT</date><size>16000kb</size><source_type>D</source_type></version><title>ARMS: Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables</title><authors>Alek Dimitriev and Mingyuan Zhou</authors><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the gradients for binary variables is a task that arises
frequently in various domains, such as training discrete latent variable
models. What has been commonly used is a REINFORCE based Monte Carlo estimation
method that uses either independent samples or pairs of negatively correlated
samples. To better utilize more than two samples, we propose ARMS, an
Antithetic REINFORCE-based Multi-Sample gradient estimator. ARMS uses a copula
to generate any number of mutually antithetic samples. It is unbiased, has low
variance, and generalizes both DisARM, which we show to be ARMS with two
samples, and the leave-one-out REINFORCE (LOORF) estimator, which is ARMS with
uncorrelated samples. We evaluate ARMS on several datasets for training
generative models, and our experimental results show that it outperforms
competing methods. We also develop a version of ARMS for optimizing the
multi-sample variational bound, and show that it outperforms both VIMCO and
DisARM. The code is publicly available.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14143</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14143</id><submitter>Alexander Stolyar</submitter><version version="v1"><date>Fri, 28 May 2021 23:26:03 GMT</date><size>48kb</size></version><title>Parallel server systems with cancel-on-completion redundancy</title><authors>Alexander Stolyar</authors><categories>math.PR cs.NI</categories><comments>37 pages</comments><msc-class>90B15, 60K25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a parallel server system with so-called cancel-on-completion
redundancy. There are $n$ servers and multiple job classes $j$. An arriving
class $j$ job consists of $d_j$ components, placed on a randomly selected
subset of servers; the job service is complete as soon as $k_j$ components out
of $d_j$ complete their service, at which point the service of all remaining
$d_j-k_j$ components is canceled. The system is in general non-work-conserving
-- the average amount of new workload added to the system by an arriving class
$j$ job depends on the system state. This poses the main challenge for the
system analysis.
  The results of this paper concern both the system with fixed number of
servers $n$ and the mean-field asymptotic regime when $n\to\infty$ while each
job class arrival rate per server remains constant. The main question we
address for the asymptotic regime is whether the steady-state asymptotic
independence of server workloads holds. We prove that this property does hold
under certain conditions, including the important special case when job
components of each class $j$ are i.i.d. with an increasing-hazard-rate
distribution.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14144</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14144</id><submitter>Mario Ignacio Gonz\'alez MI-Gonzalez-Silva</submitter><version version="v1"><date>Fri, 28 May 2021 23:28:50 GMT</date><size>1578kb</size></version><title>A mechanism of Individualistic Indirect Reciprocity with internal and
  external dynamics</title><authors>Mario Ignacio Gonz\'alez Silva, Ricardo Armando Gonz\'alez Silva,
  H\'ector Alfonso Ju\'arez L\'opez and Antonio Aguilera Ontiveros</authors><categories>nlin.AO cs.CY</categories><comments>24 pages</comments><msc-class>I.6</msc-class><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The cooperation mechanism of indirect reciprocity has been studied by making
multiple variations of its parts. This research proposes a new variant of Nowak
and Sigmund model, focused on agents' attitude; it is called Individualistic
Indirect Reciprocity. In our model, an agent reinforces its strategy to the
extent to which it makes a profit. We also include conditions related to the
environment, visibility of agents, cooperation demand, and the attitude of an
agent to maintain his cooperation strategy. Using Agent-Based Model and a Data
Science method, we show on simulation results that the discriminatory stance of
the agents prevails in most cases. In general, cooperators only appear in
conditions with low visibility of reputation and a high degree of cooperation
demand. The results also show that when the reputation of others is unknown,
with a high obstinacy and high cooperation demand, a heterogeneous society is
obtained. The simulations show a wide diversity of scenarios, centralized,
polarized, and mixed societies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14146</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14146</id><submitter>Hongjing Zhang</submitter><version version="v1"><date>Fri, 28 May 2021 23:50:48 GMT</date><size>780kb</size><source_type>D</source_type></version><title>Deep Fair Discriminative Clustering</title><authors>Hongjing Zhang, Ian Davidson</authors><categories>cs.LG cs.CY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep clustering has the potential to learn a strong representation and hence
better clustering performance compared to traditional clustering methods such
as $k$-means and spectral clustering. However, this strong representation
learning ability may make the clustering unfair by discovering surrogates for
protected information which we empirically show in our experiments. In this
work, we study a general notion of group-level fairness for both binary and
multi-state protected status variables (PSVs). We begin by formulating the
group-level fairness problem as an integer linear programming formulation whose
totally unimodular constraint matrix means it can be efficiently solved via
linear programming. We then show how to inject this solver into a
discriminative deep clustering backbone and hence propose a refinement learning
algorithm to combine the clustering goal with the fairness objective to learn
fair clusters adaptively. Experimental results on real-world datasets
demonstrate that our model consistently outperforms state-of-the-art fair
clustering algorithms. Our framework shows promising results for novel
clustering tasks including flexible fairness constraints, multi-state PSVs and
predictive clustering.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14148</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14148</id><submitter>Kuniaki Saito</submitter><version version="v1"><date>Fri, 28 May 2021 23:57:15 GMT</date><size>523kb</size><source_type>D</source_type></version><title>OpenMatch: Open-set Consistency Regularization for Semi-supervised
  Learning with Outliers</title><authors>Kuniaki Saito, Donghyun Kim, Kate Saenko</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-supervised learning (SSL) is an effective means to leverage unlabeled
data to improve a model's performance. Typical SSL methods like FixMatch assume
that labeled and unlabeled data share the same label space. However, in
practice, unlabeled data can contain categories unseen in the labeled set,
i.e., outliers, which can significantly harm the performance of SSL algorithms.
To address this problem, we propose a novel Open-set Semi-Supervised Learning
(OSSL) approach called OpenMatch. Learning representations of inliers while
rejecting outliers is essential for the success of OSSL. To this end, OpenMatch
unifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers.
The OVA-classifier outputs the confidence score of a sample being an inlier,
providing a threshold to detect outliers. Another key contribution is an
open-set soft-consistency regularization loss, which enhances the smoothness of
the OVA-classifier with respect to input transformations and greatly improves
outlier detection. OpenMatch achieves state-of-the-art performance on three
datasets, and even outperforms a fully supervised model in detecting outliers
unseen in unlabeled data on CIFAR10.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14149</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14149</id><submitter>Nandini Ramanan</submitter><version version="v1"><date>Sat, 29 May 2021 00:01:08 GMT</date><size>255kb</size><source_type>D</source_type></version><title>Log2NS: Enhancing Deep Learning Based Analysis of Logs With Formal to
  Prevent Survivorship Bias</title><authors>Charanraj Thimmisetty, Praveen Tiwari, Didac Gil de la Iglesia,
  Nandini Ramanan, Marjorie Sayer, Viswesh Ananthakrishnan, and Claudionor
  Nunes Coelho Jr</authors><categories>cs.AI</categories><comments>10 pages, 5 tables, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Analysis of large observational data sets generated by a reactive system is a
common challenge in debugging system failures and determining their root cause.
One of the major problems is that these observational data suffer from
survivorship bias. Examples include analyzing traffic logs from networks, and
simulation logs from circuit design. In such applications, users want to detect
non-spurious correlations from observational data and obtain actionable
insights about them. In this paper, we introduce log to Neuro-symbolic
(Log2NS), a framework that combines probabilistic analysis from machine
learning (ML) techniques on observational data with certainties derived from
symbolic reasoning on an underlying formal model. We apply the proposed
framework to network traffic debugging by employing the following steps. To
detect patterns in network logs, we first generate global embedding vector
representations of entities such as IP addresses, ports, and applications.
Next, we represent large log flow entries as clusters that make it easier for
the user to visualize and detect interesting scenarios that will be further
analyzed. To generalize these patterns, Log2NS provides an ability to query
from static logs and correlation engines for positive instances, as well as
formal reasoning for negative and unseen instances. By combining the strengths
of deep learning and symbolic methods, Log2NS provides a very powerful
reasoning and debugging tool for log-based data. Empirical evaluations on a
real internal data set demonstrate the capabilities of Log2NS.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14150</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14150</id><submitter>Kun Qian</submitter><version version="v1"><date>Sat, 29 May 2021 00:09:06 GMT</date><size>9389kb</size><source_type>D</source_type></version><title>Annotation Inconsistency and Entity Bias in MultiWOZ</title><authors>Kun Qian, Ahmad Beirami, Zhouhan Lin, Ankita De, Alborz Geramifard,
  Zhou Yu, Chinnadhurai Sankar</authors><categories>cs.CL</categories><comments>Accepted by SIGDIAL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MultiWOZ is one of the most popular multi-domain task-oriented dialog
datasets, containing 10K+ annotated dialogs covering eight domains. It has been
widely accepted as a benchmark for various dialog tasks, e.g., dialog state
tracking (DST), natural language generation (NLG), and end-to-end (E2E) dialog
modeling. In this work, we identify an overlooked issue with dialog state
annotation inconsistencies in the dataset, where a slot type is tagged
inconsistently across similar dialogs leading to confusion for DST modeling. We
propose an automated correction for this issue, which is present in a whopping
70% of the dialogs. Additionally, we notice that there is significant entity
bias in the dataset (e.g., &quot;cambridge&quot; appears in 50% of the destination cities
in the train domain). The entity bias can potentially lead to named entity
memorization in generative models, which may go unnoticed as the test set
suffers from a similar entity bias as well. We release a new test set with all
entities replaced with unseen entities. Finally, we benchmark joint goal
accuracy (JGA) of the state-of-the-art DST baselines on these modified versions
of the data. Our experiments show that the annotation inconsistency corrections
lead to 7-10% improvement in JGA. On the other hand, we observe a 29% drop in
JGA when models are evaluated on the new test set with unseen entities.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14151</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14151</id><submitter>Farah Ferdaus</submitter><version version="v1"><date>Sat, 29 May 2021 00:11:00 GMT</date><size>3822kb</size><source_type>D</source_type></version><title>Approximate MRAM: High-performance and Power-efficient Computing with
  MRAM Chips for Error-tolerant Applications</title><authors>Farah Ferdaus, B. M. S. Bahar Talukder, and Md Tauhidur Rahman</authors><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate computing (AC) leverages the inherent error resilience and is
used in many big-data applications from various domains such as multimedia,
computer vision, signal processing, and machine learning to improve systems
performance and power consumption. Like many other approximate circuits and
algorithms, the memory subsystem can also be used to enhance performance and
save power significantly. This paper proposes an efficient and effective
systematic methodology to construct an approximate non-volatile
magneto-resistive RAM (MRAM) framework using consumer-off-the-shelf (COTS) MRAM
chips. In the proposed scheme, an extensive experimental characterization of
memory errors is performed by manipulating the write latency of MRAM chips
which exploits the inherent (intrinsic/extrinsic process variation) stochastic
switching behavior of magnetic tunnel junctions (MTJs). The experimental
results and error-resilient image application reveal that the proposed AC
framework provides a significant performance improvement and demonstrates a
maximum reduction in MRAM write current of ~66% on average with negligible or
no loss in output quality.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14152</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14152</id><submitter>Keenan Burnett</submitter><version version="v1"><date>Sat, 29 May 2021 00:11:25 GMT</date><size>3431kb</size><source_type>D</source_type></version><title>Radar Odometry Combining Probabilistic Estimation and Unsupervised
  Feature Learning</title><authors>Keenan Burnett, David J. Yoon, Angela P. Schoellig, Timothy D. Barfoot</authors><categories>cs.RO</categories><comments>Accepted to Robotics Science and Systems 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a radar odometry method that combines probabilistic
trajectory estimation and deep learned features without needing groundtruth
pose information. The feature network is trained unsupervised, using only the
on-board radar data. With its theoretical foundation based on a data likelihood
objective, our method leverages a deep network for processing rich radar data,
and a non-differentiable classic estimator for probabilistic inference. We
provide extensive experimental results on both the publicly available Oxford
Radar RobotCar Dataset and an additional 100 km of driving collected in an
urban setting. Our sliding-window implementation of radar odometry outperforms
existing hand-crafted methods and approaches the current state of the art
without requiring a groundtruth trajectory for training. We also demonstrate
the effectiveness of radar odometry under adverse weather conditions. Code for
this project can be found at: https://github.com/utiasASRL/hero_radar_odometry
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14154</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14154</id><submitter>Vagan Terziyan</submitter><version version="v1"><date>Sat, 29 May 2021 00:16:45 GMT</date><size>414kb</size></version><title>How the University Portal Inspired Changes in the Academic Assessment
  Culture</title><authors>Valerii Semenets, Svitlana Gryshko, Mariia Golovianko, Oleksandr
  Shevchenko, Liudmyla Titova, Olena Kaikova, Vagan Terziyan, Timo Tiihonen</authors><categories>cs.CY</categories><comments>4 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Information retrieval (IR) is known facilitator of changes ongoing in human
society and vice versa. This is due to the fact that IR is a key component of
the digital ecosystems, where both information providers and information
consumers collaboratively address their problems with the use of technologies.
Organization and design of such ecosystems drives particular social impact for
all the players involved. In this paper, we study the impact made by a
particular IR ecosystem (semantic portal) used for management of academic
information resources and processes within the Ukrainian higher education. We
show how this portal is changing a collective mindset of the academic community
of its users. We argue that such impact becomes possible due to specific
organization of the ecosystem, where all the information resources, IR services
and related analytics (search, assessment, ranking, etc.) and IR users inhabit
the same semantic space under umbrella of the corresponding ontologies.
Personal values and preferences of the users configure on-the-fly the
corresponding IR analytics and enable personalized value-driven IR services,
making everyone feel involved into the organizational decision-making
processes. Four years of active use of this portal in university environment
has been reported and related impact is evaluated in this study.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14155</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14155</id><submitter>Mirjeta Pasha</submitter><version version="v1"><date>Sat, 29 May 2021 00:20:25 GMT</date><size>3120kb</size><source_type>D</source_type></version><title>An $\ell_p$ Variable Projection Method for Large-Scale Separable
  Nonlinear Inverse Problems</title><authors>Malena Espanol and Mirjeta Pasha</authors><categories>math.NA cs.NA</categories><comments>23 pages, 9 figures</comments><msc-class>65F22, 65K10, 65R32</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The variable projection (VarPro) method is an efficient method to solve
separable nonlinear least squares problems. In this paper, we propose a
modified VarPro for large-scale separable nonlinear inverse problems that
promotes edge-preserving and sparsity properties on the desired solution and
enhances the convergence of the parameters that define the forward problem. We
adopt a majorization minimization method that relies on constructing a
quadratic tangent majorant to approximate a general $\ell_p$ regularized
problem by an $\ell_2$ regularized problem that can be solved by the aid of
generalized Krylov subspace methods at a relatively low cost compared to the
original unprojected problem. In addition, we can use more potential general
regularizers including total variation (TV), framelet, and wavelets operators.
The regularization parameter can be defined automatically at each iteration by
means of generalized cross validation. Numerical examples on large-scale
two-dimensional imaging problems arising from blind deconvolution are used to
highlight the performance of the proposed approach in both quality of the
reconstructed image as well as the reconstructed forward operator.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14156</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14156</id><submitter>Kaustubh Shivdikar</submitter><version version="v1"><date>Sat, 29 May 2021 00:22:50 GMT</date><size>1062kb</size><source_type>D</source_type></version><title>SMASH: Sparse Matrix Atomic Scratchpad Hashing</title><authors>Kaustubh Shivdikar</authors><categories>cs.DC cs.AR cs.LG</categories><doi>10.13140/RG.2.2.17515.87840</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sparse matrices, more specifically SpGEMM kernels, are commonly found in a
wide range of applications, spanning graph-based path-finding to machine
learning algorithms (e.g., neural networks). A particular challenge in
implementing SpGEMM kernels has been the pressure placed on DRAM memory. One
approach to tackle this problem is to use an inner product method for the
SpGEMM kernel implementation. While the inner product produces fewer
intermediate results, it can end up saturating the memory bandwidth, given the
high number of redundant fetches of the input matrix elements. Using an outer
product-based SpGEMM kernel can reduce redundant fetches, but at the cost of
increased overhead due to extra computation and memory accesses for
producing/managing partial products.
  In this thesis, we introduce a novel SpGEMM kernel implementation based on
the row-wise product approach. We leverage atomic instructions to merge
intermediate partial products as they are generated. The use of atomic
instructions eliminates the need to create partial product matrices.
  To evaluate our row-wise product approach, we map an optimized SpGEMM kernel
to a custom accelerator designed to accelerate graph-based applications. The
targeted accelerator is an experimental system named PIUMA, being developed by
Intel. PIUMA provides several attractive features, including fast context
switching, user-configurable caches, globally addressable memory, non-coherent
caches, and asynchronous pipelines. We tailor our SpGEMM kernel to exploit many
of the features of the PIUMA fabric.
  This thesis compares our SpGEMM implementation against prior solutions, all
mapped to the PIUMA framework. We briefly describe some of the PIUMA
architecture features and then delve into the details of our optimized SpGEMM
kernel. Our SpGEMM kernel can achieve 9.4x speedup as compared to competing
approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14157</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14157</id><submitter>Tevfik Kosar</submitter><version version="v1"><date>Sat, 29 May 2021 00:27:27 GMT</date><size>7913kb</size><source_type>D</source_type></version><title>SMURF: Efficient and Scalable Metadata Access for Distributed
  Applications</title><authors>Bing Zhang and Tevfik Kosar</authors><categories>cs.DC cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In parallel with big data processing and analysis dominating the usage of
distributed and cloud infrastructures, the demand for distributed metadata
access and transfer has increased. In many application domains, the volume of
data generated exceeds petabytes, while the corresponding metadata amounts to
terabytes or even more. This paper proposes a novel solution for efficient and
scalable metadata access for distributed applications across wide-area
networks, dubbed SMURF. Our solution combines novel pipelining and concurrent
transfer mechanisms with reliability, provides distributed continuum caching
and prefetching strategies to sidestep fetching latency, and achieves scalable
and high-performance metadata fetch/prefetch services in the cloud. We also
study the phenomenon of semantic locality in real trace logs, which is not well
utilized in metadata access prediction. We implement a novel prefetch predictor
based on this observation and compare it with three existing state-of-the-art
prefetch schemes on Yahoo! Hadoop audit traces. By effectively caching and
prefetching metadata based on the access patterns, our continuum caching and
prefetching mechanism significantly improves local cache hit rate and reduces
the average fetching latency. We replayed approximately 20 Million metadata
access operations from real audit traces, in which our system achieved 90%
accuracy during prefetch prediction and reduced the average fetch latency by
50% compared to the state-of-the-art mechanisms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14158</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14158</id><submitter>Zhe Wang</submitter><version version="v1"><date>Sat, 29 May 2021 00:29:40 GMT</date><size>2318kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 15:14:27 GMT</date><size>2318kb</size><source_type>D</source_type></version><title>Unsupervised Action Segmentation with Self-supervised Feature Learning
  and Co-occurrence Parsing</title><authors>Zhe Wang, Hao Chen, Xinyu Li, Chunhui Liu, Yuanjun Xiong, Joseph
  Tighe, Charless Fowlkes</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Temporal action segmentation is a task to classify each frame in the video
with an action label. However, it is quite expensive to annotate every frame in
a large corpus of videos to construct a comprehensive supervised training
dataset. Thus in this work we explore a self-supervised method that operates on
a corpus of unlabeled videos and predicts a likely set of temporal segments
across the videos. To do this we leverage self-supervised video classification
approaches to perform unsupervised feature extraction. On top of these features
we develop CAP, a novel co-occurrence action parsing algorithm that can not
only capture the correlation among sub-actions underlying the structure of
activities, but also estimate the temporal trajectory of the sub-actions in an
accurate and general way. We evaluate on both classic datasets (Breakfast,
50Salads) and emerging fine-grained action datasets (FineGym) with more complex
activity structures and similar sub-actions. Results show that our method
achieves state-of-the-art performance on all three datasets with up to 22\%
improvement, and can even outperform some weakly-supervised approaches,
demonstrating its effectiveness and generalizability.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14159</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14159</id><submitter>Ben Chugg</submitter><version version="v1"><date>Sat, 29 May 2021 00:33:18 GMT</date><size>1741kb</size><source_type>D</source_type></version><title>Enhancing Environmental Enforcement with Near Real-Time Monitoring:
  Likelihood-Based Detection of Structural Expansion of Intensive Livestock
  Farms</title><authors>Ben Chugg, Brandon Anderson, Seiji Eicher, Sandy Lee, Daniel E. Ho</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Environmental enforcement has historically relied on physical,
resource-intensive, and infrequent inspections. Advances in remote sensing and
computer vision have the potential to augment compliance monitoring, by
providing early warning signals of permit violations. We demonstrate a process
for rapid identification of significant structural expansion using satellite
imagery and focusing on Concentrated Animal Feeding Operations (CAFOs) as a
test case. Unpermitted expansion has been a particular challenge with CAFOs,
which pose significant health and environmental risks. Using a new hand-labeled
dataset of 175,736 images of 1,513 CAFOs, we combine state-of-the-art building
segmentation with a likelihood-based change-point detection model to provide a
robust signal of building expansion (AUC = 0.80). A major advantage of this
approach is that it is able to work with high-cadence (daily to weekly), but
lower resolution (3m/pixel), satellite imagery. It is also highly generalizable
and thus provides a near real-time monitoring tool to prioritize enforcement
resources to other settings where unpermitted construction poses environmental
risk, e.g. zoning, habitat modification, or wetland protection.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14161</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14161</id><submitter>Karen Montano-Martinez</submitter><version version="v1"><date>Sat, 29 May 2021 00:37:22 GMT</date><size>1334kb</size></version><title>Detailed Primary and Secondary Distribution System Model Enhancement
  Using AMI Data</title><authors>Karen Montano-Martinez, Student Member, IEEE, Sushrut Thakar, Student
  Member, IEEE, Shanshan Ma, Member, IEEE, Zahra Soltani, Student Member, IEEE,
  Vijay Vittal, Life Fellow, IEEE, Mojdeh Khorsand, Member, IEEE, Raja Ayyanar,
  Senior Member, IEEE, and Cynthia Rojas, Member, IEEE</authors><categories>eess.SY cs.SY math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reliable and accurate distribution system modeling, including the secondary
network, is essential in examining distribution system performance with high
penetration of distributed energy resources (DERs). This paper presents a
highly automated, novel method to enhance the accuracy of utility distribution
feeder models to capture their performance by matching simulation results with
corresponding field measurements. The method is demonstrated using an actual
feeder from an electrical utility with high penetration of DERs. The method
proposed uses advanced metering infrastructure (AMI) voltage and derived active
power measurements at the customer level, and data acquisition systems (DAS)
measurements at the feeder-head, in conjunction with an AC optimal power flow
(ACOPF) to estimate customer active and reactive power consumption over a time
horizon, while accounting for unmetered loads. Additionally, the method
proposed estimates both voltage magnitude and angle for each phase at the
unbalanced distribution substation. Furthermore, the accuracy of the method
developed is verified by comparing the time-series power flow results obtained
from the enhancement algorithm with OpenDSS results. The proposed approach
seamlessly manages the data available from the optimization procedure through
the final model verification automatically.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14162</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14162</id><submitter>Zhibo Zhang</submitter><version version="v1"><date>Sat, 29 May 2021 00:42:42 GMT</date><size>1483kb</size><source_type>D</source_type></version><title>EDDA: Explanation-driven Data Augmentation to Improve Model and
  Explanation Alignment</title><authors>Ruiwen Li (co-first author), Zhibo Zhang (co-first author), Jiani Li,
  Scott Sanner, Jongseong Jang, Yeonjeong Jeong, Dongsub Shim</authors><categories>cs.LG cs.AI cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Recent years have seen the introduction of a range of methods for post-hoc
explainability of image classifier predictions. However, these post-hoc
explanations may not always align perfectly with classifier predictions, which
poses a significant challenge when attempting to debug models based on such
explanations. To this end, we seek a methodology that can improve alignment
between model predictions and explanation method that is both agnostic to the
model and explanation classes and which does not require ground truth
explanations. We achieve this through a novel explanation-driven data
augmentation (EDDA) method that augments the training data with occlusions of
existing data stemming from model-explanations; this is based on the simple
motivating principle that occluding salient regions for the model prediction
should decrease the model confidence in the prediction, while occluding
non-salient regions should not change the prediction -- if the model and
explainer are aligned. To verify that this augmentation method improves model
and explainer alignment, we evaluate the methodology on a variety of datasets,
image classification models, and explanation methods. We verify in all cases
that our explanation-driven data augmentation method improves alignment of the
model and explanation in comparison to no data augmentation and non-explanation
driven data augmentation methods. In conclusion, this approach provides a novel
model- and explainer-agnostic methodology for improving alignment between model
predictions and explanations, which we see as a critical step forward for
practical deployment and debugging of image classification models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14163</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14163</id><submitter>Sinho Chewi</submitter><version version="v1"><date>Sat, 29 May 2021 00:51:17 GMT</date><size>59kb</size></version><title>The query complexity of sampling from strongly log-concave distributions
  in one dimension</title><authors>Sinho Chewi, Patrik Gerber, Chen Lu, Thibaut Le Gouic, Philippe
  Rigollet</authors><categories>math.ST cs.LG stat.TH</categories><comments>19 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the first tight lower bound of $\Omega(\log\log\kappa)$ on the
query complexity of sampling from the class of strongly log-concave and
log-smooth distributions with condition number $\kappa$ in one dimension.
Whereas existing guarantees for MCMC-based algorithms scale polynomially in
$\kappa$, we introduce a novel algorithm based on rejection sampling that
closes this doubly exponential gap.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14166</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14166</id><submitter>Sinho Chewi</submitter><version version="v1"><date>Sat, 29 May 2021 01:00:42 GMT</date><size>184kb</size><source_type>D</source_type></version><title>Rejection sampling from shape-constrained distributions in sublinear
  time</title><authors>Sinho Chewi, Patrik Gerber, Chen Lu, Thibaut Le Gouic, Philippe
  Rigollet</authors><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>23 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of generating exact samples from a target distribution,
known up to normalization, over a finite alphabet. The classical algorithm for
this task is rejection sampling, and although it has been used in practice for
decades, there is surprisingly little study of its fundamental limitations. In
this work, we study the query complexity of rejection sampling in a minimax
framework for various classes of discrete distributions. Our results provide
new algorithms for sampling whose complexity scales sublinearly with the
alphabet size. When applied to adversarial bandits, we show that a slight
modification of the Exp3 algorithm reduces the per-iteration complexity from
$\mathcal O(K)$ to $\mathcal O(\log^2 K)$, where $K$ is the number of arms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14167</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14167</id><submitter>Zeming Chen</submitter><version version="v1"><date>Sat, 29 May 2021 01:02:40 GMT</date><size>7464kb</size><source_type>D</source_type></version><title>NeuralLog: Natural Language Inference with Joint Neural and Logical
  Reasoning</title><authors>Zeming Chen, Qiyue Gao, Lawrence S. Moss</authors><categories>cs.CL cs.AI</categories><comments>8 pages, 4 figures, The 10th Joint Conference on Lexical and
  Computational Semantics (*SEM2021) @ ACL2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep learning (DL) based language models achieve high performance on various
benchmarks for Natural Language Inference (NLI). And at this time, symbolic
approaches to NLI are receiving less attention. Both approaches (symbolic and
DL) have their advantages and weaknesses. However, currently, no method
combines them in a system to solve the task of NLI. To merge symbolic and deep
learning methods, we propose an inference framework called NeuralLog, which
utilizes both a monotonicity-based logical inference engine and a neural
network language model for phrase alignment. Our framework models the NLI task
as a classic search problem and uses the beam search algorithm to search for
optimal inference paths. Experiments show that our joint logic and neural
inference system improves accuracy on the NLI task and can achieve state-of-art
accuracy on the SICK and MED datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14170</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14170</id><submitter>Peiyuan Liu</submitter><version version="v1"><date>Sat, 29 May 2021 01:21:07 GMT</date><size>4405kb</size><source_type>D</source_type></version><title>Towards a Rigorous Statistical Analysis of Empirical Password Datasets</title><authors>Jeremiah Blocki and Peiyuan Liu</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the following problem: given $N$ independent
samples from an unknown distribution $\mathcal{P}$ over passwords $pwd_1,pwd_2,
\ldots$ can we generate high confidence upper/lower bounds on the guessing
curve $\lambda_G \doteq \sum_{i=1}^G p_i$ where $p_i=\Pr[pwd_i]$ and the
passwords are ordered such that $p_i \geq p_{i+1}$. Intuitively, $\lambda_G$
represents the probability that an attacker who knows the distribution
$\mathcal{P}$ can guess a random password $pwd \leftarrow \mathcal{P}$ within
$G$ guesses. Understanding how $\lambda_G$ increases with the number of guesses
$G$ can help quantify the damage of a password cracking attack and inform
password policies. Despite an abundance of large (breached) password datasets
upper/lower bounding $\lambda_G$ remains a challenging problem. We introduce
several statistical techniques to derive tighter upper/lower bounds on the
guessing curve $\lambda_G$ which hold with high confidence. We apply our
techniques to analyze $9$ large password datasets finding that our new lower
bounds dramatically improve upon prior work. Our empirical analysis shows that
even state-of-the-art password cracking models are significantly less guess
efficient than an attacker who knows the distribution. When $G$ is not too
large we find that our upper/lower bounds on $\lambda_G$ are both very close to
the empirical distribution which justifies the use of the empirical
distribution in settings where $G$ is not too large i.e., $G \ll N$ closely
approximates $\lambda_G$. The analysis also highlights regions of the curve
where we can, with high confidence, conclude that the empirical distribution
significantly overestimates $\lambda_G$. Our new statistical techniques yield
substantially tighter upper/lower bounds on $\lambda_G$ though there are still
regions of the curve where the best upper/lower bounds diverge significantly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14171</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14171</id><submitter>Weishen Pan</submitter><version version="v1"><date>Sat, 29 May 2021 01:44:12 GMT</date><size>736kb</size><source_type>D</source_type></version><title>The Definitions of Interpretability and Learning of Interpretable Models</title><authors>Weishen Pan, Changshui Zhang</authors><categories>cs.LG cs.HC</categories><comments>18 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As machine learning algorithms getting adopted in an ever-increasing number
of applications, interpretation has emerged as a crucial desideratum. In this
paper, we propose a mathematical definition for the human-interpretable model.
In particular, we define interpretability between two information process
systems. If a prediction model is interpretable by a human recognition system
based on the above interpretability definition, the prediction model is defined
as a completely human-interpretable model. We further design a practical
framework to train a completely human-interpretable model by user interactions.
Experiments on image datasets show the advantages of our proposed model in two
aspects: 1) The completely human-interpretable model can provide an entire
decision-making process that is human-understandable; 2) The completely
human-interpretable model is more robust against adversarial attacks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14172</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14172</id><submitter>Suyun Liu</submitter><version version="v1"><date>Sat, 29 May 2021 01:47:15 GMT</date><size>828kb</size><source_type>D</source_type></version><title>A Stochastic Alternating Balance $k$-Means Algorithm for Fair Clustering</title><authors>Suyun Liu, Luis Nunes Vicente</authors><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the application of data clustering to human-centric decision-making
systems, such as loan applications and advertisement recommendations, the
clustering outcome might discriminate against people across different
demographic groups, leading to unfairness. A natural conflict occurs between
the cost of clustering (in terms of distance to cluster centers) and the
balance representation of all demographic groups across the clusters, leading
to a bi-objective optimization problem that is nonconvex and nonsmooth. To
determine the complete trade-off between these two competing goals, we design a
novel stochastic alternating balance fair $k$-means (SAfairKM) algorithm, which
consists of alternating classical mini-batch $k$-means updates and group swap
updates. The number of $k$-means updates and the number of swap updates
essentially parameterize the weight put on optimizing each objective function.
Our numerical experiments show that the proposed SAfairKM algorithm is robust
and computationally efficient in constructing well-spread and high-quality
Pareto fronts both on synthetic and real datasets. Moreover, we propose a novel
companion algorithm, the stochastic alternating bi-objective gradient descent
(SA2GD) algorithm, which can handle a smooth version of the considered
bi-objective fair $k$-means problem, more amenable for analysis. A sublinear
convergence rate of $\mathcal{O}(1/T)$ is established under strong convexity
for the determination of a stationary point of a weighted sum of the two
functions parameterized by the number of steps or updates on each function.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14173</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14173</id><submitter>Aditya Jonnalagadda</submitter><version version="v1"><date>Sat, 29 May 2021 01:54:33 GMT</date><size>11214kb</size><source_type>D</source_type></version><title>FoveaTer: Foveated Transformer for Image Classification</title><authors>Aditya Jonnalagadda, William Wang, Miguel P. Eckstein</authors><categories>cs.CV</categories><comments>7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many animals and humans process the visual field with a varying spatial
resolution (foveated vision) and use peripheral processing to make eye
movements and point the fovea to acquire high-resolution information about
objects of interest. This architecture results in computationally efficient
rapid scene exploration. Recent progress in vision Transformers has brought
about new alternatives to the traditionally convolution-reliant computer vision
systems. However, these models do not explicitly model the foveated properties
of the visual system nor the interaction between eye movements and the
classification task. We propose foveated Transformer (FoveaTer) model, which
uses pooling regions and saccadic movements to perform object classification
tasks using a vision Transformer architecture. Our proposed model pools the
image features using squared pooling regions, an approximation to the
biologically-inspired foveated architecture, and uses the pooled features as an
input to a Transformer Network. It decides on the following fixation location
based on the attention assigned by the Transformer to various locations from
previous and present fixations. The model uses a confidence threshold to stop
scene exploration, allowing to dynamically allocate more fixation/computational
resources to more challenging images. We construct an ensemble model using our
proposed model and unfoveated model, achieving an accuracy 1.36% below the
unfoveated model with 22% computational savings. Finally, we demonstrate our
model's robustness against adversarial attacks, where it outperforms the
unfoveated model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14174</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14174</id><submitter>Shiwan Zhao Mr</submitter><version version="v1"><date>Sat, 29 May 2021 01:56:11 GMT</date><size>357kb</size><source_type>D</source_type></version><title>Multi-Label Few-Shot Learning for Aspect Category Detection</title><authors>Mengting Hu, Shiwan Zhao, Honglei Guo, Chao Xue, Hang Gao, Tiegang
  Gao, Renhong Cheng, Zhong Su</authors><categories>cs.CL</categories><comments>Accepted by ACL 2021 main conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aspect category detection (ACD) in sentiment analysis aims to identify the
aspect categories mentioned in a sentence. In this paper, we formulate ACD in
the few-shot learning scenario. However, existing few-shot learning approaches
mainly focus on single-label predictions. These methods can not work well for
the ACD task since a sentence may contain multiple aspect categories.
Therefore, we propose a multi-label few-shot learning method based on the
prototypical network. To alleviate the noise, we design two effective attention
mechanisms. The support-set attention aims to extract better prototypes by
removing irrelevant aspects. The query-set attention computes multiple
prototype-specific representations for each query instance, which are then used
to compute accurate distances with the corresponding prototypes. To achieve
multi-label inference, we further learn a dynamic threshold per instance by a
policy network. Extensive experimental results on three datasets demonstrate
that the proposed method significantly outperforms strong baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14176</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14176</id><submitter>Michael Overton</submitter><version version="v1"><date>Sat, 29 May 2021 02:07:15 GMT</date><size>2653kb</size></version><title>Local Minimizers of the Crouzeix Ratio: A Nonsmooth Optimization Case
  Study</title><authors>Michael L. Overton</authors><categories>math.OC cs.NA math.NA math.SP</categories><comments>19 pages, 6 figures</comments><msc-class>15A60, 49J52, 65F15</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Given a square matrix $A$ and a polynomial $p$, the Crouzeix ratio is the
norm of the polynomial on the field of values of $A$ divided by the 2-norm of
the matrix $p(A)$. Crouzeix's conjecture states that the globally minimal value
of the Crouzeix ratio is 0.5, regardless of the matrix order and polynomial
degree, and it is known that 1 is a frequently occurring locally minimal value.
Making use of a heavy-tailed distribution to initialize our optimization
computations, we demonstrate for the first time that the Crouzeix ratio has
many other locally minimal values between 0.5 and 1. Besides showing that the
same function values are repeatedly obtained for many different starting
points, we also verify that an approximate nonsmooth stationarity condition
holds at computed candidate local minimizers. We also find that the same
locally minimal values are often obtained both when optimizing over real
matrices and polynomials, and over complex matrices and polynomials. We argue
that minimization of the Crouzeix ratio makes a very interesting nonsmooth
optimization case study, illustrating among other things how effective the BFGS
method is for nonsmooth, nonconvex optimization. Our method for verifying
approximate nonsmooth stationarity is based on what may be a novel approach to
finding approximate subgradients of max functions on an interval. Our extensive
computations strongly support Crouzeix's conjecture: in all cases, we find that
the smallest locally minimal value is 0.5.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14177</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14177</id><submitter>Gang Wang</submitter><version version="v1"><date>Sat, 29 May 2021 02:09:18 GMT</date><size>16kb</size></version><title>The Jacobi sums over Galois rings of arbitrary characters and their
  applications in constructing asymptotically optimal codebooks</title><authors>Deng-Ming Xu, Chen Meng, Gang Wang, Fang-Wei Fu</authors><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:2001.04028</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Codebooks with small maximum cross-correlation amplitudes are used to
distinguish the signals from different users in CDMA communication systems. In
this paper, we first study the Jacobi sums over Galois rings of arbitrary
characteristics and completely determine their absolute values, which extends
the work in [34], where the Jacobi sums over Galois rings with characteristics
of a square of a prime number were discussed. Then, the deterministic
construction of codebooks based on the Jacobi sums over Galois rings of
arbitrary characteristics is presented, which produces asymptotically optimal
codebooks with respect to the Welch bound. In addition, the parameters of the
codebooks provided in this paper are new.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14179</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14179</id><submitter>Stephen MacDonell</submitter><version version="v1"><date>Sat, 29 May 2021 02:36:20 GMT</date><size>1170kb</size></version><title>Investigating the Significance of Bellwether Effect to Improve Software
  Effort Estimation</title><authors>Solomon Mensah, Jacky Keung, Stephen G. MacDonell, Michael F. Bosu and
  Kwabena E. Bennin</authors><categories>cs.SE</categories><comments>Conference paper, 13 papers, 3 figures, 9 tables. arXiv admin note:
  text overlap with arXiv:2105.07366</comments><journal-ref>Proceedings of the 2017 International Conference on Software
  Quality, Reliability and Security (QRS2017). Prague, Czech Republic, IEEE
  Computer Society Press, pp.340-351</journal-ref><doi>10.1109/QRS.2017.44</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bellwether effect refers to the existence of exemplary projects (called the
Bellwether) within a historical dataset to be used for improved prediction
performance. Recent studies have shown an implicit assumption of using recently
completed projects (referred to as moving window) for improved prediction
accuracy. In this paper, we investigate the Bellwether effect on software
effort estimation accuracy using moving windows. The existence of the
Bellwether was empirically proven based on six postulations. We apply
statistical stratification and Markov chain methodology to select the
Bellwether moving window. The resulting Bellwether moving window is used to
predict the software effort of a new project. Empirical results show that
Bellwether effect exist in chronological datasets with a set of exemplary and
recently completed projects representing the Bellwether moving window. Result
from this study has shown that the use of Bellwether moving window with the
Gaussian weighting function significantly improve the prediction accuracy.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14180</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14180</id><submitter>Pranay Manocha</submitter><version version="v1"><date>Sat, 29 May 2021 02:38:31 GMT</date><size>544kb</size><source_type>D</source_type></version><title>DPLM: A Deep Perceptual Spatial-Audio Localization Metric</title><authors>Pranay Manocha, Anurag Kumar, Buye Xu, Anjali Menon, Israel D. Gebru,
  Vamsi K. Ithapu, Paul Calamia</authors><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Subjective evaluations are critical for assessing the perceptual realism of
sounds in audio-synthesis driven technologies like augmented and virtual
reality. However, they are challenging to set up, fatiguing for users, and
expensive. In this work, we tackle the problem of capturing the perceptual
characteristics of localizing sounds. Specifically, we propose a framework for
building a general purpose quality metric to assess spatial localization
differences between two binaural recordings. We model localization similarity
by utilizing activation-level distances from deep networks trained for
direction of arrival (DOA) estimation. Our proposed metric (DPLM) outperforms
baseline metrics on correlation with subjective ratings on a diverse set of
datasets, even without the benefit of any human-labeled training data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14183</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14183</id><submitter>Katherine Cordwell</submitter><version version="v1"><date>Sat, 29 May 2021 02:49:41 GMT</date><size>533kb</size><source_type>D</source_type></version><title>Verified Quadratic Virtual Substitution for Real Arithmetic</title><authors>Matias Scharager, Katherine Cordwell, Stefan Mitsch, Andr\'e Platzer</authors><categories>cs.LO</categories><msc-class>03B35, 03C10, 68V20</msc-class><acm-class>F.3.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a formally verified quantifier elimination (QE) algorithm
for first-order real arithmetic by linear and quadratic virtual substitution
(VS) in Isabelle/HOL. The Tarski-Seidenberg theorem established that the
first-order logic of real arithmetic is decidable by QE. However, in practice,
QE algorithms are highly complicated and often combine multiple methods for
performance. VS is a practically successful method for QE that targets formulas
with low-degree polynomials. To our knowledge, this is the first work to
formalize VS for quadratic real arithmetic including inequalities. The proofs
necessitate various contributions to the existing multivariate polynomial
libraries in Isabelle/HOL, including a method for re-indexing variables in a
polynomial. Our framework is modularized and easily expandable (to facilitate
integrating future optimizations), and could serve as a basis for developing a
general-purpose QE algorithm. Further, as our formalization is designed with
practicality in mind, we export our development to SML and test the resulting
code on 378 benchmarks from the literature, comparing to Redlog, Z3,
Mathematica, and SMT-RAT.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14184</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14184</id><submitter>John Brennan Peace</submitter><version version="v1"><date>Sat, 29 May 2021 03:13:14 GMT</date><size>16089kb</size><source_type>D</source_type></version><title>E2ETag: An End-to-End Trainable Method for Generating and Detecting
  Fiducial Markers</title><authors>J. Brennan Peace, Eric Psota, Yanfeng Liu, Lance C. P\'erez</authors><categories>cs.CV</categories><comments>Accepted for publication at BMVC2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing fiducial markers solutions are designed for efficient detection and
decoding, however, their ability to stand out in natural environments is
difficult to infer from relatively limited analysis. Furthermore, worsening
performance in challenging image capture scenarios - such as poor exposure,
motion blur, and off-axis viewing - sheds light on their limitations. E2ETag
introduces an end-to-end trainable method for designing fiducial markers and a
complimentary detector. By introducing back-propagatable marker augmentation
and superimposition into training, the method learns to generate markers that
can be detected and classified in challenging real-world environments using a
fully convolutional detector network. Results demonstrate that E2ETag
outperforms existing methods in ideal conditions and performs much better in
the presence of motion blur, contrast fluctuations, noise, and off-axis viewing
angles. Source code and trained models are available at
https://github.com/jbpeace/E2ETag.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14185</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14185</id><submitter>Chunhua Shen</submitter><version version="v1"><date>Sat, 29 May 2021 03:24:59 GMT</date><size>928kb</size><source_type>D</source_type></version><title>FCPose: Fully Convolutional Multi-Person Pose Estimation with Dynamic
  Instance-Aware Convolutions</title><authors>Weian Mao and Zhi Tian and Xinlong Wang and Chunhua Shen</authors><categories>cs.CV</categories><comments>Accepted to Proc. IEEE Conf. Computer Vision and Pattern Recognition
  (CVPR) 2021. Code is at https://git.io/AdelaiDet</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose a fully convolutional multi-person pose estimation framework using
dynamic instance-aware convolutions, termed FCPose. Different from existing
methods, which often require ROI (Region of Interest) operations and/or
grouping post-processing, FCPose eliminates the ROIs and grouping
post-processing with dynamic instance-aware keypoint estimation heads. The
dynamic keypoint heads are conditioned on each instance (person), and can
encode the instance concept in the dynamically-generated weights of their
filters. Moreover, with the strong representation capacity of dynamic
convolutions, the keypoint heads in FCPose are designed to be very compact,
resulting in fast inference and making FCPose have almost constant inference
time regardless of the number of persons in the image. For example, on the COCO
dataset, a real-time version of FCPose using the DLA-34 backbone infers about
4.5x faster than Mask R-CNN (ResNet-101) (41.67 FPS vs. 9.26FPS) while
achieving improved performance. FCPose also offers better speed/accuracy
trade-off than other state-of-the-art methods. Our experiment results show that
FCPose is a simple yet effective multi-person pose estimation framework. Code
is available at: https://git.io/AdelaiDet
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14186</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14186</id><submitter>Florentin Smarandache</submitter><version version="v1"><date>Thu, 27 May 2021 00:11:12 GMT</date><size>355kb</size></version><title>Improved, Extended, and Total Impact Factor of a Journal</title><authors>Florentin Smarandache</authors><categories>cs.DL</categories><comments>5 pages</comments><msc-class>00A69</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this short paper we recall the (Garfield) Impact Factor of a Journal, we
improve and extend it, and eventually we present the Total Impact Factor that
reflects the most accurate impact factor.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14187</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14187</id><submitter>Martina Mammarella Dr.</submitter><version version="v1"><date>Tue, 25 May 2021 16:16:46 GMT</date><size>658kb</size></version><title>Prediction error quantification through probabilistic scaling</title><authors>Victor Mirasierra, Martina Mammarella, Fabrizio Dabbene, Teodoro Alamo</authors><categories>math.ST cs.SY eess.SY stat.TH</categories><comments>8 pages, 2 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we address the probabilistic error quantification of a general
class of prediction methods. We consider a given prediction model and show how
to obtain, through a sample-based approach, a probabilistic upper bound on the
absolute value of the prediction error. The proposed scheme is based on a
probabilistic scaling methodology in which the number of required randomized
samples is independent of the complexity of the prediction model. The
methodology is extended to address the case in which the probabilistic
uncertain quantification is required to be valid for every member of a finite
family of predictors. We illustrate the results of the paper by means of a
numerical example.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14188</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14188</id><submitter>Liyi Guo</submitter><version version="v1"><date>Tue, 25 May 2021 17:06:59 GMT</date><size>228kb</size><source_type>D</source_type></version><title>We Know What You Want: An Advertising Strategy Recommender System for
  Online Advertising</title><authors>Liyi Guo, Junqi Jin, Haoqi Zhang, Zhenzhe Zheng, Zhiye Yang, Zhizhuang
  Xing, Fei Pan, Fan Wu, Lvyin Niu, Haiyang Xu, Chuan Yu, Yuning Jiang,
  Xiaoqiang Zhu</authors><categories>cs.IR cs.LG</categories><comments>Accepted by KDD 2021</comments><journal-ref>KDD 2021, Virtual Event, Singapore</journal-ref><doi>10.1145/3447548.3467175</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Advertisers play an important role in e-commerce platforms, whose advertising
expenditures are the main source of revenue for e-commerce platforms.
Therefore, providing advertisers with a better advertising experience by
reducing their cost of trial and error during ad real-time bidding is crucial
to the long-term revenue of e-commerce platforms. To achieve this goal, the
advertising platform needs to understand the advertisers' unique marketing
demands and actively recommend personalized and optimal advertising strategies
for them. In this work, we first deploy a prototype recommender system on
Taobao display advertising platform for constant bid and crowd optimization.
Then, we propose a novel recommender system for dynamic bidding strategy
recommendation, which models the advertiser's strategy recommendation problem
as a contextual bandit problem. We use a neural network as the agent to predict
the advertisers' demands based on their profile and historical adoption
behaviors. Based on the estimated demand, we apply simulated bidding to derive
the optimal bidding strategy for recommendation and interact with the
advertiser by displaying the possible advertising performance. To solve the
exploration/exploitation dilemma, we use Dropout to represent the uncertainty
of the network, which approximately equals to conduct Thompson sampling for
efficient strategy exploration. Online evaluations show that the system can
optimize the advertisers' advertising performance, and advertisers are willing
to open the system, select and adopt the suggestions, which further increases
the platform's revenue income. Simulation experiments based on Alibaba online
bidding data prove that the agent can effectively optimize the adoption rate of
advertisers, and Thompson sampling can better balance exploration and
exploitation to further optimize the performance of the model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14189</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14189</id><submitter>Lingzhi Wang</submitter><version version="v1"><date>Sat, 29 May 2021 07:25:59 GMT</date><size>5275kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 06:07:23 GMT</date><size>5275kb</size><source_type>D</source_type></version><title>Quotation Recommendation and Interpretation Based on Transformation from
  Queries to Quotations</title><authors>Lingzhi Wang, Xingshan Zeng, Kam-Fai Wong</authors><categories>cs.CL cs.AI cs.SI</categories><comments>ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To help individuals express themselves better, quotation recommendation is
receiving growing attention. Nevertheless, most prior efforts focus on modeling
quotations and queries separately and ignore the relationship between the
quotations and the queries. In this work, we introduce a transformation matrix
that directly maps the query representations to quotation representations. To
better learn the mapping relationship, we employ a mapping loss that minimizes
the distance of two semantic spaces (one for quotation and another for
mapped-query). Furthermore, we explore using the words in history queries to
interpret the figurative language of quotations, where quotation-aware
attention is applied on top of history queries to highlight the indicator
words. Experiments on two datasets in English and Chinese show that our model
outperforms previous state-of-the-art models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14190</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14190</id><submitter>Ildar Rakhmatulin</submitter><version version="v1"><date>Thu, 20 May 2021 01:38:45 GMT</date><size>855kb</size></version><title>RaspberryPI for mosquito neutralization by power laser</title><authors>R. Ildar</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this article for the first time, comprehensive studies of mosquito
neutralization using machine vision and a 1 W power laser are considered.
Developed laser installation with Raspberry Pi that changing the direction of
the laser with a galvanometer. We developed a program for mosquito tracking in
real. The possibility of using deep neural networks, Haar cascades, machine
learning for mosquito recognition was considered. We considered in detail the
classification problems of mosquitoes in images. A recommendation is given for
the implementation of this device based on a microcontroller for subsequent use
as part of an unmanned aerial vehicle. Any harmful insects in the fields can be
used as objects for control.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14191</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14191</id><submitter>Thomas Haugland Johansen</submitter><version version="v1"><date>Sat, 15 May 2021 10:46:22 GMT</date><size>10279kb</size><source_type>D</source_type></version><title>Instance Segmentation of Microscopic Foraminifera</title><authors>Thomas Haugland Johansen, Steffen Aagaard S{\o}rensen, Kajsa
  M{\o}llersen, Fred Godtliebsen</authors><categories>cs.CV cs.LG</categories><comments>18 pages, 14 figures. Submitted to Applied Sciences</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Foraminifera are single-celled marine organisms that construct shells that
remain as fossils in the marine sediments. Classifying and counting these
fossils are important in e.g. paleo-oceanographic and -climatological research.
However, the identification and counting process has been performed manually
since the 1800s and is laborious and time-consuming. In this work, we present a
deep learning-based instance segmentation model for classifying, detecting, and
segmenting microscopic foraminifera. Our model is based on the Mask R-CNN
architecture, using model weight parameters that have learned on the COCO
detection dataset. We use a fine-tuning approach to adapt the parameters on a
novel object detection dataset of more than 7000 microscopic foraminifera and
sediment grains. The model achieves a (COCO-style) average precision of $0.78
\pm 0.00$ on the classification and detection task, and $0.80 \pm 0.00$ on the
segmentation task. When the model is evaluated without challenging sediment
grain images, the average precision for both tasks increases to $0.84 \pm 0.00$
and $0.86 \pm 0.00$, respectively. Prediction results are analyzed both
quantitatively and qualitatively and discussed. Based on our findings we
propose several directions for future work, and conclude that our proposed
model is an important step towards automating the identification and counting
of microscopic foraminifera.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14192</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14192</id><submitter>Tarik A. Rashid</submitter><version version="v1"><date>Fri, 14 May 2021 19:40:16 GMT</date><size>2021kb</size></version><title>Evolving Deep Convolutional Neural Network by Hybrid Sine-Cosine and
  Extreme Learning Machine for Real-time COVID19 Diagnosis from X-Ray Images</title><authors>Wu Chao, Mohammad Khishe, Mokhtar Mohammadi, Sarkhel H. Taher Karim,
  Tarik A. Rashid</authors><categories>eess.IV cs.CV cs.NE</categories><comments>28 pages, Soft Computing, 2021</comments><doi>10.1007/s00500-021-05839-6</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The COVID19 pandemic globally and significantly has affected the life and
health of many communities. The early detection of infected patients is
effective in fighting COVID19. Using radiology (X-Ray) images is perhaps the
fastest way to diagnose the patients. Thereby, deep Convolutional Neural
Networks (CNNs) can be considered as applicable tools to diagnose COVID19
positive cases. Due to the complicated architecture of a deep CNN, its
real-time training and testing become a challenging problem. This paper
proposes using the Extreme Learning Machine (ELM) instead of the last fully
connected layer to address this deficiency. However, the parameters' stochastic
tuning of ELM's supervised section causes the final model unreliability.
Therefore, to cope with this problem and maintain network reliability, the
sine-cosine algorithm was utilized to tune the ELM's parameters. The designed
network is then benchmarked on the COVID-Xray-5k dataset, and the results are
verified by a comparative study with canonical deep CNN, ELM optimized by
cuckoo search, ELM optimized by genetic algorithm, and ELM optimized by whale
optimization algorithm. The proposed approach outperforms comparative
benchmarks with a final accuracy of 98.83% on the COVID-Xray-5k dataset,
leading to a relative error reduction of 2.33% compared to a canonical deep
CNN. Even more critical, the designed network's training time is only 0.9421
milliseconds and the overall detection test time for 3100 images is 2.721
seconds.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14194</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14194</id><submitter>Nikolay Ivanov</submitter><version version="v1"><date>Tue, 11 May 2021 00:36:02 GMT</date><size>1374kb</size><source_type>D</source_type></version><title>Constraint-Based Inference of Heuristics for Foreign Exchange Trade
  Model Optimization</title><authors>Nikolay Ivanov and Qiben Yan</authors><categories>q-fin.ST cs.AI cs.CE cs.LG</categories><comments>8 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Foreign Exchange (Forex) is a large decentralized market, on which
trading analysis and algorithmic trading are popular. Research efforts have
been focusing on proof of efficiency of certain technical indicators. We
demonstrate, however, that the values of indicator functions are not
reproducible and often reduce the number of trade opportunities, compared to
price-action trading.
  In this work, we develop two dataset-agnostic Forex trading heuristic
templates with high rate of trading signals. In order to determine most optimal
parameters for the given heuristic prototypes, we perform a machine learning
simulation of 10 years of Forex price data over three low-margin instruments
and 6 different OHLC granularities. As a result, we develop a specific and
reproducible list of most optimal trade parameters found for each
instrument-granularity pair, with 118 pips of average daily profit for the
optimized configuration.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14195</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14195</id><submitter>Omid Jafari</submitter><version version="v1"><date>Mon, 10 May 2021 17:06:44 GMT</date><size>30kb</size><source_type>D</source_type></version><title>A Survey of Performance Optimization in Neural Network-Based Video
  Analytics Systems</title><authors>Nada Ibrahim, Preeti Maurya, Omid Jafari, Parth Nagarkar</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video analytics systems perform automatic events, movements, and actions
recognition in a video and make it possible to execute queries on the video. As
a result of a large number of video data that need to be processed, optimizing
the performance of video analytics systems has become an important research
topic. Neural networks are the state-of-the-art for performing video analytics
tasks such as video annotation and object detection. Prior survey papers
consider application-specific video analytics techniques that improve accuracy
of the results; however, in this survey paper, we provide a review of the
techniques that focus on optimizing the performance of Neural Network-Based
Video Analytics Systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14196</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14196</id><submitter>Qi Zheng</submitter><version version="v1"><date>Fri, 30 Apr 2021 22:26:40 GMT</date><size>1049kb</size></version><title>Classifying States of Cooking Objects Using Convolutional Neural Network</title><authors>Qi Zheng</authors><categories>cs.CV cs.LG cs.RO</categories><comments>6 pages,9 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated cooking machine is a goal for the future. The main aim is to make
the cooking process easier, safer, and create human welfare. To allow robots to
accurately perform the cooking activities, it is important for them to
understand the cooking environment and recognize the objects, especially
correctly identifying the state of the cooking objects. This will significantly
improve the correctness of the following cooking recipes. In this project,
several parts of the experiment were conducted to design a robust deep
convolutional neural network for classifying the state of the cooking objects
from scratch. The model is evaluated by using various techniques, such as
adjusting architecture layers, tuning key hyperparameters, and using different
optimization techniques to maximize the accuracy of state classification.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14197</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14197</id><submitter>Cory McCartan</submitter><version version="v1"><date>Sat, 29 May 2021 03:32:36 GMT</date><size>3160kb</size><source_type>D</source_type></version><title>The Impact of the U.S. Census Disclosure Avoidance System on
  Redistricting and Voting Rights Analysis</title><authors>Christopher T. Kenny (1), Shiro Kuriwaki (1), Cory McCartan (2), Evan
  Rosenman (3), Tyler Simko (1), Kosuke Imai (1 and 2) ((1) Department of
  Government, Harvard University, (2) Department of Statistics, Harvard
  University, (3) Harvard Data Science Initiative)</authors><categories>stat.AP cs.CY</categories><comments>18 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The US Census Bureau plans to protect the privacy of 2020 Census respondents
through its Disclosure Avoidance System (DAS), which attempts to achieve
differential privacy guarantees by adding noise to the Census microdata. By
applying redistricting simulation and analysis methods to DAS-protected 2010
Census data, we find that the protected data are not of sufficient quality for
redistricting purposes. We demonstrate that the injected noise makes it
impossible for states to accurately comply with the One Person, One Vote
principle. Our analysis finds that the DAS-protected data are biased against
certain areas, depending on voter turnout and partisan and racial composition,
and that these biases lead to large and unpredictable errors in the analysis of
partisan and racial gerrymanders. Finally, we show that the DAS algorithm does
not universally protect respondent privacy. Based on the names and addresses of
registered voters, we are able to predict their race as accurately using the
DAS-protected data as when using the 2010 Census data. Despite this, the
DAS-protected data can still inaccurately estimate the number of
majority-minority districts. We conclude with recommendations for how the
Census Bureau should proceed with privacy protection for the 2020 Census.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14201</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14201</id><submitter>Qianren Mao</submitter><version version="v1"><date>Sat, 29 May 2021 03:47:10 GMT</date><size>111kb</size><source_type>D</source_type></version><title>Automated Timeline Length Selection for Flexible Timeline Summarization</title><authors>Xi Li, Qianren Mao, Hao Peng, Hongdong Zhu, Jianxin Li, Zheng Wang</authors><categories>cs.AI cs.IR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By producing summaries for long-running events, timeline summarization (TLS)
underpins many information retrieval tasks. Successful TLS requires identifying
an appropriate set of key dates (the timeline length) to cover. However, doing
so is challenging as the right length can change from one topic to another.
Existing TLS solutions either rely on an event-agnostic fixed length or an
expert-supplied setting. Neither of the strategies is desired for real-life TLS
scenarios. A fixed, event-agnostic setting ignores the diversity of events and
their development and hence can lead to low-quality TLS. Relying on
expert-crafted settings is neither scalable nor sustainable for processing many
dynamically changing events. This paper presents a better TLS approach for
automatically and dynamically determining the TLS timeline length. We achieve
this by employing the established elbow method from the machine learning
community to automatically find the minimum number of dates within the time
series to generate concise and informative summaries. We applied our approach
to four TLS datasets of English and Chinese and compared them against three
prior methods. Experimental results show that our approach delivers comparable
or even better summaries over state-of-art TLS methods, but it achieves this
without expert involvement.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14202</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14202</id><submitter>Hanting Chen</submitter><version version="v1"><date>Sat, 29 May 2021 04:02:51 GMT</date><size>1915kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 06:16:59 GMT</date><size>1915kb</size><source_type>D</source_type></version><version version="v3"><date>Thu, 3 Jun 2021 02:00:56 GMT</date><size>1914kb</size><source_type>D</source_type></version><title>Universal Adder Neural Networks</title><authors>Hanting Chen, Yunhe Wang, Chang Xu, Chao Xu, Chunjing Xu, Tong Zhang</authors><categories>cs.CV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1912.13200</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compared with cheap addition operation, multiplication operation is of much
higher computation complexity. The widely-used convolutions in deep neural
networks are exactly cross-correlation to measure the similarity between input
feature and convolution filters, which involves massive multiplications between
float values. In this paper, we present adder networks (AdderNets) to trade
these massive multiplications in deep neural networks, especially convolutional
neural networks (CNNs), for much cheaper additions to reduce computation costs.
In AdderNets, we take the $\ell_1$-norm distance between filters and input
feature as the output response. The influence of this new similarity measure on
the optimization of neural network have been thoroughly analyzed. To achieve a
better performance, we develop a special training approach for AdderNets by
investigating the $\ell_p$-norm. We then propose an adaptive learning rate
strategy to enhance the training procedure of AdderNets according to the
magnitude of each neuron's gradient. As a result, the proposed AdderNets can
achieve 75.7% Top-1 accuracy 92.3% Top-5 accuracy using ResNet-50 on the
ImageNet dataset without any multiplication in convolutional layer. Moreover,
we develop a theoretical foundation for AdderNets, by showing that both the
single hidden layer AdderNet and the width-bounded deep AdderNet with ReLU
activation functions are universal function approximators. These results match
those of the traditional neural networks using the more complex multiplication
units. An approximation bound for AdderNets with a single hidden layer is also
presented.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14203</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14203</id><submitter>Zhifeng Kong</submitter><version version="v1"><date>Sat, 29 May 2021 04:03:09 GMT</date><size>24747kb</size><source_type>D</source_type></version><title>Understanding Instance-based Interpretability of Variational
  Auto-Encoders</title><authors>Zhifeng Kong, Kamalika Chaudhuri</authors><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instance-based interpretation methods have been widely studied for supervised
learning methods as they help explain how black box neural networks predict.
However, instance-based interpretations remain ill-understood in the context of
unsupervised learning. In this paper, we investigate influence functions [20],
a popular instance-based interpretation method, for a class of deep generative
models called variational auto-encoders (VAE). We formally frame the
counter-factual question answered by influence functions in this setting, and
through theoretical analysis, examine what they reveal about the impact of
training samples on classical unsupervised learning methods. We then introduce
VAE-TracIn, a computationally efficient and theoretically sound solution based
on Pruthi et al. [28], for VAEs. Finally, we evaluate VAE-TracIn on several
real world datasets with extensive quantitative and qualitative analysis.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14207</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14207</id><submitter>Takuma Udagawa</submitter><version version="v1"><date>Sat, 29 May 2021 04:14:29 GMT</date><size>2996kb</size><source_type>D</source_type></version><title>Maintaining Common Ground in Dynamic Environments</title><authors>Takuma Udagawa and Akiko Aizawa</authors><categories>cs.CL cs.AI</categories><comments>Accepted at TACL; pre-MIT Press publication version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common grounding is the process of creating and maintaining mutual
understandings, which is a critical aspect of sophisticated human
communication. While various task settings have been proposed in existing
literature, they mostly focus on creating common ground under static context
and ignore the aspect of maintaining them overtime under dynamic context. In
this work, we propose a novel task setting to study the ability of both
creating and maintaining common ground in dynamic environments. Based on our
minimal task formulation, we collected a large-scale dataset of 5,617 dialogues
to enable fine-grained evaluation and analysis of various dialogue systems.
Through our dataset analyses, we highlight novel challenges introduced in our
setting, such as the usage of complex spatio-temporal expressions to create and
maintain common ground. Finally, we conduct extensive experiments to assess the
capabilities of our baseline dialogue system and discuss future prospects of
our research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14209</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14209</id><submitter>Zuchao Li</submitter><version version="v1"><date>Sat, 29 May 2021 04:39:40 GMT</date><size>826kb</size><source_type>D</source_type></version><title>Grammatical Error Correction as GAN-like Sequence Labeling</title><authors>Kevin Parnow, Zuchao Li, and Hai Zhao</authors><categories>cs.CL</categories><comments>Accepted by ACL21, Findings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Grammatical Error Correction (GEC), sequence labeling models enjoy fast
inference compared to sequence-to-sequence models; however, inference in
sequence labeling GEC models is an iterative process, as sentences are passed
to the model for multiple rounds of correction, which exposes the model to
sentences with progressively fewer errors at each round. Traditional GEC models
learn from sentences with fixed error rates. Coupling this with the iterative
correction process causes a mismatch between training and inference that
affects final performance. In order to address this mismatch, we propose a
GAN-like sequence labeling model, which consists of a grammatical error
detector as a discriminator and a grammatical error labeler with Gumbel-Softmax
sampling as a generator. By sampling from real error distributions, our errors
are more genuine compared to traditional synthesized GEC errors, thus
alleviating the aforementioned mismatch and allowing for better training. Our
results on several evaluation benchmarks demonstrate that our proposed approach
is effective and improves the previous state-of-the-art baseline.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14210</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14210</id><submitter>Chen Zhang</submitter><version version="v1"><date>Sat, 29 May 2021 04:41:09 GMT</date><size>48kb</size><source_type>D</source_type></version><title>Exploiting Position Bias for Robust Aspect Sentiment Classification</title><authors>Fang Ma, Chen Zhang, Dawei Song</authors><categories>cs.CL cs.LG</categories><comments>7 pages, 2 figures, 4 tables, accepted to Findings of ACL 2021. Repo:
  https://github.com/BD-MF/POS4ASC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aspect sentiment classification (ASC) aims at determining sentiments
expressed towards different aspects in a sentence. While state-of-the-art ASC
models have achieved remarkable performance, they are recently shown to suffer
from the issue of robustness. Particularly in two common scenarios: when
domains of test and training data are different (out-of-domain scenario) or
test data is adversarially perturbed (adversarial scenario), ASC models may
attend to irrelevant words and neglect opinion expressions that truly describe
diverse aspects. To tackle the challenge, in this paper, we hypothesize that
position bias (i.e., the words closer to a concerning aspect would carry a
higher degree of importance) is crucial for building more robust ASC models by
reducing the probability of mis-attending. Accordingly, we propose two
mechanisms for capturing position bias, namely position-biased weight and
position-biased dropout, which can be flexibly injected into existing models to
enhance representations for classification. Experiments conducted on
out-of-domain and adversarial datasets demonstrate that our proposed approaches
largely improve the robustness and effectiveness of current models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14211</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14211</id><submitter>Zhu Zhang</submitter><version version="v1"><date>Sat, 29 May 2021 04:42:07 GMT</date><size>8785kb</size><source_type>D</source_type></version><title>UFC-BERT: Unifying Multi-Modal Controls for Conditional Image Synthesis</title><authors>Zhu Zhang, Jianxin Ma, Chang Zhou, Rui Men, Zhikang Li, Ming Ding, Jie
  Tang, Jingren Zhou, and Hongxia Yang</authors><categories>cs.CV</categories><comments>Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional image synthesis aims to create an image according to some
multi-modal guidance in the forms of textual descriptions, reference images,
and image blocks to preserve, as well as their combinations. In this paper,
instead of investigating these control signals separately, we propose a new
two-stage architecture, UFC-BERT, to unify any number of multi-modal controls.
In UFC-BERT, both the diverse control signals and the synthesized image are
uniformly represented as a sequence of discrete tokens to be processed by
Transformer. Different from existing two-stage autoregressive approaches such
as DALL-E and VQGAN, UFC-BERT adopts non-autoregressive generation (NAR) at the
second stage to enhance the holistic consistency of the synthesized image, to
support preserving specified image blocks, and to improve the synthesis speed.
Further, we design a progressive algorithm that iteratively improves the
non-autoregressively generated image, with the help of two estimators developed
for evaluating the compliance with the controls and evaluating the fidelity of
the synthesized image, respectively. Extensive experiments on a newly collected
large-scale clothing dataset M2C-Fashion and a facial dataset Multi-Modal
CelebA-HQ verify that UFC-BERT can synthesize high-fidelity images that comply
with flexible multi-modal controls.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14212</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14212</id><submitter>Danny Arlen De Jes\'us G\'omez-Ram\'irez</submitter><version version="v1"><date>Sat, 29 May 2021 05:01:06 GMT</date><size>352kb</size></version><title>Towards a General Many-Sorted Framework for Describing Certain Kinds of
  Legal Statutes with a Potential Computational Realization</title><authors>Danny A. J. Gomez-Ramirez, Egil Nordqvist</authors><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Examining a 20th-century Scandinavian legal theoretical tradition, we can
extract an ontological naturalistic, a logical empiristic, and a modern
idealistic rationale. We introduce the mathematical syntactic figure present in
the `logical empiricism' in a contemporary mathematical logic. A new formal
framework for describing explicit purchase statutes (Sweden) is gradually
developed and subsequently proposed. This new framework is based on a
many-sorted first-order logic (MFOL) approach, where the semantics are grounded
in concrete `physical' objects and situations with a legal relevance.
Specifically, we present a concrete formal syntactic translation of one of the
central statutes of Swedish legislation for the purchase of immovable property.
Additionally, we discuss the potential implications that a subsequent
development of such formalisations would have for constructing artificial
agents (e.g., software) that can be used as `co-creative' legal assistance for
solving highly complex legal issues concerning the transfer of property, among
others.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14214</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14214</id><submitter>Qingfeng Lan</submitter><version version="v1"><date>Sat, 29 May 2021 05:03:47 GMT</date><size>727kb</size><source_type>D</source_type></version><title>Predictive Representation Learning for Language Modeling</title><authors>Qingfeng Lan, Luke Kumar, Martha White, Alona Fyshe</authors><categories>cs.CL cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  To effectively perform the task of next-word prediction, long short-term
memory networks (LSTMs) must keep track of many types of information. Some
information is directly related to the next word's identity, but some is more
secondary (e.g. discourse-level features or features of downstream words).
Correlates of secondary information appear in LSTM representations even though
they are not part of an \emph{explicitly} supervised prediction task. In
contrast, in reinforcement learning (RL), techniques that explicitly supervise
representations to predict secondary information have been shown to be
beneficial. Inspired by that success, we propose Predictive Representation
Learning (PRL), which explicitly constrains LSTMs to encode specific
predictions, like those that might need to be learned implicitly. We show that
PRL 1) significantly improves two strong language modeling methods, 2)
converges more quickly, and 3) performs better when data is limited. Our work
shows that explicitly encoding a simple predictive task facilitates the search
for a more effective language model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14215</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14215</id><submitter>Akira Furui D.Eng.</submitter><version version="v1"><date>Sat, 29 May 2021 05:08:37 GMT</date><size>5149kb</size><source_type>D</source_type></version><title>Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type
  Muscle Model</title><authors>Akira Furui, Kosuke Nakagaki, Toshio Tsuji</authors><categories>cs.RO cs.SY eess.SP eess.SY</categories><comments>This paper is accepted for publication at the International
  Conference on Robotics and Automation 2021 (ICRA 2021)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Myoelectric prosthetic hands are intended to replace the function of the
amputee's lost arm. Therefore, developing robotic prosthetics that can mimic
not only the appearance and functionality of humans but also characteristics
unique to human movements is paramount. Although the impedance model was
proposed to realize biomimetic control, this model cannot replicate the
characteristics of human movements effectively because the joint angle always
converges to the equilibrium position during muscle relaxation. This paper
proposes a novel biomimetic control method for myoelectric prosthetic hands
integrating the impedance model with the concept of the $\lambda$-type muscle
model. The proposed method can dynamically control the joint equilibrium
position, according to the state of the muscle, and can maintain the joint
angle naturally during muscle relaxation. The effectiveness of the proposed
method is evaluated through simulations and a series of experiments on
non-amputee participants. The experimental results, based on comparison with
the actual human joint angles, suggest that the proposed method has a better
correlation with the actual human motion than the conventional methods.
Additionally, the control experiments showed that the proposed method could
achieve a natural prosthetic hand movement similar to that of a human, thereby
allowing voluntary hand opening and closing movements.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14216</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14216</id><submitter>Jiahao Xie</submitter><version version="v1"><date>Sat, 29 May 2021 05:18:02 GMT</date><size>460kb</size></version><title>A Federated Learning Framework for Nonconvex-PL Minimax Problems</title><authors>Jiahao Xie, Chao Zhang, Yunsong Zhang, Zebang Shen, Hui Qian</authors><categories>cs.LG cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general class of nonconvex-PL minimax problems in the
cross-device federated learning setting. Although nonconvex-PL minimax problems
have received a lot of interest in recent years, existing algorithms do not
apply to the cross-device federated learning setting which is substantially
different from conventional distributed settings and poses new challenges. To
bridge this gap, we propose an algorithmic framework named FedSGDA. FedSGDA
performs multiple local update steps on a subset of active clients in each
round and leverages global gradient estimates to correct the bias in local
update directions. By incorporating FedSGDA with two representative global
gradient estimators, we obtain two specific algorithms. We establish
convergence rates of the proposed algorithms by using novel potential
functions. Experimental results on synthetic and real data corroborate our
theory and demonstrate the effectiveness of our algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14217</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14217</id><submitter>Bohan Zhuang</submitter><version version="v1"><date>Sat, 29 May 2021 05:26:07 GMT</date><size>480kb</size><source_type>D</source_type></version><title>Less is More: Pay Less Attention in Vision Transformers</title><authors>Zizheng Pan, Bohan Zhuang, Haoyu He, Jing Liu, Jianfei Cai</authors><categories>cs.CV</categories><comments>11 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transformers have become one of the dominant architectures in deep learning,
particularly as a powerful alternative to convolutional neural networks (CNNs)
in computer vision. However, Transformer training and inference in previous
works can be prohibitively expensive due to the quadratic complexity of
self-attention over a long sequence of representations, especially for
high-resolution dense prediction tasks. To this end, we present a novel Less
attention vIsion Transformer (LIT), building upon the fact that convolutions,
fully-connected (FC) layers, and self-attentions have almost equivalent
mathematical expressions for processing image patch sequences. Specifically, we
propose a hierarchical Transformer where we use pure multi-layer perceptrons
(MLPs) to encode rich local patterns in the early stages while applying
self-attention modules to capture longer dependencies in deeper layers.
Moreover, we further propose a learned deformable token merging module to
adaptively fuse informative patches in a non-uniform manner. The proposed LIT
achieves promising performance on image recognition tasks, including image
classification, object detection and instance segmentation, serving as a strong
backbone for many vision tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14218</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14218</id><submitter>Fei Ye</submitter><version version="v1"><date>Sat, 29 May 2021 05:27:07 GMT</date><size>12931kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 03:50:52 GMT</date><size>12885kb</size><source_type>D</source_type></version><title>A Survey of Deep Reinforcement Learning Algorithms for Motion Planning
  and Control of Autonomous Vehicles</title><authors>Fei Ye, Shen Zhang, Pin Wang, and Ching-Yao Chan</authors><categories>cs.RO cs.LG</categories><comments>8 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this survey, we systematically summarize the current literature on studies
that apply reinforcement learning (RL) to the motion planning and control of
autonomous vehicles. Many existing contributions can be attributed to the
pipeline approach, which consists of many hand-crafted modules, each with a
functionality selected for the ease of human interpretation. However, this
approach does not automatically guarantee maximal performance due to the lack
of a system-level optimization. Therefore, this paper also presents a growing
trend of work that falls into the end-to-end approach, which typically offers
better performance and smaller system scales. However, their performance also
suffers from the lack of expert data and generalization issues. Finally, the
remaining challenges applying deep RL algorithms on autonomous driving are
summarized, and future research directions are also presented to tackle these
challenges.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14219</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14219</id><submitter>Francesc Wilhelmi</submitter><version version="v1"><date>Sat, 29 May 2021 05:33:07 GMT</date><size>10104kb</size><source_type>D</source_type></version><title>Machine Learning for Performance Prediction of Channel Bonding in
  Next-Generation IEEE 802.11 WLANs</title><authors>Francesc Wilhelmi, David G\'oez, Paola Soto, Ramon Vall\'es, Mohammad
  Alfaifi, Abdulrahman Algunayah, Jorge Martin-P\'erez, Luigi Girletti,
  Rajasekar Mohan, K Venkat Ramnan, Boris Bellalta</authors><categories>cs.NI cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the advent of Artificial Intelligence (AI)-empowered communications,
industry, academia, and standardization organizations are progressing on the
definition of mechanisms and procedures to address the increasing complexity of
future 5G and beyond communications. In this context, the International
Telecommunication Union (ITU) organized the first AI for 5G Challenge to bring
industry and academia together to introduce and solve representative problems
related to the application of Machine Learning (ML) to networks. In this paper,
we present the results gathered from Problem Statement~13 (PS-013), organized
by Universitat Pompeu Fabra (UPF), which primary goal was predicting the
performance of next-generation Wireless Local Area Networks (WLANs) applying
Channel Bonding (CB) techniques. In particular, we overview the ML models
proposed by participants (including Artificial Neural Networks, Graph Neural
Networks, Random Forest regression, and gradient boosting) and analyze their
performance on an open dataset generated using the IEEE 802.11ax-oriented
Komondor network simulator. The accuracy achieved by the proposed methods
demonstrates the suitability of ML for predicting the performance of WLANs.
Moreover, we discuss the importance of abstracting WLAN interactions to achieve
better results, and we argue that there is certainly room for improvement in
throughput prediction through ML.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14220</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14220</id><submitter>Rifat Shahriyar</submitter><version version="v1"><date>Sat, 29 May 2021 05:40:08 GMT</date><size>665kb</size><source_type>D</source_type></version><title>CoDesc: A Large Code-Description Parallel Dataset</title><authors>Masum Hasan, Tanveer Muttaqueen, Abdullah Al Ishtiaq, Kazi Sajeed
  Mehrab, Md. Mahim Anjum Haque, Tahmid Hasan, Wasi Uddin Ahmad, Anindya Iqbal,
  Rifat Shahriyar</authors><categories>cs.CL cs.AI</categories><comments>Findings of the Association for Computational Linguistics, ACL 2021
  (camera-ready)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Translation between natural language and source code can help software
development by enabling developers to comprehend, ideate, search, and write
computer programs in natural language. Despite growing interest from the
industry and the research community, this task is often difficult due to the
lack of large standard datasets suitable for training deep neural models,
standard noise removal methods, and evaluation benchmarks. This leaves
researchers to collect new small-scale datasets, resulting in inconsistencies
across published works. In this study, we present CoDesc -- a large parallel
dataset composed of 4.2 million Java methods and natural language descriptions.
With extensive analysis, we identify and remove prevailing noise patterns from
the dataset. We demonstrate the proficiency of CoDesc in two complementary
tasks for code-description pairs: code summarization and code search. We show
that the dataset helps improve code search by up to 22\% and achieves the new
state-of-the-art in code summarization. Furthermore, we show CoDesc's
effectiveness in pre-training--fine-tuning setup, opening possibilities in
building pretrained language models for Java. To facilitate future research, we
release the dataset, a data processing tool, and a benchmark at
\url{https://github.com/csebuetnlp/CoDesc}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14221</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14221</id><submitter>Francesc Wilhelmi</submitter><version version="v1"><date>Sat, 29 May 2021 05:40:16 GMT</date><size>3570kb</size><source_type>D</source_type></version><title>On the Performance of Blockchain-enabled RAN-as-a-service in Beyond 5G
  Networks</title><authors>Francesc Wilhelmi, Lorenza Giupponi</authors><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Blockchain (BC) technology can revolutionize the future of communications by
enabling decentralized and open sharing networks. In this paper, we propose the
application of BC to facilitate Mobile Network Operators (MNOs) and other
players such as Verticals or Over-The-Top (OTT) service providers to exchange
Radio Access Network (RAN) resources (e.g., infrastructure, spectrum) in a
secure, flexible and autonomous manner. In particular, we propose a BC-enabled
reverse auction mechanism for RAN sharing and dynamic users' service provision
in Beyond 5G networks, and we analyze its potential advantages with respect to
current service provisioning and RAN sharing schemes. Moreover, we study the
delay and overheads incurred by the BC in the whole process, when running over
both wireless and wired interfaces.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14224</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14224</id><submitter>Fan Hu</submitter><version version="v1"><date>Sat, 29 May 2021 06:23:05 GMT</date><size>926kb</size></version><title>A Novel Framework Integrating AI Model and Enzymological Experiments
  Promotes Identification of SARS-CoV-2 3CL Protease Inhibitors and
  Activity-based Probe</title><authors>Fan Hu, Lei Wang, Yishen Hu, Dongqi Wang, Weijie Wang, Jianbing Jiang,
  Nan Li and Peng Yin</authors><categories>q-bio.MN cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The identification of protein-ligand interaction plays a key role in
biochemical research and drug discovery. Although deep learning has recently
shown great promise in discovering new drugs, there remains a gap between deep
learning-based and experimental approaches. Here we propose a novel framework,
named AIMEE, integrating AI Model and Enzymology Experiments, to identify
inhibitors against 3CL protease of SARS-CoV-2, which has taken a significant
toll on people across the globe. From a bioactive chemical library, we have
conducted two rounds of experiments and identified six novel inhibitors with a
hit rate of 29.41%, and four of them showed an IC50 value less than 3 {\mu}M.
Moreover, we explored the interpretability of the central model in AIMEE,
mapping the deep learning extracted features to domain knowledge of chemical
properties. Based on this knowledge, a commercially available compound was
selected and proven to be an activity-based probe of 3CLpro. This work
highlights the great potential of combining deep learning models and
biochemical experiments for intelligent iteration and expanding the boundaries
of drug discovery.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14226</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14226</id><submitter>C\'esar Soto-Valero</submitter><version version="v1"><date>Sat, 29 May 2021 06:31:17 GMT</date><size>1427kb</size><source_type>D</source_type></version><title>A Longitudinal Analysis of Bloated Java Dependencies</title><authors>C\'esar Soto-Valero, Thomas Durieux, Benoit Baudry</authors><categories>cs.SE</categories><comments>In Proceeding of the ACM Joint European Software Engineering
  Conference and Symposium on the Foundations of Software Engineering
  (ESEC/FSE'2021)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the evolution and impact of bloated dependencies in a single
software ecosystem: Java/Maven. Bloated dependencies are third-party libraries
that are packaged in the application binary but are not needed to run the
application. We analyze the history of 435 Java projects. This historical data
includes 48,469 distinct dependencies, which we study across a total of 31,515
versions of Maven dependency trees. Bloated dependencies steadily increase over
time, and 89.02% of the direct dependencies that are bloated remain bloated in
all subsequent versions of the studied projects. This empirical evidence
suggests that developers can safely remove a bloated dependency. We further
report novel insights regarding the unnecessary maintenance efforts induced by
bloat. We find that 22% of dependency updates performed by developers are made
on bloated dependencies and that Dependabot suggests a similar ratio of updates
on bloated dependencies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14229</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14229</id><submitter>Peng Li</submitter><version version="v1"><date>Sat, 29 May 2021 06:40:44 GMT</date><size>80kb</size></version><title>The Dantzig selector: Recovery of Signal via $\ell_1-\alpha \ell_2$
  Minimization</title><authors>Huanmin Ge and Peng Li</authors><categories>cs.IT math.IT math.ST stat.TH</categories><msc-class>62G05, 94A12, 65K05, 90C26</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, we proposed the Dantzig selector based on the $\ell_{1}-\alpha
\ell_{2}$~$(0&lt; \alpha \leq1)$ minimization for the signal recovery. In the
Dantzig selector, the constraint $\|{\bf A}^{\top}({\bf b}-{\bf A}{\bf
x})\|_\infty \leq \eta$ for some small constant $\eta&gt;0$ means the columns of
${\bf A}$ has very weakly correlated with the error vector ${\bf e}={\bf A}{\bf
x}-{\bf b}$. First, recovery guarantees based on the restricted isometry
property (RIP) are established for signals. Next, we propose the effective
algorithm to solve the proposed Dantzig selector. Last, we illustrate the
proposed model and algorithm by extensive numerical experiments for the
recovery of signals in the cases of Gaussian, impulsive and uniform noise. And
the performance of the proposed Dantzig selector is better than that of the
existing methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14230</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14230</id><submitter>Heyi Li</submitter><version version="v1"><date>Sat, 29 May 2021 06:42:23 GMT</date><size>18012kb</size><source_type>D</source_type></version><title>Transforming the Latent Space of StyleGAN for Real Face Editing</title><authors>Heyi Li, Jinlong Liu, Yunzhi Bai, Huayan Wang, Klaus Mueller</authors><categories>cs.CV</categories><comments>16 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite recent advances in semantic manipulation using StyleGAN, semantic
editing of real faces remains challenging. The gap between the $W$ space and
the $W$+ space demands an undesirable trade-off between reconstruction quality
and editing quality. To solve this problem, we propose to expand the latent
space by replacing fully-connected layers in the StyleGAN's mapping network
with attention-based transformers. This simple and effective technique
integrates the aforementioned two spaces and transforms them into one new
latent space called $W$++. Our modified StyleGAN maintains the state-of-the-art
generation quality of the original StyleGAN with moderately better diversity.
But more importantly, the proposed $W$++ space achieves superior performance in
both reconstruction quality and editing quality. Despite these significant
advantages, our $W$++ space supports existing inversion algorithms and editing
methods with only negligible modifications thanks to its structural similarity
with the $W/W$+ space. Extensive experiments on the FFHQ dataset prove that our
proposed $W$++ space is evidently more preferable than the previous $W/W$+
space for real face editing. The code is publicly available for research
purposes at https://github.com/AnonSubm2021/TransStyleGAN.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14231</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14231</id><submitter>Juan Paredes</submitter><version version="v1"><date>Sat, 29 May 2021 06:50:09 GMT</date><size>23884kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 22:11:14 GMT</date><size>23885kb</size><source_type>D</source_type></version><title>Development, Implementation, and Experimental Outdoor Evaluation of
  Quadcopter Controllers for Computationally Limited Embedded Systems</title><authors>Juan Paredes, Prashin Sharma, Brian Ha, Manuel Lanchares, Ella Atkins,
  Peter Gaskell, Ilya Kolmanovsky</authors><categories>eess.SY cs.RO cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Quadcopters are increasingly used for applications ranging from hobby to
industrial products and services. This paper serves as a tutorial on the
design, simulation, implementation, and experimental outdoor testing of digital
quadcopter flight controllers, including Explicit Model Predictive Control,
Linear Quadratic Regulator, and Proportional Integral Derivative. A quadcopter
was flown in an outdoor testing facility and made to track an inclined,
circular path at different tangential velocities under ambient wind conditions.
Controller performance was evaluated via multiple metrics, such as position
tracking error, velocity tracking error, and onboard computation time.
Challenges related to the use of computationally limited embedded hardware and
flight in an outdoor environment are addressed with proposed solutions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14232</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14232</id><submitter>Valentina Lenarduzzi</submitter><version version="v1"><date>Sat, 29 May 2021 06:52:54 GMT</date><size>1343kb</size><source_type>D</source_type></version><title>Identification and Measurement of Technical Debt Requirements in
  Software Development: a Systematic Literature Review</title><authors>Ana Melo, Roberta Fagundes, Valentina Lenarduzzi and Williams Santos</authors><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Context: Technical Debt requirements are related to the distance between the
ideal value of the specification and the system's actual implementation, which
are consequences of strategic decisions for immediate gains, or unintended
changes in context. To ensure the evolution of the software, it is necessary to
keep it managed. Identification and measurement are the first two stages of the
management process; however, they are little explored in academic research in
requirements engineering. Objective: We aimed at investigating which evidence
helps to strengthen the process of TD requirements management, including
identification and measurement. Method: We conducted a Systematic Literature
Review through manual and automatic searches considering 7499 studies from 2010
to 2020, and including 61 primary studies. Results: We identified some causes
related to Technical Debt requirements, existing strategies to help in the
identification and measurement, and metrics to support the measurement stage.
Conclusion: Studies on TD requirements are still preliminary, especially on
management tools. Yet, not enough attention is given to interpersonal issues,
which are difficulties encountered when performing such activities, and
therefore also require research. Finally, the provision of metrics to help
measure TD is part of this work's contribution, providing insights into the
application in the requirements context.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14233</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14233</id><submitter>Arunachalam Venkatesan</submitter><version version="v1"><date>Sat, 29 May 2021 06:58:25 GMT</date><size>899kb</size></version><title>Realization of all logic gates and memory latch in the SC-CNN cell of
  the simple nonlinear MLC circuit</title><authors>P. Ashokkumar, M. Sathish Aravindh, A. Venkatesan, and M. Lakshmanan</authors><categories>cs.ET nlin.CD</categories><comments>Accepted for publication in Chaos (15 pages, 20 Figures)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We investigate the State-Controlled Cellular Neural Network (SC-CNN)
framework of Murali-Lakshmanan-Chua (MLC) circuit system subjected to two
logical signals. By exploiting the attractors generated by this circuit in
different regions of phase-space, we show that the nonlinear circuit is capable
of producing all the logic gates, namely OR, AND, NOR, NAND, Ex-OR and Ex-NOR
gates available in digital systems. Further the circuit system emulates
three-input gates and Set-Reset flip-flop logic as well. Moreover, all these
logical elements and flip-flop are found to be tolerant to noise. These
phenomena are also experimentally demonstrated. Thus our investigation to
realize all logic gates and memory latch in a nonlinear circuit system paves
the way to replace or complement the existing technology with a limited number
of hardware.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14239</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14239</id><submitter>Andrey Zhitnikov</submitter><version version="v1"><date>Sat, 29 May 2021 07:25:11 GMT</date><size>678kb</size><source_type>D</source_type></version><title>Simplified Belief-Dependent Reward MCTS Planning with Guaranteed Tree
  Consistency</title><authors>Ori Sztyglic, Andrey Zhitnikov, Vadim Indelman</authors><categories>cs.AI cs.RO</categories><comments>The first two authors contributed equally to this work</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Partially Observable Markov Decision Processes (POMDPs) are notoriously hard
to solve. Most advanced state-of-the-art online solvers leverage ideas of Monte
Carlo Tree Search (MCTS). These solvers rapidly converge to the most promising
branches of the belief tree, avoiding the suboptimal sections. Most of these
algorithms are designed to utilize straightforward access to the state reward
and assume the belief-dependent reward is nothing but expectation over the
state reward. Thus, they are inapplicable to a more general and essential
setting of belief-dependent rewards. One example of such reward is differential
entropy approximated using a set of weighted particles of the belief. Such an
information-theoretic reward introduces a significant computational burden. In
this paper, we embed the paradigm of simplification into the MCTS algorithm. In
particular, we present Simplified Information-Theoretic Particle Filter Tree
(SITH-PFT), a novel variant to the MCTS algorithm that considers
information-theoretic rewards but avoids the need to calculate them completely.
We replace the costly calculation of information-theoretic rewards with
adaptive upper and lower bounds. These bounds are easy to calculate and
tightened only by the demand of our algorithm. Crucially, we guarantee
precisely the same belief tree and solution that would be obtained by MCTS,
which explicitly calculates the original information-theoretic rewards. Our
approach is general; namely, any converging to the reward bounds can be easily
plugged-in to achieve substantial speedup without any loss in performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14240</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14240</id><submitter>Qi Tian</submitter><version version="v1"><date>Sat, 29 May 2021 07:28:35 GMT</date><size>11749kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 18:00:46 GMT</date><size>11745kb</size><source_type>D</source_type></version><title>Analysis and Applications of Class-wise Robustness in Adversarial
  Training</title><authors>Qi Tian, Kun Kuang, Kelu Jiang, Fei Wu, Yisen Wang</authors><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Adversarial training is one of the most effective approaches to improve model
robustness against adversarial examples. However, previous works mainly focus
on the overall robustness of the model, and the in-depth analysis on the role
of each class involved in adversarial training is still missing. In this paper,
we propose to analyze the class-wise robustness in adversarial training. First,
we provide a detailed diagnosis of adversarial training on six benchmark
datasets, i.e., MNIST, CIFAR-10, CIFAR-100, SVHN, STL-10 and ImageNet.
Surprisingly, we find that there are remarkable robustness discrepancies among
classes, leading to unbalance/unfair class-wise robustness in the robust
models. Furthermore, we keep investigating the relations between classes and
find that the unbalanced class-wise robustness is pretty consistent among
different attack and defense methods. Moreover, we observe that the stronger
attack methods in adversarial learning achieve performance improvement mainly
from a more successful attack on the vulnerable classes (i.e., classes with
less robustness). Inspired by these interesting findings, we design a simple
but effective attack method based on the traditional PGD attack, named
Temperature-PGD attack, which proposes to enlarge the robustness disparity
among classes with a temperature factor on the confidence distribution of each
image. Experiments demonstrate our method can achieve a higher attack rate than
the PGD attack. Furthermore, from the defense perspective, we also make some
modifications in the training and inference phases to improve the robustness of
the most vulnerable class, so as to mitigate the large difference in class-wise
robustness. We believe our work can contribute to a more comprehensive
understanding of adversarial training as well as rethinking the class-wise
properties in robust models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14241</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14241</id><submitter>Linzi Xing</submitter><version version="v1"><date>Sat, 29 May 2021 07:40:59 GMT</date><size>6322kb</size><source_type>D</source_type></version><title>Demoting the Lead Bias in News Summarization via Alternating Adversarial
  Learning</title><authors>Linzi Xing, Wen Xiao, Giuseppe Carenini</authors><categories>cs.CL</categories><comments>Accepted at ACL-IJCNLP 2021 main conference (short paper)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In news articles the lead bias is a common phenomenon that usually dominates
the learning signals for neural extractive summarizers, severely limiting their
performance on data with different or even no bias. In this paper, we introduce
a novel technique to demote lead bias and make the summarizer focus more on the
content semantics. Experiments on two news corpora with different degrees of
lead bias show that our method can effectively demote the model's learned lead
bias and improve its generality on out-of-distribution data, with little to no
performance loss on in-distribution data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14242</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14242</id><submitter>Tae Hwan Jung</submitter><version version="v1"><date>Sat, 29 May 2021 07:48:28 GMT</date><size>5316kb</size><source_type>D</source_type></version><title>CommitBERT: Commit Message Generation Using Pre-Trained Programming
  Language Model</title><authors>Tae-Hwan Jung</authors><categories>cs.CL</categories><comments>8 pages, 3 figures, 4 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commit message is a document that summarizes source code changes in natural
language. A good commit message clearly shows the source code changes, so this
enhances collaboration between developers. Therefore, our work is to develop a
model that automatically writes the commit message.
  To this end, we release 345K datasets consisting of code modification and
commit messages in six programming languages (Python, PHP, Go, Java,
JavaScript, and Ruby). Similar to the neural machine translation (NMT) model,
using our dataset, we feed the code modification to the encoder input and the
commit message to the decoder input and measure the result of the generated
commit message with BLEU-4.
  Also, we propose the following two training methods to improve the result of
generating the commit message: (1) A method of preprocessing the input to feed
the code modification to the encoder input. (2) A method that uses an initial
weight suitable for the code domain to reduce the gap in contextual
representation between programming language (PL) and natural language (NL).
Training code, dataset, and pre-trained weights are available at
https://github.com/graykode/commit-autosuggestions
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14244</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14244</id><submitter>Hongteng Xu</submitter><version version="v1"><date>Sat, 29 May 2021 08:11:40 GMT</date><size>8078kb</size><source_type>D</source_type></version><title>Learning Graphon Autoencoders for Generative Graph Modeling</title><authors>Hongteng Xu, Peilin Zhao, Junzhou Huang, Dixin Luo</authors><categories>cs.LG cs.SI stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graphon is a nonparametric model that generates graphs with arbitrary sizes
and can be induced from graphs easily. Based on this model, we propose a novel
algorithmic framework called \textit{graphon autoencoder} to build an
interpretable and scalable graph generative model. This framework treats
observed graphs as induced graphons in functional space and derives their
latent representations by an encoder that aggregates Chebshev graphon filters.
A linear graphon factorization model works as a decoder, leveraging the latent
representations to reconstruct the induced graphons (and the corresponding
observed graphs). We develop an efficient learning algorithm to learn the
encoder and the decoder, minimizing the Wasserstein distance between the model
and data distributions. This algorithm takes the KL divergence of the graph
distributions conditioned on different graphons as the underlying distance and
leads to a reward-augmented maximum likelihood estimation. The graphon
autoencoder provides a new paradigm to represent and generate graphs, which has
good generalizability and transferability.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14246</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14246</id><submitter>Ashwin Balakrishna</submitter><version version="v1"><date>Sat, 29 May 2021 08:22:55 GMT</date><size>2525kb</size><source_type>D</source_type></version><title>Orienting Novel 3D Objects Using Self-Supervised Learning of Rotation
  Transforms</title><authors>Shivin Devgon, Jeffrey Ichnowski, Ashwin Balakrishna, Harry Zhang, Ken
  Goldberg</authors><categories>cs.RO cs.CV</categories><journal-ref>Conference on Automation Science and Engineering (CASE) 2020</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Orienting objects is a critical component in the automation of many packing
and assembly tasks. We present an algorithm to orient novel objects given a
depth image of the object in its current and desired orientation. We formulate
a self-supervised objective for this problem and train a deep neural network to
estimate the 3D rotation as parameterized by a quaternion, between these
current and desired depth images. We then use the trained network in a
proportional controller to re-orient objects based on the estimated rotation
between the two depth images. Results suggest that in simulation we can rotate
unseen objects with unknown geometries by up to 30{\deg} with a median angle
error of 1.47{\deg} over 100 random initial/desired orientations each for 22
novel objects. Experiments on physical objects suggest that the controller can
achieve a median angle error of 4.2{\deg} over 10 random initial/desired
orientations each for 5 objects.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14247</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14247</id><submitter>Julian Siber</submitter><version version="v1"><date>Sat, 29 May 2021 08:24:32 GMT</date><size>411kb</size></version><title>Causality-Based Game Solving</title><authors>Christel Baier, Norine Coenen, Bernd Finkbeiner, Florian Funke, Simon
  Jantsch, and Julian Siber</authors><categories>cs.LO</categories><comments>33rd International Conference on Computer-Aided Verification (CAV
  2021)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a causality-based algorithm for solving two-player reachability
games represented by logical constraints. These games are a useful formalism to
model a wide array of problems arising, e.g., in program synthesis. Our
technique for solving these games is based on the notion of subgoals, which are
slices of the game that the reachability player necessarily needs to pass
through in order to reach the goal. We use Craig interpolation to identify
these necessary sets of moves and recursively slice the game along these
subgoals. Our approach allows us to infer winning strategies that are
structured along the subgoals. If the game is won by the reachability player,
this is a strategy that progresses through the subgoals towards the final goal;
if the game is won by the safety player, it is a permissive strategy that
completely avoids a single subgoal. We evaluate our prototype implementation on
a range of different games. On multiple benchmark families, our prototype
scales dramatically better than previously available tools.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14250</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14250</id><submitter>Mikhail Usvyatsov</submitter><version version="v1"><date>Sat, 29 May 2021 08:39:57 GMT</date><size>8174kb</size><source_type>D</source_type></version><title>Cherry-Picking Gradients: Learning Low-Rank Embeddings of Visual Data
  via Differentiable Cross-Approximation</title><authors>Mikhail Usvyatsov, Anastasia Makarova, Rafael Ballester-Ripoll, Maxim
  Rakhuba, Andreas Krause, Konrad Schindler</authors><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose an end-to-end trainable framework that processes large-scale
visual data tensors by looking \emph{at a fraction of their entries only}. Our
method combines a neural network encoder with a \emph{tensor train
decomposition} to learn a low-rank latent encoding, coupled with
cross-approximation (CA) to learn the representation through a subset of the
original samples. CA is an adaptive sampling algorithm that is native to tensor
decompositions and avoids working with the full high-resolution data
explicitly. Instead, it actively selects local representative samples that we
fetch out-of-core and on-demand. The required number of samples grows only
logarithmically with the size of the input. Our implicit representation of the
tensor in the network enables processing large grids that could not be
otherwise tractable in their uncompressed form. The proposed approach is
particularly useful for large-scale multidimensional grid data (e.g., 3D
tomography), and for tasks that require context over a large receptive field
(e.g., predicting the medical condition of entire organs). The code will be
available at https://github.com/aelphy/c-pic
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14251</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14251</id><submitter>Yajin Zhou</submitter><version version="v1"><date>Sat, 29 May 2021 08:41:08 GMT</date><size>544kb</size><source_type>D</source_type></version><title>Revisiting Challenges for Selective Data Protection of Real Applications</title><authors>Lin Ma, Jinyan Xu, Jiadong Sun, Yajin Zhou, Xun Xie, Wenbo Shen, Rui
  Chang, Kui Ren</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selective data protection is a promising technique to defend against the data
leakage attack. In this paper, we revisit technical challenges that were
neglected when applying this protection to real applications. These challenges
include the secure input channel, granularity conflict, and sensitivity
conflict. We summarize the causes of them and propose corresponding solutions.
Then we design and implement a prototype system for selective data protection
and evaluate the overhead using the RISC-V Spike simulator. The evaluation
demonstrates the efficiency (less than 3% runtime overhead with optimizations)
and the security guarantees provided by our system.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14252</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14252</id><submitter>Vladimir Filkov</submitter><version version="v1"><date>Sat, 29 May 2021 08:56:57 GMT</date><size>4382kb</size><source_type>D</source_type></version><title>Sustainability Forecasting for Apache Incubator Projects</title><authors>Likang Yin, Zhunagzhi Chen, Qi Xuan, Vladimir Filkov</authors><categories>cs.SE</categories><comments>12 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Although OSS development is very popular, ultimately more than 80 percent of
OSS projects fail. Identifying the factors associated with OSS success can help
in devising interventions when a project takes a downturn. OSS success has been
studied from a variety of angles, more recently in empirical studies of large
numbers of diverse projects, using proxies for sustainability, e.g., internal
metrics related to productivity and external ones, related to community
popularity. The internal socio-technical structure of projects has also been
shown important, especially their dynamics. This points to another angle on
evaluating software success, from the perspective of self-sustaining and
self-governing communities.
  To uncover the dynamics of how a project at a nascent development stage
gradually evolves into a sustainable one, here we apply a socio-technical
network modeling perspective to a dataset of Apache Software Foundation
Incubator (ASFI), sustainability-labeled projects. To identify and validate the
determinants of sustainability, we undertake a mix of quantitative and
qualitative studies of ASFI projects' socio-technical network trajectories. We
develop interpretable models which can forecast a project becoming sustainable
with more than 93 percent accuracy, within 8 months of incubation start. Based
on the interpretable models we describe a strategy for real-time monitoring and
suggesting actions, which can be used by projects to correct their
sustainability trajectories.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14255</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14255</id><submitter>Hengrong Lan</submitter><version version="v1"><date>Sat, 29 May 2021 09:01:58 GMT</date><size>1081kb</size><source_type>D</source_type></version><title>Compressed Sensing for Photoacoustic Computed Tomography Using an
  Untrained Neural Network</title><authors>Hengrong Lan, Juze Zhang, Changchun Yang, and Fei Gao</authors><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic (PA) computed tomography (PACT) shows great potentials in
various preclinical and clinical applications. A great number of measurements
are the premise that obtains a high-quality image, which implies a low imaging
rate or a high system cost. The artifacts or sidelobes could pollute the image
if we decrease the number of measured channels or limit the detected view. In
this paper, a novel compressed sensing method for PACT using an untrained
neural network is proposed, which decreases half number of the measured
channels and recoveries enough details. This method uses a neural network to
reconstruct without the requirement for any additional learning based on the
deep image prior. The model can reconstruct the image only using a few
detections with gradient descent. Our method can cooperate with other existing
regularization, and further improve the quality. In addition, we introduce a
shape prior to easily converge the model to the image. We verify the
feasibility of untrained network based compressed sensing in PA image
reconstruction, and compare this method with a conventional method using total
variation minimization. The experimental results show that our proposed method
outperforms 32.72% (SSIM) with the traditional compressed sensing method in the
same regularization. It could dramatically reduce the requirement for the
number of transducers, by sparsely sampling the raw PA data, and improve the
quality of PA image significantly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14256</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14256</id><submitter>S.M. Zafaruddin</submitter><version version="v1"><date>Sat, 29 May 2021 09:05:54 GMT</date><size>200kb</size><source_type>D</source_type></version><title>Performance of Dual-Hop Relaying for OWC System Over Foggy Channel with
  Pointing Errors and Atmospheric Turbulence</title><authors>Ziyaur Rahman, Tejas Nimish Shah, S. M. Zafaruddin, V. K. Chaubey</authors><categories>cs.IT eess.SP math.IT</categories><comments>14 pages, 7 figures, 2 Tables. This work has been submitted to the
  IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical wireless communication (OWC) over atmospheric turbulence and pointing
errors is a well-studied topic. Still, there is limited research on signal
fading due to random fog and pointing errors in outdoor environments. In this
paper, we analyze the performance of a decode-and-forward (DF) relaying under
the combined effect of random fog, pointing errors, and atmospheric turbulence
with a negligible line-of-sight (LOS) direct link. We consider a generalized
model for the end-to-end channel with independent and not identically
distributed (i.ni.d.) pointing errors, random fog with Gamma distributed
attenuation coefficient, asymptotic exponentiated Weibull turbulence, and
asymmetrical distance between the source and destination. We derive
distribution functions of the signal-to-noise ratio (SNR), and then we develop
analytical expressions of the outage probability, average SNR, ergodic rate,
and average bit error rate (BER) in terms of OWC system parameters. We also
develop simplified performance to provide insight on the system behavior
analytically under various practically relevant scenarios. We demonstrate the
mutual effects of channel impairments and pointing errors on the OWC
performance, and show that the relaying system provides significant performance
improvement compared with the direct transmissions, especially when pointing
errors and fog becomes more pronounced.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14257</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14257</id><submitter>Korbinian Abstreiter</submitter><version version="v1"><date>Sat, 29 May 2021 09:26:02 GMT</date><size>2896kb</size><source_type>D</source_type></version><title>Representation Learning in Continuous-Time Score-Based Generative Models</title><authors>Korbinian Abstreiter, Stefan Bauer, Arash Mehrjou</authors><categories>cs.LG cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Score-based methods represented as stochastic differential equations on a
continuous time domain have recently proven successful as a non-adversarial
generative model. Training such models relies on denoising score matching,
which can be seen as multi-scale denoising autoencoders. Here, we augment the
denoising score-matching framework to enable representation learning without
any supervised signal. GANs and VAEs learn representations by directly
transforming latent codes to data samples. In contrast, score-based
representation learning relies on a new formulation of the denoising
score-matching objective and thus encodes information needed for denoising. We
show how this difference allows for manual control of the level of detail
encoded in the representation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14258</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14258</id><submitter>Giulia Bertaglia</submitter><version version="v1"><date>Sat, 29 May 2021 09:32:43 GMT</date><size>2228kb</size><source_type>D</source_type></version><title>Hyperbolic compartmental models for epidemic spread on networks with
  uncertain data: application to the emergence of Covid-19 in Italy</title><authors>Giulia Bertaglia and Lorenzo Pareschi</authors><categories>q-bio.PE cs.NA math.NA physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of spatial networks in the spread of an epidemic is an
essential aspect in modeling the dynamics of an infectious disease.
Additionally, any realistic data-driven model must take into account the large
uncertainty in the values reported by official sources, such as the amount of
infectious individuals. In this paper we address the above aspects through a
hyperbolic compartmental model on networks, in which nodes identify locations
of interest, such as cities or regions, and arcs represent the ensemble of main
mobility paths. The model describes the spatial movement and interactions of a
population partitioned, from an epidemiological point of view, on the basis of
an extended compartmental structure and divided into commuters, moving on a
suburban scale, and non-commuters, acting on an urban scale. Through a
diffusive rescaling, the model allows us to recover classical diffusion
equations related to commuting dynamics. The numerical solution of the
resulting multiscale hyperbolic system with uncertainty is then tackled using a
stochastic collocation approach in combination with a finite-volume IMEX
method. The ability of the model to correctly describe the spatial
heterogeneity underlying the spread of an epidemic in a realistic city network
is confirmed with a study of the outbreak of COVID-19 in Italy and its spread
in the Lombardy Region.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14259</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14259</id><submitter>Mingfu Xue</submitter><version version="v1"><date>Sat, 29 May 2021 09:33:05 GMT</date><size>208kb</size><source_type>D</source_type></version><title>Detecting Backdoor in Deep Neural Networks via Intentional Adversarial
  Perturbations</title><authors>Mingfu Xue, Yinghao Wu, Zhiyu Wu, Jian Wang, Yushu Zhang, Weiqiang Liu</authors><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent researches show that deep learning model is susceptible to backdoor
attacks where the backdoor embedded in the model will be triggered when a
backdoor instance arrives. In this paper, a novel backdoor detection method
based on adversarial examples is proposed. The proposed method leverages
intentional adversarial perturbations to detect whether the image contains a
trigger, which can be applied in two scenarios (sanitize the training set in
training stage and detect the backdoor instances in inference stage).
Specifically, given an untrusted image, the adversarial perturbation is added
to the input image intentionally, if the prediction of model on the perturbed
image is consistent with that on the unperturbed image, the input image will be
considered as a backdoor instance. The proposed adversarial perturbation based
method requires low computational resources and maintains the visual quality of
the images. Experimental results show that, the proposed defense method reduces
the backdoor attack success rates from 99.47%, 99.77% and 97.89% to 0.37%,
0.24% and 0.09% on Fashion-MNIST, CIFAR-10 and GTSRB datasets, respectively.
Besides, the proposed method maintains the visual quality of the image as the
added perturbation is very small. In addition, for attacks under different
settings (trigger transparency, trigger size and trigger pattern), the false
acceptance rates of the proposed method are as low as 1.2%, 0.3% and 0.04% on
Fashion-MNIST, CIFAR-10 and GTSRB datasets, respectively, which demonstrates
that the proposed method can achieve high defense performance against backdoor
attacks under different attack settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14260</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14260</id><submitter>Houshuang Chen</submitter><version version="v1"><date>Sat, 29 May 2021 09:35:28 GMT</date><size>29kb</size></version><title>Understanding Bandits with Graph Feedback</title><authors>Houshuang Chen (1), Zengfeng Huang (2), Shuai Li (1) and Chihao Zhang
  (1) ((1) Shanghai Jiao Tong University, (2) Fudan University)</authors><categories>cs.LG cs.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bandit problem with graph feedback, proposed in [Mannor and Shamir,
NeurIPS 2011], is modeled by a directed graph $G=(V,E)$ where $V$ is the
collection of bandit arms, and once an arm is triggered, all its incident arms
are observed. A fundamental question is how the structure of the graph affects
the min-max regret. We propose the notions of the fractional weak domination
number $\delta^*$ and the $k$-packing independence number capturing upper bound
and lower bound for the regret respectively. We show that the two notions are
inherently connected via aligning them with the linear program of the weakly
dominating set and its dual -- the fractional vertex packing set respectively.
Based on this connection, we utilize the strong duality theorem to prove a
general regret upper bound $O\left(\left( \delta^*\log
|V|\right)^{\frac{1}{3}}T^{\frac{2}{3}}\right)$ and a lower bound
$\Omega\left(\left(\delta^*/\alpha\right)^{\frac{1}{3}}T^{\frac{2}{3}}\right)$
where $\alpha$ is the integrality gap of the dual linear program. Therefore,
our bounds are tight up to a $\left(\log |V|\right)^{\frac{1}{3}}$ factor on
graphs with bounded integrality gap for the vertex packing problem including
trees and graphs with bounded degree. Moreover, we show that for several
special families of graphs, we can get rid of the $\left(\log
|V|\right)^{\frac{1}{3}}$ factor and establish optimal regret.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14261</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14261</id><submitter>Dieter Spreen</submitter><version version="v1"><date>Sat, 29 May 2021 09:42:15 GMT</date><size>234kb</size><source_type>D</source_type></version><title>Computing with Infinite Objects: the Gray Code Case</title><authors>Dieter Spreen, Ulrich Berger</authors><categories>cs.LO math.LO</categories><msc-class>03B70, 03B78, 03B35, 03F60, 68V05, 68V15, 68V20, 65G20</msc-class><acm-class>D.2.4; F.4.1; I.2.2; I.2.3; I.2.4</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Infinite Gray code has been introduced by Tsuiki~\cite{ts} as a
redundancy-free representation of the reals. In applications the signed digit
representation is mostly used which has maximal redundancy. Tsuiki presented a
functional program converting signed digit code into infinite Gray code.
Moreover, he showed that infinite Gray code can effectively be converted into
signed digit code, but the program needs to have some non-deterministic
features (see also \cite{tsug}). Berger and Tsuiki~\cite{btifp,bt} reproved the
result in a system of formal first-order intuitionistic logic extended by
inductive and co-inductive definitions, as well as some new logical connectives
capturing concurrent behaviour. The programs extracted from the proofs are
exactly the ones given by Tsuiki. In order to do so, co-inductive predicates
$\bS$ and $\bG$ are defined and the inclusion $\bS \subseteq \bG$ is derived.
For the converse inclusion the new logical connectives are used to introduce a
concurrent version $\S_{2}$ of $S$ and $\bG \subseteq \bS_{2}$ is shown. What
one is looking for, however, is an equivalence proof of the involved concepts.
One of the main aims of the present paper is to close the gap. A concurrent
version $\bG^{*}$ of $\bG$ and a modification $\bS^{*}$ of $\bS_{2}$ are
presented such that $\bS^{*} = \bG^{*}$. A crucial tool in \cite{btifp} is a
formulation of the Archimedean property of the real numbers as an induction
principle. We introduce a concurrent version of this principle which allows us
to prove that $\bS^{*}$ and $\bG^{*}$ coincide. A further central contribution
is the extension of the above results to the hyperspace of non-empty compact
subsets of the reals.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14262</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14262</id><submitter>Yu Su</submitter><version version="v1"><date>Sat, 29 May 2021 09:44:16 GMT</date><size>1679kb</size><source_type>D</source_type></version><title>The Privacy Paradox and Optimal Bias-Variance Trade-offs in Data
  Acquisition</title><authors>Guocheng Liao, Yu Su, Juba Ziani, Adam Wierman, Jianwei Huang</authors><categories>cs.SI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While users claim to be concerned about privacy, often they do little to
protect their privacy in their online actions. One prominent explanation for
this &quot;privacy paradox&quot; is that when an individual shares her data, it is not
just her privacy that is compromised; the privacy of other individuals with
correlated data is also compromised. This information leakage encourages
oversharing of data and significantly impacts the incentives of individuals in
online platforms. In this paper, we study the design of mechanisms for data
acquisition in settings with information leakage and verifiable data. We design
an incentive compatible mechanism that optimizes the worst-case trade-off
between bias and variance of the estimation subject to a budget constraint,
where the worst-case is over the unknown correlation between costs and data.
Additionally, we characterize the structure of the optimal mechanism in closed
form and study monotonicity and non-monotonicity properties of the marketplace.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14267</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14267</id><submitter>Botao Hao</submitter><version version="v1"><date>Sat, 29 May 2021 10:26:23 GMT</date><size>256kb</size><source_type>D</source_type></version><title>Information Directed Sampling for Sparse Linear Bandits</title><authors>Botao Hao, Tor Lattimore, Wei Deng</authors><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Stochastic sparse linear bandits offer a practical model for high-dimensional
online decision-making problems and have a rich information-regret structure.
In this work we explore the use of information-directed sampling (IDS), which
naturally balances the information-regret trade-off. We develop a class of
information-theoretic Bayesian regret bounds that nearly match existing lower
bounds on a variety of problem instances, demonstrating the adaptivity of IDS.
To efficiently implement sparse IDS, we propose an empirical Bayesian approach
for sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior.
Numerical results demonstrate significant regret reductions by sparse IDS
relative to several baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14271</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14271</id><submitter>Shiva Raj Pokhrel Dr</submitter><version version="v1"><date>Sat, 29 May 2021 11:14:30 GMT</date><size>3618kb</size><source_type>D</source_type></version><title>Learning to Harness Bandwidth with Multipath Congestion Control and
  Scheduling</title><authors>Shiva Raj Pokhrel and Anwar Walid</authors><categories>cs.NI</categories><comments>14 pages</comments><msc-class>14J60 (Primary) 14F05, 14J26 (Secondary)</msc-class><acm-class>F.2.2; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multipath TCP (MPTCP) has emerged as a facilitator for harnessing and pooling
available bandwidth in wireless/wireline communication networks and in data
centers. Existing implementations of MPTCP such as, Linked Increase Algorithm
(LIA), Opportunistic LIA (OLIA) and BAlanced LInked Adaptation (BALIA) include
separate algorithms for congestion control and packet scheduling, with
pre-selected control parameters. We propose a Deep Q-Learning (DQL) based
framework for joint congestion control and packet scheduling for MPTCP. At the
heart of the solution is an intelligent agent for interface, learning and
actuation, which learns from experience optimal congestion control and
scheduling mechanism using DQL techniques with policy gradients. We provide a
rigorous stability analysis of system dynamics which provides important
practical design insights. In addition, the proposed DQL-MPTCP algorithm
utilizes the `recurrent neural network' and integrates it with `long short-term
memory' for continuously i) learning dynamic behavior of subflows (paths) and
ii) responding promptly to their behavior using prioritized experience replay.
With extensive emulations, we show that the proposed DQL-based MPTCP algorithm
outperforms MPTCP LIA, OLIA and BALIA algorithms. Moreover, the DQL-MPTCP
algorithm is robust to time-varying network characteristics, and provides
dynamic exploration and exploitation of paths.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14273</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14273</id><submitter>Muhui Jiang</submitter><version version="v1"><date>Sat, 29 May 2021 11:29:53 GMT</date><size>296kb</size><source_type>D</source_type></version><title>Examiner: Automatically Locating Inconsistent Instructions Between Real
  Devices and CPU Emulators for ARM</title><authors>Muhui Jiang, Tianyi Xu, Yajin Zhou, Yufeng Hu, Ming Zhong, Lei Wu,
  Xiapu Luo, Kui Ren</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emulator is widely used to build dynamic analysis frameworks due to its
fine-grained tracing capability, full system monitoring functionality, and
scalability of running on different operating systemsand architectures.
However, whether the emulator is consistent with real devices is unknown. To
understand this problem, we aim to automatically locate inconsistent
instructions, which behave differently between emulators and real devices.
  We target ARM architecture, which provides machine readable specification.
Based on the specification, we propose a test case generator by designing and
implementing the first symbolic execution engine for ARM architecture
specification language (ASL). We generate 2,774,649 representative instruction
streams and conduct differential testing with these instruction streams between
four ARM real devices in different architecture versions (i.e., ARMv5, ARMv6,
ARMv7-a, and ARMv8-a) and the state-of-the-art emulators (i.e., QEMU). We
locate 155,642 inconsistent instruction streams, which cover 30% of all
instruction encodings and 47.8% of the instructions. We find undefined
implementation in ARM manual and implementation bugs of QEMU are the major
causes of inconsistencies. Furthermore, we discover four QEMU bugs, which are
confirmed and patched by thedevelopers, covering 13 instruction encodings
including the most commonly used ones (e.g.,STR,BLX). With the inconsistent
instructions, we build three security applications and demonstrate
thecapability of these instructions on detecting emulators, anti-emulation, and
anti-fuzzing.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14274</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14274</id><submitter>Dojun Park</submitter><version version="v1"><date>Sat, 29 May 2021 11:31:59 GMT</date><size>298kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 10:03:25 GMT</date><size>299kb</size></version><title>Korean-English Machine Translation with Multiple Tokenization Strategy</title><authors>Dojun Park, Youngjin Jang and Harksoo Kim</authors><categories>cs.CL</categories><comments>KCC2021 Undergraduate/Junior Thesis Competition</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This work was conducted to find out how tokenization methods affect the
training results of machine translation models. In this work, alphabet
tokenization, morpheme tokenization, and BPE tokenization were applied to
Korean as the source language and English as the target language respectively,
and the comparison experiment was conducted by repeating 50,000 epochs of each
9 models using the Transformer neural network. As a result of measuring the
BLEU scores of the experimental models, the model that applied BPE tokenization
to Korean and morpheme tokenization to English recorded 35.73, showing the best
performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14275</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14275</id><submitter>Aleksei Tiulpin</submitter><version version="v1"><date>Sat, 29 May 2021 11:35:27 GMT</date><size>242kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 07:29:42 GMT</date><size>242kb</size><source_type>D</source_type></version><title>Greedy Bayesian Posterior Approximation with Deep Ensembles</title><authors>Aleksei Tiulpin and Matthew B. Blaschko</authors><categories>cs.LG cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Ensembles of independently trained neural networks are a state-of-the-art
approach to estimate predictive uncertainty in Deep Learning, and can be
interpreted as an approximation of the posterior distribution via a mixture of
delta functions. The training of ensembles relies on non-convexity of the loss
landscape and random initialization of their individual members, making the
resulting posterior approximation uncontrolled. This paper proposes a novel and
principled method to tackle this limitation, minimizing an $f$-divergence
between the true posterior and a kernel density estimator in a function space.
We analyze this objective from a combinatorial point of view, and show that it
is submodular with respect to mixture components for any $f$. Subsequently, we
consider the problem of greedy ensemble construction, and from the marginal
gain of the total objective, we derive a novel diversity term for ensemble
methods. The performance of our approach is demonstrated on computer vision
out-of-distribution benchmarks in a range of architectures trained on multiple
datasets. The source code of our method is publicly available at
https://github.com/MIPT-Oulu/greedy_ensembles_training.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14276</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14276</id><submitter>Rossella Arcucci Dr</submitter><version version="v1"><date>Sat, 29 May 2021 11:39:56 GMT</date><size>9594kb</size><source_type>D</source_type></version><title>Correcting public opinion trends through Bayesian data assimilation</title><authors>Robin Hendrickx, Rossella Arcucci, Julio Amador D{\i}az Lopez, Yi-Ke
  Guo, and Mark Kennedy</authors><categories>cs.CY cs.AI cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring public opinion is a key focus during democratic elections, enabling
candidates to gauge their popularity and alter their campaign strategies
accordingly. Traditional survey polling remains the most popular estimation
technique, despite its cost and time intensity, measurement errors, lack of
real-time capabilities and lagged representation of public opinion. In recent
years, Twitter opinion mining has attempted to combat these issues. Despite
achieving promising results, it experiences its own set of shortcomings such as
an unrepresentative sample population and a lack of long term stability. This
paper aims to merge data from both these techniques using Bayesian data
assimilation to arrive at a more accurate estimate of true public opinion for
the Brexit referendum. This paper demonstrates the effectiveness of the
proposed approach using Twitter opinion data and survey data from trusted
pollsters. Firstly, the possible existence of a time gap of 16 days between the
two data sets is identified. This gap is subsequently incorporated into a
proposed assimilation architecture. This method was found to adequately
incorporate information from both sources and measure a strong upward trend in
Leave support leading up to the Brexit referendum. The proposed technique
provides useful estimates of true opinion, which is essential to future opinion
measurement and forecasting research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14277</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14277</id><submitter>Dojun Park</submitter><version version="v1"><date>Sat, 29 May 2021 11:40:51 GMT</date><size>342kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 10:07:30 GMT</date><size>342kb</size></version><title>Grammar Accuracy Evaluation (GAE): Quantifiable Intrinsic Evaluation of
  Machine Translation Models</title><authors>Dojun Park, Youngjin Jang and Harksoo Kim</authors><categories>cs.CL</categories><comments>Journal of KIISE</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Intrinsic evaluation by humans for the performance of natural language
generation models is conducted to overcome the fact that the quality of
generated sentences cannot be fully represented by only extrinsic evaluation.
Nevertheless, existing intrinsic evaluations have a large score deviation
according to the evaluator's criteria. In this paper, we propose Grammar
Accuracy Evaluation (GAE) that can provide specific evaluating criteria. As a
result of analyzing the quality of machine translation by BLEU and GAE, it was
confirmed that the BLEU score does not represent the absolute performance of
machine translation models and that GAE compensates for the shortcomings of
BLEU with a flexible evaluation on alternative synonyms and changes in sentence
structure.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14278</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14278</id><submitter>Navid Ghassemi</submitter><version version="v1"><date>Sat, 29 May 2021 12:00:39 GMT</date><size>8165kb</size><source_type>D</source_type></version><title>Applications of Epileptic Seizures Detection in Neuroimaging Modalities
  Using Deep Learning Techniques: Methods, Challenges, and Future Works</title><authors>Afshin Shoeibi, Navid Ghassemi, Marjane Khodatars, Mahboobeh Jafari,
  Parisa Moridian, Roohallah Alizadehsani, Ali Khadem, Yinan Kong, Assef Zare,
  Juan Manuel Gorriz, Javier Ram\'irez, Maryam Panahiazar, Abbas Khosravi,
  Saeid Nahavandi</authors><categories>cs.LG cs.CV eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Epileptic seizures are a type of neurological disorder that affect many
people worldwide. Specialist physicians and neurologists take advantage of
structural and functional neuroimaging modalities to diagnose various types of
epileptic seizures. Neuroimaging modalities assist specialist physicians
considerably in analyzing brain tissue and the changes made in it. One method
to accelerate the accurate and fast diagnosis of epileptic seizures is to
employ computer aided diagnosis systems (CADS) based on artificial intelligence
(AI) and functional and structural neuroimaging modalities. AI encompasses a
variety of areas, and one of its branches is deep learning (DL). Not long ago,
and before the rise of DL algorithms, feature extraction was an essential part
of every conventional machine learning method, yet handcrafting features limit
these models' performances to the knowledge of system designers. DL methods
resolved this issue entirely by automating the feature extraction and
classification process; applications of these methods in many fields of
medicine, such as the diagnosis of epileptic seizures, have made notable
improvements. In this paper, a comprehensive overview of the types of DL
methods exploited to diagnose epileptic seizures from various neuroimaging
modalities has been studied. Additionally, rehabilitation systems and cloud
computing in epileptic seizures diagnosis applications have been exactly
investigated using various modalities.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14280</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14280</id><submitter>Wei Wu</submitter><version version="v1"><date>Sat, 29 May 2021 12:04:27 GMT</date><size>469kb</size></version><title>Hashing-Accelerated Graph Neural Networks for Link Prediction</title><authors>Wei Wu, Bin Li, Chuan Luo, Wolfgang Nejdl</authors><categories>cs.LG cs.SI</categories><journal-ref>The Web Conference 2021</journal-ref><doi>10.1145/3442381.3449884</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks are ubiquitous in the real world. Link prediction, as one of the key
problems for network-structured data, aims to predict whether there exists a
link between two nodes. The traditional approaches are based on the explicit
similarity computation between the compact node representation by embedding
each node into a low-dimensional space. In order to efficiently handle the
intensive similarity computation in link prediction, the hashing technique has
been successfully used to produce the node representation in the Hamming space.
However, the hashing-based link prediction algorithms face accuracy loss from
the randomized hashing techniques or inefficiency from the learning to hash
techniques in the embedding process. Currently, the Graph Neural Network (GNN)
framework has been widely applied to the graph-related tasks in an end-to-end
manner, but it commonly requires substantial computational resources and memory
costs due to massive parameter learning, which makes the GNN-based algorithms
impractical without the help of a powerful workhorse. In this paper, we propose
a simple and effective model called #GNN, which balances the trade-off between
accuracy and efficiency. #GNN is able to efficiently acquire node
representation in the Hamming space for link prediction by exploiting the
randomized hashing technique to implement message passing and capture
high-order proximity in the GNN framework. Furthermore, we characterize the
discriminative power of #GNN in probability. The extensive experimental results
demonstrate that the proposed #GNN algorithm achieves accuracy comparable to
the learning-based algorithms and outperforms the randomized algorithm, while
running significantly faster than the learning-based algorithms. Also, the
proposed algorithm shows excellent scalability on a large-scale network with
the limited resources.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14281</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14281</id><submitter>Amit Saha</submitter><version version="v1"><date>Sat, 29 May 2021 12:13:11 GMT</date><size>618kb</size><source_type>D</source_type></version><title>Circuit Design for $k$-coloring Problem and Its Implementation in Any
  Dimensional Quantum System</title><authors>Amit Saha, Debasri Saha and Amlan Chakrabarti</authors><categories>cs.ET</categories><comments>24 pages, 18 figures. arXiv admin note: text overlap with
  arXiv:2009.06073</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the evolution of quantum computing, researchers now-a-days tend to
incline to find solutions to NP-complete problems by using quantum algorithms
in order to gain asymptotic advantage. In this paper, we solve $k$-coloring
problem (NP-complete problem) using Grover's algorithm in any dimensional
quantum system or any $d$-ary quantum system for the first time to the best of
our knowledge, where $d \ge 2$. A newly proposed comparator-based approach
helps to generalize the implementation of the $k$-coloring problem in any
dimensional quantum system. Till date, $k$-coloring problem has been
implemented only in binary and ternary quantum system, hence, we abide to $d=2$
or $d=3$, that is for binary and ternary quantum system for comparing our
proposed work with the state-of-the-art techniques. This proposed approach
makes the reduction of the qubit cost possible, compared to the
state-of-the-art binary quantum systems. Further, with the help of newly
proposed ternary comparator, a substantial reduction in quantum gate count for
the ternary oracle circuit of the $k$-coloring problem than the previous
approaches has been obtained. An end-to-end automated framework has been put
forward for implementing the $k$-coloring problem for any undirected and
unweighted graph on any available Near-term quantum devices or Noisy
Intermediate-Scale Quantum (NISQ) devices or multi-valued quantum simulator,
which helps in generalizing our approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14286</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14286</id><submitter>Jianzheng Wang</submitter><version version="v1"><date>Sat, 29 May 2021 12:40:14 GMT</date><size>1274kb</size><source_type>D</source_type></version><title>Social Cost Optimization for Prosumer Community with Two Price-Package
  Incentives in Two-Settlement Based Electricity Market</title><authors>Jianzheng Wang and Guoqiang Hu</authors><categories>eess.SY cs.SY</categories><comments>15 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a future electricity market consisting of
aggregated energy prosumers, who are equipped with local wind power plants
(WPPs) to support (part of) their energy demands and can also trade energy with
day-ahead market (DAM) and energy balancing market (EBM). In addition, an
energy aggregator (EA) is established, who can provide the trading gateways
between prosumers and the markets. The EA is responsible for making pricing
strategies on the prosumers to influence their trading behaviours such that the
social benefit of the prosumer community is improved. Specifically, two price
packages are provided by the EA: wholesale price (WP) package and lump-sum (LS)
package, which can be flexibly selected by prosumers based on their own
preferences. Analytical energy-trading strategies will be derived for WP
prosumers and LS prosumers based on non-cooperative games and Nash resource
allocation strategies, respectively. In this work, a social cost optimization
problem will be formulated for the EA, where the detailed WP/LS selection plans
are unknown in advance. Consequently, a stochastic Stackelberg game between
prosumers and the EA is formulated, and a two-level stochastic convex
programming algorithm is proposed to minimize the expectation of the social
cost. The performance of the proposed algorithm is demonstrated with a
two-settlement based market model in the simulation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14289</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14289</id><submitter>Keqing He</submitter><version version="v1"><date>Sat, 29 May 2021 12:54:22 GMT</date><size>5450kb</size><source_type>D</source_type></version><title>Modeling Discriminative Representations for Out-of-Domain Detection with
  Supervised Contrastive Learning</title><authors>Zhiyuan Zeng, Keqing He, Yuanmeng Yan, Zijun Liu, Yanan Wu, Hong Xu,
  Huixing Jiang and Weiran Xu</authors><categories>cs.CL</categories><comments>Accepted by ACL2021</comments><journal-ref>ACL2021</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Detecting Out-of-Domain (OOD) or unknown intents from user queries is
essential in a task-oriented dialog system. A key challenge of OOD detection is
to learn discriminative semantic features. Traditional cross-entropy loss only
focuses on whether a sample is correctly classified, and does not explicitly
distinguish the margins between categories. In this paper, we propose a
supervised contrastive learning objective to minimize intra-class variance by
pulling together in-domain intents belonging to the same class and maximize
inter-class variance by pushing apart samples from different classes. Besides,
we employ an adversarial augmentation mechanism to obtain pseudo diverse views
of a sample in the latent space. Experiments on two public datasets prove the
effectiveness of our method capturing discriminative representations for OOD
detection.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14291</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14291</id><submitter>Zhaoxin Fan</submitter><version version="v1"><date>Sat, 29 May 2021 12:59:29 GMT</date><size>1628kb</size><source_type>D</source_type></version><title>Deep Learning on Monocular Object Pose Detection and Tracking: A
  Comprehensive Overview</title><authors>Zhaoxin Fan, Yazhi Zhu, Yulin He, Qi Sun, Hongyan Liu and Jun He</authors><categories>cs.CV</categories><comments>24 pages,8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object pose detection and tracking has recently attracted increasing
attention due to its wide applications in many areas, such as autonomous
driving, robotics, and augmented reality. Among methods for object pose
detection and tracking, deep learning is the most promising one that has shown
better performance than others. However, there is lack of survey study about
latest development of deep learning based methods. Therefore, this paper
presents a comprehensive review of recent progress in object pose detection and
tracking that belongs to the deep learning technical route. To achieve a more
thorough introduction, the scope of this paper is limited to methods taking
monocular RGB/RGBD data as input, covering three kinds of major tasks:
instance-level monocular object pose detection, category-level monocular object
pose detection, and monocular object pose tracking. In our work, metrics,
datasets, and methods about both detection and tracking are presented in
detail. Comparative results of current state-of-the-art methods on several
publicly available datasets are also presented, together with insightful
observations and inspiring future research directions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14295</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14295</id><submitter>Muhui Jiang</submitter><version version="v1"><date>Sat, 29 May 2021 13:14:24 GMT</date><size>1759kb</size><source_type>D</source_type></version><title>ECMO: Peripheral Transplantation to Rehost Embedded Linux Kernels</title><authors>Muhui Jiang, Lin Ma, Yajin Zhou, Qiang Liu, Cen Zhang, Zhi Wang, Xiapu
  Luo, Lei Wu, Kui Ren</authors><categories>cs.AR cs.CR cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic analysis based on the full-system emulator QEMU is widely used for
various purposes. However, it is challenging to run firmware images of embedded
devices in QEMU, especially theprocess to boot the Linux kernel (we call this
process rehosting the Linux kernel in this paper.) That's because embedded
devices usually use different system-on-chips (SoCs) from multiple vendors
andonly a limited number of SoCs are currently supported in QEMU.
  In this work, we propose a technique calledperipheral transplantation. The
main idea is to transplant the device drivers of designated peripherals into
the Linux kernel binary. By doing so, it can replace the peripherals in the
kernel that are currently unsupported in QEMU with supported ones, thus making
the Linux kernel rehostable. After that, various applications can be built
upon.
  We implemented this technique inside a prototype system called ECMO and
applied it to 824 firmware images, which consist of 17 kernel versions, 37
device models, and 24 vendors. The resultshows that ECMO can successfully
transplant peripherals for all the 824 Linux kernels. Among them, 719 kernels
can be successfully rehosted, i.e., launching a user-space shell (87.3% success
rate). The failed cases are mainly because the root file system format (ramfs)
is not supported by the kernel. We further build three applications, i.e.,
kernel crash analysis, rootkit forensic analysis, and kernel fuzzing, based on
the rehosted kernels to demonstrate the usage scenarios of ECMO.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14298</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14298</id><submitter>Dingding Wang</submitter><version version="v1"><date>Sat, 29 May 2021 13:33:52 GMT</date><size>462kb</size><source_type>D</source_type></version><title>A Measurement Study on the (In)security of End-of-Life (EoL) Embedded
  Devices</title><authors>Dingding Wang, Muhui Jiang, Rui Chang, Yajin Zhou, Baolei Hou, Xiapu
  Luo, Lei Wu, Kui Ren</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedded devices are becoming popular. Meanwhile, researchers are actively
working on improving the security of embedded devices. However, previous work
ignores the insecurity caused by a special category of devices, i.e., the
End-of-Life (EoL in short) devices. Once a product becomes End-of-Life, vendors
tend to no longer maintain its firmware or software, including providing bug
fixes and security patches. This makes EoL devices susceptible to attacks. For
instance, a report showed that an EoL model with thousands of active devices
was exploited to redirect web traffic for malicious purposes. In this paper, we
conduct the first measurement study to shed light on the (in)security of EoL
devices. To this end, our study performs two types of analysis, including the
aliveness analysis and the vulnerability analysis. The first one aims to detect
the scale of EoL devices that are still alive. The second one is to evaluate
the vulnerabilities existing in (active) EoL devices. We have applied our
approach to a large number of EoL models from three vendors (i.e., D-Link,
Tp-Link, and Netgear) and detect the alive devices in a time period of ten
months. Our study reveals some worrisome facts that were unknown by the
community. For instance, there exist more than 2 million active EoL devices.
Nearly 300,000 of them are still alive even after five years since they became
EoL. Although vendors may release security patches after the EoL date, however,
the process is ad hoc and incomplete. As a result, more than 1 million active
EoL devices are vulnerable, and nearly half of them are threatened by high-risk
vulnerabilities. Attackers can achieve a minimum of 2.79 Tbps DDoS attack by
compromising a large number of active EoL devices. We believe these facts pose
a clear call for more attention to deal with the security issues of EoL
devices.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14299</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14299</id><submitter>Jeffrey Ovall</submitter><version version="v1"><date>Sat, 29 May 2021 13:38:44 GMT</date><size>4087kb</size><source_type>D</source_type></version><title>An algorithm for identifying eigenvectors exhibiting strong spatial
  localization</title><authors>Jeffrey Ovall and Robyn Reid</authors><categories>math.NA cs.NA</categories><msc-class>65N25 (Primary), 35P15, 47A75 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an approach for exploring eigenvector localization phenomena for
a class of (unbounded) selfadjoint operators. More specifically, given a target
region and a tolerance, the algorithm identifies candidate eigenpairs for which
the eigenvector is expected to be localized in the target region to within that
tolerance. Theoretical results, together with detailed numerical illustrations
of them, are provided that support our algorithm. A partial realization of the
algorithm is described and tested, providing a proof of concept for the
approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14300</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14300</id><submitter>Zujie Liang</submitter><version version="v1"><date>Sat, 29 May 2021 13:48:11 GMT</date><size>1975kb</size><source_type>D</source_type></version><title>LPF: A Language-Prior Feedback Objective Function for De-biased Visual
  Question Answering</title><authors>Zujie Liang, Haifeng Hu and Jiaying Zhu</authors><categories>cs.CV cs.CL</categories><comments>Accepted by ACM SIGIR 2021</comments><doi>10.1145/3404835.3462981</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing Visual Question Answering (VQA) systems tend to overly rely on
language bias and hence fail to reason from the visual clue. To address this
issue, we propose a novel Language-Prior Feedback (LPF) objective function, to
re-balance the proportion of each answer's loss value in the total VQA loss.
The LPF firstly calculates a modulating factor to determine the language bias
using a question-only branch. Then, the LPF assigns a self-adaptive weight to
each training sample in the training process. With this reweighting mechanism,
the LPF ensures that the total VQA loss can be reshaped to a more balanced
form. By this means, the samples that require certain visual information to
predict will be efficiently used during training. Our method is simple to
implement, model-agnostic, and end-to-end trainable. We conduct extensive
experiments and the results show that the LPF (1) brings a significant
improvement over various VQA models, (2) achieves competitive performance on
the bias-sensitive VQA-CP v2 benchmark.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14301</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14301</id><submitter>Haozhe Shan</submitter><version version="v1"><date>Sat, 29 May 2021 13:50:03 GMT</date><size>5783kb</size><source_type>D</source_type></version><title>Rapid Feature Evolution Accelerates Learning in Neural Networks</title><authors>Haozhe Shan and Blake Bordelon</authors><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural network (NN) training and generalization in the infinite-width limit
are well-characterized by kernel methods with a neural tangent kernel (NTK)
that is stationary in time. However, finite-width NNs consistently outperform
corresponding kernel methods, suggesting the importance of feature learning,
which manifests as the time evolution of NTKs. Here, we analyze the phenomenon
of kernel alignment of the NTK with the target functions during gradient
descent. We first provide a mechanistic explanation for why alignment between
task and kernel occurs in deep linear networks. We then show that this behavior
occurs more generally if one optimizes the feature map over time to accelerate
learning while constraining how quickly the features evolve. Empirically,
gradient descent undergoes a feature learning phase, during which top
eigenfunctions of the NTK quickly align with the target function and the loss
decreases faster than power law in time; it then enters a kernel gradient
descent (KGD) phase where the alignment does not improve significantly and the
training loss decreases in power law. We show that feature evolution is faster
and more dramatic in deeper networks. We also found that networks with multiple
output nodes develop separate, specialized kernels for each output channel, a
phenomenon we termed kernel specialization. We show that this class-specific
alignment is does not occur in linear networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14304</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14304</id><submitter>Wenjing Liao</submitter><version version="v1"><date>Sat, 29 May 2021 13:57:11 GMT</date><size>638kb</size></version><title>Stability and Super-resolution of MUSIC and ESPRIT for Multi-snapshot
  Spectral Estimation</title><authors>Weilin Li, Zengying Zhu, Weiguo Gao, Wenjing Liao</authors><categories>cs.IT eess.SP math.IT</categories><comments>16 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the spectral estimation problem of estimating the
locations of a fixed number of point sources given multiple snapshots of
Fourier measurements collected by a uniform array of sensors. We prove novel
non-asymptotic stability bounds for MUSIC and ESPRIT as a function of the noise
standard deviation, number of snapshots, source amplitudes, and support. Our
most general result is a perturbation bound of the signal space in terms of the
minimum singular value of Fourier matrices. When the point sources are located
in several separated clumps, we provide an explicit upper bound of the
noise-space correlation perturbation error in MUSIC and the support error in
ESPRIT in terms of a Super-Resolution Factor (SRF). The upper bound for ESPRIT
is then compared with a new Cram\'er-Rao lower bound for the clumps model. As a
result, we show that ESPRIT is comparable to that of the optimal unbiased
estimator(s) in terms of the dependence on noise, number of snapshots and SRF.
As a byproduct of our analysis, we discover several fundamental differences
between the single-snapshot and multi-snapshot problems. Our theory is
validated by numerical experiments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14305</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14305</id><submitter>Ryuhei Uehara</submitter><version version="v1"><date>Sat, 29 May 2021 14:03:48 GMT</date><size>1520kb</size><source_type>D</source_type></version><title>Efficient Folding Algorithms for Regular Polyhedra</title><authors>Tonan Kamata, Akira Kadoguchi, Takashi Horiyama, and Ryuhei Uehara</authors><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the folding problem that asks if a polygon P can be folded to
a polyhedron Q for given P and Q. Recently, an efficient algorithm for this
problem has been developed when Q is a box. We extend this idea to regular
polyhedra, also known as Platonic solids. The basic idea of our algorithms is
common, which is called stamping. However, the computational complexities of
them are different depending on their geometric properties. We developed four
algorithms for the problem as follows. (1) An algorithm for a regular
tetrahedron, which can be extended to a tetramonohedron. (2) An algorithm for a
regular hexahedron (or a cube), which is much efficient than the previously
known one. (3) An algorithm for a general deltahedron, which contains the cases
that Q is a regular octahedron or a regular icosahedron. (4) An algorithm for a
regular dodecahedron. Combining these algorithms, we can conclude that the
folding problem can be solved pseudo-polynomial time when Q is a regular
polyhedron and other related solid.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14307</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14307</id><submitter>Neha Makhija</submitter><version version="v1"><date>Sat, 29 May 2021 14:21:38 GMT</date><size>3121kb</size><source_type>D</source_type></version><title>Towards a Dichotomy for Minimally Factorizing the Provenance of
  Self-Join Free Conjunctive Queries</title><authors>Neha Makhija, Wolfgang Gatterbauer</authors><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding the minimal-size factorization of the
provenance of self-join-free conjunctive queries, i.e., we want to find an
equivalent propositional formula that minimizes the number of variable
occurrences. Our work is partly motivated from probabilistic inference where
read-once formulas are known to allow exact PTIME solutions and non-read-once
formulas allow approximate solutions with an error that depends on the number
of repetitions of variables. We embark on the challenge of characterizing the
data complexity of this problem and show its connection to the query resilience
problem. While the problem is NP-complete in general, we develop an encoding as
max-flow problem that is guaranteed to give the exact solution for several
queries (and otherwise approximate minimizations). We show that our encoding is
guaranteed to return a read-once factorization if it exists. Our problem and
approach is a complete solution that naturally recovers exact solutions for all
known PTIME cases, as well as identifying additional queries for which the
problem can be solved in PTIME.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14309</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14309</id><submitter>Chao Feng</submitter><version version="v1"><date>Sat, 29 May 2021 14:25:20 GMT</date><size>156kb</size></version><title>A Simple Voting Mechanism for Online Sexist Content Identification</title><authors>Chao Feng</authors><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the participation of the MiniTrue team in the EXIST 2021
Challenge on the sexism detection in social media task for English and Spanish.
Our approach combines the language models with a simple voting mechanism for
the sexist label prediction. For this, three BERT based models and a voting
function are used. Experimental results show that our final model with the
voting function has achieved the best results among our four models, which
means that our voting mechanism brings an extra benefit to our system.
Nevertheless, we also observe that our system is robust to data sources and
languages.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14311</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14311</id><submitter>Mingshuai Chen</submitter><version version="v1"><date>Sat, 29 May 2021 14:35:55 GMT</date><size>6006kb</size><source_type>D</source_type></version><title>Synthesizing Invariant Barrier Certificates via Difference-of-Convex
  Programming</title><authors>Qiuye Wang, Mingshuai Chen, Bai Xue, Naijun Zhan and Joost-Pieter
  Katoen</authors><categories>cs.LO</categories><comments>To be published in Proc. of CAV 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  A barrier certificate often serves as an inductive invariant that isolates an
unsafe region from the reachable set of states, and hence is widely used in
proving safety of hybrid systems possibly over the infinite time horizon. We
present a novel condition on barrier certificates, termed the invariant
barrier-certificate condition, that witnesses unbounded-time safety of
differential dynamical systems. The proposed condition is by far the least
conservative one on barrier certificates, and can be shown as the weakest
possible one to attain inductive invariance. We show that discharging the
invariant barrier-certificate condition -- thereby synthesizing invariant
barrier certificates -- can be encoded as solving an optimization problem
subject to bilinear matrix inequalities (BMIs). We further propose a synthesis
algorithm based on difference-of-convex programming, which approaches a local
optimum of the BMI problem via solving a series of convex optimization
problems. This algorithm is incorporated in a branch-and-bound framework that
searches for the global optimum in a divide-and-conquer fashion. We present a
weak completeness result of our method, in the sense that a barrier certificate
is guaranteed to be found (under some mild assumptions) whenever there exists
an inductive invariant (in the form of a given template) that suffices to
certify safety of the system. Experimental results on benchmark examples
demonstrate the effectiveness and efficiency of our approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14313</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14313</id><submitter>Keqing He</submitter><version version="v1"><date>Sat, 29 May 2021 14:46:38 GMT</date><size>5494kb</size><source_type>D</source_type></version><title>Novel Slot Detection: A Benchmark for Discovering Unknown Slot Types in
  the Task-Oriented Dialogue System</title><authors>Yanan Wu, Zhiyuan Zeng, Keqing He, Hong Xu, Yuanmeng Yan, Huixing
  Jiang and Weiran Xu</authors><categories>cs.CL</categories><comments>Accepted by ACL2021</comments><journal-ref>ACL2021</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Existing slot filling models can only recognize pre-defined in-domain slot
types from a limited slot set. In the practical application, a reliable
dialogue system should know what it does not know. In this paper, we introduce
a new task, Novel Slot Detection (NSD), in the task-oriented dialogue system.
NSD aims to discover unknown or out-of-domain slot types to strengthen the
capability of a dialogue system based on in-domain training data. Besides, we
construct two public NSD datasets, propose several strong NSD baselines, and
establish a benchmark for future work. Finally, we conduct exhaustive
experiments and qualitative analysis to comprehend key challenges and provide
new guidance for future directions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14314</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14314</id><submitter>Yuanpeng Liu</submitter><version version="v1"><date>Sat, 29 May 2021 14:48:16 GMT</date><size>2950kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 16:06:47 GMT</date><size>2936kb</size><source_type>D</source_type></version><title>Automatic CT Segmentation from Bounding Box Annotations using
  Convolutional Neural Networks</title><authors>Yuanpeng Liu, Qinglei Hui, Zhiyi Peng, Shaolin Gong and Dexing Kong</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Accurate segmentation for medical images is important for clinical diagnosis.
Existing automatic segmentation methods are mainly based on fully supervised
learning and have an extremely high demand for precise annotations, which are
very costly and time-consuming to obtain. To address this problem, we proposed
an automatic CT segmentation method based on weakly supervised learning, by
which one could train an accurate segmentation model only with weak annotations
in the form of bounding boxes. The proposed method is composed of two steps: 1)
generating pseudo masks with bounding box annotations by k-means clustering,
and 2) iteratively training a 3D U-Net convolutional neural network as a
segmentation model. Some data pre-processing methods are used to improve
performance. The method was validated on four datasets containing three types
of organs with a total of 627 CT volumes. For liver, spleen and kidney
segmentation, it achieved an accuracy of 95.19%, 92.11%, and 91.45%,
respectively. Experimental results demonstrate that our method is accurate,
efficient, and suitable for clinical use.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14318</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14318</id><submitter>Shenhao Wang</submitter><version version="v1"><date>Sat, 29 May 2021 14:52:57 GMT</date><size>4101kb</size><source_type>D</source_type></version><title>Estimating air quality co-benefits of energy transition using machine
  learning</title><authors>Da Zhang, Qingyi Wang, Shaojie Song, Simiao Chen, Mingwei Li, Lu Shen,
  Siqi Zheng, Bofeng Cai, Shenhao Wang</authors><categories>econ.GN cs.LG q-fin.EC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating health benefits of reducing fossil fuel use from improved air
quality provides important rationales for carbon emissions abatement.
Simulating pollution concentration is a crucial step of the estimation, but
traditional approaches often rely on complicated chemical transport models that
require extensive expertise and computational resources. In this study, we
develop a novel and succinct machine learning framework that is able to provide
precise and robust annual average fine particle (PM2.5) concentration
estimations directly from a high-resolution fossil energy use data set. The
accessibility and applicability of this framework show great potentials of
machine learning approaches for integrated assessment studies. Applications of
the framework with Chinese data reveal highly heterogeneous health benefits of
reducing fossil fuel use in different sectors and regions in China with a mean
of \$34/tCO2 and a standard deviation of \$84/tCO2. Reducing rural and
residential coal use offers the highest co-benefits with a mean of \$360/tCO2.
Our findings prompt careful policy designs to maximize cost-effectiveness in
the transition towards a carbon-neutral energy system.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14320</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14320</id><submitter>Xi-Le Zhao</submitter><version version="v1"><date>Sat, 29 May 2021 14:56:51 GMT</date><size>17070kb</size><source_type>D</source_type></version><title>Self-Supervised Nonlinear Transform-Based Tensor Nuclear Norm for
  Multi-Dimensional Image Recovery</title><authors>Yi-Si Luo, Xi-Le Zhao, Tai-Xiang Jiang, Yi Chang, Michael K. Ng, and
  Chao Li</authors><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study multi-dimensional image recovery. Recently,
transform-based tensor nuclear norm minimization methods are considered to
capture low-rank tensor structures to recover third-order tensors in
multi-dimensional image processing applications. The main characteristic of
such methods is to perform the linear transform along the third mode of
third-order tensors, and then compute tensor nuclear norm minimization on the
transformed tensor so that the underlying low-rank tensors can be recovered.
The main aim of this paper is to propose a nonlinear multilayer neural network
to learn a nonlinear transform via the observed tensor data under
self-supervision. The proposed network makes use of low-rank representation of
transformed tensors and data-fitting between the observed tensor and the
reconstructed tensor to construct the nonlinear transformation. Extensive
experimental results on tensor completion, background subtraction, robust
tensor completion, and snapshot compressive imaging are presented to
demonstrate that the performance of the proposed method is better than that of
state-of-the-art methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14322</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14322</id><submitter>Wei Jan Ko</submitter><version version="v1"><date>Sat, 29 May 2021 15:01:52 GMT</date><size>6277kb</size><source_type>D</source_type></version><title>RPG: Learning Recursive Point Cloud Generation</title><authors>Wei-Jan Ko, Hui-Yu Huang, Yu-Liang Kuo, Chen-Yi Chiu, Li-Heng Wang,
  Wei-Chen Chiu</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we propose a novel point cloud generator that is able to
reconstruct and generate 3D point clouds composed of semantic parts. Given a
latent representation of the target 3D model, the generation starts from a
single point and gets expanded recursively to produce the high-resolution point
cloud via a sequence of point expansion stages. During the recursive procedure
of generation, we not only obtain the coarse-to-fine point clouds for the
target 3D model from every expansion stage, but also unsupervisedly discover
the semantic segmentation of the target model according to the
hierarchical/parent-child relation between the points across expansion stages.
Moreover, the expansion modules and other elements used in our recursive
generator are mostly sharing weights thus making the overall framework light
and efficient. Extensive experiments are conducted to demonstrate that our
proposed point cloud generator has comparable or even superior performance on
both generation and reconstruction tasks in comparison to various baselines, as
well as provides the consistent co-segmentation among 3D instances of the same
object class.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14326</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14326</id><submitter>Shriya Gupta</submitter><version version="v1"><date>Sat, 29 May 2021 15:28:30 GMT</date><size>2269kb</size><source_type>D</source_type></version><title>Implementing a foveal-pit inspired filter in a Spiking Convolutional
  Neural Network: a preliminary study</title><authors>Shriya T.P. Gupta, Basabdatta Sen Bhattacharya</authors><categories>cs.CV cs.AI</categories><comments>8 pages, 8 figures, 4 tables. 2020 International Joint Conference on
  Neural Networks (IJCNN)</comments><acm-class>I.2.10; I.4.5; I.4.10</acm-class><doi>10.1109/IJCNN48605.2020.9207612</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We have presented a Spiking Convolutional Neural Network (SCNN) that
incorporates retinal foveal-pit inspired Difference of Gaussian filters and
rank-order encoding. The model is trained using a variant of the
backpropagation algorithm adapted to work with spiking neurons, as implemented
in the Nengo library. We have evaluated the performance of our model on two
publicly available datasets - one for digit recognition task, and the other for
vehicle recognition task. The network has achieved up to 90% accuracy, where
loss is calculated using the cross-entropy function. This is an improvement
over around 57% accuracy obtained with the alternate approach of performing the
classification without any kind of neural filtering. Overall, our
proof-of-concept study indicates that introducing biologically plausible
filtering in existing SCNN architecture will work well with noisy input images
such as those in our vehicle recognition task. Based on our results, we plan to
enhance our SCNN by integrating lateral inhibition-based redundancy reduction
prior to rank-ordering, which will further improve the classification accuracy
by the network.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14327</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14327</id><submitter>Weihuan Deng</submitter><version version="v1"><date>Sat, 29 May 2021 15:39:03 GMT</date><size>2044kb</size></version><title>A Spectral-Spatial-Dependent Global Learning Framework for Insufficient
  and Imbalanced Hyperspectral Image Classification</title><authors>Qiqi Zhu, Weihuan Deng, Zhuo Zheng, Yanfei Zhong, Qingfeng Guan,
  Weihua Lin, Liangpei Zhang, and Deren Li</authors><categories>cs.CV</categories><comments>14 pages,14 figures</comments><doi>10.1109/TCYB.2021.3070577</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning techniques have been widely applied to hyperspectral image
(HSI) classification and have achieved great success. However, the deep neural
network model has a large parameter space and requires a large number of
labeled data. Deep learning methods for HSI classification usually follow a
patchwise learning framework. Recently, a fast patch-free global learning
(FPGA) architecture was proposed for HSI classification according to global
spatial context information. However, FPGA has difficulty extracting the most
discriminative features when the sample data is imbalanced. In this paper, a
spectral-spatial dependent global learning (SSDGL) framework based on global
convolutional long short-term memory (GCL) and global joint attention mechanism
(GJAM) is proposed for insufficient and imbalanced HSI classification. In
SSDGL, the hierarchically balanced (H-B) sampling strategy and the weighted
softmax loss are proposed to address the imbalanced sample problem. To
effectively distinguish similar spectral characteristics of land cover types,
the GCL module is introduced to extract the long short-term dependency of
spectral features. To learn the most discriminative feature representations,
the GJAM module is proposed to extract attention areas. The experimental
results obtained with three public HSI datasets show that the SSDGL has
powerful performance in insufficient and imbalanced sample problems and is
superior to other state-of-the-art methods. Code can be obtained at:
https://github.com/dengweihuan/SSDGL.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14328</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14328</id><submitter>Ye Tian</submitter><version version="v1"><date>Sat, 29 May 2021 15:39:43 GMT</date><size>969kb</size><source_type>D</source_type></version><title>Transfer Learning under High-dimensional Generalized Linear Models</title><authors>Ye Tian and Yang Feng</authors><categories>stat.ML cs.LG stat.ME</categories><comments>52 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the transfer learning problem under high-dimensional
generalized linear models (GLMs), which aim to improve the fit on target data
by borrowing information from useful source data. Given which sources to
transfer, we propose an oracle algorithm and derive its $\ell_2$-estimation
error bounds. The theoretical analysis shows that under certain conditions,
when the target and source are sufficiently close to each other, the estimation
error bound could be improved over that of the classical penalized estimator
using only target data. When we don't know which sources to transfer, an
algorithm-free transferable source detection approach is introduced to detect
informative sources. The detection consistency is proved under the
high-dimensional GLM transfer learning setting. Extensive simulations and a
real-data experiment verify the effectiveness of our algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14329</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14329</id><submitter>Gerrit Gro{\ss}mann</submitter><version version="v1"><date>Sat, 29 May 2021 15:42:33 GMT</date><size>436kb</size><source_type>D</source_type></version><title>GINA: Neural Relational Inference From Independent Snapshots</title><authors>Gerrit Gro{\ss}mann, Julian Zimmerlin, Michael Backenk\&quot;ohler, Verena
  Wolf</authors><categories>cs.LG cs.AI cs.IR cs.MA physics.soc-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Dynamical systems in which local interactions among agents give rise to
complex emerging phenomena are ubiquitous in nature and society. This work
explores the problem of inferring the unknown interaction structure
(represented as a graph) of such a system from measurements of its constituent
agents or individual components (represented as nodes). We consider a setting
where the underlying dynamical model is unknown and where different
measurements (i.e., snapshots) may be independent (e.g., may stem from
different experiments). We propose GINA (Graph Inference Network Architecture),
a graph neural network (GNN) to simultaneously learn the latent interaction
graph and, conditioned on the interaction graph, the prediction of a node's
observable state based on adjacent vertices. GINA is based on the hypothesis
that the ground truth interaction graph -- among all other potential graphs --
allows to predict the state of a node, given the states of its neighbors, with
the highest accuracy. We test this hypothesis and demonstrate GINA's
effectiveness on a wide range of interaction graphs and dynamical processes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14331</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14331</id><submitter>Shriya Gupta</submitter><version version="v1"><date>Sat, 29 May 2021 16:01:39 GMT</date><size>4559kb</size><source_type>D</source_type></version><title>Foveal-pit inspired filtering of DVS spike response</title><authors>Shriya T.P. Gupta, Pablo Linares-Serrano, Basabdatta Sen Bhattacharya,
  Teresa Serrano-Gotarredona</authors><categories>cs.CV cs.AI cs.AR</categories><comments>6 pages, 4 figures, 2 tables. 2021 55th Annual Conference on
  Information Sciences and Systems (CISS), 2021</comments><acm-class>I.2.10; I.4.5; I.4.10</acm-class><doi>10.1109/CISS50987.2021.9400245</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we present results of processing Dynamic Vision Sensor (DVS)
recordings of visual patterns with a retinal model based on foveal-pit inspired
Difference of Gaussian (DoG) filters. A DVS sensor was stimulated with varying
number of vertical white and black bars of different spatial frequencies moving
horizontally at a constant velocity. The output spikes generated by the DVS
sensor were applied as input to a set of DoG filters inspired by the receptive
field structure of the primate visual pathway. In particular, these filters
mimic the receptive fields of the midget and parasol ganglion cells (spiking
neurons of the retina) that sub-serve the photo-receptors of the foveal-pit.
The features extracted with the foveal-pit model are used for further
classification using a spiking convolutional neural network trained with a
backpropagation variant adapted for spiking neural networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14333</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14333</id><submitter>Dinesh J</submitter><version version="v1"><date>Sat, 29 May 2021 16:12:15 GMT</date><size>259kb</size></version><title>Covid-19 diagnosis from x-ray using neural networks</title><authors>Dinesh J and Mohammed Rhithick A</authors><categories>eess.IV cs.CV cs.LG</categories><comments>3 Graphs, 1 Figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Corona virus or COVID-19 is a pandemic illness, which has influenced more
than million of causalities worldwide and infected a few large number of
individuals .Innovative instrument empowering quick screening of the COVID-19
contamination with high precision can be critically useful to the medical care
experts. The primary clinical device presently being used for the analysis of
COVID-19 is the Reverse record polymerase chain response as known as RT-PCR,
which is costly, less-delicate and requires specific clinical work force. X-Ray
imaging is an effectively available apparatus that can be a great option in the
COVID-19 conclusion. This exploration was taken to examine the utility of
computerized reasoning in the quick and exact recognition of COVID-19 from
chest X-Ray pictures. The point of this paper is to propose a procedure for
programmed recognition of COVID-19 from advanced chest X-Ray images applying
pre-prepared profound learning calculations while boosting the discovery
exactness. The point is to give over-focused on clinical experts a second pair
of eyes through a learning picture characterization models. We distinguish an
appropriate Convolutional Neural Network-CNN model through beginning similar
investigation of a few mainstream CNN models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14337</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14337</id><submitter>Diego Gonz\'alez-S\'anchez</submitter><version version="v1"><date>Sat, 29 May 2021 16:37:31 GMT</date><size>1026kb</size></version><title>Optimal transport with $f$-divergence regularization and generalized
  Sinkhorn algorithm</title><authors>D\'avid Terj\'ek (1) and Diego Gonz\'alez-S\'anchez (1) ((1) Alfr\'ed
  R\'enyi Institute of Mathematics)</authors><categories>math.OC cs.IT cs.LG math.FA math.IT stat.ML</categories><comments>30 pages, 2 figures</comments><msc-class>49K30 (Primary), 49Q22, 49M29 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entropic regularization provides a generalization of the original optimal
transport problem. It introduces a penalty term defined by the Kullback-Leibler
divergence, making the problem more tractable via the celebrated Sinkhorn
algorithm. Replacing the Kullback-Leibler divergence with a general
$f$-divergence leads to a natural generalization. Using convex analysis, we
extend the theory developed so far to include $f$-divergences defined by
functions of Legendre type, and prove that under some mild conditions, strong
duality holds, optimums in both the primal and dual problems are attained, the
generalization of the $c$-transform is well-defined, and we give sufficient
conditions for the generalized Sinkhorn algorithm to converge to an optimal
solution. We propose a practical algorithm for computing the regularized
optimal transport cost and its gradient via the generalized Sinkhorn algorithm.
Finally, we present experimental results on synthetic 2-dimensional data,
demonstrating the effects of using different $f$-divergences for
regularization, which influences convergence speed, numerical stability and
sparsity of the optimal coupling.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14338</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14338</id><submitter>Gianluca Gerard</submitter><version version="v1"><date>Sat, 29 May 2021 16:42:12 GMT</date><size>2941kb</size><source_type>D</source_type></version><title>Conditional Deep Convolutional Neural Networks for Improving the
  Automated Screening of Histopathological Images</title><authors>Gianluca Gerard, Marco Piastra</authors><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Semantic segmentation of breast cancer metastases in histopathological slides
is a challenging task. In fact, significant variation in data characteristics
of histopathology images (domain shift) make generalization of deep learning to
unseen data difficult. Our goal is to address this challenge by using a
conditional Fully Convolutional Network (co-FCN) whose output can be
conditioned at run time, and which can improve its performance when a properly
selected set of reference slides are used to condition the output. We adapted
to our task a co-FCN originally applied to organs segmentation in volumetric
medical images and we trained it on the Whole Slide Images (WSIs) from three
out of five medical centers present in the CAMELYON17 dataset. We tested the
performance of the network on the WSIs of the remaining centers. We also
developed an automated selection strategy for selecting the conditioning
subset, based on an unsupervised clustering process applied to a
target-specific set of reference patches, followed by a selection policy that
relies on the cluster similarities with the input patch. We benchmarked our
proposed method against a U-Net trained on the same dataset with no
conditioning. The conditioned network shows better performance that the U-Net
on the WSIs with Isolated Tumor Cells and micro-metastases from the medical
centers used as test. Our contributions are an architecture which can be
applied to the histopathology domain and an automated procedure for the
selection of conditioning data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14344</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14344</id><submitter>Yaniv Agman</submitter><version version="v1"><date>Sat, 29 May 2021 17:28:32 GMT</date><size>278kb</size><source_type>D</source_type></version><title>BPFroid: Robust Real Time Android Malware Detection Framework</title><authors>Yaniv Agman (1), Danny Hendler (1) ((1) Department of Computer
  Science, Ben-Gurion University of The Negev, Beer Sheva, Israel)</authors><categories>cs.CR</categories><comments>22 pages, 7 figures, submitted to ieee access</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present BPFroid -- a novel dynamic analysis framework for Android that
uses the eBPF technology of the Linux kernel to continuously monitor events of
user applications running on a real device. The monitored events are collected
from different components of the Android software stack: internal kernel
functions, system calls, native library functions, and the Java API framework.
As BPFroid hooks these events in the kernel, a malware is unable to trivially
bypass monitoring. Moreover, using eBPF doesn't require any change to the
Android system or the monitored applications. We also present an analytical
comparison of BPFroid to other malware detection methods and demonstrate its
usage by developing novel signatures to detect suspicious behavior that are
based on it. These signatures are then evaluated using real apps. We also
demonstrate how BPFroid can be used to capture forensic artifacts for further
investigation. Our results show that BPFroid successfully alerts in real time
when a suspicious behavioral signature is detected, without incurring a
significant runtime performance overhead.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14347</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14347</id><submitter>Peratham Wiriyathammabhum Mr.</submitter><version version="v1"><date>Sat, 29 May 2021 17:51:02 GMT</date><size>26kb</size></version><title>Is Sluice Resolution really just Question Answering?</title><authors>Peratham Wiriyathammabhum</authors><categories>cs.CL cs.AI</categories><comments>Extended Abstract at the The First Workshop on Understanding Implicit
  and Underspecified Language @ ACL-2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Sluice resolution is a problem where a system needs to output the
corresponding antecedents of wh-ellipses. The antecedents are elided contents
behind the wh-words but are implicitly referred to using contexts. Previous
work frames sluice resolution as question answering where this setting
outperforms all its preceding works by large margins. Ellipsis and questions
are referentially dependent expressions (anaphoras) and retrieving the
corresponding antecedents are like answering questions to output pieces of
clarifying information. However, the task is not fully solved. Therefore, we
want to further investigate what makes sluice resolution differ to question
answering and fill in the error gaps. We also present some results using recent
state-of-the-art question answering systems which improve the previous work
(86.01 to 90.39 F1).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14351</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14351</id><submitter>Mohsen Shahhosseini</submitter><version version="v1"><date>Sat, 29 May 2021 18:25:07 GMT</date><size>963kb</size></version><title>Corn Yield Prediction with Ensemble CNN-DNN</title><authors>Mohsen Shahhosseini, Guiping Hu, Saeed Khaki, Sotirios V. Archontoulis</authors><categories>q-bio.QM cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We investigate the predictive performance of two novel CNN-DNN machine
learning ensemble models in predicting county-level corn yields across the US
Corn Belt (12 states). The developed data set is a combination of management,
environment, and historical corn yields from 1980-2019. Two scenarios for
ensemble creation are considered: homogenous and heterogeneous ensembles. In
homogenous ensembles, the base CNN-DNN models are all the same, but they are
generated with a bagging procedure to ensure they exhibit a certain level of
diversity. Heterogenous ensembles are created from different base CNN-DNN
models which share the same architecture but have different levels of depth.
Three types of ensemble creation methods were used to create several ensembles
for either of the scenarios: Basic Ensemble Method (BEM), Generalized Ensemble
Method (GEM), and stacked generalized ensembles. Results indicated that both
designed ensemble types (heterogenous and homogenous) outperform the ensembles
created from five individual ML models (linear regression, LASSO, random
forest, XGBoost, and LightGBM). Furthermore, by introducing improvements over
the heterogeneous ensembles, the homogenous ensembles provide the most accurate
yield predictions across US Corn Belt states. This model could make 2019 yield
predictions with a root mean square error of 866 kg/ha, equivalent to 8.5%
relative root mean square, and could successfully explain about 77% of the
spatio-temporal variation in the corn grain yields. The significant predictive
power of this model can be leveraged for designing a reliable tool for corn
yield prediction which will, in turn, assist agronomic decision-makers.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14352</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14352</id><submitter>Rafael Ferreira da Silva</submitter><version version="v1"><date>Sat, 29 May 2021 18:31:14 GMT</date><size>1290kb</size><source_type>D</source_type></version><title>WfCommons: A Framework for Enabling Scientific Workflow Research and
  Development</title><authors>Tain\~a Coleman, Henri Casanova, Lo\&quot;ic Pottier, Manav Kaushik, Ewa
  Deelman, Rafael Ferreira da Silva</authors><categories>cs.DC</categories><comments>arXiv admin note: substantial text overlap with arXiv:2009.00250</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scientific workflows are a cornerstone of modern scientific computing. They
are used to describe complex computational applications that require efficient
and robust management of large volumes of data, which are typically
stored/processed on heterogeneous, distributed resources. The workflow research
and development community has employed a number of methods for the quantitative
evaluation of existing and novel workflow algorithms and systems. In
particular, a common approach is to simulate workflow executions. In previous
works, we have presented a collection of tools that have been adopted by the
community for conducting workflow research. Despite their popularity, they
suffer from several shortcomings that prevent easy adoption, maintenance, and
consistency with the evolving structures and computational requirements of
production workflows. In this work, we present WfCommons, a framework that
provides a collection of tools for analyzing workflow executions, for producing
generators of synthetic workflows, and for simulating workflow executions. We
demonstrate the realism of the generated synthetic workflows by comparing their
simulated executions to real workflow executions. We also contrast these
results with results obtained when using the previously available collection of
tools. We find that the workflow generators that are automatically constructed
by our framework not only generate representative same-scale workflows (i.e.,
with structures and task characteristics distributions that resemble those
observed in real-world workflows), but also do so at scales larger than that of
available real-world workflows. Finally, we conduct a case study to demonstrate
the usefulness of our framework for estimating the energy consumption of
large-scale workflow executions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14353</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14353</id><submitter>Vincenzo Gulizzi</submitter><version version="v1"><date>Sat, 29 May 2021 18:45:58 GMT</date><size>16630kb</size><source_type>D</source_type></version><title>A coupled discontinuous Galerkin-Finite Volume framework for solving gas
  dynamics over embedded geometries</title><authors>Vincenzo Gulizzi, Ann S. Almgren, John B. Bell</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a computational framework for solving the equations of inviscid
gas dynamics using structured grids with embedded geometries. The novelty of
the proposed approach is the use of high-order discontinuous Galerkin (dG)
schemes and a shock-capturing Finite Volume (FV) scheme coupled via an $hp$
adaptive mesh refinement ($hp$-AMR) strategy that offers high-order accurate
resolution of the embedded geometries. The $hp$-AMR strategy is based on a
multi-level block-structured domain partition in which each level is
represented by block-structured Cartesian grids and the embedded geometry is
represented implicitly by a level set function. The intersection of the
embedded geometry with the grids produces the implicitly-defined mesh that
consists of a collection of regular rectangular cells plus a relatively small
number of irregular curved elements in the vicinity of the embedded boundaries.
High-order quadrature rules for implicitly-defined domains enable high-order
accuracy resolution of the curved elements with a cell-merging strategy to
address the small-cell problem. The $hp$-AMR algorithm treats the system with a
second-order finite volume scheme at the finest level to dynamically track the
evolution of solution discontinuities while using dG schemes at coarser levels
to provide high-order accuracy in smooth regions of the flow. On the dG levels,
the methodology supports different orders of basis functions on different
levels. The space-discretized governing equations are then advanced explicitly
in time using high-order Runge-Kutta algorithms. Numerical tests are presented
for two-dimensional and three-dimensional problems involving an ideal gas. The
results are compared with both analytical solutions and experimental
observations and demonstrate that the framework provides high-order accuracy
for smooth flows and accurately captures solution discontinuities.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14355</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14355</id><submitter>Jhacson Meza</submitter><version version="v1"><date>Sat, 29 May 2021 18:50:00 GMT</date><size>7972kb</size><source_type>D</source_type></version><title>Three-dimensional multimodal medical imaging system based on free-hand
  ultrasound and structured light</title><authors>Jhacson Meza, Sonia H. Contreras-Ortiz, Lenny A. Romero, Andres G.
  Marrugo</authors><categories>cs.CV eess.IV</categories><journal-ref>Optical Engineering 60(5), 054106 (2021)</journal-ref><doi>10.1117/1.OE.60.5.054106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a three-dimensional (3D) multimodal medical imaging system that
combines freehand ultrasound and structured light 3D reconstruction in a single
coordinate system without requiring registration. To the best of our knowledge,
these techniques have not been combined before as a multimodal imaging
technique. The system complements the internal 3D information acquired with
ultrasound, with the external surface measured with the structure light
technique. Moreover, the ultrasound probe's optical tracking for pose
estimation was implemented based on a convolutional neural network.
Experimental results show the system's high accuracy and reproducibility, as
well as its potential for preoperative and intraoperative applications. The
experimental multimodal error, or the distance from two surfaces obtained with
different modalities, was 0.12 mm. The code is available as a Github
repository.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14357</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14357</id><submitter>Kuntal Kumar Pal</submitter><version version="v1"><date>Sat, 29 May 2021 19:06:35 GMT</date><size>5598kb</size><source_type>D</source_type></version><title>Constructing Flow Graphs from Procedural Cybersecurity Texts</title><authors>Kuntal Kumar Pal, Kazuaki Kashihara, Pratyay Banerjee, Swaroop Mishra,
  Ruoyu Wang, Chitta Baral</authors><categories>cs.CL cs.AI cs.CR</categories><comments>13 pages, 5 pages, accepted in the Findings of ACL 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Following procedural texts written in natural languages is challenging. We
must read the whole text to identify the relevant information or identify the
instruction flows to complete a task, which is prone to failures. If such texts
are structured, we can readily visualize instruction-flows, reason or infer a
particular step, or even build automated systems to help novice agents achieve
a goal. However, this structure recovery task is a challenge because of such
texts' diverse nature. This paper proposes to identify relevant information
from such texts and generate information flows between sentences. We built a
large annotated procedural text dataset (CTFW) in the cybersecurity domain
(3154 documents). This dataset contains valuable instructions regarding
software vulnerability analysis experiences. We performed extensive experiments
on CTFW with our LM-GNN model variants in multiple settings. To show the
generalizability of both this task and our method, we also experimented with
procedural texts from two other domains (Maintenance Manual and Cooking), which
are substantially different from cybersecurity. Our experiments show that Graph
Convolution Network with BERT sentence embeddings outperforms BERT in all three
domains
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14359</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14359</id><submitter>Ahmed Elzanaty Dr.</submitter><version version="v1"><date>Sat, 29 May 2021 19:22:59 GMT</date><size>3853kb</size></version><title>Green Tethered UAVs for EMF-Aware Cellular Networks</title><authors>Zhengying Lou and Ahmed Elzanaty and Mohamed-Slim Alouini</authors><categories>eess.SP cs.NI</categories><comments>30 pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  A prevalent theory circulating among the non-scientific community is that the
intensive deployment of base stations over the territory significantly
increases the level of electromagnetic field (EMF) exposure and affects
population health. To alleviate this concern, in this work, we propose a
network architecture that introduces tethered unmanned aerial vehicles (TUAVs)
carrying green antennas to minimize the EMF exposure while guaranteeing a high
data rate for users. In particular, each TUAV can attach itself to one of the
possible ground stations at the top of some buildings. The location of the
TUAVs, transmit power of user equipment and association policy are optimized to
minimize the EMF exposure. Unfortunately, the problem turns out to be
mixed-integer non-linear programming (MINLP), which is non-deterministic
polynomial-time (NP) hard. We propose an efficient low-complexity algorithm
composed of three submodules. Firstly, we propose an algorithm based on the
greedy principle to determine the optimal association matrix between the users
and base stations. Then, we offer two approaches, a modified K-mean and shrink
and realign (SR) process, to associate each TUAV with a ground station.
Finally, we put forward two algorithms based on the golden search and SR
process to adjust the TUAV's position within the hovering area over the
building. After that, we consider the dual problem that maximizes the sum rate
while keeping the exposure below a predefined value, such as the level enforced
by the regulation. Next, we perform extensive simulations to show the
effectiveness of the proposed TUAVs to reduce the exposure compared to various
architectures. Eventually, we show that TUAVs with green antennas can
effectively mitigate the EMF exposure by more than 20% compared to fixed green
small cells while achieving a higher data rate.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14362</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14362</id><submitter>Alberto Garcia-Robledo Ph.D.</submitter><version version="v1"><date>Sat, 29 May 2021 19:39:18 GMT</date><size>43924kb</size><source_type>D</source_type></version><title>Dash Sylvereye: A WebGL-powered Library for Dashboard-driven
  Visualization of Large Street Networks</title><authors>Alberto Garcia-Robledo and Mahboobeh Zangiabady</authors><categories>cs.HC</categories><comments>Submitted to IEEE Access on May 8, 2021</comments><acm-class>H.5.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  State-of-the-art open network visualization tools like Gephi, KeyLines, and
Cytoscape are not suitable for studying street networks with thousands of roads
since they do not support simultaneously polylines for edges, navigable maps,
GPU-accelerated rendering, interactivity, and the means for visualizing
multivariate data. The present paper presents Dash Sylvereye: a new Python
library to produce interactive visualizations of primal street networks on top
of tiled web maps to fill this gap. Dash Sylvereye can render large street
graphs in commodity computers by exploiting WebGL for GPU acceleration. Dash
Sylvereye also provides convenient functions to easily import OpenStreetMap
street topologies obtained with the OSMnx library. Thanks to its integration
with the Dash framework, Dash Sylvereye can be used to develop web dashboards
around temporal and multivariate street data by coordinating the various
elements of a Dash Sylvereye visualization with other plotting and UI
components provided by Dash. We conduct experiments to assess the performance
of Dash Sylvereye on a commodity computer in terms of animation CPU time and
frames per second. To further illustrate the features of Dash Sylvereye, we
also describe a web dashboard application that exploits Dash Sylvereye for the
analysis of a SUMO vehicle traffic simulation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14363</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14363</id><submitter>Niladri Chatterji</submitter><version version="v1"><date>Sat, 29 May 2021 19:48:51 GMT</date><size>168kb</size><source_type>D</source_type></version><title>On the Theory of Reinforcement Learning with Once-per-Episode Feedback</title><authors>Niladri S. Chatterji, Aldo Pacchiano, Peter L. Bartlett, Michael I.
  Jordan</authors><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a theory of reinforcement learning (RL) in which the learner
receives feedback only once at the end of an episode. While this is an extreme
test case for theory, it is also arguably more representative of real-world
applications than the traditional requirement in RL practice that the learner
receive feedback at every time step. Indeed, in many real-world applications of
reinforcement learning, such as self-driving cars and robotics, it is easier to
evaluate whether a learner's complete trajectory was either &quot;good&quot; or &quot;bad,&quot;
but harder to provide a reward signal at each step. To show that learning is
possible in this more challenging setting, we study the case where trajectory
labels are generated by an unknown parametric model, and provide a
statistically and computationally efficient algorithm that achieves sub-linear
regret.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14364</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14364</id><submitter>Corinna Coupette</submitter><version version="v1"><date>Sat, 29 May 2021 19:55:27 GMT</date><size>1096kb</size><source_type>D</source_type></version><title>Graph Similarity Description: How Are These Graphs Similar?</title><authors>Corinna Coupette, Jilles Vreeken</authors><categories>cs.SI cs.IT cs.LG math.IT</categories><comments>27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
  (KDD 2021); 9+2 pages, 9+4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  How do social networks differ across platforms? How do information networks
change over time? Answering questions like these requires us to compare two or
more graphs. This task is commonly treated as a measurement problem, but
numerical answers give limited insight. Here, we argue that if the goal is to
gain understanding, we should treat graph similarity assessment as a
description problem instead. We formalize this problem as a model selection
task using the Minimum Description Length principle, capturing the similarity
of the input graphs in a common model and the differences between them in
transformations to individual models. To discover good models, we propose Momo,
which breaks the problem into two parts and introduces efficient algorithms for
each. Through an extensive set of experiments on a wide range of synthetic and
real-world graphs, we confirm that Momo works well in practice.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14367</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14367</id><submitter>Mazharul Islam</submitter><version version="v1"><date>Sat, 29 May 2021 20:09:25 GMT</date><size>1898kb</size><source_type>D</source_type></version><title>Deconvolutional Density Network: Free-Form Conditional Density
  Estimation</title><authors>Bing Chen, Mazharul Islam, Lin Wang, Jisuo Gao and Jeff Orchard</authors><categories>cs.LG stat.ML</categories><comments>11 pages, 5 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional density estimation is the task of estimating the probability of
an event, conditioned on some inputs. A neural network can be used to compute
the output distribution explicitly. For such a task, there are many ways to
represent a continuous-domain distribution using the output of a neural
network, but each comes with its own limitations for what distributions it can
accurately render. If the family of functions is too restrictive, it will not
be appropriate for many datasets. In this paper, we demonstrate the benefits of
modeling free-form distributions using deconvolution. It has the advantage of
being flexible, but also takes advantage of the topological smoothness offered
by the deconvolution layers. We compare our method to a number of other
density-estimation approaches, and show that our Deconvolutional Density
Network (DDN) outperforms the competing methods on many artificial and real
tasks, without committing to a restrictive parametric model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14368</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14368</id><submitter>Mikhail Belkin</submitter><version version="v1"><date>Sat, 29 May 2021 20:15:53 GMT</date><size>1357kb</size><source_type>D</source_type></version><title>Fit without fear: remarkable mathematical phenomena of deep learning
  through the prism of interpolation</title><authors>Mikhail Belkin</authors><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>A version of this paper will appear in Acta Numerica</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the past decade the mathematical theory of machine learning has lagged far
behind the triumphs of deep neural networks on practical challenges. However,
the gap between theory and practice is gradually starting to close. In this
paper I will attempt to assemble some pieces of the remarkable and still
incomplete mathematical mosaic emerging from the efforts to understand the
foundations of deep learning. The two key themes will be interpolation, and its
sibling, over-parameterization. Interpolation corresponds to fitting data, even
noisy data, exactly. Over-parameterization enables interpolation and provides
flexibility to select a right interpolating model.
  As we will see, just as a physical prism separates colors mixed within a ray
of light, the figurative prism of interpolation helps to disentangle
generalization and optimization properties within the complex picture of modern
Machine Learning. This article is written with belief and hope that clearer
understanding of these issues brings us a step closer toward a general theory
of deep learning and machine learning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14369</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14369</id><submitter>Walter Forkel</submitter><version version="v1"><date>Sat, 29 May 2021 20:20:13 GMT</date><size>146kb</size><source_type>D</source_type></version><title>Temporal Minimal-World Semantics for Sparse ABoxes</title><authors>Stefan Borgwardt, Walter Forkel, Alisa Kovtunova</authors><categories>cs.DB cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontology-mediated query answering is a popular paradigm for enriching answers
to user queries with background knowledge. For querying the absence of
information, however, there exist only few ontology-based approaches. Moreover,
these proposals conflate the closed-domain and closed-world assumption, and
therefore are not suited to deal with the anonymous objects that are common in
ontological reasoning. Many real-world applications, like processing electronic
health records (EHRs), also contain a temporal dimension, and require efficient
reasoning algorithms. Moreover, since medical data is not recorded on a regular
basis, reasoners must deal with sparse data with potentially large temporal
gaps. Our contribution consists of two main parts: In the first part we
introduce a new closed-world semantics for answering conjunctive queries with
negation over ontologies formulated in the description logic ELHb, which is
based on the minimal canonical model. We propose a rewriting strategy for
dealing with negated query atoms, which shows that query answering is possible
in polynomial time in data complexity. In the second part, we extend this
minimal-world semantics for answering metric temporal conjunctive queries with
negation over the lightweight temporal logic TELHb and obtain similar
rewritability and complexity results. This paper is under consideration in
Theory and Practice of Logic Programming (TPLP).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14370</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14370</id><submitter>Ma Bing</submitter><version version="v1"><date>Sat, 29 May 2021 20:40:55 GMT</date><size>9365kb</size><source_type>D</source_type></version><title>BAAI-VANJEE Roadside Dataset: Towards the Connected Automated Vehicle
  Highway technologies in Challenging Environments of China</title><authors>Deng Yongqiang, Wang Dengjiang, Cao Gang, Ma Bing, Guan Xijia, Wang
  Yajun, Liu Jianchao, Fang Yanming, Li Juanjuan</authors><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As the roadside perception plays an increasingly significant role in the
Connected Automated Vehicle Highway(CAVH) technologies, there are immediate
needs of challenging real-world roadside datasets for bench marking and
training various computer vision tasks such as 2D/3D object detection and
multi-sensor fusion. In this paper, we firstly introduce a challenging
BAAI-VANJEE roadside dataset which consist of LiDAR data and RGB images
collected by VANJEE smart base station placed on the roadside about 4.5m high.
This dataset contains 2500 frames of LiDAR data, 5000 frames of RGB images,
including 20% collected at the same time. It also contains 12 classes of
objects, 74K 3D object annotations and 105K 2D object annotations. By providing
a real complex urban intersections and highway scenes, we expect the
BAAI-VANJEE roadside dataset will actively assist the academic and industrial
circles to accelerate the innovation research and achievement transformation in
the field of intelligent transportation in big data era.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14371</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14371</id><submitter>Bahare Salmani</submitter><version version="v1"><date>Sat, 29 May 2021 20:41:56 GMT</date><size>1649kb</size><source_type>D</source_type></version><title>Fine-Tuning the Odds in Bayesian Networks</title><authors>Bahare Salmani and Joost-Pieter Katoen</authors><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper proposes various new analysis techniques for Bayes networks in
which conditional probability tables (CPTs) may contain symbolic variables. The
key idea is to exploit scalable and powerful techniques for synthesis problems
in parametric Markov chains. Our techniques are applicable to arbitrarily many,
possibly dependent parameters that may occur in various CPTs. This lifts the
severe restrictions on parameters, e.g., by restricting the number of
parametrized CPTs to one or two, or by avoiding parameter dependencies between
several CPTs, in existing works for parametric Bayes networks (pBNs). We
describe how our techniques can be used for various pBN synthesis problems
studied in the literature such as computing sensitivity functions (and values),
simple and difference parameter tuning, ratio parameter tuning, and minimal
change tuning. Experiments on several benchmarks show that our prototypical
tool built on top of the probabilistic model checker Storm can handle several
hundreds of parameters.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14372</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14372</id><submitter>Anthony Gitter</submitter><version version="v1"><date>Sat, 29 May 2021 21:02:44 GMT</date><size>904kb</size></version><title>Ten Quick Tips for Deep Learning in Biology</title><authors>Benjamin D. Lee, Anthony Gitter, Casey S. Greene, Sebastian Raschka,
  Finlay Maguire, Alexander J. Titus, Michael D. Kessler, Alexandra J. Lee,
  Marc G. Chevrette, Paul Allen Stewart, Thiago Britto-Borges, Evan M. Cofer,
  Kun-Hsing Yu, Juan Jose Carmona, Elana J. Fertig, Alexandr A. Kalinin, Beth
  Signal, Benjamin J. Lengerich, Timothy J. Triche Jr, Simina M. Boca</authors><categories>q-bio.OT cs.LG</categories><comments>23 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Machine learning is a modern approach to problem-solving and task automation.
In particular, machine learning is concerned with the development and
applications of algorithms that can recognize patterns in data and use them for
predictive modeling. Artificial neural networks are a particular class of
machine learning algorithms and models that evolved into what is now described
as deep learning. Given the computational advances made in the last decade,
deep learning can now be applied to massive data sets and in innumerable
contexts. Therefore, deep learning has become its own subfield of machine
learning. In the context of biological research, it has been increasingly used
to derive novel insights from high-dimensional biological data. To make the
biological applications of deep learning more accessible to scientists who have
some experience with machine learning, we solicited input from a community of
researchers with varied biological and deep learning interests. These
individuals collaboratively contributed to this manuscript's writing using the
GitHub version control platform and the Manubot manuscript generation toolset.
The goal was to articulate a practical, accessible, and concise set of
guidelines and suggestions to follow when using deep learning. In the course of
our discussions, several themes became clear: the importance of understanding
and applying machine learning fundamentals as a baseline for utilizing deep
learning, the necessity for extensive model comparisons with careful
evaluation, and the need for critical thought in interpreting results generated
by deep learning, among others.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14373</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14373</id><submitter>S\'ergio Barreto Junior</submitter><version version="v1"><date>Sat, 29 May 2021 21:05:28 GMT</date><size>54kb</size></version><title>Sentiment analysis in tweets: an assessment study from classical to
  modern text representation models</title><authors>S\'ergio Barreto, Ricardo Moura, Jonnathan Carvalho, Aline Paes,
  Alexandre Plastino</authors><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  With the growth of social medias, such as Twitter, plenty of user-generated
data emerge daily. The short texts published on Twitter -- the tweets -- have
earned significant attention as a rich source of information to guide many
decision-making processes. However, their inherent characteristics, such as the
informal, and noisy linguistic style, remain challenging to many natural
language processing (NLP) tasks, including sentiment analysis. Sentiment
classification is tackled mainly by machine learning-based classifiers. The
literature has adopted word representations from distinct natures to transform
tweets to vector-based inputs to feed sentiment classifiers. The
representations come from simple count-based methods, such as bag-of-words, to
more sophisticated ones, such as BERTweet, built upon the trendy BERT
architecture. Nevertheless, most studies mainly focus on evaluating those
models using only a small number of datasets. Despite the progress made in
recent years in language modelling, there is still a gap regarding a robust
evaluation of induced embeddings applied to sentiment analysis on tweets.
Furthermore, while fine-tuning the model from downstream tasks is prominent
nowadays, less attention has been given to adjustments based on the specific
linguistic style of the data. In this context, this study fulfils an assessment
of existing language models in distinguishing the sentiment expressed in tweets
by using a rich collection of 22 datasets from distinct domains and five
classification algorithms. The evaluation includes static and contextualized
representations. Contexts are assembled from Transformer-based autoencoder
models that are also fine-tuned based on the masked language model task, using
a plethora of strategies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14376</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14376</id><submitter>Yang He</submitter><version version="v1"><date>Sat, 29 May 2021 21:22:24 GMT</date><size>6714kb</size><source_type>D</source_type></version><title>Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis</title><authors>Yang He and Ning Yu and Margret Keuper and Mario Fritz</authors><categories>cs.CV</categories><comments>To appear in IJCAI2021. Source code at
  https://github.com/SSAW14/BeyondtheSpectrum</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid advances in deep generative models over the past years have led to
highly {realistic media, known as deepfakes,} that are commonly
indistinguishable from real to human eyes. These advances make assessing the
authenticity of visual data increasingly difficult and pose a misinformation
threat to the trustworthiness of visual content in general. Although recent
work has shown strong detection accuracy of such deepfakes, the success largely
relies on identifying frequency artifacts in the generated images, which will
not yield a sustainable detection approach as generative models continue
evolving and closing the gap to real images. In order to overcome this issue,
we propose a novel fake detection that is designed to re-synthesize testing
images and extract visual cues for detection. The re-synthesis procedure is
flexible, allowing us to incorporate a series of visual tasks - we adopt
super-resolution, denoising and colorization as the re-synthesis. We
demonstrate the improved effectiveness, cross-GAN generalization, and
robustness against perturbations of our approach in a variety of detection
scenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN
datasets. Source code is available at
https://github.com/SSAW14/BeyondtheSpectrum.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14380</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14380</id><submitter>Derya Malak</submitter><version version="v1"><date>Sat, 29 May 2021 21:55:25 GMT</date><size>245kb</size><source_type>D</source_type></version><title>Transmission Delay Minimization via Joint Power Control and Caching in
  Wireless HetNets</title><authors>Derya Malak and Faruk V. Mutlu and Jinkun Zhang and Edmund M. Yeh</authors><categories>cs.IT cs.NI math.IT</categories><comments>Supplementary material for conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental challenge in wireless heterogeneous networks (HetNets) is to
effectively utilize the limited transmission and storage resources in the
presence of increasing deployment density and backhaul capacity constraints. To
alleviate bottlenecks and reduce resource consumption, we design optimal
caching and power control algorithms for multi-hop wireless HetNets. We
formulate a joint optimization framework to minimize the average transmission
delay as a function of the caching variables and the
signal-to-interference-plus-noise ratios (SINR) which are determined by the
transmission powers, while explicitly accounting for backhaul connection costs
and the power constraints.
  Using convex relaxation and rounding, we obtain a reduced-complexity
formulation (RCF) of the joint optimization problem, which can provide a
constant factor approximation to the globally optimal solution. We then solve
RCF in two ways: 1) alternating optimization of the power and caching variables
by leveraging biconvexity, and 2) joint optimization of power control and
caching. We characterize the necessary (KKT) conditions for an optimal solution
to RCF, and use strict quasi-convexity to show that the KKT points are Pareto
optimal for RCF. We then devise a subgradient projection algorithm to jointly
update the caching and power variables, and show that under appropriate
conditions, the algorithm converges at a linear rate to the local minima of
RCF, under general SINR conditions. We support our analytical findings with
results from extensive numerical experiments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14381</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14381</id><submitter>Gaurav Parthasarathy</submitter><version version="v1"><date>Sat, 29 May 2021 22:11:30 GMT</date><size>92kb</size><source_type>D</source_type></version><title>Formally Validating a Practical Verification Condition Generator
  (extended version)</title><authors>Gaurav Parthasarathy and Peter M\&quot;uller and Alexander J. Summers</authors><categories>cs.PL</categories><comments>Extended version of CAV 2021 publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A program verifier produces reliable results only if both the logic used to
justify the program's correctness is sound, and the implementation of the
program verifier is itself correct. Whereas it is common to formally prove
soundness of the logic, the implementation of a verifier typically remains
unverified. Bugs in verifier implementations may compromise the trustworthiness
of successful verification results. Since program verifiers used in practice
are complex, evolving software systems, it is generally not feasible to
formally verify their implementation.
  In this paper, we present an alternative approach: we validate successful
runs of the widely-used Boogie verifier by producing a certificate which proves
correctness of the obtained verification result. Boogie performs a complex
series of program translations before ultimately generating a verification
condition whose validity should imply the correctness of the input program. We
show how to certify three of Boogie's core transformation phases: the
elimination of cyclic control flow paths, the (SSA-like) replacement of
assignments by assumptions using fresh variables (passification), and the final
generation of verification conditions. Similar translations are employed by
other verifiers. Our implementation produces certificates in Isabelle, based on
a novel formalisation of the Boogie language.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14383</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14383</id><submitter>Aman Bhargava</submitter><version version="v1"><date>Sat, 29 May 2021 22:26:18 GMT</date><size>352kb</size><source_type>D</source_type></version><title>Gradient-Free Neural Network Training via Synaptic-Level Reinforcement
  Learning</title><authors>Aman Bhargava, Mohammad R. Rezaei, Milad Lankarany</authors><categories>cs.NE</categories><comments>10 pages, 3 figures, submitted to NeurIPS 2021</comments><msc-class>68T07</msc-class><acm-class>I.2.6</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An ongoing challenge in neural information processing is: how do neurons
adjust their connectivity to improve task performance over time (i.e.,
actualize learning)? It is widely believed that there is a consistent,
synaptic-level learning mechanism in specific brain regions that actualizes
learning. However, the exact nature of this mechanism remains unclear. Here we
propose an algorithm based on reinforcement learning (RL) to generate and apply
a simple synaptic-level learning policy for multi-layer perceptron (MLP)
models. In this algorithm, the action space for each MLP synapse consists of a
small increase, decrease, or null action on the synapse weight, and the state
for each synapse consists of the last two actions and reward signals. A binary
reward signal indicates improvement or deterioration in task performance. The
static policy produces superior training relative to the adaptive policy and is
agnostic to activation function, network shape, and task. Trained MLPs yield
character recognition performance comparable to identically shaped networks
trained with gradient descent. 0 hidden unit character recognition tests
yielded an average validation accuracy of 88.28%, 1.86$\pm$0.47% higher than
the same MLP trained with gradient descent. 32 hidden unit character
recognition tests yielded an average validation accuracy of 88.45%,
1.11$\pm$0.79% lower than the same MLP trained with gradient descent. The
robustness and lack of reliance on gradient computations opens the door for new
techniques for training difficult-to-differentiate artificial neural networks
such as spiking neural networks (SNNs) and recurrent neural networks (RNNs).
Further, the method's simplicity provides a unique opportunity for further
development of local rule-driven multi-agent connectionist models for machine
intelligence analogous to cellular automata.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14385</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14385</id><submitter>Youbang Sun</submitter><version version="v1"><date>Sat, 29 May 2021 23:05:56 GMT</date><size>186kb</size><source_type>D</source_type></version><title>On Centralized and Distributed Mirror Descent: Exponential Convergence
  Analysis Using Quadratic Constraints</title><authors>Youbang Sun, Mahyar Fazlyab, Shahin Shahrampour</authors><categories>math.OC cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mirror descent (MD) is a powerful first-order optimization technique that
subsumes several optimization algorithms including gradient descent (GD). In
this work, we study the exact convergence rate of MD in both centralized and
distributed cases for strongly convex and smooth problems. We view MD with a
dynamical system lens and leverage quadratic constraints (QCs) to provide
convergence guarantees based on the Lyapunov stability. For centralized MD, we
establish a semi-definite programming (SDP) that certifies exponentially fast
convergence of MD subject to a linear matrix inequality (LMI). We prove that
the SDP always has a feasible solution that recovers the optimal GD rate. Next,
we analyze the exponential convergence of distributed MD and characterize the
rate using two LMIs. To the best of our knowledge, the exact (exponential) rate
of distributed MD has not been previously explored in the literature. We
present numerical results as a verification of our theory and observe that the
richness of the Lyapunov function entails better (worst-case) convergence rates
compared to existing works on distributed GD.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14388</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14388</id><submitter>Paul G\&quot;olz</submitter><version version="v1"><date>Sat, 29 May 2021 23:35:41 GMT</date><size>1307kb</size><source_type>D</source_type></version><title>Dynamic Placement in Refugee Resettlement</title><authors>Narges Ahani, Paul G\&quot;olz, Ariel D. Procaccia, Alexander Teytelboym
  and Andrew C. Trapp</authors><categories>cs.GT physics.soc-ph</categories><doi>10.1145/3465456.3467534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Employment outcomes of resettled refugees depend strongly on where they are
placed inside the host country. While the United States sets refugee capacities
for communities on an annual basis, refugees arrive and must be placed over the
course of the year. We introduce a dynamic allocation system based on two-stage
stochastic programming to improve employment outcomes. Our algorithm is able to
achieve over 98 percent of the hindsight-optimal employment compared to under
90 percent of current greedy-like approaches. This dramatic improvement
persists even when we incorporate a vast array of practical features of the
refugee resettlement process including indivisible families, batching, and
uncertainty with respect to the number of future arrivals. Our algorithm is now
part of the Annie MOORE optimization software used by a leading American
refugee resettlement agency.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14391</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14391</id><submitter>Bowen Wen</submitter><version version="v1"><date>Sat, 29 May 2021 23:56:05 GMT</date><size>5731kb</size><source_type>D</source_type></version><title>Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic
  Domains</title><authors>Bowen Wen, Chaitanya Mitash and Kostas Bekris</authors><categories>cs.CV cs.RO</categories><comments>CVPR 2021 Workshop on 3D Vision and Robotics. arXiv admin note:
  substantial text overlap with arXiv:2007.13866</comments><journal-ref>CVPR 2021 Workshop</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tracking the 6D pose of objects in video sequences is important for robot
manipulation. This work presents se(3)-TrackNet, a data-driven optimization
approach for long term, 6D pose tracking. It aims to identify the optimal
relative pose given the current RGB-D observation and a synthetic image
conditioned on the previous best estimate and the object's model. The key
contribution in this context is a novel neural network architecture, which
appropriately disentangles the feature encoding to help reduce domain shift,
and an effective 3D orientation representation via Lie Algebra. Consequently,
even when the network is trained solely with synthetic data can work
effectively over real images. Comprehensive experiments over multiple
benchmarks show se(3)-TrackNet achieves consistently robust estimates and
outperforms alternatives, even though they have been trained with real images.
The approach runs in real time at 90.9Hz. Code, data and supplementary video
for this project are available at
https://github.com/wenbowen123/iros20-6d-pose-tracking
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14396</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14396</id><submitter>Carlos Magno C. O. Valle</submitter><version version="v1"><date>Sun, 30 May 2021 00:30:27 GMT</date><size>1517kb</size><source_type>D</source_type></version><title>SyReNets: Symbolic Residual Neural Networks</title><authors>Carlos Magno C. O. Valle, Sami Haddadin</authors><categories>cs.LG cs.RO</categories><comments>11 pages, 3 figures, 2 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite successful seminal works on passive systems in the literature,
learning free-form physical laws for controlled dynamical systems given
experimental data is still an open problem. For decades, symbolic mathematical
equations and system identification were the golden standards. Unfortunately, a
set of assumptions about the properties of the underlying system is required,
which makes the model very rigid and unable to adapt to unforeseen changes in
the physical system. Neural networks, on the other hand, are known universal
function approximators but are prone to over-fit, limited accuracy, and bias
problems, which makes them alone unreliable candidates for such tasks. In this
paper, we propose SyReNets, an approach that leverages neural networks for
learning symbolic relations to accurately describe dynamic physical systems
from data. It explores a sequence of symbolic layers that build, in a residual
manner, mathematical relations that describes a given desired output from input
variables. We apply it to learn the symbolic equation that describes the
Lagrangian of a given physical system. We do this by only observing random
samples of position, velocity, and acceleration as input and torque as output.
Therefore, using the Lagrangian as a latent representation from which we derive
torque using the Euler-Lagrange equations. The approach is evaluated using a
simulated controlled double pendulum and compared with neural networks, genetic
programming, and traditional system identification. The results demonstrate
that, compared to neural networks and genetic programming, SyReNets converges
to representations that are more accurate and precise throughout the state
space. Despite having slower convergence than traditional system
identification, similar to neural networks, the approach remains flexible
enough to adapt to an unforeseen change in the physical system structure.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14397</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14397</id><submitter>Francois Meyer</submitter><version version="v1"><date>Sun, 30 May 2021 00:40:43 GMT</date><size>11kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 02:52:21 GMT</date><size>12kb</size></version><title>The Sample Fr\'echet Mean of Sparse Graphs is Sparse</title><authors>Daniel Ferguson, Francois G. Meyer</authors><categories>math.CO cs.SI physics.data-an stat.AP stat.ML</categories><comments>16 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The availability of large datasets composed of graphs creates an
unprecedented need to invent novel tools in statistical learning for
&quot;graph-valued random variables&quot;. To characterize the &quot;average&quot; of a sample of
graphs, one can compute the sample Fr\'echet mean.
  Because the sample mean should provide an interpretable summary of the graph
sample, one would expect that the structural properties of the sample be
transmitted to the Fr\'echet mean. In this paper, we address the following
foundational question: does the sample Fr\'echet mean inherit the structural
properties of the graphs in the sample?
  Specifically, we prove the following result: the sample Fr\'echet mean of a
set of sparse graphs is sparse. We prove the result for the graph Hamming
distance, and the spectral adjacency pseudometric, using very different
arguments. In fact, we prove a stronger result: the edge density of the sample
Fr\'echet mean is bounded by the edge density of the graphs in the sample. This
result guarantees that sparsity is an hereditary property, which can be
transmitted from a graph sample to its sample Fr\'echet mean, irrespective of
the method used to estimate the sample Fr\'echet mean.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14398</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14398</id><submitter>Fangyu Liu</submitter><version version="v1"><date>Sun, 30 May 2021 00:50:00 GMT</date><size>5258kb</size><source_type>D</source_type></version><title>Learning Domain-Specialised Representations for Cross-Lingual Biomedical
  Entity Linking</title><authors>Fangyu Liu, Ivan Vuli\'c, Anna Korhonen, Nigel Collier</authors><categories>cs.CL cs.AI cs.LG</categories><comments>ACL-IJCNLP 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Injecting external domain-specific knowledge (e.g., UMLS) into pretrained
language models (LMs) advances their capability to handle specialised in-domain
tasks such as biomedical entity linking (BEL). However, such abundant expert
knowledge is available only for a handful of languages (e.g., English). In this
work, by proposing a novel cross-lingual biomedical entity linking task
(XL-BEL) and establishing a new XL-BEL benchmark spanning 10 typologically
diverse languages, we first investigate the ability of standard
knowledge-agnostic as well as knowledge-enhanced monolingual and multilingual
LMs beyond the standard monolingual English BEL task. The scores indicate large
gaps to English performance. We then address the challenge of transferring
domain-specific knowledge in resource-rich languages to resource-poor ones. To
this end, we propose and evaluate a series of cross-lingual transfer methods
for the XL-BEL task, and demonstrate that general-domain bitext helps propagate
the available English knowledge to languages with little to no in-domain data.
Remarkably, we show that our proposed domain-specific transfer methods yield
consistent gains across all target languages, sometimes up to 20 Precision@1
points, without any in-domain knowledge in the target language, and without any
in-domain parallel data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14399</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14399</id><submitter>David Mac\^edo</submitter><version version="v1"><date>Sun, 30 May 2021 00:55:03 GMT</date><size>141kb</size><source_type>D</source_type></version><title>Improving Entropic Out-of-Distribution Detection using Isometric
  Distances and the Minimum Distance Score</title><authors>David Mac\^edo, Teresa Ludermir</authors><categories>cs.LG cs.AI cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current out-of-distribution detection approaches usually present special
requirements (e.g., collecting outlier data and hyperparameter validation) and
produce side effects (classification accuracy drop and slow/inefficient
inferences). Recently, entropic out-of-distribution detection has been proposed
as a seamless approach (i.e., a solution that avoids all the previously
mentioned drawbacks). The entropic out-of-distribution detection solution
comprises the IsoMax loss for training and the entropic score for
out-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in
replacement because swapping the SoftMax loss with the IsoMax loss requires no
changes in the model's architecture or training procedures/hyperparameters. In
this paper, we propose to perform what we call an isometrization of the
distances used in the IsoMax loss. Additionally, we propose to replace the
entropic score with the minimum distance score. Our experiments showed that
these simple modifications increase out-of-distribution detection performance
while keeping the solution seamless.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14401</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14401</id><submitter>Lucius Schoenbaum</submitter><version version="v1"><date>Sun, 30 May 2021 01:12:12 GMT</date><size>828kb</size><source_type>D</source_type></version><title>A Tapered Floating Point Extension for the Redundant Signed Radix 2
  System Using the Canonical Recoding</title><authors>Lucius T. Schoenbaum</authors><categories>cs.AR</categories><comments>17 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A tapered floating point encoding is proposed which uses the redundant signed
radix 2 system and is based on the canonical recoding. By making use of ternary
technology, the encoding has a dynamic range exceeding that of the
recently-proposed Posit number system and the IEEE 754-1985 Standard for
Floating Point Arithmetic (IEEE-754-1985), and precision equal to or better
than that of the IEEE-754-1985 system and the recently proposed Posit system
when equal input sizes are compared. In addition, the encoding is capable of
supporting several proposed extensions, including extensions to integers,
boolean values, complex numbers, higher number systems, low-dimensional
vectors, and system artifacts such as machine instructions. A detailed analytic
comparison is provided between the proposed encoding, the IEEE-754-1985 system,
and the recently proposed Posit number system.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14403</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14403</id><submitter>Ryoma Sato</submitter><version version="v1"><date>Sun, 30 May 2021 01:35:03 GMT</date><size>348kb</size></version><title>Re-evaluating Word Mover's Distance</title><authors>Ryoma Sato, Makoto Yamada, Hisashi Kashima</authors><categories>cs.LG cs.CL cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The word mover's distance (WMD) is a fundamental technique for measuring the
similarity of two documents. As the crux of WMD, it can take advantage of the
underlying geometry of the word space by employing an optimal transport
formulation. The original study on WMD reported that WMD outperforms classical
baselines such as bag-of-words (BOW) and TF-IDF by significant margins in
various datasets. In this paper, we point out that the evaluation in the
original study could be misleading. We re-evaluate the performances of WMD and
the classical baselines and find that the classical baselines are competitive
with WMD if we employ an appropriate preprocessing, i.e., L1 normalization.
However, this result is not intuitive. WMD should be superior to BOW because
WMD can take the underlying geometry into account, whereas BOW cannot. Our
analysis shows that this is due to the high-dimensional nature of the
underlying metric. We find that WMD in high-dimensional spaces behaves more
similarly to BOW than in low-dimensional spaces due to the curse of
dimensionality.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14405</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14405</id><submitter>Yinxin Wan</submitter><version version="v1"><date>Sun, 30 May 2021 01:40:12 GMT</date><size>2806kb</size><source_type>D</source_type></version><title>IoTAthena: Unveiling IoT Device Activities from Network Traffic</title><authors>Yinxin Wan, Kuai Xu, Feng Wang, Guoliang Xue</authors><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recent spate of cyber attacks towards Internet of Things (IoT) devices in
smart homes calls for effective techniques to understand, characterize, and
unveil IoT device activities. In this paper, we present a new system, named
IoTAthena, to unveil IoT device activities from raw network traffic consisting
of timestamped IP packets. IoTAthena characterizes each IoT device activity
using an activity signature consisting of an ordered sequence of IP packets
with inter-packet time intervals. IoTAthena has two novel polynomial time
algorithms, sigMatch and actExtract. For any given signature, sigMatch can
capture all matches of the signature in the raw network traffic. Using sigMatch
as a subfunction, actExtract can accurately unveil the sequence of various IoT
device activities from the raw network traffic. Using the network traffic of
heterogeneous IoT devices collected at the router of a real-world smart home
testbed and a public IoT dataset, we demonstrate that IoTAthena is able to
characterize and generate activity signatures of IoT device activities and
accurately unveil the sequence of IoT device activities from raw network
traffic.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14406</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14406</id><submitter>Yuzhou Peng</submitter><version version="v1"><date>Sun, 30 May 2021 01:43:25 GMT</date><size>368kb</size><source_type>D</source_type></version><title>A splitting Hamiltonian Monte Carlo method for efficient sampling</title><authors>Lei Li, Lin Liu and Yuzhou Peng</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a splitting Hamiltonian Monte Carlo (SHMC) algorithm, which can be
numerically and computationally efficient when combined with the random
mini-batch strategy. By splitting the &quot;effective potential energy&quot; $U\propto
-\beta^{-1}\log \rho$ into two parts $U = U_1 + U_2$, one makes a proposal
using the &quot;easy-to-sample&quot; part $U_1$, followed by probabilistically accepting
that proposal by a Metropolis rejection step using $U_2$. The splitting allows
efficient sampling from systems with singular potentials (or distributions with
degenerate points) and/or with multiple potential barriers. In our SHMC
algorithm, the proposal using $U_1$ is generated by the Hamiltonian dynamics,
which can be potentially more efficient than the overdamped Langevin dynamics.
We also use random batch strategies to reduce the computational cost to
$\mathcal{O}(1)$ per time step in generating the proposals for problems arising
from many-body systems and Bayesian inference, and prove that the errors of the
Hamiltonian induced by the random batch approximation is
$\mathcal{O}(\sqrt{\Delta t})$ in the strong and $\mathcal{O}(\Delta t)$ in the
weak sense, where $\Delta t$ is the time step. Numerical experiments are
conducted to verify the theoretical results and the computational efficiency of
the proposed algorithms in practice.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14408</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14408</id><submitter>Qian Chen</submitter><version version="v1"><date>Sun, 30 May 2021 01:59:54 GMT</date><size>670kb</size><source_type>D</source_type></version><title>PPT: A Privacy-Preserving Global Model Training Protocol for Federated
  Learning in P2P Networks</title><authors>Qian Chen, Zilong Wang, Xiaodong Lin</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of Federated Learning has emerged as a convergence of distributed
machine learning, information, and communication technology. It is vital to the
development of distributed machine learning, which is expected to be fully
decentralized, robust, communication efficient, and secure. However, the
federated learning settings with a central server can't meet requirements in
fully decentralized networks. In this paper, we propose a fully decentralized,
efficient, and privacy-preserving global model training protocol, named PPT,
for federated learning in Peer-to-peer (P2P) Networks. PPT uses a one-hop
communication form to aggregate local model update parameters and adopts the
symmetric cryptosystem to ensure security. It is worth mentioning that PPT
modifies the Eschenauer-Gligor (E-G) scheme to distribute keys for encryption.
PPT also adopts Neighborhood Broadcast, Supervision and Report, and Termination
as complementary mechanisms to enhance security and robustness. Through
extensive analysis, we demonstrate that PPT resists various security threats
and preserve user privacy. Ingenious experiments demonstrate the utility and
efficiency as well.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14409</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14409</id><submitter>Niharika S. D'Souza</submitter><version version="v1"><date>Sun, 30 May 2021 02:06:12 GMT</date><size>2071kb</size><source_type>D</source_type></version><title>A Matrix Autoencoder Framework to Align the Functional and Structural
  Connectivity Manifolds as Guided by Behavioral Phenotypes</title><authors>Niharika Shimona D'Souza, Mary Beth Nebel, Deana Crocetti, Nicholas
  Wymbs, Joshua Robinson, Stewart Mostofsky, Archana Venkataraman</authors><categories>q-bio.NC cs.LG eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel matrix autoencoder to map functional connectomes from
resting state fMRI (rs-fMRI) to structural connectomes from Diffusion Tensor
Imaging (DTI), as guided by subject-level phenotypic measures. Our specialized
autoencoder infers a low dimensional manifold embedding for the rs-fMRI
correlation matrices that mimics a canonical outer-product decomposition. The
embedding is simultaneously used to reconstruct DTI tractography matrices via a
second manifold alignment decoder and to predict inter-subject phenotypic
variability via an artificial neural network. We validate our framework on a
dataset of 275 healthy individuals from the Human Connectome Project database
and on a second clinical dataset consisting of 57 subjects with Autism Spectrum
Disorder. We demonstrate that the model reliably recovers structural
connectivity patterns across individuals, while robustly extracting predictive
and interpretable brain biomarkers in a cross-validated setting. Finally, our
framework outperforms several baselines at predicting behavioral phenotypes in
both real-world datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14410</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14410</id><submitter>Juntao Huang</submitter><version version="v1"><date>Sun, 30 May 2021 02:10:59 GMT</date><size>186kb</size></version><title>Machine learning moment closure models for the radiative transfer
  equation II: enforcing global hyperbolicity in gradient based closures</title><authors>Juntao Huang, Yingda Cheng, Andrew J. Christlieb, Luke F. Roberts,
  Wen-An Yong</authors><categories>math.NA cs.LG cs.NA physics.comp-ph</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This is the second paper in a series in which we develop machine learning
(ML) moment closure models for the radiative transfer equation (RTE). In our
previous work \cite{huang2021gradient}, we proposed an approach to directly
learn the gradient of the unclosed high order moment, which performs much
better than learning the moment itself and the conventional $P_N$ closure.
However, the ML moment closure model in \cite{huang2021gradient} is not able to
guarantee hyperbolicity and long time stability. We propose in this paper a
method to enforce the global hyperbolicity of the ML closure model. The main
idea is to seek a symmetrizer (a symmetric positive definite matrix) for the
closure system, and derive constraints such that the system is globally
symmetrizable hyperbolic. It is shown that the new ML closure system inherits
the dissipativeness of the RTE and preserves the correct diffusion limit as the
Knunsden number goes to zero. Several benchmark tests including the Gaussian
source problem and the two-material problem show the good accuracy, long time
stability and generalizability of our globally hyperbolic ML closure model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14412</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14412</id><submitter>Andrei Velichko</submitter><version version="v1"><date>Sun, 30 May 2021 02:12:45 GMT</date><size>694kb</size></version><title>An improved LogNNet classifier for IoT application</title><authors>Hanif Heidari and Andrei Velichko</authors><categories>cs.LG cs.CV cs.NE eess.IV nlin.CD</categories><comments>16 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The internet of things devices suffer of low memory while good accuracy is
needed. Designing suitable algorithms is vital in this subject. This paper
proposes a feed forward LogNNet neural network which uses a semi-linear Henon
type discrete chaotic map to classify MNIST-10 dataset. The model is composed
of reservoir part and trainable classifier. The aim of reservoir part is
transforming the inputs to maximize the classification accuracy using a special
matrix filing method and a time series generated by the chaotic map. The
parameters of the chaotic map are optimized using particle swarm optimization
with random immigrants. The results show that the proposed LogNNet/Henon
classifier has higher accuracy and same RAM saving comparable to the original
version of LogNNet and has broad prospects for implementation in IoT devices.
In addition, the relation between the entropy and accuracy of the
classification is investigated. It is shown that there exists a direct relation
between the value of entropy and accuracy of the classification.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14416</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14416</id><submitter>Qiongxiu Li</submitter><version version="v1"><date>Sun, 30 May 2021 02:43:41 GMT</date><size>650kb</size><source_type>D</source_type></version><title>Communication efficient privacy-preserving distributed optimization
  using adaptive differential quantization</title><authors>Qiongxiu Li, Richard Heusdens and Mads Gr{\ae}sb{\o}ll Christensen</authors><categories>cs.DC eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Privacy issues and communication cost are both major concerns in distributed
optimization. There is often a trade-off between them because the encryption
methods required for privacy-preservation often incur expensive communication
bandwidth. To address this issue, we, in this paper, propose a
quantization-based approach to achieve both communication efficient and
privacy-preserving solutions in the context of distributed optimization. By
deploying an adaptive differential quantization scheme, we allow each node in
the network to achieve its optimum solution with a low communication cost while
keeping its private data unrevealed. Additionally, the proposed approach is
general and can be applied in various distributed optimization methods, such as
the primal-dual method of multipliers (PDMM) and the alternating direction
method of multipliers (ADMM). Moveover, we consider two widely used adversary
models: passive and eavesdropping. Finally, we investigate the properties of
the proposed approach using different applications and demonstrate its superior
performance in terms of several parameters including accuracy, privacy, and
communication cost.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14417</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14417</id><submitter>Zhiyan Ding</submitter><version version="v1"><date>Sun, 30 May 2021 02:46:09 GMT</date><size>64kb</size></version><title>Overparameterization of deep ResNet: zero loss and mean-field analysis</title><authors>Zhiyan Ding and Shi Chen and Qin Li and Stephen Wright</authors><categories>cs.LG cs.NA math.NA stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Finding parameters in a deep neural network (NN) that fit training data is a
nonconvex optimization problem, but a basic first-order optimization method
(gradient descent) finds a global solution with perfect fit in many practical
situations. We examine this phenomenon for the case of Residual Neural Networks
(ResNet) with smooth activation functions in a limiting regime in which both
the number of layers (depth) and the number of neurons in each layer (width) go
to infinity. First, we use a mean-field-limit argument to prove that the
gradient descent for parameter training becomes a partial differential equation
(PDE) that characterizes gradient flow for a probability distribution in the
large-NN limit. Next, we show that the solution to the PDE converges in the
training time to a zero-loss solution. Together, these results imply that
training of the ResNet also gives a near-zero loss if the Resnet is large
enough. We give estimates of the depth and width needed to reduce the loss
below a given threshold, with high probability.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14418</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14418</id><submitter>Gianmarco Manzini</submitter><version version="v1"><date>Sun, 30 May 2021 02:46:49 GMT</date><size>183kb</size><source_type>D</source_type></version><title>Virtual element approximation of two-dimensional parabolic variational
  inequalities</title><authors>Dibyendu Adak, Gianmarco Manzini, Sundararajan Natarajan</authors><categories>math.NA cs.NA</categories><comments>33 pages, 3 figures</comments><msc-class>65M12, 65M60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a virtual element method for the numerical treatment of the
two-dimensional parabolic variational inequality problem on unstructured
polygonal meshes. Due to the expected low regularity of the exact solution, the
virtual element method is based on the lowest-order virtual element space that
contains the subspace of the linear polynomials defined on each element. The
connection between the nonnegativity of the virtual element functions and the
nonnegativity of the degrees of freedom, i.e., the values at the mesh vertices,
is established by applying the Maximum and Minimum Principle Theorem. The mass
matrix is computed through an approximate L 2 polynomial projection, whose
properties are carefully investigated in the paper. We prove the well-posedness
of the resulting scheme in two different ways that reveal the contractive
nature of the VEM and its connection with the minimization of quadratic
functionals. The convergence analysis requires the existence of a nonnegative
quasi-interpolation operator, whose construction is also discussed in the
paper. The variational crime introduced by the virtual element setting produces
five error terms that we control by estimating a suitable upper bound.
Numerical experiments confirm the theoretical convergence rate for the
refinement in space and time on three different mesh families including
distorted squares, nonconvex elements, and Voronoi tesselations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14421</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14421</id><submitter>Xi Li</submitter><version version="v1"><date>Sun, 30 May 2021 03:39:53 GMT</date><size>6014kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 02:53:54 GMT</date><size>0kb</size><source_type>I</source_type></version><title>VersatileGait: A Large-Scale Synthetic Gait Dataset Towards in-the-Wild
  Simulation</title><authors>Pengyi Zhang, Huanzhang Dou, Wenhu Zhang, Yuhan Zhao, Songyuan Li,
  Zequn Qin, Xi Li</authors><categories>cs.CV</categories><comments>We should have updated 2101.01394 but we did a new submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gait recognition has a rapid development in recent years. However, gait
recognition in the wild is not well explored yet. An obvious reason could be
ascribed to the lack of diverse training data from the perspective of intrinsic
and extrinsic factors. To remedy this problem, we propose to construct a
large-scale gait dataset with the help of controllable computer simulation. In
detail, to diversify the intrinsic factors of gait, we generate numerous
characters with diverse attributes and empower them with various types of
walking styles. To diversify the extrinsic factors of gait, we build a
complicated scene with a dense camera layout. Finally, we design an automated
generation toolkit under Unity3D for simulating the walking scenario and
capturing the gait data automatically. As a result, we obtain an in-the-wild
gait dataset, called VersatileGait, which has more than one million silhouette
sequences of 10,000 subjects with diverse scenarios. VersatileGait possesses
several nice properties, including huge dataset size, diverse pedestrian
attributes, complicated camera layout, high-quality annotations, small domain
gap with the real one, good scalability for new demands, and no privacy issues.
Based on VersatileGait, we propose series of experiments and applications for
both research exploration of gait in the wild and practical applications. Our
dataset and its corresponding generation toolkit will be publicly available for
further studies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14422</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14422</id><submitter>Hengrui Cai</submitter><version version="v1"><date>Sun, 30 May 2021 03:40:16 GMT</date><size>737kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 20:14:01 GMT</date><size>737kb</size><source_type>D</source_type></version><title>Periodic-GP: Learning Periodic World with Gaussian Process Bandits</title><authors>Hengrui Cai, Zhihao Cen, Ling Leng, Rui Song</authors><categories>cs.LG cs.AI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the sequential decision optimization on the periodic environment,
that occurs in a wide variety of real-world applications when the data involves
seasonality, such as the daily demand of drivers in ride-sharing and dynamic
traffic patterns in transportation. In this work, we focus on learning the
stochastic periodic world by leveraging this seasonal law. To deal with the
general action space, we use the bandit based on Gaussian process (GP) as the
base model due to its flexibility and generality, and propose the Periodic-GP
method with a temporal periodic kernel based on the upper confidence bound.
Theoretically, we provide a new regret bound of the proposed method, by
explicitly characterizing the periodic kernel in the periodic stationary model.
Empirically, the proposed algorithm significantly outperforms the existing
methods in both synthetic data experiments and a real data application on
Madrid traffic pollution.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14423</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14423</id><submitter>Ryoma Sato</submitter><version version="v1"><date>Sun, 30 May 2021 04:06:03 GMT</date><size>148kb</size></version><title>Enumerating Fair Packages for Group Recommendations</title><authors>Ryoma Sato</authors><categories>cs.IR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In package recommendations, a set of items is regarded as a unified package
towards a single common goal, whereas conventional recommender systems treat
items independently. For example, for music playlist recommendations, each
package (i.e., playlist) should be consistent with respect to the genres. In
group recommendations, items are recommended to a group of users, whereas
conventional recommender systems recommend items to an individual user.
Different from the conventional settings, it is difficult to measure the
utility of group recommendations because it involves more than one user. In
particular, fairness is crucial in group recommendations. Even if some members
in a group are substantially satisfied with a recommendation, it is undesirable
if other members are ignored to increase the total utility. Various methods for
evaluating and applying the fairness of group recommendations have been
proposed in the literature. However, all these methods maximize the score and
output only a single package. This is in contrast to conventional recommender
systems, which output several (e.g., top-$K$) candidates. This can be
problematic because a group can be dissatisfied with the recommended package
owing to some unobserved reasons, even if the score is high. In particular,
each fairness measure is not absolute, and users may call for different
fairness criteria than the one adopted in the recommender system in operation.
To address this issue, we propose a method to enumerate fair packages so that a
group can select their favorite packages from the list. Our proposed method can
enumerate fair packages efficiently, and users can search their favorite
packages by various filtering queries. We confirm that our algorithm scales to
large datasets and can balance several aspects of the utility of the packages.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14424</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14424</id><submitter>Yihua Cheng</submitter><version version="v1"><date>Sun, 30 May 2021 04:06:29 GMT</date><size>132kb</size><source_type>D</source_type></version><title>Gaze Estimation using Transformer</title><authors>Yihua Cheng and Feng Lu</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has proven the effectiveness of transformers in many computer
vision tasks. However, the performance of transformers in gaze estimation is
still unexplored. In this paper, we employ transformers and assess their
effectiveness for gaze estimation. We consider two forms of vision transformer
which are pure transformers and hybrid transformers. We first follow the
popular ViT and employ a pure transformer to estimate gaze from images. On the
other hand, we preserve the convolutional layers and integrate CNNs as well as
transformers. The transformer serves as a component to complement CNNs. We
compare the performance of the two transformers in gaze estimation. The Hybrid
transformer significantly outperforms the pure transformer in all evaluation
datasets with less parameters. We further conduct experiments to assess the
effectiveness of the hybrid transformer and explore the advantage of
self-attention mechanism. Experiments show the hybrid transformer can achieve
state-of-the-art performance in all benchmarks with pre-training.To facilitate
further research, we release codes and models in
https://github.com/yihuacheng/GazeTR.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14426</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14426</id><submitter>Pratik Kayal</submitter><version version="v1"><date>Sun, 30 May 2021 04:17:55 GMT</date><size>1292kb</size><source_type>I</source_type></version><title>ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX</title><authors>Pratik Kayal, Mrinal Anand, Harsh Desai, Mayank Singh</authors><categories>cs.IR cs.AI cs.CV</categories><comments>This submission has been removed by arXiv administrators because the
  submitter did not have the right to grant the license at the time of
  submission</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tables present important information concisely in many scientific documents.
Visual features like mathematical symbols, equations, and spanning cells make
structure and content extraction from tables embedded in research documents
difficult. This paper discusses the dataset, tasks, participants' methods, and
results of the ICDAR 2021 Competition on Scientific Table Image Recognition to
LaTeX. Specifically, the task of the competition is to convert a tabular image
to its corresponding LaTeX source code. We proposed two subtasks. In Subtask 1,
we ask the participants to reconstruct the LaTeX structure code from an image.
In Subtask 2, we ask the participants to reconstruct the LaTeX content code
from an image. This report describes the datasets and ground truth
specification, details the performance evaluation metrics used, presents the
final results, and summarizes the participating methods. Submission by team
VCGroup got the highest Exact Match accuracy score of 74% for Subtask 1 and 55%
for Subtask 2, beating previous baselines by 5% and 12%, respectively. Although
improvements can still be made to the recognition capabilities of models, this
competition contributes to the development of fully automated table recognition
systems by challenging practitioners to solve problems under specific
constraints and sharing their approaches; the platform will remain available
for post-challenge submissions at
https://competitions.codalab.org/competitions/26979 .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14427</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14427</id><submitter>Tianhao Wang</submitter><version version="v1"><date>Sun, 30 May 2021 04:35:50 GMT</date><size>453kb</size><source_type>D</source_type></version><title>Concurrent Composition of Differential Privacy</title><authors>Salil Vadhan, Tianhao Wang</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate a study of the composition properties of interactive
differentially private mechanisms. An interactive differentially private
mechanism is an algorithm that allows an analyst to adaptively ask queries
about a sensitive dataset, with the property that an adversarial analyst's view
of the interaction is approximately the same regardless of whether or not any
individual's data is in the dataset. Previous studies of composition of
differential privacy have focused on non-interactive algorithms, but
interactive mechanisms are needed to capture many of the intended applications
of differential privacy and a number of the important differentially private
primitives.
  We focus on concurrent composition, where an adversary can arbitrarily
interleave its queries to several differentially private mechanisms, which may
be feasible when differentially private query systems are deployed in practice.
We prove that when the interactive mechanisms being composed are pure
differentially private, their concurrent composition achieves privacy
parameters (with respect to pure or approximate differential privacy) that
match the (optimal) composition theorem for noninteractive differential
privacy. We also prove a composition theorem for interactive mechanisms that
satisfy approximate differential privacy. That bound is weaker than even the
basic (suboptimal) composition theorem for noninteractive differential privacy,
and we leave closing the gap as a direction for future research, along with
understanding concurrent composition for other variants of differential
privacy.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14428</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14428</id><submitter>Liqi Yang</submitter><version version="v1"><date>Sun, 30 May 2021 04:55:04 GMT</date><size>2331kb</size><source_type>D</source_type></version><title>DAGNN: Demand-aware Graph Neural Networks for Session-based
  Recommendation</title><authors>Liqi Yang, Linhan Luo, Lifeng Xin, Xiaofeng Zhang, Xinni Zhang</authors><categories>cs.IR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Session-based recommendations have been widely adopted for various online
video and E-commerce Websites. Most existing approaches are intuitively
proposed to discover underlying interests or preferences out of the anonymous
session data. This apparently ignores the fact these sequential behaviors
usually reflect session user's potential demand, i.e., a semantic level factor,
and therefore how to estimate underlying demands from a session is challenging.
To address aforementioned issue, this paper proposes a demand-aware graph
neural networks (DAGNN). Particularly, a demand modeling component is designed
to first extract session demand and the underlying multiple demands of each
session is estimated using the global demand matrix. Then, the demand-aware
graph neural network is designed to extract session demand graph to learn the
demand-aware item embedddings for the later recommendations. The mutual
information loss is further designed to enhance the quality of the learnt
embeddings. Extensive experiments are evaluated on several real-world datasets
and the proposed model achieves the SOTA model performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14429</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14429</id><submitter>Yuhao Guo</submitter><version version="v1"><date>Sun, 30 May 2021 05:11:55 GMT</date><size>546kb</size><source_type>D</source_type></version><title>Deformation Control of a Deformable Object Based on Visual and Tactile
  Feedback</title><authors>Yuhao Guo, Xin Jiang and Yunhui Liu</authors><categories>cs.RO</categories><comments>&quot;7 pages&quot; &quot;9 figures&quot; &quot;submitted to IROS2021&quot;</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we presented a new method for deformation control of
deformable objects, which utilizes both visual and tactile feedback. At
present, manipulation of deformable objects is basically formulated by assuming
positional constraints. But in fact, in many situations manipulation has to be
performed under actively applied force constraints. This scenario is considered
in this research. In the proposed scheme a tactile feedback is integrated to
ensure a stable contact between the robot end-effector and the soft object to
be manipulated. The controlled contact force is also utilized to regulate the
deformation of the soft object with its shape measured by a vision sensor. The
effectiveness of the proposed method is demonstrated by a book page turning and
shaping experiment.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14430</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14430</id><submitter>Jianning Wu</submitter><version version="v1"><date>Sun, 30 May 2021 05:13:30 GMT</date><size>753kb</size><source_type>D</source_type></version><title>Rethinking the constraints of multimodal fusion: case study in
  Weakly-Supervised Audio-Visual Video Parsing</title><authors>Jianning Wu, Zhuqing Jiang, Shiping Wen, Aidong Men, Haiying Wang</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For multimodal tasks, a good feature extraction network should extract
information as much as possible and ensure that the extracted feature embedding
and other modal feature embedding have an excellent mutual understanding. The
latter is often more critical in feature fusion than the former. Therefore,
selecting the optimal feature extraction network collocation is a very
important subproblem in multimodal tasks. Most of the existing studies ignore
this problem or adopt an ergodic approach. This problem is modeled as an
optimization problem in this paper. A novel method is proposed to convert the
optimization problem into an issue of comparative upper bounds by referring to
the general practice of extreme value conversion in mathematics. Compared with
the traditional method, it reduces the time cost.
  Meanwhile, aiming at the common problem that the feature similarity and the
feature semantic similarity are not aligned in the multimodal time-series
problem, we refer to the idea of contrast learning and propose a multimodal
time-series contrastive loss(MTSC).
  Based on the above issues, We demonstrated the feasibility of our approach in
the audio-visual video parsing task. Substantial analyses verify that our
methods promote the fusion of different modal features.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14431</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14431</id><submitter>Xianyi Cheng</submitter><version version="v1"><date>Sun, 30 May 2021 05:23:54 GMT</date><size>7497kb</size><source_type>D</source_type></version><title>Contact Mode Guided Motion Planning for Dexterous Manipulation</title><authors>Xianyi Cheng, Eric Huang, Yifan Hou, Matthew T. Mason</authors><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the field of robotic manipulation, a central goal is to replicate the
human ability to manipulate any object in any situation using a sequence of
manipulation primitives such as grasping, pushing, inserting, sliding, etc.
Conceptually, each manipulation primitive restricts the object and robot to
move on a lower-dimensional manifold defined by the primitive's dynamic
equations of motion. Likewise, a manipulation sequence represents a dynamically
feasible trajectory that traverses multiple manifolds. To manipulate any object
in any situation, robotic systems must include the ability to automatically
synthesize manipulation primitives (manifolds) and sequence those primitives
into a coherent plan (find a path across the manifolds). This paper
investigates a principled approach for solving dexterous manipulation planning.
This approach is based on rapidly-exploring random trees which use contact
modes to guide tree expansion along primitive manifolds. This paper extends
this algorithm from 2D domains to 3D domains. We validated our algorithm on a
large collection of simulated 3D manipulation tasks. These tasks required our
algorithm to sequence between 6-42 manipulation primitives (i.e.\! distinct
contact modes). We believe this work represents an important step towards
robotic manipulation capabilities which generalize across objects and
environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14432</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14432</id><submitter>Shengcai Liao</submitter><version version="v1"><date>Sun, 30 May 2021 05:38:33 GMT</date><size>316kb</size><source_type>D</source_type></version><title>Transformer-Based Deep Image Matching for Generalizable Person
  Re-identification</title><authors>Shengcai Liao and Ling Shao</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformers have recently gained increasing attention in computer vision.
However, existing studies mostly use Transformers for feature representation
learning, e.g. for image classification and dense predictions. In this work, we
further investigate the possibility of applying Transformers for image matching
and metric learning given pairs of images. We find that the Vision Transformer
(ViT) and the vanilla Transformer with decoders are not adequate for image
matching due to their lack of image-to-image attention. Thus, we further design
two naive solutions, i.e. query-gallery concatenation in ViT, and query-gallery
cross-attention in the vanilla Transformer. The latter improves the
performance, but it is still limited. This implies that the attention mechanism
in Transformers is primarily designed for global feature aggregation, which is
not naturally suitable for image matching. Accordingly, we propose a new
simplified decoder, which drops the full attention implementation with the
softmax weighting, keeping only the query-key similarity computation.
Additionally, global max pooling and a multilayer perceptron (MLP) head are
applied to decode the matching result. This way, the simplified decoder is
computationally more efficient, while at the same time more effective for image
matching. The proposed method, called TransMatcher, achieves state-of-the-art
performance in generalizable person re-identification, with up to 6.1% and 5.7%
performance gains in Rank-1 and mAP, respectively, on several popular datasets.
The source code of this study will be made publicly available.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14435</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14435</id><submitter>Remy Wang</submitter><version version="v1"><date>Sun, 30 May 2021 06:03:43 GMT</date><size>113kb</size></version><title>Convergence of Datalog over (Pre-) Semirings</title><authors>Mahmoud Abo Khamis, Hung Q. Ngo, Reinhard Pichler, Dan Suciu, Yisu
  Remy Wang</authors><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recursive queries have been traditionally studied in the framework of
datalog, a language that restricts recursion to monotone queries over sets,
which is guaranteed to converge in polynomial time in the size of the input.
But modern big data systems require recursive computations beyond the Boolean
space. In this paper we study the convergence of datalog when it is interpreted
over an arbitrary semiring. We consider an ordered semiring, define the
semantics of a datalog program as a least fixpoint in this semiring, and study
the number of steps required to reach that fixpoint, if ever. We identify
algebraic properties of the semiring that correspond to certain convergence
properties of datalog programs. Finally, we describe a class of ordered
semirings on which one can use the semi-naive evaluation algorithm on any
datalog program.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14438</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14438</id><submitter>Francesco Tudisco</submitter><version version="v1"><date>Sun, 30 May 2021 06:26:21 GMT</date><size>127kb</size><source_type>D</source_type></version><title>Hitting times for non-backtracking random walks</title><authors>Dario Fasino, Arianna Tonetto, Francesco Tudisco</authors><categories>math.PR cs.DM cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A non-backtracking random walk on a graph is a random walk where, at each
step, it is not allowed to return back to the node that has just been left.
Non-backtracking random walks can model physical diffusion phenomena in a more
realistic way than traditional random walks. However, the interest in these
stochastic processes has grown only in recent years and, for this reason, there
are still various open questions. In this work, we show how to compute the
average number of steps a non-backtracking walker takes to reach a specific
node starting from a given node. This problem can be reduced to solving a
linear system that, under suitable conditions, has a unique solution. Finally,
we compute the average number of steps required to perform a round trip from a
given node and we show that mean return times for non-backtracking random walks
coincide with their analogue for random walks in all finite, undirected graphs
in which both stochastic processes are well-defined.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14441</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14441</id><submitter>Cody Karcher</submitter><version version="v1"><date>Sun, 30 May 2021 06:49:26 GMT</date><size>152kb</size><source_type>D</source_type></version><title>Logspace Sequential Quadratic Programming for Design Optimization</title><authors>Cody Karcher</authors><categories>cs.CE math.OC</categories><comments>24 pages, 7 figures, 5 tables, submitted to the AIAA Journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A novel approach to exploiting the log-convex structure present in many
design problems is developed by modifying the classical Sequential Quadratic
Programming (SQP) algorithm. The modified algorithm, Logspace Sequential
Quadratic Programming (LSQP), inherits some of the computational efficiency
exhibited by log-convex methods such as Geometric Programing and Signomial
Programing, but retains the the natural integration of black box analysis
methods from SQP. As a result, significant computational savings is achieved
without the need to invasively modify existing black box analysis methods
prevalent in practical design problems. In the cases considered here, the LSQP
algorithm shows a 40-70% reduction in number of iterations compared to SQP.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14442</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14442</id><submitter>Chundong Wang</submitter><version version="v1"><date>Sun, 30 May 2021 06:50:41 GMT</date><size>393kb</size><source_type>D</source_type></version><title>Reuse Distance-based Copy-backs of Clean Cache Lines to Lower-level
  Caches</title><authors>Rui Wang, Chundong Wang, Chongnan Ye</authors><categories>cs.AR</categories><comments>Under Review</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cache plays a critical role in reducing the performance gap between CPU and
main memory. A modern multi-core CPU generally employs a multi-level hierarchy
of caches, through which the most recently and frequently used data are
maintained in each core's local private caches while all cores share the
last-level cache (LLC). For inclusive caches, clean cache lines replaced in
higher-level caches are not necessarily copied back to lower levels, as the
inclusiveness implies their existences in lower levels. For exclusive and
non-inclusive caches that are widely utilized by Intel, AMD, and ARM today,
either indiscriminately copying back all or none of replaced clean cache lines
to lower levels raises no violation to exclusiveness and non-inclusiveness
definitions.
  We have conducted a quantitative study and found that, copying back all or
none of clean cache lines to lower-level cache of exclusive caches entails
suboptimal performance. The reason is that only a part of cache lines would be
reused and others turn to be dead in a long run. This observation motivates us
to selectively copy back some clean cache lines to LLC in an architecture of
exclusive or non-inclusive caches. We revisit the concept of reuse distance of
cache lines. In a nutshell, a clean cache line with a shorter reuse distance is
copied back to lower-level cache as it is likely to be re-referenced in the
near future, while cache lines with much longer reuse distances would be
discarded or sent to memory if they are dirty. We have implemented and
evaluated our proposal with non-volatile (STT-MRAM) LLC. Experimental results
with gem5 and SPEC CPU 2017 benchmarks show that on average our proposal yields
up to 12.8% higher throughput of IPC (instructions per cycle) than the
least-recently-used (LRU) replacement policy with copying back all clean cache
lines for STT-MRAM LLC.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14444</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14444</id><submitter>Jin Xu</submitter><version version="v1"><date>Sun, 30 May 2021 07:20:27 GMT</date><size>1114kb</size><source_type>D</source_type></version><title>NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural
  Architecture Search</title><authors>Jin Xu, Xu Tan, Renqian Luo, Kaitao Song, Jian Li, Tao Qin, Tie-Yan
  Liu</authors><categories>cs.CL cs.AI cs.LG</categories><comments>Accepted by KDD 2021</comments><doi>10.1145/3447548.3467262</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While pre-trained language models (e.g., BERT) have achieved impressive
results on different natural language processing tasks, they have large numbers
of parameters and suffer from big computational and memory costs, which make
them difficult for real-world deployment. Therefore, model compression is
necessary to reduce the computation and memory cost of pre-trained models. In
this work, we aim to compress BERT and address the following two challenging
practical issues: (1) The compression algorithm should be able to output
multiple compressed models with different sizes and latencies, in order to
support devices with different memory and latency limitations; (2) The
algorithm should be downstream task agnostic, so that the compressed models are
generally applicable for different downstream tasks. We leverage techniques in
neural architecture search (NAS) and propose NAS-BERT, an efficient method for
BERT compression. NAS-BERT trains a big supernet on a search space containing a
variety of architectures and outputs multiple compressed models with adaptive
sizes and latency. Furthermore, the training of NAS-BERT is conducted on
standard self-supervised pre-training tasks (e.g., masked language model) and
does not depend on specific downstream tasks. Thus, the compressed models can
be used across various downstream tasks. The technical challenge of NAS-BERT is
that training a big supernet on the pre-training task is extremely costly. We
employ several techniques including block-wise search, search space pruning,
and performance approximation to improve search efficiency and accuracy.
Extensive experiments on GLUE and SQuAD benchmark datasets demonstrate that
NAS-BERT can find lightweight models with better accuracy than previous
approaches, and can be directly applied to different downstream tasks with
adaptive model sizes for different requirements of memory or latency.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14445</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14445</id><submitter>Jiwei Li</submitter><version version="v1"><date>Sun, 30 May 2021 07:20:28 GMT</date><size>7625kb</size><source_type>D</source_type></version><title>Modeling Text-visual Mutual Dependency for Multi-modal Dialog Generation</title><authors>Shuhe Wang, Yuxian Meng, Xiaofei Sun, Fei Wu, Rongbin Ouyang, Rui Yan,
  Tianwei Zhang, Jiwei Li</authors><categories>cs.CL</categories><comments>arXiv admin note: text overlap with arXiv:2012.15015</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multi-modal dialog modeling is of growing interest. In this work, we propose
frameworks to resolve a specific case of multi-modal dialog generation that
better mimics multi-modal dialog generation in the real world, where each
dialog turn is associated with the visual context in which it takes place.
Specifically, we propose to model the mutual dependency between text-visual
features, where the model not only needs to learn the probability of generating
the next dialog utterance given preceding dialog utterances and visual
contexts, but also the probability of predicting the visual features in which a
dialog utterance takes place, leading the generated dialog utterance specific
to the visual context. We observe significant performance boosts over vanilla
models when the mutual dependency between text and visual features is modeled.
Code is available at https://github.com/ShannonAI/OpenViDial.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14447</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14447</id><submitter>Hu Zhang</submitter><version version="v1"><date>Sun, 30 May 2021 07:26:41 GMT</date><size>365kb</size><source_type>D</source_type></version><title>EPSANet: An Efficient Pyramid Split Attention Block on Convolutional
  Neural Network</title><authors>Hu Zhang and Keke Zu and Jian Lu and Yuru Zou and Deyu Meng</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been demonstrated that the performance of a deep
convolutional neural network can be effectively improved by embedding an
attention module into it. In this work, a novel lightweight and effective
attention method named Pyramid Split Attention (PSA) module is proposed. By
replacing the 3x3 convolution with the PSA module in the bottleneck blocks of
the ResNet, a novel representational block named Efficient Pyramid Split
Attention (EPSA) is obtained. The EPSA block can be easily added as a
plug-and-play component into a well-established backbone network, and
significant improvements on model performance can be achieved. Hence, a simple
and efficient backbone architecture named EPSANet is developed in this work by
stacking these ResNet-style EPSA blocks. Correspondingly, a stronger
multi-scale representation ability can be offered by the proposed EPSANet for
various computer vision tasks including but not limited to, image
classification, object detection, instance segmentation, etc. Without bells and
whistles, the performance of the proposed EPSANet outperforms most of the
state-of-the-art channel attention methods. As compared to the SENet-50, the
Top-1 accuracy is improved by 1.93 % on ImageNet dataset, a larger margin of
+2.7 box AP for object detection and an improvement of +1.7 mask AP for
instance segmentation by using the Mask-RCNN on MS-COCO dataset are obtained.
Our source code is available at:https://github.com/murufeng/EPSANet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14450</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14450</id><submitter>Yang You</submitter><version version="v1"><date>Sun, 30 May 2021 07:41:08 GMT</date><size>1354kb</size><source_type>D</source_type></version><title>Maximizing Parallelism in Distributed Training for Huge Neural Networks</title><authors>Zhengda Bian and Qifan Xu and Boxiang Wang and Yang You</authors><categories>cs.DC cs.LG cs.PF</categories><comments>Technical Report of NUS HPC-AI Lab (https://ai.comp.nus.edu.sg). The
  leading two authors have equal contributions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent Natural Language Processing techniques have been refreshing the
state-of-the-art performance at an incredible speed. Training huge language
models is therefore an imperative demand in both industry and academy. However,
huge language models impose challenges to both hardware and software. Graphical
processing units (GPUs) are iterated frequently to meet the exploding demand,
and a variety of ASICs like TPUs are spawned. However, there is still a tension
between the fast growth of the extremely huge models and the fact that Moore's
law is approaching the end. To this end, many model parallelism techniques are
proposed to distribute the model parameters to multiple devices, so as to
alleviate the tension on both memory and computation. Our work is the first to
introduce a 3-dimensional model parallelism for expediting huge language
models. By reaching a perfect load balance, our approach presents smaller
memory and communication cost than existing state-of-the-art 1-D and 2-D model
parallelism. Our experiments on 64 TACC's V100 GPUs show that our 3-D
parallelism outperforms the 1-D and 2-D parallelism with 2.32x and 1.57x
speedup, respectively.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14452</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14452</id><submitter>Xinghan Liu</submitter><version version="v1"><date>Sun, 30 May 2021 07:49:56 GMT</date><size>115kb</size></version><title>A logic for binary classifiers and their explanation</title><authors>Xinghan Liu and Emiliano Lorini</authors><categories>cs.LO cs.AI math.LO</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed a renewed interest in Boolean function in
explaining binary classifiers in the field of explainable AI (XAI). The
standard approach of Boolean function is propositional logic. We present a
modal language of a ceteris paribus nature which supports reasoning about
binary classifiers and their properties. We study families of decision models
for binary classifiers, axiomatize them and show completeness of our
axiomatics. Moreover, we prove that the variant of our modal language with
finite propositional atoms interpreted over these models is NP-complete. We
leverage the language to formalize counterfactual conditional as well as a
bunch of notions of explanation such as abductive, contrastive and
counterfactual explanations, and biases. Finally, we present two extensions of
our language: a dynamic extension by the notion of assignment enabling
classifier change and an epistemic extension in which the classifier's
uncertainty about the actual input can be represented.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14454</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14454</id><submitter>Sungdong Kim</submitter><version version="v1"><date>Sun, 30 May 2021 07:54:54 GMT</date><size>7676kb</size><source_type>D</source_type></version><title>NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based
  Simulation</title><authors>Sungdong Kim, Minsuk Chang and Sang-Woo Lee</authors><categories>cs.CL</categories><comments>Accepted to ACL 2021 as a long paper</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose NeuralWOZ, a novel dialogue collection framework that uses
model-based dialogue simulation. NeuralWOZ has two pipelined models, Collector
and Labeler. Collector generates dialogues from (1) user's goal instructions,
which are the user context and task constraints in natural language, and (2)
system's API call results, which is a list of possible query responses for user
requests from the given knowledge base. Labeler annotates the generated
dialogue by formulating the annotation as a multiple-choice problem, in which
the candidate labels are extracted from goal instructions and API call results.
We demonstrate the effectiveness of the proposed method in the zero-shot domain
transfer learning for dialogue state tracking. In the evaluation, the synthetic
dialogue corpus generated from NeuralWOZ achieves a new state-of-the-art with
improvements of 4.4% point joint goal accuracy on average across domains, and
improvements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1
dataset.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14455</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14455</id><submitter>Nathan Lepora</submitter><version version="v1"><date>Sun, 30 May 2021 07:56:56 GMT</date><size>9601kb</size><source_type>D</source_type></version><title>Soft Biomimetic Optical Tactile Sensing with the TacTip: A Review</title><authors>Nathan F. Lepora</authors><categories>cs.RO</categories><comments>13 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reproducing the capabilities of the human sense of touch in machines is an
important step in enabling robot manipulation to have the ease of human
dexterity. A combination of robotic technologies will be needed, including soft
robotics, biomimetics and the high-resolution sensing offered by optical
tactile sensors. This combination is considered here as a SoftBOT (Soft
Biomimetic Optical Tactile) sensor. This article reviews the BRL TacTip as a
prototypical example of such a sensor. Topics include the relation between
artificial skin morphology and the transduction principles of human touch, the
nature and benefits of tactile shear sensing, 3D printing for fabrication and
integration into robot hands, the application of AI to tactile perception and
control, and the recent step-change in capabilities due to deep learning. This
review consolidates those advances from the past decade to indicate a path for
robots to reach human-like dexterity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14457</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14457</id><submitter>David Chuan-En Lin</submitter><version version="v1"><date>Sun, 30 May 2021 08:04:42 GMT</date><size>1136kb</size><source_type>D</source_type></version><title>Learning Personal Style from Few Examples</title><authors>David Chuan-En Lin, Nikolas Martelaro</authors><categories>cs.CV cs.HC</categories><acm-class>H.5.0; I.5.4; J.5</acm-class><doi>10.1145/3461778.3462115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key task in design work is grasping the client's implicit tastes. Designers
often do this based on a set of examples from the client. However, recognizing
a common pattern among many intertwining variables such as color, texture, and
layout and synthesizing them into a composite preference can be challenging. In
this paper, we leverage the pattern recognition capability of computational
models to aid in this task. We offer a set of principles for computationally
learning personal style. The principles are manifested in PseudoClient, a deep
learning framework that learns a computational model for personal graphic
design style from only a handful of examples. In several experiments, we found
that PseudoClient achieves a 79.40% accuracy with only five positive and
negative examples, outperforming several alternative methods. Finally, we
discuss how PseudoClient can be utilized as a building block to support the
development of future design applications.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14461</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14461</id><submitter>Shunchuan Yang</submitter><version version="v1"><date>Sun, 30 May 2021 08:23:51 GMT</date><size>2553kb</size><source_type>D</source_type></version><title>A Hybrid SIE-PDE Formulation Without Boundary Condition Requirement for
  Electromagnetic Analysis</title><authors>Aipeng Sun, Zekun Zhu, Shunchuan Yang</authors><categories>math.NA cs.CE cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hybrid surface integral equation partial differential equation (SIE-PDE)
formulation without the boundary condition requirement is proposed to solve the
electromagnetic problems. In the proposed formulation, the computational domain
is decomposed into two \emph{overlapping} domains: the SIE and PDE domains. In
the SIE domain, complex structures with piecewise homogeneous media, e.g.,
highly conductive media, are included. An equivalent model for those structures
is constructed through replacing them by the background medium and introducing
a surface equivalent electric current density on an enclosed boundary to
represent their electromagnetic effects. The remaining computational domain and
homogeneous background medium replaced domain consist of the PDE domain, in
which inhomogeneous or non-isotropic media are included. Through combining the
surface equivalent electric current density and the inhomogeneous Helmholtz
equation, a hybrid SIE-PDE formulation is derived. Unlike other hybrid
formulations, where the transmission condition is usually used, no boundary
conditions are required in the proposed SIE-PDE formulation, and it is
mathematically equivalent to the original physical model. Through careful
construction of basis functions to expand electric fields and the equivalent
current density, the discretized formulation is compatible on the interface of
the SIE and PDE domain. Finally, its accuracy and efficiency are validated
through two numerical examples. Results show that the proposed SIE-PDE
formulation can obtain accurate results including both near and far fields, and
significant performance improvements in terms of CPU time and memory
consumption compared with the FEM are achieved.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14462</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14462</id><submitter>Zhiyong Wu</submitter><version version="v1"><date>Sun, 30 May 2021 08:27:16 GMT</date><size>1426kb</size><source_type>D</source_type></version><title>Good for Misconceived Reasons: An Empirical Revisiting on the Need for
  Visual Context in Multimodal Machine Translation</title><authors>Zhiyong Wu, Lingpeng Kong, Wei Bi, Xiang Li, Ben Kao</authors><categories>cs.CL cs.AI</categories><comments>To appear at ACL 2021 main conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A neural multimodal machine translation (MMT) system is one that aims to
perform better translation by extending conventional text-only translation
models with multimodal information. Many recent studies report improvements
when equipping their models with the multimodal module, despite the controversy
of whether such improvements indeed come from the multimodal part. We revisit
the contribution of multimodal information in MMT by devising two interpretable
MMT models. To our surprise, although our models replicate similar gains as
recently developed multimodal-integrated systems achieved, our models learn to
ignore the multimodal information. Upon further investigation, we discover that
the improvements achieved by the multimodal models over text-only counterparts
are in fact results of the regularization effect. We report empirical findings
that highlight the importance of MMT models' interpretability, and discuss how
our findings will benefit future research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14463</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14463</id><submitter>Batya Kenig</submitter><version version="v1"><date>Sun, 30 May 2021 08:30:14 GMT</date><size>41kb</size></version><title>Approximate Implication with d-Separation</title><authors>Batya Kenig</authors><categories>cs.AI cs.IT math.IT</categories><comments>Accepted for the 37th conference on Uncertainty in Artificial
  Intelligence (UAI 2021)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The graphical structure of Probabilistic Graphical Models (PGMs) encodes the
conditional independence (CI) relations that hold in the modeled distribution.
Graph algorithms, such as d-separation, use this structure to infer additional
conditional independencies, and to query whether a specific CI holds in the
distribution. The premise of all current systems-of-inference for deriving CIs
in PGMs, is that the set of CIs used for the construction of the PGM hold
exactly. In practice, algorithms for extracting the structure of PGMs from
data, discover approximate CIs that do not hold exactly in the distribution. In
this paper, we ask how the error in this set propagates to the inferred CIs
read off the graphical structure. More precisely, what guarantee can we provide
on the inferred CI when the set of CIs that entailed it hold only
approximately? It has recently been shown that in the general case, no such
guarantee can be provided. We prove that such a guarantee exists for the set of
CIs inferred in directed graphical models, making the d-separation algorithm a
sound and complete system for inferring approximate CIs. We also prove an
approximation guarantee for independence relations derived from marginal CIs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14464</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14464</id><submitter>Joseph Chataignon</submitter><version version="v1"><date>Sun, 30 May 2021 08:32:54 GMT</date><size>979kb</size><source_type>D</source_type></version><title>Comparison-limited Vector Quantization</title><authors>Joseph Chataignon, Stefano Rini</authors><categories>cs.IT math.IT</categories><comments>27 pages, 10 figures</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In this paper a variation of the classic vector quantization problem is
considered. In the standard formulation, a quantizer is designed to minimize
the distortion between input and output when the number of reconstruction
points is fixed. We consider, instead, the scenario in which the number of
comparators used in quantization is fixed. More precisely, we study the case in
which a vector quantizer of dimension d is comprised of k comparators, each
receiving a linear combination of the inputs and producing the output value
one/zero if this linear combination is above/below a certain threshold. In
reconstruction, the comparators' output is mapped to a reconstruction point,
chosen so as to minimize a chosen distortion measure between the quantizer
input and its reconstruction. The Comparison-Limited Vector Quantization (CLVQ)
problem is then defined as the problem of optimally designing the configuration
of the compactors and the choice of reconstruction points so as to minimize the
given distortion. In this paper, we design a numerical optimization algorithm
for the CLVQ problem. This algorithm leverages combinatorial geometrical
notions to describe the hyperplane arrangement induced by the configuration of
the comparators. It also relies on a genetic genetic meta heuristic to improve
the selection of the quantizer initialization and avoid local minima
encountered during optimization. We numerically evaluate the performance of our
algorithm in the case of input distributions following uniform and Gaussian
i.i.d. sources to be compressed under quadratic distortion and compare it to
the classic Linde-Buzo-Gray (LBG) algorithm.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14465</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14465</id><submitter>Pradipta Biswas</submitter><version version="v1"><date>Sun, 30 May 2021 08:37:35 GMT</date><size>206kb</size></version><title>A Brief Survey on Interactive Automotive UI</title><authors>Gowdham Prabhakar and Pradipta Biswas</authors><categories>cs.HC</categories><acm-class>H.5.2</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automotive User Interface (AutoUI) is relatively a new discipline in the
context of both Transportation Engineering and Human Machine Interaction (HMI).
It covers various HMI aspects both inside and outside vehicle ranging from
operating the vehicle itself, undertaking various secondary tasks, driver
behaviour analysis, cognitive load estimation and so on. This review paper
discusses various interactive HMI inside a vehicle used for undertaking
secondary tasks. We divided recent HMIs through four sections on virtual touch
interfaces, wearable devices, speech recognition and non-visual interfaces and
eye gaze controlled systems. Finally, we summarized advantages and
disadvantages of various technologies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14467</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14467</id><submitter>Ruyi Ji</submitter><version version="v1"><date>Sun, 30 May 2021 08:53:11 GMT</date><size>803kb</size><source_type>D</source_type></version><title>Occam Learning Meets Synthesis Through Unification</title><authors>Ruyi Ji, Jingtao Xia, Yingfei Xiong, Zhenjiang Hu</authors><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalizability of PBE solvers is the key to the empirical synthesis
performance. Despite the importance of generalizability, related studies on PBE
solvers are still limited. In theory, few existing solvers provide theoretical
guarantees on generalizability, and in practice, there is a lack of PBE solvers
with satisfactory generalizability on important domains such as conditional
linear integer arithmetic (CLIA). In this paper, we adopt a concept from the
computational learning theory, Occam learning, and perform a comprehensive
study on the framework of synthesis through unification (STUN), a
state-of-the-art framework for synthesizing programs with nested if-then-else
operators. We prove that Eusolver, a state-of-the-art STUN solver, does not
satisfy the condition of Occam learning, and then we design a novel STUN
solver, PolyGen, of which the generalizability is theoretically guaranteed by
Occam learning. We evaluate PolyGen on the domains of CLIA and demonstrate that
PolyGen significantly outperforms two state-of-the-art PBE solvers on CLIA,
Eusolver and Euphony, on both generalizability and efficiency.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14470</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14470</id><submitter>Seyed Mojtaba Hosseini Bamakan</submitter><version version="v1"><date>Sun, 30 May 2021 09:09:09 GMT</date><size>1827kb</size></version><title>Internet of Everything Driven Neuromarketing: Key Technologies and
  Challenges</title><authors>Seyed Mojtaba Hosseini Bamakan, Aref Toghroljerdib, Peyman Tirandazib</authors><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Preserving customers' expectations and understanding factors affecting their
purchasing decisions would significantly affect designing effective marketing
and advertising strategies. However, constantly and swiftly changing the
customers' interests and consumption behaviors, make it inevitable to utilize
the sophisticated tools and approaches based on advanced technologies. Among
them, neuromarketing by measuring the customers' physiological and neural
signals, studying the consumers' cognitive, and affective responses to
marketing stimulus, provides deep insight into the customers' motivations,
preferences, and decisions. Recently, the Internet of Everything (IoE) has
brought many new opportunities to the industry and has attracted the attention
of many researchers in recent years. The main objective of this paper is to
address how the Internet of Everything (IoE) would empower neuromarketing
techniques. In particular, applications of IoE gadgets and devices in eleven
groups of neuromarketing techniques are discussed to present numerous solutions
that would help meet this goal. Moreover, we present an in-depth understanding
of current research issues as well as emerging trends.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14471</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14471</id><submitter>Chin-Jui Chang</submitter><version version="v1"><date>Sun, 30 May 2021 09:14:39 GMT</date><size>12135kb</size><source_type>D</source_type></version><title>Reducing the Deployment-Time Inference Control Costs of Deep
  Reinforcement Learning Agents via an Asymmetric Architecture</title><authors>Chin-Jui Chang, Yu-Wei Chu, Chao-Hsien Ting, Hao-Kang Liu, Zhang-Wei
  Hong, Chun-Yi Lee</authors><categories>cs.AI cs.RO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep reinforcement learning (DRL) has been demonstrated to provide promising
results in several challenging decision making and control tasks. However, the
required inference costs of deep neural networks (DNNs) could prevent DRL from
being applied to mobile robots which cannot afford high energy-consuming
computations. To enable DRL methods to be affordable in such energy-limited
platforms, we propose an asymmetric architecture that reduces the overall
inference costs via switching between a computationally expensive policy and an
economic one. The experimental results evaluated on a number of representative
benchmark suites for robotic control tasks demonstrate that our method is able
to reduce the inference costs while retaining the agent's overall performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14473</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14473</id><submitter>Isabelle Augenstein</submitter><version version="v1"><date>Sun, 30 May 2021 09:16:11 GMT</date><size>44kb</size><source_type>D</source_type></version><title>Determining the Credibility of Science Communication</title><authors>Isabelle Augenstein</authors><categories>cs.DL cs.CL</categories><journal-ref>In Proceedings of the Second Workshop on Scholarly Document
  Processing (SDP at NAACL 2021)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most work on scholarly document processing assumes that the information
processed is trustworthy and factually correct. However, this is not always the
case. There are two core challenges, which should be addressed: 1) ensuring
that scientific publications are credible -- e.g. that claims are not made
without supporting evidence, and that all relevant supporting evidence is
provided; and 2) that scientific findings are not misrepresented, distorted or
outright misreported when communicated by journalists or the general public. I
will present some first steps towards addressing these problems and outline
remaining challenges.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14476</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14476</id><submitter>Xianyuan Zhan</submitter><version version="v1"><date>Sun, 30 May 2021 09:28:25 GMT</date><size>6585kb</size><source_type>D</source_type></version><title>CSCAD: Correlation Structure-based Collective Anomaly Detection in
  Complex System</title><authors>Huiling Qin, Xianyuan Zhan, Yu Zheng</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting anomalies in large complex systems is a critical and challenging
task. The difficulties arise from several aspects. First, collecting ground
truth labels or prior knowledge for anomalies is hard in real-world systems,
which often lead to limited or no anomaly labels in the dataset. Second,
anomalies in large systems usually occur in a collective manner due to the
underlying dependency structure among devices or sensors. Lastly, real-time
anomaly detection for high-dimensional data requires efficient algorithms that
are capable of handling different types of data (i.e. continuous and discrete).
We propose a correlation structure-based collective anomaly detection (CSCAD)
model for high-dimensional anomaly detection problem in large systems, which is
also generalizable to semi-supervised or supervised settings. Our framework
utilize graph convolutional network combining a variational autoencoder to
jointly exploit the feature space correlation and reconstruction deficiency of
samples to perform anomaly detection. We propose an extended mutual information
(EMI) metric to mine the internal correlation structure among different data
features, which enhances the data reconstruction capability of CSCAD. The
reconstruction loss and latent standard deviation vector of a sample obtained
from reconstruction network can be perceived as two natural anomalous degree
measures. An anomaly discriminating network can then be trained using low
anomalous degree samples as positive samples, and high anomalous degree samples
as negative samples. Experimental results on five public datasets demonstrate
that our approach consistently outperforms all the competing baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14477</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14477</id><submitter>Yuqing Song</submitter><version version="v1"><date>Sun, 30 May 2021 09:28:43 GMT</date><size>3032kb</size><source_type>D</source_type></version><title>Towards Diverse Paragraph Captioning for Untrimmed Videos</title><authors>Yuqing Song, Shizhe Chen, Qin Jin</authors><categories>cs.CV</categories><comments>Accepted by CVPR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video paragraph captioning aims to describe multiple events in untrimmed
videos with descriptive paragraphs. Existing approaches mainly solve the
problem in two steps: event detection and then event captioning. Such two-step
manner makes the quality of generated paragraphs highly dependent on the
accuracy of event proposal detection which is already a challenging task. In
this paper, we propose a paragraph captioning model which eschews the
problematic event detection stage and directly generates paragraphs for
untrimmed videos. To describe coherent and diverse events, we propose to
enhance the conventional temporal attention with dynamic video memories, which
progressively exposes new video features and suppresses over-accessed video
contents to control visual focuses of the model. In addition, a
diversity-driven training strategy is proposed to improve diversity of
paragraph on the language perspective. Considering that untrimmed videos
generally contain massive but redundant frames, we further augment the video
encoder with keyframe awareness to improve efficiency. Experimental results on
the ActivityNet and Charades datasets show that our proposed model
significantly outperforms the state-of-the-art performance on both accuracy and
diversity metrics without using any event boundary annotations. Code will be
released at https://github.com/syuqings/video-paragraph.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14478</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14478</id><submitter>Yian Li</submitter><version version="v1"><date>Sun, 30 May 2021 09:29:01 GMT</date><size>5243kb</size></version><title>Pre-training Universal Language Representation</title><authors>Yian Li, Hai Zhao</authors><categories>cs.CL cs.AI</categories><comments>Accepted by ACL-IJCNLP 2021 main conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the well-developed cut-edge representation learning for language,
most language representation models usually focus on specific levels of
linguistic units. This work introduces universal language representation
learning, i.e., embeddings of different levels of linguistic units or text with
quite diverse lengths in a uniform vector space. We propose the training
objective MiSAD that utilizes meaningful n-grams extracted from large unlabeled
corpus by a simple but effective algorithm for pre-trained language models.
Then we empirically verify that well designed pre-training scheme may
effectively yield universal language representation, which will bring great
convenience when handling multiple layers of linguistic objects in a unified
way. Especially, our model achieves the highest accuracy on analogy tasks in
different language levels and significantly improves the performance on
downstream tasks in the GLUE benchmark and a question answering dataset.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14483</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14483</id><submitter>Sabrina Francesca Pellegrino</submitter><version version="v1"><date>Sun, 30 May 2021 09:45:24 GMT</date><size>1137kb</size><source_type>D</source_type></version><title>Computation of Eigenvalues for Nonlocal Models by Spectral Methods</title><authors>Luciano Lopez and Sabrina Francesca Pellegrino</authors><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The purpose of this work is to study spectral methods to approximate the
eigenvalues of nonlocal integral operators. Indeed, even if the spatial domain
is an interval, it is very challenging to obtain closed analytical expressions
for the eigenpairs of peridynamic operators. Our approach is based on the weak
formulation of eigenvalue problem and we consider as orthogonal basis to
compute the eigenvalues a set of Fourier trigonometric or Chebyshev
polynomials. We show the order of convergence for eigenvalues and
eigenfunctions in $L^2$-norm, and finally, we perform some numerical
simulations to compare the two proposed methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14484</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14484</id><submitter>Jiancheng An</submitter><version version="v1"><date>Sun, 30 May 2021 09:46:04 GMT</date><size>1774kb</size></version><title>Joint Training of the Superimposed Direct and Reflected Links in
  Reconfigurable Intelligent Surface Assisted Multiuser Communications</title><authors>Jiancheng An, Chao Xu, Li Wang, Yusha Liu, Lu Gan, and Lajos Hanzo</authors><categories>cs.IT eess.SP math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In Reconfigurable intelligent surface (RIS)-assisted systems the acquisition
of CSI and the optimization of the reflecting coefficients constitute a pair of
salient design issues. In this paper, a novel channel training protocol is
proposed, which is capable of achieving a flexible performance vs. signalling
and pilot overhead as well as implementation complexity trade-off. More
specifically, first of all, we conceive a holistic channel estimation protocol,
which integrates the existing channel estimation techniques and passive
beamforming design. Secondly, we propose a new channel training framework. In
contrast to the conventional channel estimation arrangements, our new framework
divides the training phase into several periods, where the superimposed
end-to-end channel is estimated instead of separately estimating the direct
BS-user channel and cascaded reflected BS-RIS-user channels. As a result, the
reflecting coefficients of the RIS are optimized by comparing the objective
function values over multiple training periods. Moreover, the theoretical
performance of our channel training protocol is analyzed and compared to that
under the optimal reflecting coefficients. In addition, the potential benefits
of our channel training protocol in reducing the complexity, pilot overhead as
well as signalling overhead are also detailed. Thirdly, we derive the
theoretical performance of channel estimation protocols and our channel
training protocol in the presence of noise for a SISO scenario, which provides
useful insights into the impact of the noise on the overall RIS performance.
Finally, our numerical simulations characterize the performance of the proposed
protocols and verify our theoretical analysis. In particular, the simulation
results demonstrate that our channel training protocol is more competitive than
the channel estimation protocol at low signal-to-noise ratios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14485</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14485</id><submitter>Xiaozhi Wang</submitter><version version="v1"><date>Sun, 30 May 2021 09:50:17 GMT</date><size>359kb</size><source_type>D</source_type></version><title>CLEVE: Contrastive Pre-training for Event Extraction</title><authors>Ziqi Wang, Xiaozhi Wang, Xu Han, Yankai Lin, Lei Hou, Zhiyuan Liu,
  Peng Li, Juanzi Li, Jie Zhou</authors><categories>cs.CL</categories><comments>Accepted at ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event extraction (EE) has considerably benefited from pre-trained language
models (PLMs) by fine-tuning. However, existing pre-training methods have not
involved modeling event characteristics, resulting in the developed EE models
cannot take full advantage of large-scale unsupervised data. To this end, we
propose CLEVE, a contrastive pre-training framework for EE to better learn
event knowledge from large unsupervised data and their semantic structures
(e.g. AMR) obtained with automatic parsers. CLEVE contains a text encoder to
learn event semantics and a graph encoder to learn event structures
respectively. Specifically, the text encoder learns event semantic
representations by self-supervised contrastive learning to represent the words
of the same events closer than those unrelated words; the graph encoder learns
event structure representations by graph contrastive pre-training on parsed
event-related semantic structures. The two complementary representations then
work together to improve both the conventional supervised EE and the
unsupervised &quot;liberal&quot; EE, which requires jointly extracting events and
discovering event schemata without any annotated data. Experiments on ACE 2005
and MAVEN datasets show that CLEVE achieves significant improvements,
especially in the challenging unsupervised setting. The source code and
pre-trained checkpoints can be obtained from https://github.com/THU-KEG/CLEVE.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14488</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14488</id><submitter>Jun Gao</submitter><version version="v1"><date>Sun, 30 May 2021 10:04:13 GMT</date><size>6565kb</size><source_type>D</source_type></version><title>REAM$\sharp$: An Enhancement Approach to Reference-based Evaluation
  Metrics for Open-domain Dialog Generation</title><authors>Jun Gao, Wei Bi, Ruifeng Xu and Shuming Shi</authors><categories>cs.CL</categories><comments>ACL Findings 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The lack of reliable automatic evaluation metrics is a major impediment to
the development of open-domain dialogue systems. Various reference-based
metrics have been proposed to calculate a score between a predicted response
and a small set of references. However, these metrics show unsatisfactory
correlations with human judgments. For a reference-based metric, its
reliability mainly depends on two factors: its ability to measure the
similarity between the predicted response and the reference response, as well
as the reliability of the given reference set. Yet, there are few discussions
on the latter. Our work attempts to fill this vacancy. We first clarify an
assumption on reference-based metrics that, if more high-quality references are
added into the reference set, the reliability of the metric will increase.
Next, we present REAM$\sharp$: an enhancement approach to Reference-based
EvAluation Metrics for open-domain dialogue systems. A prediction model is
designed to estimate the reliability of the given reference set. We show how
its predicted results can be helpful to augment the reference set, and thus
improve the reliability of the metric. Experiments validate both the
effectiveness of our prediction model and that the reliability of
reference-based metrics improves with the augmented reference sets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14490</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14490</id><submitter>Ailing Zeng</submitter><version version="v1"><date>Sun, 30 May 2021 10:12:56 GMT</date><size>6866kb</size><source_type>D</source_type></version><title>Hop-Aware Dimension Optimization for Graph Neural Networks</title><authors>Ailing Zeng, Minhao Liu, Zhiwei Liu, Ruiyuan Gao, Qiang Xu</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Graph Neural Networks (GNNs), the embedding of each node is obtained by
aggregating information with its direct and indirect neighbors. As the messages
passed among nodes contain both information and noise, the critical issue in
GNN representation learning is how to retrieve information effectively while
suppressing noise. Generally speaking, interactions with distant nodes usually
introduce more noise for a particular node than those with close nodes.
However, in most existing works, the messages being passed among nodes are
mingled together, which is inefficient from a communication perspective. Mixing
the information from clean sources (low-order neighbors) and noisy sources
(high-order neighbors) makes discriminative feature extraction challenging.
Motivated by the above, we propose a simple yet effective ladder-style GNN
architecture, namely LADDER-GNN. Specifically, we separate messages from
different hops and assign different dimensions for them before concatenating
them to obtain the node representation. Such disentangled representations
facilitate extracting information from messages passed from different hops, and
their corresponding dimensions are determined with a reinforcement
learning-based neural architecture search strategy. The resulted hop-aware
representations generally contain more dimensions for low-order neighbors and
fewer dimensions for high-order neighbors, leading to a ladder-style
aggregation scheme. We verify the proposed LADDER-GNN on several
semi-supervised node classification datasets. Experimental results show that
the proposed simple hop-aware representation learning solution can achieve
state-of-the-art performance on most datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14491</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14491</id><submitter>Shaked Brody</submitter><version version="v1"><date>Sun, 30 May 2021 10:17:58 GMT</date><size>704kb</size><source_type>D</source_type></version><title>How Attentive are Graph Attention Networks?</title><authors>Shaked Brody, Uri Alon, Eran Yahav</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph Attention Networks (GATs) are one of the most popular GNN architectures
and are considered as the state-of-the-art architecture for representation
learning with graphs. In GAT, every node attends to its neighbors given its own
representation as the query. However, in this paper we show that GATs can only
compute a restricted kind of attention where the ranking of attended nodes is
unconditioned on the query node. We formally define this restricted kind of
attention as static attention and distinguish it from a strictly more
expressive dynamic attention. Because GATs use a static attention mechanism,
there are simple graph problems that GAT cannot express: in a controlled
problem, we show that static attention hinders GAT from even fitting the
training data. To remove this limitation, we introduce a simple fix by
modifying the order of operations and propose GATv2: a dynamic graph attention
variant that is strictly more expressive than GAT. We perform an extensive
evaluation and show that GATv2 outperforms GAT across 11 OGB and other
benchmarks while we match their parametric costs. Our code is available at
https://github.com/tech-srl/how_attentive_are_gats .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14493</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14493</id><submitter>Tamer Olmez</submitter><version version="v1"><date>Sun, 30 May 2021 10:34:41 GMT</date><size>3141kb</size></version><title>Generating Ten BCI Commands Using Four Simple Motor Imageries</title><authors>Nuri Korkan, Tamer Olmez, Zumray Dokur</authors><categories>cs.HC cs.LG eess.SP q-bio.NC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The brain computer interface (BCI) systems are utilized for transferring
information among humans and computers by analyzing electroencephalogram (EEG)
recordings.The process of mentally previewing a motor movement without
generating the corporal output can be described as motor imagery (MI).In this
emerging research field, the number of commands is also limited in relation to
the number of MI tasks; in the current literature, mostly two or four commands
(classes) are studied. As a solution to this problem, it is recommended to use
mental tasks as well as MI tasks. Unfortunately, the use of this approach
reduces the classification performance of MI EEG signals. The fMRI analyses
show that the resources in the brain associated with the motor imagery can be
activated independently. It is assumed that the brain activity induced by the
MI of the combination of body parts corresponds to the superposition of the
activities generated during each body parts's simple MI. In this study, in
order to create more than four BCI commands, we suggest to generate combined MI
EEG signals artificially by using left hand, right hand, tongue, and feet motor
imageries in pairs. A maximum of ten different BCI commands can be generated by
using four motor imageries in pairs.This study aims to achieve high
classification performances for BCI commands produced from four motor imageries
by implementing a small-sized deep neural network (DNN).The presented method is
evaluated on the four-class datasets of BCI Competitions III and IV, and an
average classification performance of 81.8% is achieved for ten classes. The
above assumption is also validated on a different dataset which consists of
simple and combined MI EEG signals acquired in real time. Trained with the
artificially generated combined MI EEG signals, DivFE resulted in an average of
76.5% success rate for the combined MI EEG signals acquired in real-time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14499</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14499</id><submitter>Matteo Rubagotti</submitter><version version="v1"><date>Sun, 30 May 2021 11:03:01 GMT</date><size>1130kb</size><source_type>D</source_type></version><title>Perceived Safety in Physical Human Robot Interaction -- A Survey</title><authors>Matteo Rubagotti, Inara Tusseyeva, Sara Baltabayeva, Danna Summers,
  Anara Sandygulova</authors><categories>cs.RO</categories><comments>23 pages, 3 figures, 4 tables, submitted for journal publication</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This review paper focuses on different aspects of perceived safety for a
number of autonomous physical systems. This is a major aspect of robotics
research, as more and more applications allow human and autonomous systems to
share their space, with crucial implications both on safety and on its
perception. The alternative terms used to express related concepts (e.g.,
psychological safety, trust, comfort, stress, fear, and anxiety) are listed and
explained. Then, the available methods to assess perceived safety (i.e.,
questionnaires, physiological measurements, behavioral assessment, and direct
input devices) are described. Six categories of autonomous systems are
considered (industrial manipulators, mobile robots, mobile manipulators,
humanoid robots, drones, and autonomous vehicles), providing an overview of the
main themes related to perceived safety in the specific domain, a description
of selected works, and an analysis of how motion and characteristics of the
system influence the perception of safety. The survey also discusses
experimental duration and location of the reviewed papers as well as identified
trends over time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14500</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14500</id><submitter>Boxiang Wang</submitter><version version="v1"><date>Sun, 30 May 2021 11:06:49 GMT</date><size>135kb</size><source_type>D</source_type></version><title>2.5-dimensional distributed model training</title><authors>Boxiang Wang, Qifan Xu, Zhengda Bian, Yang You</authors><categories>cs.DC cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data parallelism does a good job in speeding up the training. However, when
it comes to the case when the memory of a single device can not host a whole
model, data parallelism would not have the chance to do anything. Another
option is to split the model by operator, or horizontally. Megatron-LM
introduced a 1-Dimensional distributed method to use GPUs to speed up the
training process. Optimus is a 2D solution for distributed tensor parallelism.
However, these methods have a high communication overhead and a low scaling
efficiency on large-scale computing clusters. To solve this problem, we
investigate the 2.5-Dimensional distributed tensor parallelism.Introduced by
Solomonik et al., 2.5-Dimensional Matrix Multiplication developed an effective
method to perform multiple Cannon's algorithm at the same time to increase the
efficiency. With many restrictions of Cannon's Algorithm and a huge amount of
shift operation, we need to invent a new method of 2.5-dimensional matrix
multiplication to enhance the performance. Absorbing the essence from both
SUMMA and 2.5-Dimensional Matrix Multiplication, we introduced SUMMA2.5-LM for
language models to overcome the abundance of unnecessary transmission loss
result from the increasing size of language model parallelism. Compared to
previous 1D and 2D model parallelization of language models, our SUMMA2.5-LM
managed to reduce the transmission cost on each layer, which could get a 1.45X
efficiency according to our weak scaling result between 2.5-D [4,4,4]
arrangement and 2-D [8,8,1] arrangement.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14504</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14504</id><submitter>Jeremy Barnes</submitter><version version="v1"><date>Sun, 30 May 2021 11:19:46 GMT</date><size>7504kb</size><source_type>D</source_type></version><title>Structured Sentiment Analysis as Dependency Graph Parsing</title><authors>Jeremy Barnes, Robin Kurtz, Stephan Oepen, Lilja {\O}vrelid, Erik
  Velldal</authors><categories>cs.CL</categories><comments>Accepted at ACL-IJCNLP 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Structured sentiment analysis attempts to extract full opinion tuples from a
text, but over time this task has been subdivided into smaller and smaller
sub-tasks, e,g,, target extraction or targeted polarity classification. We
argue that this division has become counterproductive and propose a new unified
framework to remedy the situation. We cast the structured sentiment problem as
dependency graph parsing, where the nodes are spans of sentiment holders,
targets and expressions, and the arcs are the relations between them. We
perform experiments on five datasets in four languages (English, Norwegian,
Basque, and Catalan) and show that this approach leads to strong improvements
over state-of-the-art baselines. Our analysis shows that refining the sentiment
graphs with syntactic dependency information further improves results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14505</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14505</id><submitter>Masahito Hayashi</submitter><version version="v1"><date>Sun, 30 May 2021 11:19:47 GMT</date><size>4467kb</size><source_type>D</source_type></version><title>Computation-aided classical-quantum multiple access to boost network
  communication speeds</title><authors>Masahito Hayashi and Angeles Vazquez-Castro</authors><categories>quant-ph cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiple access channel (MAC) consists of multiple senders simultaneously
transmitting their messages to a single receiver. For the classical-quantum
case (cq-MAC), achievable rates are known assuming that all the messages are
decoded, a common assumption in quantum network design. However, such a
conventional design approach ignores the global network structure, i.e., the
network topology. When a cq-MAC is given as a part of quantum network
communication, this work shows that computation properties can be used to boost
communication speeds with code design dependently on the network topology. We
quantify achievable quantum communication rates of codes with computation
property for a two-sender cq-MAC. When the two-sender cq-MAC is a boson
coherent channel with binary discrete modulation, we show that it achieves the
maximum possible communication rate (the single-user capacity), which cannot be
achieved with conventional design. Further, such a rate can be achieved by
different detection methods: quantum (with and without quantum memory), on-off
photon counting and homodyne (each at different photon power). Finally, we
describe two practical applications, one of which cryptographic.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14506</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14506</id><submitter>Jivitesh Sharma</submitter><version version="v1"><date>Sun, 30 May 2021 11:29:49 GMT</date><size>3486kb</size><source_type>D</source_type></version><title>Human Interpretable AI: Enhancing Tsetlin Machine Stochasticity with
  Drop Clause</title><authors>Jivitesh Sharma, Rohan Yadav, Ole-Christoffer Granmo and Lei Jiao</authors><categories>cs.LG cs.AI cs.NE</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In this article, we introduce a novel variant of the Tsetlin machine (TM)
that randomly drops clauses, the key learning elements of a TM. In effect, TM
with drop clause ignores a random selection of the clauses in each epoch,
selected according to a predefined probability. In this way, additional
stochasticity is introduced in the learning phase of TM. Along with producing
more distinct and well-structured patterns that improve the performance, we
also show that dropping clauses increases learning robustness. To explore the
effects clause dropping has on accuracy, training time, and interpretability,
we conduct extensive experiments on various benchmark datasets in natural
language processing (NLP) (IMDb and SST2) as well as computer vision (MNIST and
CIFAR10). In brief, we observe from +2% to +4% increase in accuracy and 2x to
4x faster learning. We further employ the Convolutional TM to document
interpretable results on the CIFAR10 dataset. To the best of our knowledge,
this is the first time an interpretable machine learning algorithm has been
used to produce pixel-level human-interpretable results on CIFAR10. Also,
unlike previous interpretable methods that focus on attention visualisation or
gradient interpretability, we show that the TM is a more general interpretable
method. That is, by producing rule-based propositional logic expressions that
are \emph{human}-interpretable, the TM can explain how it classifies a
particular instance at the pixel level for computer vision and at the word
level for NLP.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14507</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14507</id><submitter>Mahdi Chehimi</submitter><version version="v1"><date>Sun, 30 May 2021 11:34:23 GMT</date><size>298kb</size><source_type>D</source_type></version><title>Entanglement Rate Optimization in Heterogeneous Quantum Communication
  Networks</title><authors>Mahdi Chehimi and Walid Saad</authors><categories>cs.NI cs.IT math.IT quant-ph</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum communication networks are emerging as a promising technology that
could constitute a key building block in future communication networks in the
6G era and beyond. These networks have an inherent feature of parallelism that
allows them to boost the capacity and enhance the security of communication
systems. Recent advances led to the deployment of small- and large-scale
quantum communication networks with real quantum hardware. In quantum networks,
entanglement is a key resource that allows for data transmission between
different nodes. However, to reap the benefits of entanglement and enable
efficient quantum communication, the number of generated entangled pairs must
be optimized. Indeed, if the entanglement generation rates are not optimized,
then some of these valuable resources will be discarded and lost. In this
paper, the problem of optimizing the entanglement generation rates and their
distribution over a quantum memory is studied. In particular, a quantum network
in which users have heterogeneous distances and applications is considered.
This problem is posed as a mixed integer nonlinear programming optimization
problem whose goal is to efficiently utilize the available quantum memory by
distributing the quantum entangled pairs in a way that maximizes the user
satisfaction. An interior point optimization method is used to solve the
optimization problem and extensive simulations are conducted to evaluate the
effectiveness of the proposed system. Simulation results show the key design
considerations for efficient quantum networks, and the effect of different
network parameters on the network performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14508</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14508</id><submitter>Luca Giuzzi DPhil</submitter><version version="v1"><date>Sun, 30 May 2021 11:35:46 GMT</date><size>16kb</size></version><version version="v2"><date>Thu, 3 Jun 2021 15:57:42 GMT</date><size>16kb</size></version><title>Secret sharing schemes from hypersurfaces over finite fields</title><authors>Angela Aguglia, Michela Ceria, Luca Giuzzi</authors><categories>cs.IT math.CO math.IT</categories><comments>19 pages; version revised after feedback on the original preprint</comments><msc-class>94B05, 51E22, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear error-correcting codes can be used for constructing secret sharing
schemes, however finding in general the access structures of these secret
sharing schemes and, in particular, determining efficient access structures is
difficult. Here we investigate the properties of certain algebraic
hypersurfaces over finite fields, whose intersection numbers with any
hyperplane only takes a few values. These varieties give rise to $q$-divisible
linear codes with at most $5$ weights. Furthermore, for $q$ odd these codes
turn out to be minimal and we characterize the access structures of the secret
sharing schemes based on their dual codes. Indeed, we prove that the secret
sharing schemes thus obtained are democratic that is, each participant belongs
to the same number of minimal access sets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14512</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14512</id><submitter>Mishel Jain</submitter><version version="v1"><date>Sun, 30 May 2021 11:48:34 GMT</date><size>253kb</size><source_type>D</source_type></version><title>SHELBRS: Location Based Recommendation Services using Switchable
  Homomorphic Encryption</title><authors>Mishel Jain, Priyanka Singh, Balasubramanian Raman</authors><categories>cs.CR</categories><comments>9 pages, 6 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Location-Based Recommendation Services (LBRS) has seen an unprecedented rise
in its usage in recent years. LBRS facilitates a user by recommending services
based on his location and past preferences. However, leveraging such services
comes at a cost of compromising one's sensitive information like their shopping
preferences, lodging places, food habits, recently visited places, etc. to the
third-party servers. Losing such information could be crucial and threatens
one's privacy. Nowadays, the privacy-aware society seeks solutions that can
provide such services, with minimized risks. Recently, a few privacy-preserving
recommendation services have been proposed that exploit the fully homomorphic
encryption (FHE) properties to address the issue. Though, it reduced privacy
risks but suffered from heavy computational overheads that ruled out their
commercial applications. Here, we propose SHELBRS, a lightweight LBRS that is
based on switchable homomorphic encryption (SHE), which will benefit the users
as well as the service providers. A SHE exploits both the additive as well as
the multiplicative homomorphic properties but with comparatively much lesser
processing time as it's FHE counterpart. We evaluate the performance of our
proposed scheme with the other state-of-the-art approaches without compromising
security.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14513</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14513</id><submitter>Qi Lu</submitter><version version="v1"><date>Sun, 30 May 2021 11:57:41 GMT</date><size>1008kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 04:54:59 GMT</date><size>1008kb</size><source_type>D</source_type></version><title>Knowledge Transfer for Few-shot Segmentation of Novel White Matter
  Tracts</title><authors>Qi Lu and Chuyang Ye</authors><categories>cs.CV eess.IV</categories><comments>accepted by IPMI 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNNs) have achieved stateof-the-art
performance for white matter (WM) tract segmentation based on diffusion
magnetic resonance imaging (dMRI). These CNNs require a large number of manual
delineations of the WM tracts of interest for training, which are generally
labor-intensive and costly. The expensive manual delineation can be a
particular disadvantage when novel WM tracts, i.e., tracts that have not been
included in existing manual delineations, are to be analyzed. To accurately
segment novel WM tracts, it is desirable to transfer the knowledge learned
about existing WM tracts, so that even with only a few delineations of the
novel WM tracts, CNNs can learn adequately for the segmentation. In this paper,
we explore the transfer of such knowledge to the segmentation of novel WM
tracts in the few-shot setting. Although a classic fine-tuning strategy can be
used for the purpose, the information in the last task-specific layer for
segmenting existing WM tracts is completely discarded. We hypothesize that the
weights of this last layer can bear valuable information for segmenting the
novel WM tracts and thus completely discarding the information is not optimal.
In particular, we assume that the novel WM tracts can correlate with existing
WM tracts and the segmentation of novel WM tracts can be predicted with the
logits of existing WM tracts. In this way, better initialization of the last
layer than random initialization can be achieved for fine-tuning. Further, we
show that a more adaptive use of the knowledge in the last layer for segmenting
existing WM tracts can be conveniently achieved by simply inserting a warmup
stage before classic fine-tuning. The proposed method was evaluated on a
publicly available dMRI dataset, where we demonstrate the benefit of our method
for few-shot segmentation of novel WM tracts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14515</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14515</id><submitter>Rachit Bansal</submitter><version version="v1"><date>Sun, 30 May 2021 12:09:59 GMT</date><size>11602kb</size><source_type>D</source_type></version><title>How Low is Too Low? A Computational Perspective on Extremely
  Low-Resource Languages</title><authors>Rachit Bansal, Himanshu Choudhary, Ravneet Punia, Niko Schenk, Jacob L
  Dahl, \'Emilie Pag\'e-Perron</authors><categories>cs.CL</categories><comments>ACL SRW 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Despite the recent advancements of attention-based deep learning
architectures across a majority of Natural Language Processing tasks, their
application remains limited in a low-resource setting because of a lack of
pre-trained models for such languages. In this study, we make the first attempt
to investigate the challenges of adapting these techniques for an extremely
low-resource language -- Sumerian cuneiform -- one of the world's oldest
written languages attested from at least the beginning of the 3rd millennium
BC. Specifically, we introduce the first cross-lingual information extraction
pipeline for Sumerian, which includes part-of-speech tagging, named entity
recognition, and machine translation. We further curate InterpretLR, an
interpretability toolkit for low-resource NLP, and use it alongside human
attributions to make sense of the models. We emphasize on human evaluations to
gauge all our techniques. Notably, most components of our pipeline can be
generalised to any other language to obtain an interpretable execution of the
techniques, especially in a low-resource setting. We publicly release all
software, model checkpoints, and a novel dataset with domain-specific
pre-processing to promote further research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14517</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14517</id><submitter>Jiaqi Chen</submitter><version version="v1"><date>Sun, 30 May 2021 12:34:17 GMT</date><size>12034kb</size><source_type>D</source_type></version><title>GeoQA: A Geometric Question Answering Benchmark Towards Multimodal
  Numerical Reasoning</title><authors>Jiaqi Chen, Jianheng Tang, Jinghui Qin, Xiaodan Liang, Lingbo Liu,
  Eric P. Xing, Liang Lin</authors><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automatic math problem solving has recently attracted increasing attention as
a long-standing AI benchmark. In this paper, we focus on solving geometric
problems, which requires a comprehensive understanding of textual descriptions,
visual diagrams, and theorem knowledge. However, the existing methods were
highly dependent on handcraft rules and were merely evaluated on small-scale
datasets. Therefore, we propose a Geometric Question Answering dataset GeoQA,
containing 5,010 geometric problems with corresponding annotated programs,
which illustrate the solving process of the given problems. Compared with
another publicly available dataset GeoS, GeoQA is 25 times larger, in which the
program annotations can provide a practical testbed for future research on
explicit and explainable numerical reasoning. Moreover, we introduce a Neural
Geometric Solver (NGS) to address geometric problems by comprehensively parsing
multimodal information and generating interpretable programs. We further add
multiple self-supervised auxiliary tasks on NGS to enhance cross-modal semantic
representation. Extensive experiments on GeoQA validate the effectiveness of
our proposed NGS and auxiliary tasks. However, the results are still
significantly lower than human performance, which leaves large room for future
research. Our benchmark and code are released at
https://github.com/chen-judge/GeoQA .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14519</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14519</id><submitter>Xiongshi Deng</submitter><version version="v1"><date>Sun, 30 May 2021 12:36:32 GMT</date><size>550kb</size></version><title>RFCBF: enhance the performance and stability of Fast Correlation-Based
  Filter</title><authors>Xiongshi Deng, Min Li, Lei Wang, Qikang Wan</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection is a preprocessing step which plays a crucial role in the
domain of machine learning and data mining. Feature selection methods have been
shown to be effctive in removing redundant and irrelevant features, improving
the learning algorithm's prediction performance. Among the various methods of
feature selection based on redundancy, the fast correlation-based filter (FCBF)
is one of the most effective. In this paper, we proposed a novel extension of
FCBF, called RFCBF, which combines resampling technique to improve
classification accuracy. We performed comprehensive experiments to compare the
RFCBF with other state-of-the-art feature selection methods using the KNN
classifier on 12 publicly available data sets. The experimental results show
that the RFCBF algorithm yields significantly better results than previous
state-of-the-art methods in terms of classification accuracy and runtime.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14520</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14520</id><submitter>Jianfeng Li</submitter><version version="v1"><date>Sun, 30 May 2021 12:39:48 GMT</date><size>3046kb</size><source_type>D</source_type></version><title>Unsupervised Joint Learning of Depth, Optical Flow, Ego-motion from
  Video</title><authors>Jianfeng Li, Junqiao Zhao, Shuangfu Song, Tiantian Feng</authors><categories>cs.CV</categories><comments>9 pages, 4 figures</comments><msc-class>65Dxx</msc-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Estimating geometric elements such as depth, camera motion, and optical flow
from images is an important part of the robot's visual perception. We use a
joint self-supervised method to estimate the three geometric elements. Depth
network, optical flow network and camera motion network are independent of each
other but are jointly optimized during training phase. Compared with
independent training, joint training can make full use of the geometric
relationship between geometric elements and provide dynamic and static
information of the scene. In this paper, we improve the joint self-supervision
method from three aspects: network structure, dynamic object segmentation, and
geometric constraints. In terms of network structure, we apply the attention
mechanism to the camera motion network, which helps to take advantage of the
similarity of camera movement between frames. And according to attention
mechanism in Transformer, we propose a plug-and-play convolutional attention
module. In terms of dynamic object, according to the different influences of
dynamic objects in the optical flow self-supervised framework and the
depth-pose self-supervised framework, we propose a threshold algorithm to
detect dynamic regions, and mask that in the loss function respectively. In
terms of geometric constraints, we use traditional methods to estimate the
fundamental matrix from the corresponding points to constrain the camera motion
network. We demonstrate the effectiveness of our method on the KITTI dataset.
Compared with other joint self-supervised methods, our method achieves
state-of-the-art performance in the estimation of pose and optical flow, and
the depth estimation has also achieved competitive results. Code will be
available https://github.com/jianfenglihg/Unsupervised_geometry.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14522</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14522</id><submitter>Zhipeng Dong Ph.D.</submitter><version version="v1"><date>Sun, 30 May 2021 12:40:55 GMT</date><size>13882kb</size><source_type>D</source_type></version><title>Vector Detection Network: An Application Study on Robots Reading Analog
  Meters in the Wild</title><authors>Zhipeng Dong, Yi Gao, Yunhui Yan, Fei Chen</authors><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog meters equipped with one or multiple pointers are wildly utilized to
monitor vital devices' status in industrial sites for safety concerns. Reading
these legacy meters {\bi autonomously} remains an open problem since estimating
pointer origin and direction under imaging damping factors imposed in the wild
could be challenging. Nevertheless, high accuracy, flexibility, and real-time
performance are demanded. In this work, we propose the Vector Detection Network
(VDN) to detect analog meters' pointers given their images, eliminating the
barriers for autonomously reading such meters using intelligent agents like
robots. We tackled the pointer as a two-dimensional vector, whose initial point
coincides with the tip, and the direction is along tail-to-tip. The network
estimates a confidence map, wherein the peak pixels are treated as vectors'
initial points, along with a two-layer scalar map, whose pixel values at each
peak form the scalar components in the directions of the coordinate axes. We
established the Pointer-10K dataset composing of real-world analog meter images
to evaluate our approach due to no similar dataset is available for now.
Experiments on the dataset demonstrated that our methods generalize well to
various meters, robust to harsh imaging factors, and run in real-time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14524</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14524</id><submitter>Jiwei Li</submitter><version version="v1"><date>Sun, 30 May 2021 12:51:45 GMT</date><size>804kb</size><source_type>D</source_type></version><title>Parameter Estimation for the SEIR Model Using Recurrent Nets</title><authors>Chun Fan, Yuxian Meng, Xiaofei Sun, Fei Wu, Tianwei Zhang, Jiwei Li</authors><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The standard way to estimate the parameters $\Theta_\text{SEIR}$ (e.g., the
transmission rate $\beta$) of an SEIR model is to use grid search, where
simulations are performed on each set of parameters, and the parameter set
leading to the least $L_2$ distance between predicted number of infections and
observed infections is selected. This brute-force strategy is not only time
consuming, as simulations are slow when the population is large, but also
inaccurate, since it is impossible to enumerate all parameter combinations. To
address these issues, in this paper, we propose to transform the
non-differentiable problem of finding optimal $\Theta_\text{SEIR}$ to a
differentiable one, where we first train a recurrent net to fit a small number
of simulation data. Next, based on this recurrent net that is able to
generalize SEIR simulations, we are able to transform the objective to a
differentiable one with respect to $\Theta_\text{SEIR}$, and straightforwardly
obtain its optimal value. The proposed strategy is both time efficient as it
only relies on a small number of SEIR simulations, and accurate as we are able
to find the optimal $\Theta_\text{SEIR}$ based on the differentiable objective.
On two COVID-19 datasets, we observe that the proposed strategy leads to
significantly better parameter estimations with a smaller number of
simulations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14526</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14526</id><submitter>Nikhil Iyer</submitter><version version="v1"><date>Sun, 30 May 2021 13:06:26 GMT</date><size>331kb</size><source_type>D</source_type></version><title>LRTuner: A Learning Rate Tuner for Deep Neural Networks</title><authors>Nikhil Iyer, V Thejas, Nipun Kwatra, Ramachandran Ramjee, Muthian
  Sivathanu</authors><categories>cs.LG</categories><comments>17 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One very important hyperparameter for training deep neural networks is the
learning rate schedule of the optimizer. The choice of learning rate schedule
determines the computational cost of getting close to a minima, how close you
actually get to the minima, and most importantly the kind of local minima
(wide/narrow) attained. The kind of minima attained has a significant impact on
the generalization accuracy of the network. Current systems employ hand tuned
learning rate schedules, which are painstakingly tuned for each network and
dataset. Given that the state space of schedules is huge, finding a
satisfactory learning rate schedule can be very time consuming. In this paper,
we present LRTuner, a method for tuning the learning rate as training proceeds.
Our method works with any optimizer, and we demonstrate results on SGD with
Momentum, and Adam optimizers.
  We extensively evaluate LRTuner on multiple datasets, models, and across
optimizers. We compare favorably against standard learning rate schedules for
the given dataset and models, including ImageNet on Resnet-50, Cifar-10 on
Resnet-18, and SQuAD fine-tuning on BERT. For example on ImageNet with
Resnet-50, LRTuner shows up to 0.2% absolute gains in test accuracy compared to
the hand-tuned baseline schedule. Moreover, LRTuner can achieve the same
accuracy as the baseline schedule in 29% less optimization steps.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14527</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14527</id><submitter>Denis Roio</submitter><version version="v1"><date>Sun, 30 May 2021 13:07:09 GMT</date><size>830kb</size><source_type>D</source_type></version><title>Reflow: Zero Knowledge Multi Party Signatures with Application to
  Distributed Authentication</title><authors>Denis Roio, Alberto Ibrisevic, Andrea D'Intino</authors><categories>cs.CR cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Reflow is a novel signature scheme supporting unlinkable signatures by
multiple parties authenticated by means of zero-knowledge credentials. Reflow
integrates with blockchains and graph databases to ensure confidentiality and
authenticity of signatures made by disposable identities that can be verified
even when credential issuing authorities are offline. We implement and evaluate
Reflow smart contracts for Zenroom and present an application to produce
authenticated material passports for resource-event-agent accounting systems
based on graph data structures. Reflow uses short and computationally efficient
authentication credentials and can easily scale signatures to include thousands
of participants.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14528</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14528</id><submitter>Jiwei Li</submitter><version version="v1"><date>Sun, 30 May 2021 13:10:32 GMT</date><size>577kb</size><source_type>D</source_type></version><title>Fast Nearest Neighbor Machine Translation</title><authors>Yuxian Meng, Xiaoya Li, Xiayu Zheng, Fei Wu, Xiaofei Sun, Tianwei
  Zhang, Jiwei Li</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Though nearest neighbor Machine Translation ($k$NN-MT)
\cite{khandelwal2020nearest} has proved to introduce significant performance
boosts over standard neural MT systems, it is prohibitively slow since it uses
the entire reference corpus as the datastore for the nearest neighbor search.
This means each step for each beam in the beam search has to search over the
entire reference corpus. $k$NN-MT is thus two-order slower than vanilla MT
models, making it hard to be applied to real-world applications, especially
online services. In this work, we propose Fast $k$NN-MT to address this issue.
Fast $k$NN-MT constructs a significantly smaller datastore for the nearest
neighbor search: for each word in a source sentence, Fast $k$NN-MT first
selects its nearest token-level neighbors, which is limited to tokens that are
the same as the query token. Then at each decoding step, in contrast to using
the entire corpus as the datastore, the search space is limited to target
tokens corresponding to the previously selected reference source tokens. This
strategy avoids search through the whole datastore for nearest neighbors and
drastically improves decoding efficiency. Without loss of performance, Fast
$k$NN-MT is two-order faster than $k$NN-MT, and is only two times slower than
the standard NMT model. Fast $k$NN-MT enables the practical use of $k$NN-MT
systems in real-world MT applications.\footnote{Code is available at
\url{https://github.com/ShannonAI/fast-knn-nmt.}}
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14529</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14529</id><submitter>Changjian Shui</submitter><version version="v1"><date>Sun, 30 May 2021 13:13:55 GMT</date><size>145kb</size><source_type>D</source_type></version><title>On the benefits of representation regularization in invariance based
  domain generalization</title><authors>Changjian Shui, Boyu Wang, Christian Gagn\'e</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A crucial aspect in reliable machine learning is to design a deployable
system in generalizing new related but unobserved environments. Domain
generalization aims to alleviate such a prediction gap between the observed and
unseen environments. Previous approaches commonly incorporated learning
invariant representation for achieving good empirical performance. In this
paper, we reveal that merely learning invariant representation is vulnerable to
the unseen environment. To this end, we derive novel theoretical analysis to
control the unseen test environment error in the representation learning, which
highlights the importance of controlling the smoothness of representation. In
practice, our analysis further inspires an efficient regularization method to
improve the robustness in domain generalization. Our regularization is
orthogonal to and can be straightforwardly adopted in existing domain
generalization algorithms for invariant representation learning. Empirical
results show that our algorithm outperforms the base versions in various
dataset and invariance criteria.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14536</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14536</id><submitter>Jae Lee</submitter><version version="v1"><date>Sun, 30 May 2021 13:27:47 GMT</date><size>12076kb</size><source_type>D</source_type></version><title>On the Lagrangian-Eulerian Coupling in the Immersed Finite
  Element/Difference Method</title><authors>Jae H. Lee and Boyce E. Griffith</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The immersed boundary (IB) method is a non-body conforming approach to
fluid-structure interaction (FSI) that uses an Eulerian description of the
momentum, viscosity, and incompressibility of a coupled fluid-structure system
and a Lagrangian description of the deformations, stresses, and resultant
forces of the immersed structure. Integral transforms with Dirac delta function
kernels couple Eulerian and Lagrangian variables. In practice, discretizations
of these integral transforms use regularized delta function kernels, and
although a number of different types of regularized delta functions have been
proposed, there has been limited prior work to investigate the impact of the
choice of kernel function on the accuracy of the methodology. This work
systematically studies the effect of the choice of regularized delta function
in several fluid-structure interaction benchmark tests using the immersed
finite element/difference (IFED) method, which is an extension of the IB method
that uses finite element structural discretizations combined with a Cartesian
grid finite difference method for the incompressible Navier-Stokes equations.
Further, many IB-type methods evaluate the delta functions at the nodes of the
structural mesh, and this requires the Lagrangian mesh to be relatively fine
compared to the background Eulerian grid to avoid leaks. The IFED formulation
offers the possibility to avoid leaks with relatively coarse structural meshes
by evaluating the delta function on a denser collection of interaction points.
This study investigates the effect of varying the relative mesh widths of the
Lagrangian and Eulerian discretizations. Although this study is done within the
context of the IFED method, the effect of different kernels could be important
not just for this method, but also for other IB-type methods more generally.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14538</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14538</id><submitter>Jia-Hong Huang</submitter><version version="v1"><date>Sun, 30 May 2021 13:37:03 GMT</date><size>1949kb</size><source_type>D</source_type></version><title>Longer Version for &quot;Deep Context-Encoding Network for Retinal Image
  Captioning&quot;</title><authors>Jia-Hong Huang, Ting-Wei Wu, Chao-Han Huck Yang, Marcel Worring</authors><categories>cs.CV cs.AI cs.CL cs.MM</categories><comments>This paper is a longer version of &quot;Deep Context-Encoding Network for
  Retinal Image Captioning&quot; which is accepted by IEEE International Conference
  on Image Processing (ICIP), 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automatically generating medical reports for retinal images is one of the
promising ways to help ophthalmologists reduce their workload and improve work
efficiency. In this work, we propose a new context-driven encoding network to
automatically generate medical reports for retinal images. The proposed model
is mainly composed of a multi-modal input encoder and a fused-feature decoder.
Our experimental results show that our proposed method is capable of
effectively leveraging the interactive information between the input image and
context, i.e., keywords in our case. The proposed method creates more accurate
and meaningful reports for retinal images than baseline models and achieves
state-of-the-art performance. This performance is shown in several commonly
used metrics for the medical report generation task: BLEU-avg (+16%), CIDEr
(+10.2%), and ROUGE (+8.6%).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14540</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14540</id><submitter>Tashnim Chowdhury</submitter><version version="v1"><date>Sun, 30 May 2021 13:39:03 GMT</date><size>3182kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 18:11:43 GMT</date><size>3181kb</size><source_type>D</source_type></version><title>Attention Based Semantic Segmentation on UAV Dataset for Natural
  Disaster Damage Assessment</title><authors>Tashnim Chowdhury, Maryam Rahnemoonfar</authors><categories>cs.CV</categories><comments>arXiv admin note: text overlap with arXiv:2009.01193</comments><msc-class>68T45</msc-class><acm-class>I.4.6</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The detrimental impacts of climate change include stronger and more
destructive hurricanes happening all over the world. Identifying different
damaged structures of an area including buildings and roads are vital since it
helps the rescue team to plan their efforts to minimize the damage caused by a
natural disaster. Semantic segmentation helps to identify different parts of an
image. We implement a novel self-attention based semantic segmentation model on
a high resolution UAV dataset and attain Mean IoU score of around 88% on the
test set. The result inspires to use self-attention schemes in natural disaster
damage assessment which will save human lives and reduce economic losses.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14545</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14545</id><submitter>Xie Xie</submitter><version version="v1"><date>Sun, 30 May 2021 13:51:45 GMT</date><size>97kb</size><source_type>D</source_type></version><title>A Joint Power Splitting, Active and Passive Beamforming Optimization
  Framework for IRS Assisted MIMO SWIPT System</title><authors>Chen He, Xie Xie, Kun Yang and Z. Jane Wang</authors><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper considers an intelligent reflecting surface (IRS) assisted
multi-input multi-output (MIMO) power splitting (PS) based simultaneous
wireless information and power transfer (SWIPT) system with multiple PS
receivers (PSRs). The objective is to maximize the achievable data rate of the
system by jointly optimizing the PS ratios at the PSRs, the active transmit
beamforming (ATB) at the access point (AP), and the passive reflective
beamforming (PRB) at the IRS, while the constraints on maximum transmission
power at the AP, the reflective phase shift of each element at the IRS, the
individual minimum harvested energy requirement of each PSR, and the domain of
PS ratio of each PSR are all satisfied. For this unsolved problem, however,
since the optimization variables are intricately coupled and the constraints
are conflicting, the formulated problem is non-convex, and cannot be addressed
by employing exist approaches directly. To this end, we propose a joint
optimization framework to solve this problem. Particularly, we reformulate it
as an equivalent form by employing the Lagrangian dual transform and the
fractional programming transform, and decompose the transformed problem into
several sub-problems. Then, we propose an alternate optimization algorithm by
capitalizing on the dual sub-gradient method, the successive convex
approximation method, and the penalty-based majorization-minimization approach,
to solve the sub-problems iteratively, and obtain the optimal solutions in
nearly closed-forms. Numerical simulation results verify the effectiveness of
the IRS in SWIPT system and indicate that the proposed algorithm offers a
substantial performance gain.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14547</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14547</id><submitter>Pablo Baldivieso Monasterios</submitter><version version="v1"><date>Sun, 30 May 2021 13:56:05 GMT</date><size>4736kb</size><source_type>D</source_type></version><title>Incorporating forecasting and peer-to-peer negotiation frameworks into a
  distributed model predictive control approach for meshed electric networks</title><authors>Pablo R. Baldivieso Monasterios, Nandor Verba, Euan A Morris, Thomas
  Morstyn, George. C, . Konstantopoulos, Elena Gaura and Stephen McArthur</authors><categories>eess.SY cs.SY</categories><comments>13 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Continuous integration of renewable energy sources into power networks is
causing a paradigm shift in energy generation and distribution with regards to
trading and control; the intermittent nature of renewable sources affects
pricing of energy sold or purchased; the networks are subject to operational
constraints, voltage limits at each node, rated capacities for the power
electronic devices, current bounds for distribution lines. These economic and
technical constraints coupled with intermittent renewable injection may pose a
threat to system stability and performance. We propose a novel holistic
approach to energy trading composed of a distributed predictive control
framework to handle physical interactions, i,e., voltage constraints and power
dispatch, together with a negotiation framework to determine pricing policies
for energy transactions. We study the effect of forecasting generation and
consumption on the overall network's performance and market behaviours. We
provide a rigorous convergence analysis for both the negotiation framework and
the distributed control. Lastly, we assess the impact of forecasting in the
proposed system with the aid of testing scenarios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14548</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14548</id><submitter>Gal Metzer</submitter><version version="v1"><date>Sun, 30 May 2021 13:58:24 GMT</date><size>6467kb</size><source_type>D</source_type></version><title>Z2P: Instant Rendering of Point Clouds</title><authors>Gal Metzer, Rana Hanocka, Raja Giryes, Niloy J. Mitra, Daniel Cohen-Or</authors><categories>cs.GR cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a technique for rendering point clouds using a neural network.
Existing point rendering techniques either use splatting, or first reconstruct
a surface mesh that can then be rendered. Both of these techniques require
solving for global point normal orientation, which is a challenging problem on
its own. Furthermore, splatting techniques result in holes and overlaps,
whereas mesh reconstruction is particularly challenging, especially in the
cases of thin surfaces and sheets.
  We cast the rendering problem as a conditional image-to-image translation
problem. In our formulation, Z2P, i.e., depth-augmented point features as
viewed from target camera view, are directly translated by a neural network to
rendered images, conditioned on control variables (e.g., color, light). We
avoid inevitable issues with splatting (i.e., holes and overlaps), and bypass
solving the notoriously challenging surface reconstruction problem or
estimating oriented normals. Yet, our approach results in a rendered image as
if a surface mesh was reconstructed. We demonstrate that our framework produces
a plausible image, and can effectively handle noise, non-uniform sampling, thin
surfaces / sheets, and is fast.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14550</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14550</id><submitter>Wei Sun</submitter><version version="v1"><date>Sun, 30 May 2021 14:04:10 GMT</date><size>3850kb</size><source_type>D</source_type></version><title>Blind Quality Assessment for in-the-Wild Images via Hierarchical Feature
  Fusion and Iterative Mixed Database Training</title><authors>Wei Sun and Xiongkuo Min and Guangtao Zhai and Siwei Ma</authors><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image quality assessment (IQA) is very important for both end-users and
service-providers since a high-quality image can significantly improve the
user's quality of experience (QoE). Most existing blind image quality
assessment (BIQA) models were developed for synthetically distorted images,
however, they perform poorly on in-the-wild images, which are widely existed in
various practical applications. In this paper, we propose a novel BIQA model
for in-the-wild images by addressing two critical problems in this field: how
to learn better quality-aware features, and how to solve the problem of
insufficient training samples. Considering that perceptual visual quality is
affected by both low-level visual features and high-level semantic information,
we first propose a staircase structure to hierarchically integrate the features
from intermediate layers into the final feature representation, which enables
the model to make full use of visual information from low-level to high-level.
Then an iterative mixed database training (IMDT) strategy is proposed to train
the BIQA model on multiple databases simultaneously, so the model can benefit
from the increase in both training samples and image content and distortion
diversity and can learn a more general feature representation. Experimental
results show that the proposed model outperforms other state-of-the-art BIQA
models on six in-the-wild IQA databases by a large margin. Moreover, the
proposed model shows an excellent performance in the cross-database evaluation
experiments, which further demonstrates that the learned feature representation
is robust to images sampled from various distributions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14553</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14553</id><submitter>Rongzhou Bao</submitter><version version="v1"><date>Sun, 30 May 2021 14:24:53 GMT</date><size>5944kb</size><source_type>D</source_type></version><title>Defending Pre-trained Language Models from Adversarial Word
  Substitutions Without Performance Sacrifice</title><authors>Rongzhou Bao, Jiayi Wang, Hai Zhao</authors><categories>cs.CL</categories><comments>Findings of ACL: ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Pre-trained contextualized language models (PrLMs) have led to strong
performance gains in downstream natural language understanding tasks. However,
PrLMs can still be easily fooled by adversarial word substitution, which is one
of the most challenging textual adversarial attack methods. Existing defence
approaches suffer from notable performance loss and complexities. Thus, this
paper presents a compact and performance-preserved framework, Anomaly Detection
with Frequency-Aware Randomization (ADFAR). In detail, we design an auxiliary
anomaly detection classifier and adopt a multi-task learning procedure, by
which PrLMs are able to distinguish adversarial input samples. Then, in order
to defend adversarial word substitution, a frequency-aware randomization
process is applied to those recognized adversarial input samples. Empirical
results show that ADFAR significantly outperforms those newly proposed defense
methods over various tasks with much higher inference speed. Remarkably, ADFAR
does not impair the overall performance of PrLMs. The code is available at
https://github.com/LilyNLP/ADFAR
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14556</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14556</id><submitter>Yinhe Zheng Dr.</submitter><version version="v1"><date>Sun, 30 May 2021 14:41:09 GMT</date><size>903kb</size><source_type>D</source_type></version><title>Diversifying Dialog Generation via Adaptive Label Smoothing</title><authors>Yida Wang, Yinhe Zheng, Yong Jiang, Minlie Huang</authors><categories>cs.CL cs.AI</categories><comments>ACL2021 Main Track (Long Paper), Code Available in
  https://github.com/lemon234071/AdaLabel</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural dialogue generation models trained with the one-hot target
distribution suffer from the over-confidence issue, which leads to poor
generation diversity as widely reported in the literature. Although existing
approaches such as label smoothing can alleviate this issue, they fail to adapt
to diverse dialog contexts. In this paper, we propose an Adaptive Label
Smoothing (AdaLabel) approach that can adaptively estimate a target label
distribution at each time step for different contexts. The maximum probability
in the predicted distribution is used to modify the soft target distribution
produced by a novel light-weight bi-directional decoder module. The resulting
target distribution is aware of both previous and future contexts and is
adjusted to avoid over-training the dialogue model. Our model can be trained in
an end-to-end manner. Extensive experiments on two benchmark datasets show that
our approach outperforms various competitive baselines in producing diverse
responses.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14557</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14557</id><submitter>Chengbin Hou</submitter><version version="v1"><date>Sun, 30 May 2021 14:44:26 GMT</date><size>2519kb</size><source_type>D</source_type></version><title>Robust Dynamic Network Embedding via Ensembles</title><authors>Chengbin Hou, Guoji Fu, Peng Yang, Shan He, Ke Tang</authors><categories>cs.SI cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic Network Embedding (DNE) has recently attracted considerable attention
due to the advantage of network embedding in various applications and the
dynamic nature of many real-world networks. For dynamic networks, the degree of
changes, i.e., defined as the averaged number of changed edges between
consecutive snapshots spanning a dynamic network, could be very different in
real-world scenarios. Although quite a few DNE methods have been proposed, it
still remains unclear that whether and to what extent the existing DNE methods
are robust to the degree of changes, which is however an important factor in
both academic research and industrial applications. In this work, we
investigate the robustness issue of DNE methods w.r.t. the degree of changes
for the first time and accordingly, propose a robust DNE method. Specifically,
the proposed method follows the notion of ensembles where the base learner
adopts an incremental Skip-Gram neural embedding approach. To further boost the
performance, a novel strategy is proposed to enhance the diversity among base
learners at each timestep by capturing different levels of local-global
topology. Extensive experiments demonstrate the benefits of special designs in
the proposed method, and the superior performance of the proposed method
compared to state-of-the-art methods. The comparative study also reveals the
robustness issue of some DNE methods. The source code is available at
https://github.com/houchengbin/SG-EDNE
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14559</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14559</id><submitter>Jae Oh Woo</submitter><version version="v1"><date>Sun, 30 May 2021 14:49:10 GMT</date><size>1646kb</size><source_type>D</source_type></version><title>BABA: Beta Approximation for Bayesian Active Learning</title><authors>Jae Oh Woo</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper introduces a new acquisition function under the Bayesian active
learning framework, namely BABA. It is motivated by previously well-established
works BALD, and BatchBALD which capture the mutual information between the
model parameters and the predictive outputs of the data. Our proposed measure,
BABA, endeavors to quantify the normalized mutual information by approximating
the stochasticity of predictive probabilities using Beta distributions. BABA
outperforms the well-known family of acquisition functions, including BALD and
BatchBALD. We demonstrate this by showing extensive experimental results
obtained from MNIST and EMNIST datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14564</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14564</id><submitter>Danish Sattar</submitter><version version="v1"><date>Sun, 30 May 2021 15:07:12 GMT</date><size>109kb</size><source_type>D</source_type></version><title>Evaluating Resilience of Encrypted Traffic Classification Against
  Adversarial Evasion Attacks</title><authors>Ramy Maarouf, Danish Sattar, and Ashraf Matrawy</authors><categories>cs.CR cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning and deep learning algorithms can be used to classify
encrypted Internet traffic. Classification of encrypted traffic can become more
challenging in the presence of adversarial attacks that target the learning
algorithms. In this paper, we focus on investigating the effectiveness of
different evasion attacks and see how resilient machine and deep learning
algorithms are. Namely, we test C4.5 Decision Tree, K-Nearest Neighbor (KNN),
Artificial Neural Network (ANN), Convolutional Neural Networks (CNN) and
Recurrent Neural Networks (RNN). In most of our experimental results, deep
learning shows better resilience against the adversarial samples in comparison
to machine learning. Whereas, the impact of the attack varies depending on the
type of attack.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14565</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14565</id><submitter>JingKai Siow</submitter><version version="v1"><date>Sun, 30 May 2021 15:09:40 GMT</date><size>539kb</size><source_type>D</source_type></version><title>SPI: Automated Identification of Security Patches via Commits</title><authors>Yaqin Zhou, Jing Kai Siow, Chenyu Wang, ShangQing Liu, Yang Liu</authors><categories>cs.CR cs.SE</categories><comments>Accepted By ACM Transactions on Software Engineering and Methodology
  (TOSEM), Continuous Special Section: AI and SE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security patches in open-source software, providing security fixes to
identified vulnerabilities, are crucial in protecting against cyberattacks.
Despite the National Vulnerability Database (NVD) publishes identified
vulnerabilities, a vast majority of vulnerabilities and their corresponding
security patches remain beyond public exposure, e.g., in the open-source
libraries that are heavily relied on by developers. An extensive security
patches dataset could help end-users such as security companies, e.g., building
a security knowledge base, or researchers, e.g., aiding in vulnerability
research. To curate security patches including undisclosed patches at a large
scale and low cost, we propose a deep neural-network-based approach built upon
commits of open-source repositories. We build security patch datasets that
include 38,291 security-related commits and 1,045 CVE patches from four C
libraries. We manually verify each commit, among the 38,291 security-related
commits, to determine if they are security-related. We devise a deep
learning-based security patch identification system that consists of two neural
networks: one commit-message neural network that utilizes pretrained word
representations learned from our commits dataset; and one code-revision neural
network that takes code before and after revision and learns the distinction on
the statement level. Our evaluation results show that our system outperforms
SVM and K-fold stacking algorithm, achieving as high as 87.93% F1-score and
precision of 86.24%. We deployed our pipeline and learned model in an
industrial production environment to evaluate the generalization ability of our
approach. The industrial dataset consists of 298,917 commits from 410 new
libraries that range from a wide functionality. Our experiment results and
observation proved that our approach identifies security patches effectively
among open-sourced projects.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14566</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14566</id><submitter>Hao Cheng</submitter><version version="v1"><date>Sun, 30 May 2021 15:11:53 GMT</date><size>805kb</size><source_type>D</source_type></version><title>CNN Retrieval based Unsupervised Metric Learning for Near-Duplicated
  Video Retrieval</title><authors>Hao Cheng, Ping Wang, Chun Qi</authors><categories>cs.IR</categories><comments>This paper is submitted to ICIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As important data carriers, the drastically increasing number of multimedia
videos often brings many duplicate and near-duplicate videos in the top results
of search. Near-duplicate video retrieval (NDVR) can cluster and filter out the
redundant contents. In this paper, the proposed NDVR approach extracts the
frame-level video representation based on convolutional neural network (CNN)
features from fully-connected layer and aggregated intermediate convolutional
layers. Unsupervised metric learning is used for similarity measurement and
feature matching. An efficient re-ranking algorithm combined with k-nearest
neighborhood fuses the retrieval results from two levels of features and
further improves the retrieval performance. Extensive experiments on the widely
used CC\_WEB\_VIDEO dataset shows that the proposed approach exhibits superior
performance over the state-of-the-art.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14568</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14568</id><submitter>Ronald Pereira</submitter><version version="v1"><date>Sun, 30 May 2021 15:17:13 GMT</date><size>37kb</size><source_type>D</source_type></version><title>How effective are Graph Neural Networks in Fraud Detection for Network
  Data?</title><authors>Ronald D. R. Pereira and Fabr\'icio Murai</authors><categories>cs.LG cs.AI</categories><comments>12 pages, in Portuguese</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graph-based Neural Networks (GNNs) are recent models created for learning
representations of nodes (and graphs), which have achieved promising results
when detecting patterns that occur in large-scale data relating different
entities. Among these patterns, financial fraud stands out for its
socioeconomic relevance and for presenting particular challenges, such as the
extreme imbalance between the positive (fraud) and negative (legitimate
transactions) classes, and the concept drift (i.e., statistical properties of
the data change over time). Since GNNs are based on message propagation, the
representation of a node is strongly impacted by its neighbors and by the
network's hubs, amplifying the imbalance effects. Recent works attempt to adapt
undersampling and oversampling strategies for GNNs in order to mitigate this
effect without, however, accounting for concept drift. In this work, we conduct
experiments to evaluate existing techniques for detecting network fraud,
considering the two previous challenges. For this, we use real data sets,
complemented by synthetic data created from a new methodology introduced here.
Based on this analysis, we propose a series of improvement points that should
be investigated in future research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14572</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14572</id><submitter>Azim Ahmadzadeh</submitter><version version="v1"><date>Sun, 30 May 2021 15:31:42 GMT</date><size>500kb</size><source_type>D</source_type></version><title>Multiscale IoU: A Metric for Evaluation of Salient Object Detection with
  Fine Structures</title><authors>Azim Ahmadzadeh, Dustin J. Kempton, Yang Chen, Rafal A. Angryk</authors><categories>cs.CV</categories><comments>5 pages, 3 figures, ICIP 2021</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  General-purpose object-detection algorithms often dismiss the fine structure
of detected objects. This can be traced back to how their proposed regions are
evaluated. Our goal is to renegotiate the trade-off between the generality of
these algorithms and their coarse detections. In this work, we present a new
metric that is a marriage of a popular evaluation metric, namely Intersection
over Union (IoU), and a geometrical concept, called fractal dimension. We
propose Multiscale IoU (MIoU) which allows comparison between the detected and
ground-truth regions at multiple resolution levels. Through several
reproducible examples, we show that MIoU is indeed sensitive to the fine
boundary structures which are completely overlooked by IoU and f1-score. We
further examine the overall reliability of MIoU by comparing its distribution
with that of IoU on synthetic and real-world datasets of objects. We intend
this work to re-initiate exploration of new evaluation methods for
object-detection algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14573</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14573</id><submitter>Zhongwang Zhang</submitter><version version="v1"><date>Sun, 30 May 2021 15:32:32 GMT</date><size>1237kb</size><source_type>D</source_type></version><title>Embedding Principle of Loss Landscape of Deep Neural Networks</title><authors>Yaoyu Zhang, Zhongwang Zhang, Tao Luo, Zhi-Qin John Xu</authors><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the structure of loss landscape of deep neural networks
(DNNs)is obviously important. In this work, we prove an embedding principle
that the loss landscape of a DNN &quot;contains&quot; all the critical points of all the
narrower DNNs. More precisely, we propose a critical embedding such that any
critical point, e.g., local or global minima, of a narrower DNN can be embedded
to a critical point/hyperplane of the target DNN with higher degeneracy and
preserving the DNN output function. The embedding structure of critical points
is independent of loss function and training data, showing a stark difference
from other nonconvex problems such as protein-folding. Empirically, we find
that a wide DNN is often attracted by highly-degenerate critical points that
are embedded from narrow DNNs. The embedding principle provides an explanation
for the general easy optimization of wide DNNs and unravels a potential
implicit low-complexity regularization during the training. Overall, our work
provides a skeleton for the study of loss landscape of DNNs and its
implication, by which a more exact and comprehensive understanding can be
anticipated in the near
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14574</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14574</id><submitter>Aristeidis Panos</submitter><version version="v1"><date>Sun, 30 May 2021 15:37:57 GMT</date><size>245kb</size><source_type>D</source_type></version><title>Scalable and Interpretable Marked Point Processes</title><authors>Aristeidis Panos, Ioannis Kosmidis, Petros Dellaportas</authors><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a novel inferential framework for marked point processes that
enjoys both scalability and interpretability. The framework is based on
variational inference and it aims to speed up inference for a flexible family
of marked point processes where the joint distribution of times and marks can
be specified in terms of the conditional distribution of times given the
process filtration, and of the conditional distribution of marks given the
process filtration and the current time. We assess the predictive ability of
our proposed method over four real-world datasets where results show its
competitive performance against other baselines. The attractiveness of our
framework for the modelling of marked point processes is illustrated through a
case study of association football data where scalability and interpretability
are exploited for extracting useful informative patterns.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14576</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14576</id><submitter>Yingying Deng</submitter><version version="v1"><date>Sun, 30 May 2021 15:57:09 GMT</date><size>8311kb</size><source_type>D</source_type></version><title>StyTr^2: Unbiased Image Style Transfer with Transformers</title><authors>Yingying Deng and Fan Tang and Xingjia Pan, Weiming Dong and
  ChongyangMa and Changsheng Xu</authors><categories>cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The goal of image style transfer is to render an image with artistic features
guided by a style reference while maintaining the original content. Due to the
locality and spatial invariance in CNNs, it is difficult to extract and
maintain the global information of input images. Therefore, traditional neural
style transfer methods are usually biased and content leak can be observed by
running several times of the style transfer process with the same reference
style image. To address this critical issue, we take long-range dependencies of
input images into account for unbiased style transfer by proposing a
transformer-based approach, namely StyTr^2. In contrast with visual
transformers for other vision tasks, our StyTr^2 contains two different
transformer encoders to generate domain-specific sequences for content and
style, respectively. Following the encoders, a multi-layer transformer decoder
is adopted to stylize the content sequence according to the style sequence. In
addition, we analyze the deficiency of existing positional encoding methods and
propose the content-aware positional encoding (CAPE) which is scale-invariant
and more suitable for image style transfer task. Qualitative and quantitative
experiments demonstrate the effectiveness of the proposed StyTr^2 compared to
state-of-the-art CNN-based and flow-based approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14579</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14579</id><submitter>Francesco Ranzato</submitter><version version="v1"><date>Sun, 30 May 2021 16:39:55 GMT</date><size>239kb</size><source_type>D</source_type></version><title>A Rice's Theorem for Abstract Semantics</title><authors>Paolo Baldan and Francesco Ranzato and Linpeng Zhang</authors><categories>cs.LO cs.FL</categories><comments>Full version of a conference paper presented at the 48th
  International Colloquium on Automata, Languages, and Programming (ICALP 2021)</comments><acm-class>F.1.1; F.3.1</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Classical results in computability theory, notably Rice's theorem, focus on
the extensional content of programs, namely, on the partial recursive functions
that programs compute. Later and more recent work investigated intensional
generalisations of such results that take into account the way in which
functions are computed, thus affected by the specific programs computing them.
In this paper, we single out a novel class of program semantics based on
abstract domains of program properties that are able to capture nonextensional
aspects of program computations, such as their asymptotic complexity or logical
invariants, and allow us to generalise some foundational computability results
such as Rice's Theorem and Kleene's Second Recursion Theorem to these
semantics. In particular, it turns out that for this class of abstract program
semantics, any nontrivial abstract property is undecidable and every decidable
overapproximation necessarily includes an infinite set of false positives which
covers all values of the semantic abstract domain.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14582</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14582</id><submitter>Angel Arcos-Vargas</submitter><version version="v1"><date>Sun, 30 May 2021 17:00:20 GMT</date><size>1743kb</size></version><title>Robustness of electricity systems with nearly 100% share of renewables:
  a worst-case study</title><authors>Francisco Gutierrez-Garcia, Angel Arcos-Vargas, Antonio Gomez-Exposito</authors><categories>eess.SY cs.SY</categories><comments>33 pages, 13 figures, 10 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Several research studies have shown that future sustainable electricity
systems, mostly based on renewable generation and storage, are feasible with
current technologies and costs. However, recent episodes of extreme weather
conditions, probably associated with climate change, cast shades of doubt on
whether the resulting generation portfolios are sufficiently robust to assure,
at all times, a suitable balance between generation and demand, when adverse
conditions are faced. To address this issue, this work elaborates a methodology
intended to determine a sustainable electricity system that can endure extreme
weather conditions, which are likely to occur. First, using hourly production
and demand data from the last decade, along with estimates of new uses of
electricity, a worst-case scenario is constructed, including the storage
capacity and additional photovoltaic power which are needed to serve the demand
on an hourly basis. Next, several key parameters which may have a significant
influence on the LCOE are considered, and a sensitivity analysis is carried out
to determine their real impact, significance and potential trends. The proposed
methodology is then applied to the Spanish system. The results show that, under
the hypotheses and conditions considered in this paper, it is possible to
design a decarbonized electricity system that, taking advantage of existing
sustainable assets, satisfies the long-term needs by providing a reliable
supply at an average cost significantly lower than current market prices.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14583</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14583</id><submitter>J\&quot;urgen Gro{\ss}</submitter><version version="v1"><date>Sun, 30 May 2021 17:08:36 GMT</date><size>274kb</size><source_type>D</source_type></version><title>A Note On The Randomized Kaczmarz Method With A Partially Weighted
  Selection Step</title><authors>J\&quot;urgen Gro{\ss}</authors><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this note we reconsider two known algorithms which both usually converge
faster than the randomized Kaczmarz method introduced by Strohmer and
Vershynin(2009), but require the additional computation of all residuals of an
iteration at each step. As already indicated in the literature, e.g.
arXiv:2007.02910 and arXiv:2011.14693, it is shown that the non-randomized
version of the two algorithms converges at least as fast as the randomized
version, while still requiring computation of all residuals. Based on that
observation, a new simple random sample selection scheme has been introduced by
arXiv:2011.14693 to reduce the required total of residuals. In the same light
we propose an alternative random selection scheme which can easily be included
as a `partially weighted selection step' into the classical randomized Kaczmarz
algorithm without much ado. Numerical examples show that the randomly
determined number of required residuals can be quite moderate.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14584</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14584</id><submitter>Gunhee Nam</submitter><version version="v1"><date>Sun, 30 May 2021 17:12:36 GMT</date><size>8669kb</size><source_type>D</source_type></version><title>Polygonal Point Set Tracking</title><authors>Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim</authors><categories>cs.CV cs.AI cs.LG</categories><comments>14 pages, 10 figures, 6 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose a novel learning-based polygonal point set tracking
method. Compared to existing video object segmentation~(VOS) methods that
propagate pixel-wise object mask information, we propagate a polygonal point
set over frames.
  Specifically, the set is defined as a subset of points in the target contour,
and our goal is to track corresponding points on the target contour. Those
outputs enable us to apply various visual effects such as motion tracking, part
deformation, and texture mapping. To this end, we propose a new method to track
the corresponding points between frames by the global-local alignment with
delicately designed losses and regularization terms. We also introduce a novel
learning strategy using synthetic and VOS datasets that makes it possible to
tackle the problem without developing the point correspondence dataset. Since
the existing datasets are not suitable to validate our method, we build a new
polygonal point set tracking dataset and demonstrate the superior performance
of our method over the baselines and existing contour-based VOS methods. In
addition, we present visual-effects applications of our method on part
distortion and text mapping.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14586</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14586</id><submitter>Hardhik Mohanty</submitter><version version="v1"><date>Sun, 30 May 2021 17:28:41 GMT</date><size>260kb</size></version><title>Kolmogorov-Smirnov Test-Based Actively-Adaptive Thompson Sampling for
  Non-Stationary Bandits</title><authors>Gourab Ghatak, Hardhik Mohanty, Aniq Ur Rahman</authors><categories>stat.ML cs.LG cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the non-stationary multi-armed bandit (MAB) framework and propose
a Kolmogorov-Smirnov (KS) test based Thompson Sampling (TS) algorithm named
TS-KS, that actively detects change points and resets the TS parameters once a
change is detected. In particular, for the two-armed bandit case, we derive
bounds on the number of samples of the reward distribution to detect the change
once it occurs. Consequently, we show that the proposed algorithm has
sub-linear regret. Contrary to existing works, our algorithm is able to detect
a change when the underlying reward distribution changes even though the mean
reward remains the same. Finally, to test the efficacy of the proposed
algorithm, we employ it in two case-studies: i) task-offloading scenario in
wireless edge-computing, and ii) portfolio optimization. Our results show that
the proposed TS-KS algorithm outperforms not only the static TS algorithm but
also it performs better than other bandit algorithms designed for
non-stationary environments. Moreover, the performance of TS-KS is at par with
the state-of-the-art forecasting algorithms such as Facebook-PROPHET and ARIMA.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14594</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14594</id><submitter>Yingzhen Li</submitter><version version="v1"><date>Sun, 30 May 2021 18:17:47 GMT</date><size>857kb</size><source_type>D</source_type></version><title>Sparse Uncertainty Representation in Deep Learning with Inducing Weights</title><authors>Hippolyt Ritter, Martin Kukla, Cheng Zhang, Yingzhen Li</authors><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bayesian neural networks and deep ensembles represent two modern paradigms of
uncertainty quantification in deep learning. Yet these approaches struggle to
scale mainly due to memory inefficiency issues, since they require parameter
storage several times higher than their deterministic counterparts. To address
this, we augment the weight matrix of each layer with a small number of
inducing weights, thereby projecting the uncertainty quantification into such
low dimensional spaces. We further extend Matheron's conditional Gaussian
sampling rule to enable fast weight sampling, which enables our inference
method to maintain reasonable run-time as compared with ensembles. Importantly,
our approach achieves competitive performance to the state-of-the-art in
prediction and uncertainty estimation tasks with fully connected neural
networks and ResNets, while reducing the parameter size to $\leq 24.3\%$ of
that of a $single$ neural network.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14599</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14599</id><submitter>Franziska Scherpinski</submitter><version version="v1"><date>Sun, 30 May 2021 18:40:07 GMT</date><size>798kb</size></version><title>Personalization in E-Grocery: Top-N versus Top-k Rankings</title><authors>Franziska Scherpinski, Stefan Lessmann</authors><categories>cs.IR</categories><msc-class>62P20</msc-class><acm-class>H.3.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Business success in e-commerce depends on customer perceived value. A
customer with high perceived value buys, returns, and recommends items. The
perceived value is at risk whenever the information load harms users' shopping
experience. In e-grocery, shoppers face an overwhelming number of items, the
majority of which is irrelevant for the shopper. Recommender systems (RS)
enable businesses to master information overload (IO) by providing users with
an item ranking by relevance. Prior work proposes RS with short personalized
rankings (top-k). Given large order sizes and high user heterogeneity in
e-grocery, top-k RS are insufficient to diminish IO in this domain. To fill
this gap and raise business performance, this paper introduces an RS with a
personalized long ranking (top-N). Undertaking a randomized field experiment,
the paper establishes the merit of shifting from top-k to top-N rankings.
Specifically, the proposed RS reduces IO by 29.4% and lowers users' search time
by 3.3 seconds per item. The field experiment also reveals a 7% uplift in
revenue due to the top-N ranking. Substantial benefits for the customer and the
company highlight the business value of top-N rankings as a new design
requirement for recommender systems in e-grocery.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14600</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14600</id><submitter>Md Shad Akhtar Dr.</submitter><version version="v1"><date>Sun, 30 May 2021 18:53:33 GMT</date><size>3843kb</size><source_type>D</source_type></version><title>HIT: A Hierarchically Fused Deep Attention Network for Robust Code-mixed
  Language Representation</title><authors>Ayan Sengupta, Sourabh Kumar Bhattacharjee, Tanmoy Chakraborty, Md
  Shad Akhtar</authors><categories>cs.CL</categories><comments>15 pages, 13 tables, 6 Figures. Accepted at ACL-IJCNLP-2021
  (Findings)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Understanding linguistics and morphology of resource-scarce code-mixed texts
remains a key challenge in text processing. Although word embedding comes in
handy to support downstream tasks for low-resource languages, there are plenty
of scopes in improving the quality of language representation particularly for
code-mixed languages. In this paper, we propose HIT, a robust representation
learning method for code-mixed texts. HIT is a hierarchical transformer-based
framework that captures the semantic relationship among words and
hierarchically learns the sentence-level semantics using a fused attention
mechanism. HIT incorporates two attention modules, a multi-headed
self-attention and an outer product attention module, and computes their
weighted sum to obtain the attention weights. Our evaluation of HIT on one
European (Spanish) and five Indic (Hindi, Bengali, Tamil, Telugu, and
Malayalam) languages across four NLP tasks on eleven datasets suggests
significant performance improvement against various state-of-the-art systems.
We further show the adaptability of learned representation across tasks in a
transfer learning setup (with and without fine-tuning).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14602</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14602</id><submitter>SueYeon Chung</submitter><version version="v1"><date>Sun, 30 May 2021 19:07:33 GMT</date><size>10801kb</size><source_type>D</source_type></version><title>On the geometry of generalization and memorization in deep neural
  networks</title><authors>Cory Stephenson, Suchismita Padhy, Abhinav Ganesh, Yue Hui, Hanlin
  Tang and SueYeon Chung</authors><categories>cs.LG cond-mat.dis-nn stat.ML</categories><comments>ICLR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding how large neural networks avoid memorizing training data is key
to explaining their high generalization performance. To examine the structure
of when and where memorization occurs in a deep network, we use a recently
developed replica-based mean field theoretic geometric analysis method. We find
that all layers preferentially learn from examples which share features, and
link this behavior to generalization performance. Memorization predominately
occurs in the deeper layers, due to decreasing object manifolds' radius and
dimension, whereas early layers are minimally affected. This predicts that
generalization can be restored by reverting the final few layer weights to
earlier epochs before significant memorization occurred, which is confirmed by
the experiments. Additionally, by studying generalization under different model
sizes, we reveal the connection between the double descent phenomenon and the
underlying model geometry. Finally, analytical analysis shows that networks
avoid memorization early in training because close to initialization, the
gradient contribution from permuted examples are small. These findings provide
quantitative evidence for the structure of memorization across layers of a deep
neural network, the drivers for such structure, and its connection to manifold
geometric properties.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14607</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14607</id><submitter>Adnan Akhunzada</submitter><version version="v1"><date>Sun, 30 May 2021 19:28:52 GMT</date><size>501kb</size></version><title>Power and Performance Efficient SDN-Enabled Fog Architecture</title><authors>Adnan Akhunzada (Senior Member, IEEE), Sherali Zeadally (Senior
  Member, IEEE), Saif ul Islam</authors><categories>cs.DC cs.AI cs.NI</categories><comments>7 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Software Defined Networks (SDNs) have dramatically simplified network
management. However, enabling pure SDNs to respond in real-time while handling
massive amounts of data still remains a challenging task. In contrast, fog
computing has strong potential to serve large surges of data in real-time. SDN
control plane enables innovation, and greatly simplifies network operations and
management thereby providing a promising solution to implement energy and
performance aware SDN-enabled fog computing. Besides, power efficiency and
performance evaluation in SDN-enabled fog computing is an area that has not yet
been fully explored by the research community. We present a novel SDN-enabled
fog architecture to improve power efficacy and performance by leveraging
cooperative and non-cooperative policy-based computing. Preliminary results
from extensive simulation demonstrate an improvement in the power utilization
as well as the overall performance (i.e., processing time, response time).
Finally, we discuss several open research issues that need further
investigation in the future.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14608</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14608</id><submitter>Hassan Almubarak</submitter><version version="v1"><date>Sun, 30 May 2021 19:29:24 GMT</date><size>9763kb</size><source_type>D</source_type></version><title>Safety Embedded Differential Dynamic Programming using Discrete Barrier
  States</title><authors>Hassan Almubarak, Kyle Stachowicz, Nader Sadegh and Evangelos A.
  Theodorou</authors><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Certified safe control is a growing challenge in robotics, especially when
performance and safety objectives are desired to be concurrently achieved. In
this work, we extend the barrier state (BaS) concept, recently proposed for
stabilization of continuous time systems, to enforce safety for discrete time
systems by creating a discrete barrier state (DBaS). The constructed DBaS is
embedded into the discrete model of the safety-critical system in order to
integrate safety objectives into performance objectives. We subsequently use
the proposed technique to implement a safety embedded stabilizing control for
nonlinear discrete systems. Furthermore, we employ the DBaS method to develop a
safety embedded differential dynamic programming (DDP) technique to plan and
execute safe optimal trajectories. The proposed algorithm is leveraged on a
differential wheeled robot and on a quadrotor to safely perform several tasks
including reaching, tracking and safe multi-quadrotor movement. The DBaS-based
DDP (DBaS-DDP) is compared to the penalty method used in constrained DDP
problems where it is shown that the DBaS-DDP consistently outperforms the
penalty method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14609</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14609</id><submitter>Sagie Benaim</submitter><version version="v1"><date>Sun, 30 May 2021 19:32:27 GMT</date><size>3111kb</size><source_type>D</source_type></version><title>Identity and Attribute Preserving Thumbnail Upscaling</title><authors>Noam Gat, Sagie Benaim, Lior Wolf</authors><categories>cs.CV</categories><comments>ICIP 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider the task of upscaling a low resolution thumbnail image of a
person, to a higher resolution image, which preserves the person's identity and
other attributes. Since the thumbnail image is of low resolution, many higher
resolution versions exist. Previous approaches produce solutions where the
person's identity is not preserved, or biased solutions, such as predominantly
Caucasian faces. We address the existing ambiguity by first augmenting the
feature extractor to better capture facial identity, facial attributes (such as
smiling or not) and race, and second, use this feature extractor to generate
high-resolution images which are identity preserving as well as conditioned on
race and facial attributes. Our results indicate an improvement in face
similarity recognition and lookalike generation as well as in the ability to
generate higher resolution images which preserve an input thumbnail identity
and whose race and attributes are maintained.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14613</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14613</id><submitter>Priyaa Thavasimani Dr</submitter><version version="v1"><date>Sun, 30 May 2021 20:01:48 GMT</date><size>1061kb</size><source_type>D</source_type></version><title>Square Kilometre Array : Processing Voluminous MeerKAT Data on IRIS</title><authors>Priyaa Thavasimani, Anna Scaife</authors><categories>astro-ph.IM cs.DC</categories><comments>10 pages, 10 figures</comments><acm-class>H.3.2; H.2.7; B.3.4; C.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Processing astronomical data often comes with huge challenges with regards to
data management as well as data processing. MeerKAT telescope is one of the
precursor telescopes of the World's largest observatory - Square Kilometre
Array. So far, MeerKAT data was processed using the South African computing
facility i.e. IDIA, and exploited to make ground-breaking discoveries. However,
to process MeerKAT data on UK's IRIS computing facility requires new
implementation of the MeerKAT pipeline. This paper focuses on how to transfer
MeerKAT data from the South African site to UK's IRIS systems for processing.
We discuss about our RapifXfer Data transfer framework for transferring the
MeerKAT data from South Africa to the UK, and the MeerKAT job processing
framework pertaining to the UK's IRIS resources.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14614</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14614</id><submitter>Danielle Azar</submitter><version version="v1"><date>Sun, 30 May 2021 20:08:20 GMT</date><size>402kb</size></version><title>Evolution of Activation Functions: An Empirical Investigation</title><authors>Andrew Nader and Danielle Azar</authors><categories>cs.NE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The hyper-parameters of a neural network are traditionally designed through a
time consuming process of trial and error that requires substantial expert
knowledge. Neural Architecture Search (NAS) algorithms aim to take the human
out of the loop by automatically finding a good set of hyper-parameters for the
problem at hand. These algorithms have mostly focused on hyper-parameters such
as the architectural configurations of the hidden layers and the connectivity
of the hidden neurons, but there has been relatively little work on automating
the search for completely new activation functions, which are one of the most
crucial hyper-parameters to choose. There are some widely used activation
functions nowadays which are simple and work well, but nonetheless, there has
been some interest in finding better activation functions. The work in the
literature has mostly focused on designing new activation functions by hand, or
choosing from a set of predefined functions while this work presents an
evolutionary algorithm to automate the search for completely new activation
functions. We compare these new evolved activation functions to other existing
and commonly used activation functions. The results are favorable and are
obtained from averaging the performance of the activation functions found over
30 runs, with experiments being conducted on 10 different datasets and
architectures to ensure the statistical robustness of the study.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14615</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14615</id><submitter>Mohammad Reza Jafari Harandi</submitter><version version="v1"><date>Sun, 30 May 2021 20:10:26 GMT</date><size>44kb</size></version><title>On the Controllers Based on Time Delay Estimation for Robotic
  Manipulators</title><authors>M. Reza J. Harandi</authors><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assurance of asymptotic trajectory tracking in robotic manipulators with a
continuous control law in the presence of unmodeled dynamics or external
disturbance is a challenging problem. Recently, it is asserted that this aim is
achieved by designing a traditional model-free controller together with time
delay estimation (TDE) such that neither dynamical parameters nor conservative
assumptions on the external disturbance are required. In this note, the purpose
is to show that this claim is wrong. Additionally, modification of this method
for some special cases is presented.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14618</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14618</id><submitter>Lun Wang</submitter><version version="v1"><date>Sun, 30 May 2021 20:29:59 GMT</date><size>59kb</size></version><title>FED-$\chi^2$: Privacy Preserving Federated Correlation Test</title><authors>Lun Wang, Qi Pang, Shuai Wang and Dawn Song</authors><categories>cs.CR cs.DC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose the first secure federated $\chi^2$-test protocol
Fed-$\chi^2$. To minimize both the privacy leakage and the communication cost,
we recast $\chi^2$-test to the second moment estimation problem and thus can
take advantage of stable projection to encode the local information in a short
vector. As such encodings can be aggregated with only summation, secure
aggregation can be naturally applied to hide the individual updates. We
formally prove the security guarantee of Fed-$\chi^2$ that the joint
distribution is hidden in a subspace with exponential possible distributions.
Our evaluation results show that Fed-$\chi^2$ achieves negligible accuracy
drops with small client-side computation overhead. In several real-world case
studies, the performance of Fed-$\chi^2$ is comparable to the centralized
$\chi^2$-test.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14619</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14619</id><submitter>Noel Warford</submitter><version version="v1"><date>Sun, 30 May 2021 20:31:55 GMT</date><size>542kb</size><source_type>D</source_type></version><title>Strategies and Perceived Risks of Sending Sensitive Documents</title><authors>Noel Warford (1), Collins W. Munyendo (2), Ashna Mediratta (1), Adam
  J. Aviv (2), and Michelle L. Mazurek (1) ((1) University of Maryland, (2) The
  George Washington University)</authors><categories>cs.CR cs.HC</categories><comments>25 pages, to appear in USENIX Security Symposium 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  People are frequently required to send documents, forms, or other materials
containing sensitive data (e.g., personal information, medical records,
financial data) to remote parties, sometimes without a formal procedure to do
so securely. The specific transmission mechanisms end up relying on the
knowledge and preferences of the parties involved. Through two online surveys
($n=60$ and $n=250$), we explore the various methods used to transmit sensitive
documents, as well as the perceived risk and satisfaction with those methods.
We find that users are more likely to recognize risk to data-at-rest after
receipt (but not at the sender, namely, themselves). When not using an online
portal provided by the recipient, participants primarily envision transmitting
sensitive documents in person or via email, and have little experience using
secure, privacy-preserving alternatives. Despite recognizing general risks,
participants express high privacy satisfaction and convenience with actually
experienced situations. These results suggest opportunities to design new
solutions to promote securely sending sensitive materials, perhaps as new
utilities within standard email workflows.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14620</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14620</id><submitter>Yicong He</submitter><version version="v1"><date>Sun, 30 May 2021 20:33:36 GMT</date><size>14523kb</size></version><title>Non-local Patch-based Low-rank Tensor Ring Completion for Visual Data</title><authors>Yicong He, George K. Atia</authors><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tensor completion is the problem of estimating the missing entries of a
partially observed tensor with a certain low-rank structure. It improves on
matrix completion for image and video data by capturing additional structural
information intrinsic to such data. % With more inherent information involving
in tensor structure than matrix, tensor completion has shown better performance
compared with matrix completion especially in image and video data. Traditional
completion algorithms treat the entire visual data as a tensor, which may not
always work well especially when camera or object motion exists. In this paper,
we develop a novel non-local patch-based tensor ring completion algorithm. In
the proposed approach, similar patches are extracted for each reference patch
along both the spatial and temporal domains of the visual data. The collected
patches are then formed into a high-order tensor and a tensor ring completion
algorithm is proposed to recover the completed tensor. A novel interval
sampling-based block matching (ISBM) strategy and a hybrid completion strategy
are also proposed to improve efficiency and accuracy. Further, we develop an
online patch-based completion algorithm to deal with streaming video data. An
efficient online tensor ring completion algorithm is proposed to reduce the
time cost. Extensive experimental results demonstrate the superior performance
of the proposed algorithms compared with state-of-the-art methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14622</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14622</id><submitter>Giulio Romualdi</submitter><version version="v1"><date>Sun, 30 May 2021 20:54:36 GMT</date><size>3117kb</size><source_type>D</source_type></version><title>Modeling of Visco-Elastic Environments for Humanoid Robot Motion Control</title><authors>Giulio Romualdi, Stefano Dafarra and Daniele Pucci</authors><categories>cs.RO</categories><journal-ref>IEEE Robotics and Automation Letters ( Volume: 6, Issue: 3, July
  2021)</journal-ref><doi>10.1109/LRA.2021.3067589</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript presents a model of compliant contacts for time-critical
humanoid robot motion control. The proposed model considers the environment as
a continuum of spring-damper systems, which allows us to compute the equivalent
contact force and torque that the environment exerts on the contact surface. We
show that the proposed model extends the linear and rotational springs and
dampers - classically used to characterize soft terrains - to the case of large
contact surface orientations. The contact model is then used for the real-time
whole-body control of humanoid robots walking on visco-elastic environments.
The overall approach is validated by simulating walking motions of the iCub
humanoid robot. Furthermore, the paper compares the proposed whole-body control
strategy and state of the art approaches. In this respect, we investigate the
terrain compliance that makes the classical approaches assuming rigid contacts
fail. We finally analyze the robustness of the presented control design with
respect to non-parametric uncertainty in the contact-model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14625</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14625</id><submitter>Thomas Bartz-Beielstein</submitter><version version="v1"><date>Sun, 30 May 2021 21:16:51 GMT</date><size>1832kb</size><source_type>D</source_type></version><title>Surrogate Model Based Hyperparameter Tuning for Deep Learning with SPOT</title><authors>Thomas Bartz-Beielstein</authors><categories>cs.LG</categories><msc-class>68T07</msc-class><acm-class>A.1; B.8.0; G.1.6; G.4; I.2.8</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  A surrogate model based hyperparameter tuning approach for deep learning is
presented. This article demonstrates how the architecture-level parameters
(hyperparameters) of deep learning models that were implemented in
Keras/tensorflow can be optimized. The implementation of the tuning procedure
is 100 % based on R, the software environment for statistical computing. With a
few lines of code, existing R packages (tfruns and SPOT) can be combined to
perform hyperparameter tuning. An elementary hyperparameter tuning task (neural
network and the MNIST data) is used to exemplify this approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14629</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14629</id><submitter>Li Chen</submitter><version version="v1"><date>Sun, 30 May 2021 21:27:58 GMT</date><size>60kb</size></version><title>$\ell_2$-norm Flow Diffusion in Near-Linear Time</title><authors>Li Chen, Richard Peng, and Di Wang</authors><categories>cs.DS cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion is a fundamental graph process and has been a basic building block
in the study of graph clustering and graph learning tasks such as node
classification. In this paper, we initiate the study of computationally
efficient diffusion primitives beyond random walk.
  We provide an $\widetilde{O}(m)$-time randomized algorithm for the
$\ell_2$-norm flow diffusion problem, obtaining the approximation factor of
$1+1/\mathrm{poly}(n)$. Using the connection between its dual solution and
local cut structure, we give an alternative approach for finding locally-biased
low conductance cuts. It is done simply by sweeping over the dual solution
vector.
  This algorithm demonstrates a novel way of dealing with inequality
constraints in graph optimization problems. It adapts the high-level
algorithmic framework of Laplacian system solvers, but requires several new
tools: vertex elimination under constraints, a new family of graph
ultra-sparsifiers, and accelerated proximal gradient methods with inexact
proximal mapping computation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14633</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14633</id><submitter>Zhichao Peng</submitter><version version="v1"><date>Sun, 30 May 2021 21:54:15 GMT</date><size>2010kb</size><source_type>D</source_type></version><title>A learning-based projection method for model order reduction of
  transport problems</title><authors>Zhichao Peng, Min Wang, Fengyan Li</authors><categories>math.NA cs.NA</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kolmogorov $n$-width of the solution manifolds of transport-dominated
problems can decay slowly. As a result, it can be challenging to design
efficient and accurate reduced order models (ROMs) for such problems. To
address this issue, we propose a new learning-based projection method to
construct nonlinear adaptive ROMs for transport problems. The construction
follows the offline-online decomposition. In the offline stage, we train a
neural network to construct adaptive reduced basis dependent on time and model
parameters. In the online stage, we project the solution to the learned reduced
manifold. Inheriting the merits from both deep learning and the projection
method, the proposed method is more efficient than the conventional linear
projection-based methods, and may reduce the generalization error of a solely
learning-based ROM. Unlike some learning-based projection methods, the proposed
method does not need to take derivatives of the neural network in the online
stage.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14634</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14634</id><submitter>Fady Aziz</submitter><version version="v1"><date>Sun, 30 May 2021 21:58:50 GMT</date><size>2215kb</size><source_type>D</source_type></version><title>DimRad: A Radar-Based Perception System for Prosthetic Leg Barrier
  Traversing</title><authors>Fady Aziz, Bassam Elmakhzangy, Christophe Maufroy, Urs Schneider,
  Marco F. Huber</authors><categories>eess.SP cs.RO</categories><comments>5 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lower extremity amputees face challenges in natural locomotion, which is
partially compensated using powered assistive systems, e.g., micro-processor
controlled prosthetic leg. In this paper, a radar-based perception system is
proposed to assist prosthetic legs for autonomous obstacle traversing, focusing
on multiple-step staircases. The presented perception system is composed of a
radar module operating with a multiple-input-multiple-output (MIMO)
configuration to localize consecutive stair corners. An inertial measurement
unit (IMU) is integrated for coordinates correction due to the angular
dis-positioning that occurs because of the knee angular motion. The captured
information from both sensors is used for staircase dimensioning (depth and
height). A shallow neural network (NN) is proposed to model the error due to
the hardware limitations and enhance the dimension estimation accuracy (1 cm).
The algorithm is implemented on a microcontroller subsystem of the radar kit to
qualify the perception system for embedded integration in powered prosthetic
legs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14636</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14636</id><submitter>Zhewei Yao</submitter><version version="v1"><date>Sun, 30 May 2021 22:00:44 GMT</date><size>388kb</size><source_type>D</source_type></version><title>MLPruning: A Multilevel Structured Pruning Framework for
  Transformer-based Models</title><authors>Zhewei Yao, Linjian Ma, Sheng Shen, Kurt Keutzer, Michael W. Mahoney</authors><categories>cs.CL cs.LG</categories><comments>20 pages, 4 figures, 9 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pruning is an effective method to reduce the memory footprint and
computational cost associated with large natural language processing models.
However, current approaches either only explore head pruning, which has a
limited pruning ratio, or only focus on unstructured pruning, which has
negligible effects on the real inference time and/or power consumption. To
address these challenges, we develop a novel MultiLevel structured Pruning
(MLPruning) framework, which uses three different levels of structured pruning:
head pruning, row pruning, and block-wise sparse pruning. We propose using a
learnable Top-k threshold, which employs an adaptive regularization to adjust
the regularization magnitude adaptively, to select appropriate pruning ratios
for different weight matrices. We also propose a two-step pipeline to combine
block-wise pruning with head/row pruning to achieve high structured pruning
ratios with minimum accuracy degradation. Our empirical results show that for
\bertbase, with \textapprox20\% of remaining weights, \OURS can achieve an
accuracy that is comparable to the full model on QQP/MNLI/\squad, with up to
\textapprox3.69x speedup. Our framework has been open sourced~\cite{codebase}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14637</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14637</id><submitter>Fred Morstatter</submitter><version version="v1"><date>Sun, 30 May 2021 22:04:09 GMT</date><size>1469kb</size><source_type>D</source_type></version><title>Organizational Artifacts of Code Development</title><authors>Parisa Kaghazgaran, Nichola Lubold, Fred Morstatter</authors><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Software is the outcome of active and effective communication between members
of an organization. This has been noted with Conway's law, which states that
``organizations design systems that mirror their own communication structure.''
However, software developers are often members of multiple organizational
groups (e.g., corporate, regional,) and it is unclear how association with
groups beyond one's company influence the development process. In this paper,
we study social effects of country by measuring differences in software
repositories associated with different countries. Using a novel dataset we
obtain from GitHub, we identify key properties that differentiate software
repositories based upon the country of the developers. We propose a novel
approach of modeling repositories based on their sequence of development
activities as a sequence embedding task and coupled with repo profile features
we achieve 79.2% accuracy in identifying the country of a repository. Finally,
we conduct a case study on repos from well-known corporations and find that
country can describe the differences in development better than the company
affiliation itself. These results have larger implications for software
development and indicate the importance of considering the multiple groups
developers are associated with when considering the formation and structure of
teams.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14638</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14638</id><submitter>Johannes Otterbach</submitter><version version="v1"><date>Sun, 30 May 2021 22:07:13 GMT</date><size>10794kb</size><source_type>D</source_type></version><title>DAAIN: Detection of Anomalous and Adversarial Input using Normalizing
  Flows</title><authors>Samuel von Bau{\ss}nern, Johannes Otterbach, Adrian Loy, Mathieu
  Salzmann, Thomas Wollmann</authors><categories>cs.CV cs.CR cs.LG</categories><comments>14 pages, 4 figures, 4 tables</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Despite much recent work, detecting out-of-distribution (OOD) inputs and
adversarial attacks (AA) for computer vision models remains a challenge. In
this work, we introduce a novel technique, DAAIN, to detect OOD inputs and AA
for image segmentation in a unified setting. Our approach monitors the inner
workings of a neural network and learns a density estimator of the activation
distribution. We equip the density estimator with a classification head to
discriminate between regular and anomalous inputs. To deal with the
high-dimensional activation-space of typical segmentation networks, we
subsample them to obtain a homogeneous spatial and layer-wise coverage. The
subsampling pattern is chosen once per monitored model and kept fixed for all
inputs. Since the attacker has access to neither the detection model nor the
sampling key, it becomes harder for them to attack the segmentation network, as
the attack cannot be backpropagated through the detector. We demonstrate the
effectiveness of our approach using an ESPNet trained on the Cityscapes dataset
as segmentation model, an affine Normalizing Flow as density estimator and use
blue noise to ensure homogeneous sampling. Our model can be trained on a single
GPU making it compute efficient and deployable without requiring specialized
accelerators.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14639</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14639</id><submitter>Kiran Lekkala</submitter><version version="v1"><date>Sun, 30 May 2021 22:15:06 GMT</date><size>3678kb</size><source_type>D</source_type></version><title>Shaped Policy Search for Evolutionary Strategies using Waypoints</title><authors>Kiran Lekkala, Laurent Itti</authors><categories>cs.RO cs.LG cs.NE</categories><comments>Presented at the International Conference on Robotics and Automation
  (ICRA) 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we try to improve exploration in Blackbox methods,
particularly Evolution strategies (ES), when applied to Reinforcement Learning
(RL) problems where intermediate waypoints/subgoals are available. Since
Evolutionary strategies are highly parallelizable, instead of extracting just a
scalar cumulative reward, we use the state-action pairs from the trajectories
obtained during rollouts/evaluations, to learn the dynamics of the agent. The
learnt dynamics are then used in the optimization procedure to speed-up
training. Lastly, we show how our proposed approach is universally applicable
by presenting results from experiments conducted on Carla driving and UR5
robotic arm simulators.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14641</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14641</id><submitter>Vaibhav Kumar</submitter><version version="v1"><date>Sun, 30 May 2021 22:35:50 GMT</date><size>45kb</size></version><title>On the Secrecy Rate under Statistical QoS Provisioning for RIS-Assisted
  MISO Wiretap Channel</title><authors>Vaibhav Kumar, Mark F. Flanagan, Derrick Wing Kwan Ng, and Le-Nam Tran</authors><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, 1 table</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reconfigurable intelligent surface (RIS) assisted radio is considered as an
enabling technology with great potential for the sixth-generation (6G) wireless
communications standard. The achievable secrecy rate (ASR) is one of the most
fundamental metrics to evaluate the capability of facilitating secure
communication for RIS-assisted systems. However, the definition of ASR is based
on Shannon's information theory, which generally requires long codewords and
thus fails to quantify the secrecy of emerging delay-critical services.
Motivated by this, in this paper we investigate the problem of maximizing the
secrecy rate under a delay-limited quality-of-service (QoS) constraint, termed
as the effective secrecy rate (ESR), for an RIS-assisted multiple-input
single-output (MISO) wiretap channel subject to a transmit power constraint. We
propose an iterative method to find a stationary solution to the formulated
non-convex optimization problem using a block coordinate ascent method (BCAM),
where both the beamforming vector at the transmitter as well as the phase
shifts at the RIS are obtained in closed forms in each iteration. We also
present a convergence proof, an efficient implementation, and the associated
complexity analysis for the proposed method. Our numerical results demonstrate
that the proposed optimization algorithm converges significantly faster that an
existing solution. The simulation results also confirm that the secrecy rate
performance of the system with stringent delay requirements reduce
significantly compared to the system without any delay constraints, and that
this reduction can be significantly mitigated by an appropriately placed
large-size RIS.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14642</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14642</id><submitter>Cristian Rusu</submitter><version version="v1"><date>Sun, 30 May 2021 22:38:36 GMT</date><size>924kb</size></version><title>An iterative Jacobi-like algorithm to compute a few sparse
  eigenvalue-eigenvector pairs</title><authors>Cristian Rusu</authors><categories>math.NA cs.NA eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe a new algorithm to compute the extreme
eigenvalue/eigenvector pairs of a symmetric matrix. The proposed algorithm can
be viewed as an extension of the Jacobi transformation method for symmetric
matrix diagonalization to the case where we want to compute just a few
eigenvalues/eigenvectors. The method is also particularly well suited for the
computation of sparse eigenspaces. We show the effectiveness of the method for
sparse low-rank approximations and show applications to random symmetric
matrices, graph Fourier transforms, and with the sparse principal component
analysis in image classification experiments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14644</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14644</id><submitter>Florian Jaeckle</submitter><version version="v1"><date>Sun, 30 May 2021 22:46:41 GMT</date><size>1275kb</size><source_type>D</source_type></version><title>Generating Adversarial Examples with Graph Neural Networks</title><authors>Florian Jaeckle and M. Pawan Kumar</authors><categories>cs.LG cs.CR</categories><comments>To be published in UAI 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Recent years have witnessed the deployment of adversarial attacks to evaluate
the robustness of Neural Networks. Past work in this field has relied on
traditional optimization algorithms that ignore the inherent structure of the
problem and data, or generative methods that rely purely on learning and often
fail to generate adversarial examples where they are hard to find. To alleviate
these deficiencies, we propose a novel attack based on a graph neural network
(GNN) that takes advantage of the strengths of both approaches; we call it
AdvGNN. Our GNN architecture closely resembles the network we wish to attack.
During inference, we perform forward-backward passes through the GNN layers to
guide an iterative procedure towards adversarial examples. During training, its
parameters are estimated via a loss function that encourages the efficient
computation of adversarial examples over a time horizon. We show that our
method beats state-of-the-art adversarial attacks, including PGD-attack,
MI-FGSM, and Carlini and Wagner attack, reducing the time required to generate
adversarial examples with small perturbation norms by over 65\%. Moreover,
AdvGNN achieves good generalization performance on unseen networks. Finally, we
provide a new challenging dataset specifically designed to allow for a more
illustrative comparison of adversarial attacks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14645</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14645</id><submitter>Akshay Dave</submitter><version version="v1"><date>Sun, 30 May 2021 22:53:39 GMT</date><size>1007kb</size><source_type>D</source_type></version><title>Empirical Models for Multidimensional Regression of Fission Systems</title><authors>Akshay J. Dave (1), Jiankai Yu (1), Jarod Wilson (1), Bren Phillips
  (1), Kaichao Sun (1), Benoit Forget (1) ((1) Massachusetts Institute of
  Technology)</authors><categories>physics.comp-ph cs.LG</categories><comments>20 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of next-generation autonomous control of fission systems,
such as nuclear power plants, will require leveraging advancements in machine
learning. For fission systems, accurate prediction of nuclear transport is
important to quantify the safety margin and optimize performance. The
state-of-the-art approach to this problem is costly Monte Carlo (MC)
simulations to approximate solutions of the neutron transport equation. Such an
approach is feasible for offline calculations e.g., for design or licensing,
but is precluded from use as a model-based controller. In this work, we explore
the use of Artificial Neural Networks (ANN), Gradient Boosting Regression
(GBR), Gaussian Process Regression (GPR) and Support Vector Regression (SVR) to
generate empirical models. The empirical model can then be deployed, e.g., in a
model predictive controller. Two fission systems are explored: the subcritical
MIT Graphite Exponential Pile (MGEP), and the critical MIT Research Reactor
(MITR).
  Findings from this work establish guidelines for developing empirical models
for multidimensional regression of neutron transport. An assessment of the
accuracy and precision finds that the SVR, followed closely by ANN, performs
the best. For both MGEP and MITR, the optimized SVR model exhibited a
domain-averaged, test, mean absolute percentage error of 0.17 %. A spatial
distribution of performance metrics indicates that physical regions of poor
performance coincide with locations of largest neutron flux perturbation --
this outcome is mitigated by ANN and SVR. Even at local maxima, ANN and SVR
bias is within experimental uncertainty bounds. A comparison of the performance
vs. training dataset size found that SVR is more data-efficient than ANN. Both
ANN and SVR achieve a greater than 7 order reduction in evaluation time vs. a
MC simulation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14648</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14648</id><submitter>Jesse Geneson</submitter><version version="v1"><date>Sun, 30 May 2021 23:06:21 GMT</date><size>7kb</size></version><title>Sharper bounds for online learning of smooth functions of a single
  variable</title><authors>Jesse Geneson</authors><categories>cs.LG cs.DM stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We investigate the generalization of the mistake-bound model to continuous
real-valued single variable functions. Let $\mathcal{F}_q$ be the class of
absolutely continuous functions $f: [0, 1] \rightarrow \mathbb{R}$ with
$||f'||_q \le 1$, and define $opt_p(\mathcal{F}_q)$ as the best possible bound
on the worst-case sum of the $p^{th}$ powers of the absolute prediction errors
over any number of trials. Kimber and Long (Theoretical Computer Science, 1995)
proved for $q \ge 2$ that $opt_p(\mathcal{F}_q) = 1$ when $p \ge 2$ and
$opt_p(\mathcal{F}_q) = \infty$ when $p = 1$. For $1 &lt; p &lt; 2$ with $p =
1+\epsilon$, the only known bound was $opt_p(\mathcal{F}_{q}) =
O(\epsilon^{-1})$ from the same paper. We show for all $\epsilon \in (0, 1)$
and $q \ge 2$ that $opt_{1+\epsilon}(\mathcal{F}_q) =
\Theta(\epsilon^{-\frac{1}{2}})$, where the constants in the bound do not
depend on $q$. We also show that $opt_{1+\epsilon}(\mathcal{F}_{\infty}) =
\Theta(\epsilon^{-\frac{1}{2}})$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14652</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14652</id><submitter>Kawin Ethayarajh</submitter><version version="v1"><date>Mon, 31 May 2021 00:06:10 GMT</date><size>96kb</size><source_type>D</source_type></version><title>Attention Flows are Shapley Value Explanations</title><authors>Kawin Ethayarajh and Dan Jurafsky</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shapley Values, a solution to the credit assignment problem in cooperative
game theory, are a popular type of explanation in machine learning, having been
used to explain the importance of features, embeddings, and even neurons. In
NLP, however, leave-one-out and attention-based explanations still predominate.
Can we draw a connection between these different methods? We formally prove
that -- save for the degenerate case -- attention weights and leave-one-out
values cannot be Shapley Values. $\textit{Attention flow}$ is a post-processed
variant of attention weights obtained by running the max-flow algorithm on the
attention graph. Perhaps surprisingly, we prove that attention flows are indeed
Shapley Values, at least at the layerwise level. Given the many desirable
theoretical qualities of Shapley Values -- which has driven their adoption
among the ML community -- we argue that NLP practitioners should, when
possible, adopt attention flow explanations alongside more traditional ones.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14655</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14655</id><submitter>Zhuoran Qiao</submitter><version version="v1"><date>Mon, 31 May 2021 00:48:18 GMT</date><size>1742kb</size><source_type>D</source_type></version><title>UNiTE: Unitary N-body Tensor Equivariant Network with Applications to
  Quantum Chemistry</title><authors>Zhuoran Qiao, Anders S. Christensen, Frederick R. Manby, Matthew
  Welborn, Anima Anandkumar, Thomas F. Miller III</authors><categories>cs.LG physics.chem-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equivariant neural networks have been successful in incorporating various
types of symmetries, but are mostly limited to vector representations of
geometric objects. Despite the prevalence of higher-order tensors in various
application domains, e.g. in quantum chemistry, equivariant neural networks for
general tensors remain unexplored. Previous strategies for learning equivariant
functions on tensors mostly rely on expensive tensor factorization which is not
scalable when the dimensionality of the problem becomes large. In this work, we
propose unitary $N$-body tensor equivariant neural network (UNiTE), an
architecture for a general class of symmetric tensors called $N$-body tensors.
The proposed neural network is equivariant with respect to the actions of a
unitary group, such as the group of 3D rotations. Furthermore, it has a linear
time complexity with respect to the number of non-zero elements in the tensor.
We also introduce a normalization method, viz., Equivariant Normalization, to
improve generalization of the neural network while preserving symmetry. When
applied to quantum chemistry, UNiTE outperforms all state-of-the-art machine
learning methods of that domain with over 110% average improvements on multiple
benchmarks. Finally, we show that UNiTE achieves a robust zero-shot
generalization performance on diverse down stream chemistry tasks, while being
three orders of magnitude faster than conventional numerical methods with
competitive accuracy.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14656</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14656</id><submitter>Arash Mohammadi</submitter><version version="v1"><date>Mon, 31 May 2021 00:49:34 GMT</date><size>3041kb</size><source_type>D</source_type></version><title>Human-level COVID-19 Diagnosis from Low-dose CT Scans Using a Two-stage
  Time-distributed Capsule Network</title><authors>Parnian Afshar, Moezedin Javad Rafiee, Farnoosh Naderkhani, Shahin
  Heidarian, Nastaran Enshaei, Anastasia Oikonomou, Faranak Babaki Fard, Reut
  Anconina, Keyvan Farahani, Konstantinos N. Plataniotis, and Arash Mohammadi</authors><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reverse transcription-polymerase chain reaction (RT-PCR) is currently the
gold standard in COVID-19 diagnosis. It can, however, take days to provide the
diagnosis, and false negative rate is relatively high. Imaging, in particular
chest computed tomography (CT), can assist with diagnosis and assessment of
this disease. Nevertheless, it is shown that standard dose CT scan gives
significant radiation burden to patients, especially those in need of multiple
scans. In this study, we consider low-dose and ultra-low-dose (LDCT and ULDCT)
scan protocols that reduce the radiation exposure close to that of a single
X-Ray, while maintaining an acceptable resolution for diagnosis purposes. Since
thoracic radiology expertise may not be widely available during the pandemic,
we develop an Artificial Intelligence (AI)-based framework using a collected
dataset of LDCT/ULDCT scans, to study the hypothesis that the AI model can
provide human-level performance. The AI model uses a two stage capsule network
architecture and can rapidly classify COVID-19, community acquired pneumonia
(CAP), and normal cases, using LDCT/ULDCT scans. The AI model achieves COVID-19
sensitivity of 89.5% +\- 0.11, CAP sensitivity of 95% +\- 0.11, normal cases
sensitivity (specificity) of 85.7% +\- 0.16, and accuracy of 90% +\- 0.06. By
incorporating clinical data (demographic and symptoms), the performance further
improves to COVID-19 sensitivity of 94.3% +\- pm 0.05, CAP sensitivity of 96.7%
+\- 0.07, normal cases sensitivity (specificity) of 91% +\- 0.09 , and accuracy
of 94.1% +\- 0.03. The proposed AI model achieves human-level diagnosis based
on the LDCT/ULDCT scans with reduced radiation exposure. We believe that the
proposed AI model has the potential to assist the radiologists to accurately
and promptly diagnose COVID-19 infection and help control the transmission
chain during the pandemic.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14658</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14658</id><submitter>Shobhit Gupta</submitter><version version="v1"><date>Mon, 31 May 2021 00:55:47 GMT</date><size>16486kb</size><source_type>D</source_type></version><title>Eco-Driving of Connected and Autonomous Vehicles with
  Sequence-to-Sequence Prediction of Target Vehicle Velocity</title><authors>Shobhit Gupta, Marcello Canova</authors><categories>eess.SY cs.SY</categories><comments>8 pages, 11 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Eco-Driving control problem seeks to perform fuel efficient speed
planning for a Connected and Autonomous Vehicle (CAV) that can exploit
information available from advanced mapping, and from Vehicle-to-Everything
(V2X) communication. The ability of an Eco-Driving strategy to adapt in real
time to variable traffic scenarios where surrounding vehicles can be either
connected or unconnected is critical for further development and deployment of
this technology in the transportation sector. In this work, the Eco-Driving
strategy, formulated as a receding-horizon optimal control problem, is
integrated with a target vehicle speed prediction model and solved via Dynamic
Programming (DP) to determine the optimal speed trajectory in the presence of a
human-driven target vehicle. An encoder-decoder architecture analyzes the
patterns in the target vehicle velocity recorded over a historic window using a
Gated-Recurrent-Unit (GRU) based encoder and generates an estimate of the
future velocity trajectory using the GRU based decoder. A sensitivity study is
done to analyze the effect of the historical and prediction windows on the
accuracy of the velocity predictor. The proposed Eco-Driving controller is
evaluated through microscopic simulations using a traffic simulator.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14659</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14659</id><submitter>Dinh Nguyen</submitter><version version="v1"><date>Mon, 31 May 2021 01:02:59 GMT</date><size>995kb</size><source_type>D</source_type></version><title>Federated Learning for Industrial Internet of Things in Future
  Industries</title><authors>Dinh C. Nguyen, Ming Ding, Pubudu N. Pathirana, Aruna Seneviratne, Jun
  Li, Dusit Niyato, H. Vincent Poor</authors><categories>cs.LG eess.SP</categories><comments>Accepted at IEEE Wireless Communications Magazine</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Industrial Internet of Things (IIoT) offers promising opportunities to
transform the operation of industrial systems and becomes a key enabler for
future industries. Recently, artificial intelligence (AI) has been widely
utilized for realizing intelligent IIoT applications where AI techniques
require centralized data collection and processing. However, this is not always
feasible in realistic scenarios due to the high scalability of modern IIoT
networks and growing industrial data confidentiality. Federated Learning (FL),
as an emerging collaborative AI approach, is particularly attractive for
intelligent IIoT networks by coordinating multiple IIoT devices and machines to
perform AI training at the network edge while helping protect user privacy. In
this article, we provide a detailed overview and discussions of the emerging
applications of FL in key IIoT services and applications. A case study is also
provided to demonstrate the feasibility of FL in IIoT. Finally, we highlight a
range of interesting open research topics that need to be addressed for the
full realization of FL-IIoT in industries.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14666</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14666</id><submitter>Lu Ma</submitter><version version="v1"><date>Mon, 31 May 2021 01:39:08 GMT</date><size>4547kb</size></version><title>EchoFilter: End-to-End Neural Network for Acoustic Echo Cancellation</title><authors>Lu Ma, Song Yang, Yaguang Gong, Xintian Wang, Zhongqin Wu</authors><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, 6 tabels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic Echo Cancellation (AEC) whose aim is to suppress the echo originated
from acoustic coupling between loudspeakers and microphones, plays a key role
in voice interaction. Linear adaptive filter (AF) is always used for handling
this problem. However, since there would be some severe effects in real
scenarios, such nonlinear distortions, background noises, and microphone
clipping, it would lead to considerable residual echo, giving poor performance
in practice. In this paper, we propose an end-to-end network structure for echo
cancellation, which is directly done on time-domain audio waveform. It is
transformed to deep representation by temporal convolution, and modelled by
Long Short-Term Memory (LSTM) for considering temporal property. Since time
delay and severe reverberation may exist at the near-end with respect to the
far-end, a local attention is employed for alignment. The network is trained
using multitask learning by employing an auxiliary classification network for
double-talk detection. Experiments show the superiority of our proposed method
in terms of the echo return loss enhancement (ERLE) for single-talk periods and
the perceptual evaluation of speech quality (PESQ) score for double-talk
periods in background noise and nonlinear distortion scenarios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14668</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14668</id><submitter>Lang Yu</submitter><version version="v1"><date>Mon, 31 May 2021 01:49:56 GMT</date><size>742kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 01:11:04 GMT</date><size>741kb</size></version><title>On the Interplay Between Fine-tuning and Composition in Transformers</title><authors>Lang Yu and Allyson Ettinger</authors><categories>cs.CL</categories><comments>To appear in Findings of ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pre-trained transformer language models have shown remarkable performance on
a variety of NLP tasks. However, recent research has suggested that
phrase-level representations in these models reflect heavy influences of
lexical content, but lack evidence of sophisticated, compositional phrase
information. Here we investigate the impact of fine-tuning on the capacity of
contextualized embeddings to capture phrase meaning information beyond lexical
content. Specifically, we fine-tune models on an adversarial paraphrase
classification task with high lexical overlap, and on a sentiment
classification task. After fine-tuning, we analyze phrasal representations in
controlled settings following prior work. We find that fine-tuning largely
fails to benefit compositionality in these representations, though training on
sentiment yields a small, localized benefit for certain models. In follow-up
analyses, we identify confounding cues in the paraphrase dataset that may
explain the lack of composition benefits from that task, and we discuss
potential factors underlying the localized benefits from sentiment training.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14669</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14669</id><submitter>Yuekai Zhao</submitter><version version="v1"><date>Mon, 31 May 2021 01:52:36 GMT</date><size>476kb</size><source_type>D</source_type></version><title>Memory-Efficient Differentiable Transformer Architecture Search</title><authors>Yuekai Zhao, Li Dong, Yelong Shen, Zhihua Zhang, Furu Wei, Weizhu Chen</authors><categories>cs.LG cs.CL</categories><comments>Accepted by Findings of ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Differentiable architecture search (DARTS) is successfully applied in many
vision tasks. However, directly using DARTS for Transformers is
memory-intensive, which renders the search process infeasible. To this end, we
propose a multi-split reversible network and combine it with DARTS.
Specifically, we devise a backpropagation-with-reconstruction algorithm so that
we only need to store the last layer's outputs. By relieving the memory burden
for DARTS, it allows us to search with larger hidden size and more candidate
operations. We evaluate the searched architecture on three sequence-to-sequence
datasets, i.e., WMT'14 English-German, WMT'14 English-French, and WMT'14
English-Czech. Experimental results show that our network consistently
outperforms standard Transformers across the tasks. Moreover, our method
compares favorably with big-size Evolved Transformers, reducing search
computation by an order of magnitude.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14673</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14673</id><submitter>Waheed Bajwa</submitter><version version="v1"><date>Mon, 31 May 2021 02:06:34 GMT</date><size>26kb</size></version><title>A Minimax Lower Bound for Low-Rank Matrix-Variate Logistic Regression</title><authors>Batoul Taki, Mohsen Ghassemi, Anand D. Sarwate, and Waheed U. Bajwa</authors><categories>cs.LG eess.SP math.ST stat.ML stat.TH</categories><comments>8 pages; preprint of a conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of matrix-variate logistic regression. The
fundamental error threshold on estimating coefficient matrices in the logistic
regression problem is found by deriving a lower bound on the minimax risk. The
focus of this paper is on derivation of a minimax risk lower bound for low-rank
coefficient matrices. The bound depends explicitly on the dimensions and
distribution of the covariates, the rank and energy of the coefficient matrix,
and the number of samples. The resulting bound is proportional to the intrinsic
degrees of freedom in the problem, which suggests the sample complexity of the
low-rank matrix logistic regression problem can be lower than that for
vectorized logistic regression. \color{red}\color{black} The proof techniques
utilized in this work also set the stage for development of minimax lower
bounds for tensor-variate logistic regression problems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14675</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14675</id><submitter>Huanle Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 02:08:36 GMT</date><size>423kb</size></version><title>Towards a Federated Learning Framework for Heterogeneous Devices of
  Internet of Things</title><authors>Huanle Zhang, Jeonghoon Kim</authors><categories>cs.LG cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Federated Learning (FL) has received a significant amount of attention in the
industry and research community due to its capability of keeping data on local
devices. To aggregate the gradients of local models to train the global model,
existing works require that the global model and the local models are the same.
However, Internet of Things (IoT) devices are inherently diverse regarding
computation speed and onboard memory. In this paper, we propose an FL framework
targeting the heterogeneity of IoT devices. Specifically, local models are
compressed from the global model, and the gradients of the compressed local
models are used to update the global model. We conduct preliminary experiments
to illustrate that our framework can facilitate the design of IoT-aware FL.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14676</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14676</id><submitter>Jingfeng Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 02:17:51 GMT</date><size>4620kb</size><source_type>D</source_type></version><title>NoiLIn: Do Noisy Labels Always Hurt Adversarial Training?</title><authors>Jingfeng Zhang, Xilie Xu, Bo Han, Tongliang Liu, Gang Niu, Lizhen Cui,
  Masashi Sugiyama</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial training (AT) based on minimax optimization is a popular learning
style that enhances the model's adversarial robustness. Noisy labels (NL)
commonly undermine the learning and hurt the model's performance.
Interestingly, both research directions hardly crossover and hit sparks. In
this paper, we raise an intriguing question -- Does NL always hurt AT? Firstly,
we find that NL injection in inner maximization for generating adversarial data
augments natural data implicitly, which benefits AT's generalization. Secondly,
we find NL injection in outer minimization for the learning serves as
regularization that alleviates robust overfitting, which benefits AT's
robustness. To enhance AT's adversarial robustness, we propose &quot;NoiLIn&quot; that
gradually increases \underline{Noi}sy \underline{L}abels \underline{In}jection
over the AT's training process. Empirically, NoiLIn answers the previous
question negatively -- the adversarial robustness can be indeed enhanced by NL
injection. Philosophically, we provide a new perspective of the learning with
NL: NL should not always be deemed detrimental, and even in the absence of NL
in the training set, we may consider injecting it deliberately.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14677</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14677</id><submitter>Biswadeep Chakraborty</submitter><version version="v1"><date>Mon, 31 May 2021 02:19:06 GMT</date><size>1985kb</size><source_type>D</source_type></version><title>Characterization of Generalizability of Spike Time Dependent Plasticity
  trained Spiking Neural Networks</title><authors>Biswadeep Chakraborty, Saibal Mukhopadhyay</authors><categories>cs.NE cs.AI</categories><comments>15 pages, submitted to Frontiers in Neuroscience. arXiv admin note:
  text overlap with arXiv:2010.08195, arXiv:2006.09313 by other authors</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A Spiking Neural Network (SNN) trained with Spike Time Dependent Plasticity
(STDP) is a neuro-inspired unsupervised learning method for various machine
learning applications. This paper studies the generalizability properties of
the STDP learning processes using the Hausdorff dimension of the trajectories
of the learning algorithm. The paper analyzes the effects of STDP learning
models and associated hyper-parameters on the generalizability properties of an
SNN and characterizes the generalizability vs learnability trade-off in an SNN.
The analysis is used to develop a Bayesian optimization approach to optimize
the hyper-parameters for an STDP model to improve the generalizability
properties of an SNN.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14678</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14678</id><submitter>Xiaoguang Tu</submitter><version version="v1"><date>Mon, 31 May 2021 02:30:11 GMT</date><size>11054kb</size><source_type>D</source_type></version><title>Image-to-Video Generation via 3D Facial Dynamics</title><authors>Xiaoguang Tu, Yingtian Zou, Jian Zhao, Wenjie Ai, Jian Dong, Yuan Yao,
  Zhikang Wang, Guodong Guo, Zhifeng Li, Wei Liu, and Jiashi Feng</authors><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a versatile model, FaceAnime, for various video generation tasks
from still images. Video generation from a single face image is an interesting
problem and usually tackled by utilizing Generative Adversarial Networks (GANs)
to integrate information from the input face image and a sequence of sparse
facial landmarks. However, the generated face images usually suffer from
quality loss, image distortion, identity change, and expression mismatching due
to the weak representation capacity of the facial landmarks. In this paper, we
propose to &quot;imagine&quot; a face video from a single face image according to the
reconstructed 3D face dynamics, aiming to generate a realistic and
identity-preserving face video, with precisely predicted pose and facial
expression. The 3D dynamics reveal changes of the facial expression and motion,
and can serve as a strong prior knowledge for guiding highly realistic face
video generation. In particular, we explore face video prediction and exploit a
well-designed 3D dynamic prediction network to predict a 3D dynamic sequence
for a single face image. The 3D dynamics are then further rendered by the
sparse texture mapping algorithm to recover structural details and sparse
textures for generating face frames. Our model is versatile for various AR/VR
and entertainment applications, such as face video retargeting and face video
prediction. Superior experimental results have well demonstrated its
effectiveness in generating high-fidelity, identity-preserving, and visually
pleasant face video clips from a single source face image.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14680</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14680</id><submitter>Franklin Mingzhe Li</submitter><version version="v1"><date>Mon, 31 May 2021 02:47:56 GMT</date><size>7635kb</size><source_type>D</source_type></version><title>ThumbTrak: Recognizing Micro-finger Poses Using a Ring with Proximity
  Sensing</title><authors>Wei Sun, Franklin Mingzhe Li, Congshu Huang, Zhenyu Lei, Benjamin
  Steeper, Songyun Tao, Feng Tian, Cheng Zhang</authors><categories>cs.HC</categories><comments>MobileHCI '21: The ACM International Conference on Mobile
  Human-Computer Interaction, September 27 - October 1, 2021, Toulouse, France</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  ThumbTrak is a novel wearable input device that recognizes 12 micro-finger
poses in real-time. Poses are characterized by the thumb touching each of the
12 phalanges on the hand. It uses a thumb-ring, built with a flexible printed
circuit board, which hosts nine proximity sensors. Each sensor measures the
distance from the thumb to various parts of the palm or other fingers.
ThumbTrak uses a support-vector-machine (SVM) model to classify finger poses
based on distance measurements in real-time. A user study with ten participants
showed that ThumbTrak could recognize 12 micro finger poses with an average
accuracy of 93.6%. We also discuss potential opportunities and challenges in
applying ThumbTrak in real-world applications.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14682</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14682</id><submitter>Liangming Pan</submitter><version version="v1"><date>Mon, 31 May 2021 03:13:52 GMT</date><size>2818kb</size><source_type>D</source_type></version><title>Zero-shot Fact Verification by Claim Generation</title><authors>Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang
  Wang</authors><categories>cs.CL cs.AI</categories><comments>ACL-IJCNLP 2021 (main conference, short paper)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural models for automated fact verification have achieved promising results
thanks to the availability of large, human-annotated datasets. However, for
each new domain that requires fact verification, creating a dataset by manually
writing claims and linking them to their supporting evidence is expensive. We
develop QACG, a framework for training a robust fact verification model by
using automatically generated claims that can be supported, refuted, or
unverifiable from evidence from Wikipedia. QACG generates question-answer pairs
from the evidence and then converts them into different types of claims.
Experiments on the FEVER dataset show that our QACG framework significantly
reduces the demand for human-annotated training data. In a zero-shot scenario,
QACG improves a RoBERTa model's F1 from 50% to 77%, equivalent in performance
to 2K+ manually-curated examples. Our QACG code is publicly available.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14683</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14683</id><submitter>Wentao Yu</submitter><version version="v1"><date>Mon, 31 May 2021 03:16:38 GMT</date><size>24567kb</size><source_type>D</source_type></version><title>Know Your Surroundings: Panoramic Multi-Object Tracking by Multimodality
  Collaboration</title><authors>Yuhang He, Wentao Yu, Jie Han, Xing Wei, Xiaopeng Hong, Yihong Gong</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the multi-object tracking (MOT) problem of
automatic driving and robot navigation. Most existing MOT methods track
multiple objects using a singular RGB camera, which are prone to camera
field-of-view and suffer tracking failures in complex scenarios due to
background clutters and poor light conditions. To meet these challenges, we
propose a MultiModality PAnoramic multi-object Tracking framework (MMPAT),
which takes both 2D panorama images and 3D point clouds as input and then
infers target trajectories using the multimodality data. The proposed method
contains four major modules, a panorama image detection module, a multimodality
data fusion module, a data association module and a trajectory inference model.
We evaluate the proposed method on the JRDB dataset, where the MMPAT achieves
the top performance in both the detection and tracking tasks and significantly
outperforms state-of-the-art methods by a large margin (15.7 and 8.5
improvement in terms of AP and MOTA, respectively).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14685</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14685</id><submitter>Peng Xu</submitter><version version="v1"><date>Mon, 31 May 2021 03:35:00 GMT</date><size>1388kb</size><source_type>D</source_type></version><title>Long-term Person Re-identification: A Benchmark</title><authors>Peng Xu and Xiatian Zhu</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing person re-identification (Re-ID) works mostly consider a short-term
search problem assuming unchanged clothes and personal appearance. However, in
realworld we often dress ourselves differently across locations, time, dates,
seasons, weather, and events. As a result, the existing methods are unsuitable
for long-term person Re-ID with clothes change involved. Whilst there are
several recent longterm Re-ID attempts, a large realistic dataset with clothes
change is lacking and indispensable for enabling extensive study as already
experienced in short-term Re-ID setting. In this work, we contribute timely a
large, realistic long-term person re-identification benchmark. It consists of
171K bounding boxes from 1.1K person identities, collected and constructed over
a course of 12 months. Unique characteristics of this dataset include: (1)
Natural/native personal appearance (e.g., clothes and hair style) variations:
The degrees of clothes-change and dressing styles all are highly diverse, with
the reappearing gap in time ranging from minutes, hours, and days to weeks,
months, seasons, and years. (2) Diverse walks of life: Persons across a wide
range of ages and professions appear in different weather conditions (e.g.,
sunny, cloudy, windy, rainy, snowy, extremely cold) and events (e.g., working,
leisure, daily activities). (3) Rich camera setups: The raw videos were
recorded by 17 outdoor security cameras with various resolutions operating in a
real-world surveillance system for a wide and dense block. (4) Largest scale:
It covers the largest number of (17) cameras, (1082) identities, and (171K)
bounding boxes, as compared to alternative datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14686</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14686</id><submitter>Weize Chen</submitter><version version="v1"><date>Mon, 31 May 2021 03:36:49 GMT</date><size>1363kb</size><source_type>D</source_type></version><title>Fully Hyperbolic Neural Networks</title><authors>Weize Chen, Xu Han, Yankai Lin, Hexu Zhao, Zhiyuan Liu, Peng Li,
  Maosong Sun, Jie Zhou</authors><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperbolic neural networks have shown great potential for modeling complex
data. However, existing hyperbolic networks are not completely hyperbolic, as
they encode features in a hyperbolic space yet formalize most of their
operations in the tangent space (a Euclidean subspace) at the origin of the
hyperbolic space. This hybrid method greatly limits the modeling ability of
networks. In this paper, we propose a fully hyperbolic framework to build
hyperbolic networks based on the Lorentz model by adapting the Lorentz
transformations (including boost and rotation) to formalize essential
operations of neural networks. Moreover, we also prove that linear
transformation in tangent spaces used by existing hyperbolic networks is a
relaxation of the Lorentz rotation and does not include the boost, implicitly
limiting the capabilities of existing hyperbolic networks. The experimental
results on four NLP tasks show that our method has better performance for
building both shallow and deep networks. Our code will be released to
facilitate follow-up research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14688</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14688</id><submitter>Yongchun Zhu</submitter><version version="v1"><date>Mon, 31 May 2021 03:43:10 GMT</date><size>2832kb</size><source_type>D</source_type></version><title>Learning to Expand Audience via Meta Hybrid Experts and Critics for
  Recommendation and Advertising</title><authors>Yongchun Zhu, Yudan Liu, Ruobing Xie, Fuzhen Zhuang, Xiaobo Hao,
  Kaikai Ge, Xu Zhang, Leyu Lin and Juan Cao</authors><categories>cs.IR</categories><comments>accepted by KDD2021</comments><doi>10.1145/3447548.3467093</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recommender systems and advertising platforms, marketers always want to
deliver products, contents, or advertisements to potential audiences over media
channels such as display, video, or social. Given a set of audiences or
customers (seed users), the audience expansion technique (look-alike modeling)
is a promising solution to identify more potential audiences, who are similar
to the seed users and likely to finish the business goal of the target
campaign. However, look-alike modeling faces two challenges: (1) In practice, a
company could run hundreds of marketing campaigns to promote various contents
within completely different categories every day, e.g., sports, politics,
society. Thus, it is difficult to utilize a common method to expand audiences
for all campaigns. (2) The seed set of a certain campaign could only cover
limited users. Therefore, a customized approach based on such a seed set is
likely to be overfitting.
  In this paper, to address these challenges, we propose a novel two-stage
framework named Meta Hybrid Experts and Critics (MetaHeac) which has been
deployed in WeChat Look-alike System. In the offline stage, a general model
which can capture the relationships among various tasks is trained from a
meta-learning perspective on all existing campaign tasks. In the online stage,
for a new campaign, a customized model is learned with the given seed set based
on the general model. According to both offline and online experiments, the
proposed MetaHeac shows superior effectiveness for both content marketing
campaigns in recommender systems and advertising campaigns in advertising
platforms. Besides, MetaHeac has been successfully deployed in WeChat for the
promotion of both contents and advertisements, leading to great improvement in
the quality of marketing. The code has been available at
\url{https://github.com/easezyc/MetaHeac}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14693</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14693</id><submitter>Junghoon Seo</submitter><version version="v1"><date>Mon, 31 May 2021 04:09:00 GMT</date><size>6576kb</size><source_type>D</source_type></version><title>Training Domain-invariant Object Detector Faster with Feature Replay and
  Slow Learner</title><authors>Chaehyeon Lee, Junghoon Seo, Heechul Jung</authors><categories>cs.CV cs.LG</categories><comments>2021 CVPR Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In deep learning-based object detection on remote sensing domain, nuisance
factors, which affect observed variables while not affecting predictor
variables, often matters because they cause domain changes. Previously,
nuisance disentangled feature transformation (NDFT) was proposed to build
domain-invariant feature extractor with with knowledge of nuisance factors.
However, NDFT requires enormous time in a training phase, so it has been
impractical. In this paper, we introduce our proposed method, A-NDFT, which is
an improvement to NDFT. A-NDFT utilizes two acceleration techniques, feature
replay and slow learner. Consequently, on a large-scale UAVDT benchmark, it is
shown that our framework can reduce the training time of NDFT from 31 hours to
3 hours while still maintaining the performance. The code will be made publicly
available online.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14694</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14694</id><submitter>Jing An</submitter><version version="v1"><date>Mon, 31 May 2021 04:21:25 GMT</date><size>1602kb</size></version><title>Combining resampling and reweighting for faithful stochastic
  optimization</title><authors>Jing An, Lexing Ying</authors><categories>cs.LG math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many machine learning and data science tasks require solving non-convex
optimization problems. When the loss function is a sum of multiple terms, a
popular method is stochastic gradient descent. Viewed as a process for sampling
the loss function landscape, the stochastic gradient descent is known to prefer
flat local minimums. Though this is desired for certain optimization problems
such as in deep learning, it causes issues when the goal is to find the global
minimum, especially if the global minimum resides in a sharp valley.
  Illustrated with a simple motivating example, we show that the fundamental
reason is that the difference in the Lipschitz constants of multiple terms in
the loss function causes stochastic gradient descent to experience different
variances at different minimums. In order to mitigate this effect and perform
faithful optimization, we propose a combined resampling-reweighting scheme to
balance the variance at local minimums and extend to general loss functions. We
also explain from the stochastic asymptotics perspective how the proposed
scheme is more likely to select the true global minimum when compared with the
vanilla stochastic gradient descent. Experiments from robust statistics,
computational chemistry, and neural network training are provided to
demonstrate the theoretical findings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14695</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14695</id><submitter>Koji Nuida</submitter><version version="v1"><date>Mon, 31 May 2021 04:26:46 GMT</date><size>19kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 03:54:11 GMT</date><size>19kb</size></version><title>Halt Properties and Complexity Evaluations for Optimal DeepLLL Algorithm
  Families</title><authors>Takuto Odagawa and Koji Nuida</authors><categories>cs.DS cs.CR</categories><comments>20 pages; (v2) Abstract slightly revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DeepLLL algorithm (Schnorr, 1994) is a famous variant of LLL lattice basis
reduction algorithm, and PotLLL algorithm (Fontein et al., 2014) and $S^2$LLL
algorithm (Yasuda and Yamaguchi, 2019) are recent polynomial-time variants of
DeepLLL algorithm developed from cryptographic applications. However, the known
polynomial bounds for computational complexity are shown only for parameter
$\delta &lt; 1$; for &quot;optimal&quot; parameter $\delta = 1$ which ensures the best
output quality, no polynomial bounds are known, and except for LLL algorithm,
it is even not formally proved that the algorithm always halts within finitely
many steps. In this paper, we prove that these four algorithms always halt also
with optimal parameter $\delta = 1$, and furthermore give explicit upper bounds
for the numbers of loops executed during the algorithms. Unlike the known bound
(Akhavi, 2003) applicable to LLL algorithm only, our upper bounds are deduced
in a unified way for all of the four algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14697</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14697</id><submitter>Emre Yolcu</submitter><version version="v1"><date>Mon, 31 May 2021 04:28:48 GMT</date><size>45kb</size></version><title>An Automated Approach to the Collatz Conjecture</title><authors>Emre Yolcu, Scott Aaronson, Marijn J.H. Heule</authors><categories>cs.LO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We explore the Collatz conjecture and its variants through the lens of
termination of string rewriting. We construct a rewriting system that simulates
the iterated application of the Collatz function on strings corresponding to
mixed binary-ternary representations of positive integers. We prove that the
termination of this rewriting system is equivalent to the Collatz conjecture.
We also prove that a previously studied rewriting system that simulates the
Collatz function using unary representations does not admit termination proofs
via matrix interpretations. To show the feasibility of our approach in proving
mathematically interesting statements, we implement a minimal termination
prover that uses matrix/arctic interpretations and we find automated proofs of
nontrivial weakenings of the Collatz conjecture. Finally, we adapt our
rewriting system to show that other open problems in mathematics can also be
approached as termination problems for relatively small rewriting systems.
Although we do not succeed in proving the Collatz conjecture, we believe that
the ideas here represent an interesting new approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14703</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14703</id><submitter>Meena Pargaei</submitter><version version="v1"><date>Mon, 31 May 2021 04:48:23 GMT</date><size>2880kb</size><source_type>D</source_type></version><title>Myocardial ischemic effects on cardiac electro-mechanical activity</title><authors>B.V. Rathish Kumar, Meena Pargaei, Luca F. Pavarino, Simone Scacchi</authors><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we investigated the effect of varying strength of Hyperkalemia
and Hypoxia, in human cardiac tissue with a local ischemic subregion, on the
electrical and mechanical activity of healthy and ischemic zones of the cardiac
muscle. The Monodomain model in a deforming domain is taken with the addition
of mechanical feedback and stretch-activated channel current coupled with the
ten Tusscher human ventricular membrane model. The equations of finite
elasticity are used to describe the deformation of the cardiac tissue. The
resulting coupled electro-mechanical PDEs-ODEs non-linear system is solved
numerically using finite elements in space and finite difference method in
time. We examined the effect of local ischemia on cardiac electrical and
mechanical activity in different cases. We concluded that the spread of
Hyperkalemic or Hypoxic region alters the electro-mechanical coupling in terms
of the action potential ($v$), intracellular calcium ion concentration
$[Ca^{+2}]_i$, active tension, ($T_A$), stretch ($\lambda$), stretch rate ($
\frac{d \lambda}{dt}$). With the increase in the size of the ischemic region by
a factor of five, approximately $45\%$ variation in the stretch rate $\frac{d
\lambda}{dt}$ is noticed. It is also shown that ischemia affects the
deformation (expansion and contraction) of the heart.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14704</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14704</id><submitter>Hao Fang</submitter><version version="v1"><date>Mon, 31 May 2021 04:51:44 GMT</date><size>473kb</size><source_type>D</source_type></version><title>Parkinsonian Chinese Speech Analysis towards Automatic Classification of
  Parkinson's Disease</title><authors>Hao Fang, Chen Gong, Chen Zhang, Yanan Sui, Luming Li</authors><categories>eess.AS cs.CL cs.SD</categories><comments>12 pages, 5 figures, proceedings of the Machine Learning for Health
  NeurIPS Workshop, PMLR 136:114-125, 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech disorders often occur at the early stage of Parkinson's disease (PD).
The speech impairments could be indicators of the disorder for early diagnosis,
while motor symptoms are not obvious. In this study, we constructed a new
speech corpus of Mandarin Chinese and addressed classification of patients with
PD. We implemented classical machine learning methods with ranking algorithms
for feature selection, convolutional and recurrent deep networks, and an end to
end system. Our classification accuracy significantly surpassed
state-of-the-art studies. The result suggests that free talk has stronger
classification power than standard speech tasks, which could help the design of
future speech tasks for efficient early diagnosis of the disease. Based on
existing classification methods and our natural speech study, the automatic
detection of PD from daily conversation could be accessible to the majority of
the clinical population.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14706</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14706</id><submitter>Zsolt Zombori</submitter><version version="v1"><date>Mon, 31 May 2021 04:57:44 GMT</date><size>39kb</size></version><title>The Role of Entropy in Guiding a Connection Prover</title><authors>Zsolt Zombori, Josef Urban, Miroslav Ol\v{s}\'ak</authors><categories>cs.AI cs.LG cs.LO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work we study how to learn good algorithms for selecting reasoning
steps in theorem proving. We explore this in the connection tableau calculus
implemented by leanCoP where the partial tableau provides a clean and compact
notion of a state to which a limited number of inferences can be applied. We
start by incorporating a state-of-the-art learning algorithm -- a graph neural
network (GNN) -- into the plCoP theorem prover. Then we use it to observe the
system's behaviour in a reinforcement learning setting, i.e., when learning
inference guidance from successful Monte-Carlo tree searches on many problems.
Despite its better pattern matching capability, the GNN initially performs
worse than a simpler previously used learning algorithm. We observe that the
simpler algorithm is less confident, i.e., its recommendations have higher
entropy. This leads us to explore how the entropy of the inference selection
implemented via the neural network influences the proof search. This is related
to research in human decision-making under uncertainty, and in particular the
probability matching theory. Our main result shows that a proper entropy
regularisation, i.e., training the GNN not to be overconfident, greatly
improves plCoP's performance on a large mathematical corpus.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14707</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14707</id><submitter>Felipe S. Abrah\~ao</submitter><version version="v1"><date>Mon, 31 May 2021 04:59:59 GMT</date><size>40kb</size></version><title>Emergence and algorithmic information dynamics of systems and observers</title><authors>Felipe S. Abrah\~ao, Hector Zenil</authors><categories>cs.IT cs.FL cs.MA cs.SY eess.SY math.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work has shown that perturbation analysis in algorithmic information
dynamics can uncover generative causal processes of finite objects and quantify
each of its element's information contribution to computably constructing the
objects. One of the challenges for defining emergence is that the dependency on
the observer's previous knowledge may cause a phenomenon to present itself as
emergent for one observer at the same time that reducible for another observer.
Thus, in order to quantify emergence of algorithmic information in computable
generative processes, perturbation analyses may inherit such a problem of the
dependency on the observer's previous formal knowledge. In this sense, by
formalizing the act of observing as mutual perturbations, the emergence of
algorithmic information becomes invariant, minimal, and robust to information
costs and distortions, while it indeed depends on the observer. Then, we
demonstrate that the unbounded increase of emergent algorithmic information
implies asymptotically observer-independent emergence, which eventually
overcomes any formal theory that any observer might devise. In addition, we
discuss weak and strong emergence and analyze the concepts of
observer-dependent emergence and asymptotically observer-independent emergence
found in previous definitions and models in the literature of deterministic
dynamical and computable systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14708</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14708</id><submitter>Kang Wei</submitter><version version="v1"><date>Mon, 31 May 2021 05:01:01 GMT</date><size>538kb</size><source_type>D</source_type></version><title>On Dynamic Resource Allocation for Blockchain Assisted Federated
  Learning over Wireless Channels</title><authors>Xiumei Deng, Jun Li, Chuan Ma, Kang Wei, Long Shi, Ming Ding, Wen
  Chen, and H. Vincent Poor</authors><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blockchain assisted federated learning (BFL) has been widely studied as a
promising technology to process data at the network edge in a distributed
manner. However, the study of BFL involves key challenges, including resource
allocation and client scheduling. In this paper, we propose a BFL framework
consisting of multiple clients, where the roles of clients include local model
training, wireless uploading, and block mining in each round. First, we develop
a renewal BFL framework to study the long-term system performance under
time-varying fading channels. Second, in order to speed up the BFL process with
limited communication, computation and energy resources, we propose a dynamic
resource allocation and client scheduling (DRACS) algorithm based on Lyapunov
optimization to maximize the training data size under energy consumption
constraints, by jointly optimizing the allocation of communication,
computation, and energy resources. For the DRACS algorithm, we characterize a
trade-off of [$\mathcal{O}(1/V)$, $\mathcal{O}(\sqrt{V})$] between the training
data size and energy consumption to balance the maximization of training data
size and the minimization of energy consumption. Our experimental results show
that the DRACS algorithm can provide both higher learning accuracy and faster
convergence with limited time and energy based on the MNIST and Fashion-MNIST
datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14709</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14709</id><submitter>Jafar Abbaszadeh Chekan</submitter><version version="v1"><date>Mon, 31 May 2021 05:18:34 GMT</date><size>623kb</size></version><title>Joint Stabilization and Regret Minimization through Switching in Systems
  with Actuator Redundancy</title><authors>Jafar Abbaszadeh Chekan, Kamyar Azizzadenesheli, and Cedric Langbort</authors><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptively controlling and minimizing regret in unknown dynamical systems
while controlling the growth of the system state is crucial in real-world
applications. In this work, we study the problem of stabilizing and regret
minimization of linear dynamical systems with system-level actuator redundancy.
We propose an optimism-based algorithm that utilizes the actuator redundancy
and the possibility of switching between actuating modes to guarantee the
boundedness of the state. This is in contrast to the prior works that may
result in an exponential (in system dimension) explosion of the state of the
system. We theoretically study the rate at which our algorithm learns a
stabilizing controller and prove that it achieves a regret upper bound of
$\mathcal{O}(\sqrt{T})$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14710</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14710</id><submitter>Ameya Patil</submitter><version version="v1"><date>Mon, 31 May 2021 05:18:42 GMT</date><size>1806kb</size><source_type>D</source_type></version><title>Robustifying $\ell_\infty$ Adversarial Training to the Union of
  Perturbation Models</title><authors>Ameya D. Patil, Michael Tuttle, Alexander G. Schwing, Naresh R.
  Shanbhag</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Classical adversarial training (AT) frameworks are designed to achieve high
adversarial accuracy against a single attack type, typically $\ell_\infty$
norm-bounded perturbations. Recent extensions in AT have focused on defending
against the union of multiple perturbations but this benefit is obtained at the
expense of a significant (up to $10\times$) increase in training complexity
over single-attack $\ell_\infty$ AT. In this work, we expand the capabilities
of widely popular single-attack $\ell_\infty$ AT frameworks to provide
robustness to the union of ($\ell_\infty, \ell_2, \ell_1$) perturbations while
preserving their training efficiency. Our technique, referred to as Shaped
Noise Augmented Processing (SNAP), exploits a well-established byproduct of
single-attack AT frameworks -- the reduction in the curvature of the decision
boundary of networks. SNAP prepends a given deep net with a shaped noise
augmentation layer whose distribution is learned along with network parameters
using any standard single-attack AT. As a result, SNAP enhances adversarial
accuracy of ResNet-18 on CIFAR-10 against the union of ($\ell_\infty, \ell_2,
\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)
single-attack $\ell_\infty$ AT frameworks, and, for the first time, establishes
a benchmark for ResNet-50 and ResNet-101 on ImageNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14711</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14711</id><submitter>Ce Wang</submitter><version version="v1"><date>Mon, 31 May 2021 05:34:27 GMT</date><size>13914kb</size><source_type>D</source_type></version><title>CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in
  Computed Tomography</title><authors>Yang Deng, Ce Wang, Yuan Hui, Qian Li, Jun Li, Shiwei Luo, Mengke Sun,
  Quan Quan, Shuxin Yang, You Hao, Pengbo Liu, Honghu Xiao, Chunpeng Zhao,
  Xinbao Wu, S. Kevin Zhou</authors><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Spine-related diseases have high morbidity and cause a huge burden of social
cost. Spine imaging is an essential tool for noninvasively visualizing and
assessing spinal pathology. Segmenting vertebrae in computed tomography (CT)
images is the basis of quantitative medical image analysis for clinical
diagnosis and surgery planning of spine diseases. Current publicly available
annotated datasets on spinal vertebrae are small in size. Due to the lack of a
large-scale annotated spine image dataset, the mainstream deep learning-based
segmentation methods, which are data-driven, are heavily restricted. In this
paper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated
from multiple sources for vertebra segmentation, which contains 1,005 CT
volumes with over 11,100 labeled vertebrae belonging to different spinal
conditions. Based on this dataset, we conduct several spinal vertebrae
segmentation experiments to set the first benchmark. We believe that this
large-scale dataset will facilitate further research in many spine-related
image analysis tasks, including but not limited to vertebrae segmentation,
labeling, 3D spine reconstruction from biplanar radiographs, image
super-resolution, and enhancement.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14713</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14713</id><submitter>Mingbao Lin</submitter><version version="v1"><date>Mon, 31 May 2021 05:50:33 GMT</date><size>1157kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 11:59:07 GMT</date><size>1159kb</size><source_type>D</source_type></version><title>1$\times$N Block Pattern for Network Sparsity</title><authors>Mingbao Lin, Yuchao Li, Yuxin Zhang, Bohong Chen, Fei Chao, Mengdi
  Wang, Shen Li, Jun Yang, Rongrong Ji</authors><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Though network sparsity emerges as a promising direction to overcome the
drastically increasing size of neural networks, it remains an open problem to
concurrently maintain model accuracy as well as achieve significant speedups on
general CPUs. In this paper, we propose one novel concept of $1\times N$ block
sparsity pattern (block pruning) to break this limitation. In particular,
consecutive $N$ output kernels with the same input channel index are grouped
into one block, which serves as a basic pruning granularity of our pruning
pattern. Our $1 \times N$ sparsity pattern prunes these blocks considered
unimportant. We also provide a workflow of filter rearrangement that first
rearranges the weight matrix in the output channel dimension to derive more
influential blocks for accuracy improvements, and then applies similar
rearrangement to the next-layer weights in the input channel dimension to
ensure correct convolutional operations. Moreover, the output computation after
our $1 \times N$ block sparsity can be realized via a parallelized block-wise
vectorized operation, leading to significant speedups on general CPUs-based
platforms. The efficacy of our pruning pattern is proved with experiments on
ILSVRC-2012. For example, in the case of 50% sparsity and $N=4$, our pattern
obtains about 3.0% improvements over filter pruning in the top-1 accuracy of
MobileNet-V2. Meanwhile, it obtains 56.04ms inference savings on Cortex-A7 CPU
over weight pruning. Code is available at https://github.com/lmbxmu/1xN.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14716</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14716</id><submitter>Haizheng Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 06:05:15 GMT</date><size>4478kb</size><source_type>D</source_type></version><title>Improving the Accuracy and Efficiency of Online Calibration for
  Simulation-based Dynamic Traffic Assignment</title><authors>Haizheng Zhang, Ravi Seshadri, A. Arun Prakash, Constantinos Antoniou,
  Francisco C. Pereira, Moshe Ben-Akiva</authors><categories>eess.SY cs.MA cs.SY</categories><comments>26 pages, 15 figures</comments><journal-ref>Transportation Research Part C: Emerging Technologies Volume 128,
  July 2021, 103195</journal-ref><doi>10.1016/j.trc.2021.103195</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Simulation-based Dynamic Traffic Assignment models have important
applications in real-time traffic management and control. The efficacy of these
systems rests on the ability to generate accurate estimates and predictions of
traffic states, which necessitates online calibration. A widely used solution
approach for online calibration is the Extended Kalman Filter (EKF), which --
although appealing in its flexibility to incorporate any class of parameters
and measurements -- poses several challenges with regard to calibration
accuracy and scalability, especially in congested situations for large-scale
networks. This paper addresses these issues in turn so as to improve the
accuracy and efficiency of EKF-based online calibration approaches for large
and congested networks. First, the concept of state augmentation is revisited
to handle violations of the Markovian assumption typically implicit in online
applications of the EKF. Second, a method based on graph-coloring is proposed
to operationalize the partitioned finite-difference approach that enhances
scalability of the gradient computations.
  Several synthetic experiments and a real world case study demonstrate that
application of the proposed approaches yields improvements in terms of both
prediction accuracy and computational performance. The work has applications in
real-world deployments of simulation-based dynamic traffic assignment systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14717</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14717</id><submitter>Lu Ma</submitter><version version="v1"><date>Mon, 31 May 2021 06:26:26 GMT</date><size>2797kb</size></version><title>Multi-Scale Temporal Convolution Network for Classroom Voice Detection</title><authors>Lu Ma, Xintian Wang, Song Yang, Yaguang Gong, Zhongqin Wu</authors><categories>cs.SD eess.AS</categories><comments>5 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Teaching with the cooperation of expert teacher and assistant teacher, which
is the so-called &quot;double-teachers classroom&quot;, i.e., the course is giving by the
expert online and presented through projection screen at the classroom, and the
teacher at the classroom performs as an assistant for guiding the students in
learning, is becoming more prevalent in today's teaching method for K-12
education. For monitoring the teaching quality, a microphone clipped on the
assistant's neckline is always used for voice recording, then fed to the
downstream tasks of automatic speech recognition (ASR) and neural language
processing (NLP). However, besides its voice, there would be some other
interfering voices, including the expert's one and the student's one. Here, we
propose to extract the assistant' voices from the perspective of sound event
detection, i.e., the voices are classified into four categories, namely the
expert, the teacher, the mixture of them, and the background. To make
frame-level identification, which is important for grabbing sensitive words for
the downstream tasks, a multi-scale temporal convolution neural network is
constructed with stacked dilated convolutions for considering both local and
global properties. These features are concatenated and fed to a classification
network constructed by three linear layers. The framework is evaluated on
simulated data and real-world recordings, giving considerable performance in
terms of precision and recall, compared with some classical classification
methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14719</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14719</id><submitter>Lu Ma</submitter><version version="v1"><date>Mon, 31 May 2021 06:30:07 GMT</date><size>3204kb</size></version><title>Noise Classification Aided Attention-Based Neural Network for Monaural
  Speech Enhancement</title><authors>Lu Ma, Song Yang, Yaguang Gong, Zhongqin Wu</authors><categories>cs.SD eess.AS</categories><comments>2 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an noise type classification aided attention-based neural
network approach for monaural speech enhancement. The network is constructed
based on a previous work by introducing a noise classification subnetwork into
the structure and taking the classification embedding into the attention
mechanism for guiding the network to make better feature extraction.
Specifically, to make the network an end-to-end way, an audio encoder and
decoder constructed by temporal convolution is used to make transformation
between waveform and spectrogram. Additionally, our model is composed of two
long short term memory (LSTM) based encoders, two attention mechanism, a noise
classifier and a speech mask generator. Experiments show that, compared with
OM-LSA and the previous work, the proposed noise classification aided
attention-based approach can achieve better performance in terms of speech
quality (PESQ). More promisingly, our approach has better generalization
ability to unseen noise conditions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14720</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14720</id><submitter>Hou Baohui</submitter><version version="v1"><date>Mon, 31 May 2021 06:33:21 GMT</date><size>1036kb</size></version><title>Energy-preserving fully-discrete schemes for nonlinear stochastic wave
  equations with multiplicative noise</title><authors>Jialin Hong, Baohui Hou, Liying Sun</authors><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we focus on constructing numerical schemes preserving the
averaged energy evolution law for nonlinear stochastic wave equations driven by
multiplicative noise. We first apply the compact finite difference method and
the interior penalty discontinuous Galerkin finite element method to discretize
space variable and present two semi-discrete schemes, respectively. Then we
make use of the discrete gradient method and Pad\'e approximation and propose
efficient fully-discrete schemes. These semi-discrete and fully-discrete
schemes are proved to preserve the discrete averaged energy evolution law, In
particular, we also prove that the proposed fully-discrete schemes exactly
inherit the averaged energy evolution law almost surely if the considered model
is driven by additive noise. Numerical experiments are given to confirm
theoretical findings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14727</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14727</id><submitter>Ziwen He</submitter><version version="v1"><date>Mon, 31 May 2021 06:44:58 GMT</date><size>405kb</size><source_type>D</source_type></version><title>Transferable Sparse Adversarial Attack</title><authors>Ziwen He, Wei Wang, Jing Dong, Tieniu Tan</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have shown their vulnerability to adversarial attacks.
In this paper, we focus on sparse adversarial attack based on the $\ell_0$ norm
constraint, which can succeed by only modifying a few pixels of an image.
Despite a high attack success rate, prior sparse attack methods achieve a low
transferability under the black-box protocol due to overfitting the target
model. Therefore, we introduce a generator architecture to alleviate the
overfitting issue and thus efficiently craft transferable sparse adversarial
examples. Specifically, the generator decouples the sparse perturbation into
amplitude and position components. We carefully design a random quantization
operator to optimize these two components jointly in an end-to-end way. The
experiment shows that our method has improved the transferability by a large
margin under a similar sparsity setting compared with state-of-the-art methods.
Moreover, our method achieves superior inference speed, 700$\times$ faster than
other optimization-based methods. The code is available at
https://github.com/shaguopohuaizhe/TSAA.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14730</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14730</id><submitter>Benjamin Maschler</submitter><version version="v1"><date>Mon, 31 May 2021 06:50:58 GMT</date><size>769kb</size></version><title>Transfer Learning as an Enhancement for Reconfiguration Management of
  Cyber-Physical Production Systems</title><authors>Benjamin Maschler, Timo M\&quot;uller, Andreas L\&quot;ocklin and Michael
  Weyrich</authors><categories>cs.LG cs.AI cs.SE cs.SY eess.SY</categories><comments>6 pages, 4 figures, 1 table. Submitted for publication at CIRP ICME
  2021</comments><doi>10.13140/RG.2.2.14077.69606</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Reconfiguration demand is increasing due to frequent requirement changes for
manufacturing systems. Recent approaches aim at investigating feasible
configuration alternatives from which they select the optimal one. This relies
on processes whose behavior is not reliant on e.g. the production sequence.
However, when machine learning is used, components' behavior depends on the
process' specifics, requiring additional concepts to successfully conduct
reconfiguration management. Therefore, we propose the enhancement of the
comprehensive reconfiguration management with transfer learning. This provides
the ability to assess the machine learning dependent behavior of the different
CPPS configurations with reduced effort and further assists the recommissioning
of the chosen one. A real cyber-physical production system from the discrete
manufacturing domain is utilized to demonstrate the aforementioned proposal.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14731</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14731</id><submitter>Fahri Wisnu Murti</submitter><version version="v1"><date>Mon, 31 May 2021 06:51:26 GMT</date><size>1001kb</size><source_type>D</source_type></version><title>Deep Reinforcement Based Optimization of Function Splitting in
  Virtualized Radio Access Networks</title><authors>Fahri Wisnu Murti, Samad Ali, and Matti Latva-aho</authors><categories>cs.NI</categories><comments>This paper has been accepted in IEEE International Conference on
  Communications Workshops (ICC Workshops) 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtualized Radio Access Network (vRAN) is one of the key enablers of future
wireless networks as it brings the agility to the radio access network (RAN)
architecture and offers degrees of design freedom. Yet, it also creates a
challenging problem on how to design the functional split configuration. In
this paper, a deep reinforcement learning approach is proposed to optimize
function splitting in vRAN. A learning paradigm is developed that optimizes the
location of functions in the RAN. These functions can be placed either at a
central/cloud unit (CU) or a distributed unit (DU). This problem is formulated
as constrained neural combinatorial reinforcement learning to minimize the
total network cost. In this solution, a policy gradient method with Lagrangian
relaxation is applied that uses a stacked long short-term memory (LSTM) neural
network architecture to approximate the policy. Then, a sampling technique with
a temperature hyperparameter is applied for the inference process. The results
show that our proposed solution can learn the optimal function split decision
and solve the problem with a $0.4\%$ optimality gap. Moreover, our method can
reduce the cost by up to $320\%$ compared to a distributed-RAN (D-RAN). We also
conclude that altering the traffic load and routing cost does not significantly
degrade the optimality performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14732</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14732</id><submitter>Chenxin Li</submitter><version version="v1"><date>Mon, 31 May 2021 06:55:43 GMT</date><size>9252kb</size><source_type>D</source_type></version><title>Hierarchical Deep Network with Uncertainty-aware Semi-supervised
  Learning for Vessel Segmentation</title><authors>Chenxin Li, Wenao Ma, Liyan Sun, Xinghao Ding, Yue Huang, Guisheng
  Wang, Yizhou Yu</authors><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The analysis of organ vessels is essential for computer-aided diagnosis and
surgical planning. But it is not a easy task since the fine-detailed connected
regions of organ vessel bring a lot of ambiguity in vessel segmentation and
sub-type recognition, especially for the low-contrast capillary regions.
Furthermore, recent two-staged approaches would accumulate and even amplify
these inaccuracies from the first-stage whole vessel segmentation into the
second-stage sub-type vessel pixel-wise classification. Moreover, the scarcity
of manual annotation in organ vessels poses another challenge. In this paper,
to address the above issues, we propose a hierarchical deep network where an
attention mechanism localizes the low-contrast capillary regions guided by the
whole vessels, and enhance the spatial activation in those areas for the
sub-type vessels. In addition, we propose an uncertainty-aware semi-supervised
training framework to alleviate the annotation-hungry limitation of deep
models. The proposed method achieves the state-of-the-art performance in the
benchmarks of both retinal artery/vein segmentation in fundus images and liver
portal/hepatic vessel segmentation in CT images.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14734</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14734</id><submitter>Mingyuan Mao</submitter><version version="v1"><date>Mon, 31 May 2021 06:56:29 GMT</date><size>1056kb</size><source_type>D</source_type></version><title>Dual-stream Network for Visual Recognition</title><authors>Mingyuan Mao, Renrui Zhang, Honghui Zheng, Peng Gao, Teli Ma, Yan
  Peng, Errui Ding, Shumin Han</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformers with remarkable global representation capacities achieve
competitive results for visual tasks, but fail to consider high-level local
pattern information in input images. In this paper, we present a generic
Dual-stream Network (DS-Net) to fully explore the representation capacity of
local and global pattern features for image classification. Our DS-Net can
simultaneously calculate fine-grained and integrated features and efficiently
fuse them. Specifically, we propose an Intra-scale Propagation module to
process two different resolutions in each block and an Inter-Scale Alignment
module to perform information interaction across features at dual scales.
Besides, we also design a Dual-stream FPN (DS-FPN) to further enhance
contextual information for downstream dense predictions. Without bells and
whistles, the propsed DS-Net outperforms Deit-Small by 2.4% in terms of top-1
accuracy on ImageNet-1k and achieves state-of-the-art performance over other
Vision Transformers and ResNets. For object detection and instance
segmentation, DS-Net-Small respectively outperforms ResNet-50 by 6.4% and 5.5 %
in terms of mAP on MSCOCO 2017, and surpasses the previous state-of-the-art
scheme, which significantly demonstrates its potential to be a general backbone
in vision tasks. The code will be released soon.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14736</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14736</id><submitter>Bangti Jin</submitter><version version="v1"><date>Mon, 31 May 2021 07:00:57 GMT</date><size>185kb</size><source_type>D</source_type></version><title>Recovering the Potential in One-Dimensional Time-Fractional Diffusion
  with Unknown Initial Condition and Source</title><authors>Bangti Jin and Zhi Zhou</authors><categories>math.AP cs.NA math.NA</categories><comments>23 pages, 3 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper is concerned with an inverse problem of recovering a potential
term in a one-dimensional subdiffusion problem, which involves a
Djrbashian-Caputo fractional derivative of order $\alpha\in(0,1)$ in time, from
the lateral Cauchy data. In the model, we do not assume a full knowledge of the
initial data and the source term, since they might be unavailable in some
practical applications. We prove the unique recovery of the spatially-dependent
potential coefficient and the order $\alpha$ of the derivation simultaneously
from the measured trace data at one end point, when the model is equipped with
a boundary excitation with compact supports away from $t=0$. One of the initial
data and the source can also be uniquely determined, provided that the other is
known. The analysis employs a representation of the solution and the time
analyticity of the associated function. Further, we discuss a two-stage
procedure, directly inspired by the analysis, for the numerical identification
of the order and potential coefficient, and illustrate the feasibility of the
recovery with several numerical experiments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14737</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14737</id><submitter>Jin-Hwa Kim</submitter><version version="v1"><date>Mon, 31 May 2021 07:02:20 GMT</date><size>2065kb</size><source_type>D</source_type></version><title>Semi-orthogonal Embedding for Efficient Unsupervised Anomaly
  Segmentation</title><authors>Jin-Hwa Kim, Do-Hyeong Kim, Saehoon Yi, Taehoon Lee</authors><categories>cs.CV cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the efficiency of semi-orthogonal embedding for unsupervised
anomaly segmentation. The multi-scale features from pre-trained CNNs are
recently used for the localized Mahalanobis distances with significant
performance. However, the increased feature size is problematic to scale up to
the bigger CNNs, since it requires the batch-inverse of multi-dimensional
covariance tensor. Here, we generalize an ad-hoc method, random feature
selection, into semi-orthogonal embedding for robust approximation, cubically
reducing the computational cost for the inverse of multi-dimensional covariance
tensor. With the scrutiny of ablation studies, the proposed method achieves a
new state-of-the-art with significant margins for the MVTec AD, KolektorSDD,
KolektorSDD2, and mSTC datasets. The theoretical and empirical analyses offer
insights and verification of our straightforward yet cost-effective approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14739</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14739</id><submitter>Jichao Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 07:07:44 GMT</date><size>4597kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 01:24:00 GMT</date><size>3058kb</size><source_type>D</source_type></version><title>Controllable Person Image Synthesis with Spatially-Adaptive Warped
  Normalization</title><authors>Jichao Zhang, Aliaksandr Siarohin, Hao Tang, Jingjing Chen, Enver
  Sangineto, Wei Wang, Nicu Sebe</authors><categories>cs.CV cs.GR</categories><comments>12 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Controllable person image generation aims to produce realistic human images
with desirable attributes (e.g., the given pose, cloth textures or hair style).
However, the large spatial misalignment between the source and target images
makes the standard architectures for image-to-image translation not suitable
for this task. Most of the state-of-the-art architectures avoid the alignment
step during the generation, which causes many artifacts, especially for person
images with complex textures. To solve this problem, we introduce a novel
Spatially-Adaptive Warped Normalization (SAWN), which integrates a learned
flow-field to warp modulation parameters. This allows us to align person
spatial-adaptive styles with pose features efficiently. Moreover, we propose a
novel self-training part replacement strategy to refine the pretrained model
for the texture-transfer task, significantly improving the quality of the
generated cloth and the preservation ability of irrelevant regions. Our
experimental results on the widely used DeepFashion dataset demonstrate a
significant improvement of the proposed method over the state-of-the-art
methods on both pose-transfer and texture-transfer tasks. The source code is
available at https://github.com/zhangqianhui/Sawn.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14740</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14740</id><submitter>Ioan Marius Bilasco PhD</submitter><version version="v1"><date>Mon, 31 May 2021 07:07:48 GMT</date><size>1018kb</size><source_type>D</source_type></version><title>A Study On the Effects of Pre-processing On Spatio-temporal Action
  Recognition Using Spiking Neural Networks Trained with STDP</title><authors>El-Assal Mireille and Tirilly Pierre and Bilasco Ioan Marius</authors><categories>cs.CV</categories><acm-class>I.4.7; I.4.8; I.5.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been an increasing interest in spiking neural networks in recent
years. SNNs are seen as hypothetical solutions for the bottlenecks of ANNs in
pattern recognition, such as energy efficiency. But current methods such as
ANN-to-SNN conversion and back-propagation do not take full advantage of these
networks, and unsupervised methods have not yet reached a success comparable to
advanced artificial neural networks. It is important to study the behavior of
SNNs trained with unsupervised learning methods such as spike-timing dependent
plasticity (STDP) on video classification tasks, including mechanisms to model
motion information using spikes, as this information is critical for video
understanding. This paper presents multiple methods of transposing temporal
information into a static format, and then transforming the visual information
into spikes using latency coding. These methods are paired with two types of
temporal fusion known as early and late fusion, and are used to help the
spiking neural network in capturing the spatio-temporal features from videos.
In this paper, we rely on the network architecture of a convolutional spiking
neural network trained with STDP, and we test the performance of this network
when challenged with action recognition tasks. Understanding how a spiking
neural network responds to different methods of movement extraction and
representation can help reduce the performance gap between SNNs and ANNs. In
this paper we show the effect of the similarity in the shape and speed of
certain actions on action recognition with spiking neural networks, we also
highlight the effectiveness of some methods compared to others.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14741</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14741</id><submitter>Vipin Chandra Pandey</submitter><version version="v1"><date>Mon, 31 May 2021 07:12:30 GMT</date><size>945kb</size></version><title>An Adaptive Demand Response Framework using Price Elasticity Model in
  Distribution Networks: A Case Study</title><authors>Vipin Chandra Pandey, Nikhil Gupta, K. R. Niazi, Anil Swarnkar and
  Rayees Ahmad Thokar</authors><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Price elasticity model (PEM) is an appealing and modest model for assessing
the potential of flexible demand in DR. It measures the customers demand
sensitivity through elasticity in relation to price variation. However,
application of PEM in DR is partially apprehensible on attributing the
adaptability and adjustability with intertemporal constraints in DR. Thus, this
article presents an adaptive economic DR framework with attributes of DR via a
dynamic elasticity approach to model customers sensitivity. This dynamic
elasticity is modeled through the deterministic and stochastic approaches. Both
approaches envision the notion of load recovery for shiftable/flexible loads to
make the proposed DR framework adaptive and adjustable relative to price
variation. In stochastic approach, a geometric Brownian motion is employed to
emulate load recovery with inclusion of intertemporal constraint of load
flexibility. The proposed mathematical model shows what should be the customers
elasticity value to achieve the factual DR. The case study is carried out on
standard IEEE 33 distribution system bus load data to assess technical and
socio-economic impact of DR on customers and is also compared with the exiting
model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14742</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14742</id><submitter>Dominik Linzner</submitter><version version="v1"><date>Mon, 31 May 2021 07:13:50 GMT</date><size>3057kb</size><source_type>D</source_type></version><title>Active Learning of Continuous-time Bayesian Networks through
  Interventions</title><authors>Dominik Linzner and Heinz Koeppl</authors><categories>stat.ML cs.LG</categories><comments>Accepted at ICML2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning structures and parameters of
Continuous-time Bayesian Networks (CTBNs) from time-course data under minimal
experimental resources. In practice, the cost of generating experimental data
poses a bottleneck, especially in the natural and social sciences. A popular
approach to overcome this is Bayesian optimal experimental design (BOED).
However, BOED becomes infeasible in high-dimensional settings, as it involves
integration over all possible experimental outcomes. We propose a novel
criterion for experimental design based on a variational approximation of the
expected information gain. We show that for CTBNs, a semi-analytical expression
for this criterion can be calculated for structure and parameter learning. By
doing so, we can replace sampling over experimental outcomes by solving the
CTBNs master-equation, for which scalable approximations exist. This alleviates
the computational burden of sampling possible experimental outcomes in
high-dimensions. We employ this framework in order to recommend interventional
sequences. In this context, we extend the CTBN model to conditional CTBNs in
order to incorporate interventions. We demonstrate the performance of our
criterion on synthetic and real-world data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14748</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14748</id><submitter>Divyesh Unadkat</submitter><version version="v1"><date>Mon, 31 May 2021 07:28:30 GMT</date><size>702kb</size><source_type>D</source_type></version><title>Diffy: Inductive Reasoning of Array Programs using Difference Invariants</title><authors>Supratik Chakraborty, Ashutosh Gupta, Divyesh Unadkat</authors><categories>cs.PL cs.SE</categories><comments>arXiv version of the paper accepted at CAV 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a novel verification technique to prove interesting properties of
a class of array programs with a symbolic parameter N denoting the size of the
array. The technique relies on constructing two slightly different versions of
the program. It infers difference relations between the corresponding variables
at key control points of the joint control-flow graph of the two program
versions. The inferred difference invaraints are agnostic of the post-condition
to be proved and are typically much simpler than the inductive invariants
needed for proving the post-condition directly. We formulate a new technique to
prove the desired post-condition by inducting on the program parameter N, in
which the difference invariants are crucially used in the key inductive step.
This contrasts with classical techniques that rely on finding potentially
complex loop invaraints for each loop in the program. Our synergistic
combination of inductive reasoning and finding simple difference invariants
helps prove properties of programs that cannot be proved even by the winner of
Arrays sub-category from SV-COMP 2021. We have implemented a prototype tool
called diffy to demonstrate these ideas. We show the results on a set of
benchmarks and compare its performance vis-a-vis state-of-the-art tools for
verifying array programs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14750</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14750</id><submitter>Siyuan Li</submitter><version version="v1"><date>Mon, 31 May 2021 07:28:59 GMT</date><size>12519kb</size><source_type>D</source_type></version><title>Efficient Hierarchical Exploration with Stable Subgoal Representation
  Learning</title><authors>Siyuan Li, Jin Zhang, Jianhao Wang, Chongjie Zhang</authors><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goal-conditioned hierarchical reinforcement learning (HRL) serves as a
successful approach to solving complex and temporally extended tasks. Recently,
its success has been extended to more general settings by concurrently learning
hierarchical policies and subgoal representations. However, online subgoal
representation learning exacerbates the non-stationary issue of HRL and
introduces challenges for exploration in high-level policy learning. In this
paper, we propose a state-specific regularization that stabilizes subgoal
embeddings in well-explored areas while allowing representation updates in less
explored state regions. Benefiting from this stable representation, we design
measures of novelty and potential for subgoals, and develop an efficient
hierarchical exploration strategy that actively seeks out new promising
subgoals and states. Experimental results show that our method significantly
outperforms state-of-the-art baselines in continuous control tasks with sparse
rewards and further demonstrate the stability and efficiency of the subgoal
representation learning of this work, which promotes superior policy learning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14753</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14753</id><submitter>Am\'elie Gruel</submitter><version version="v1"><date>Mon, 31 May 2021 07:34:13 GMT</date><size>579kb</size><source_type>D</source_type></version><title>Bio-inspired visual attention for silicon retinas based on spiking
  neural networks applied to pattern classification</title><authors>Am\'elie Gruel and Jean Martinet</authors><categories>cs.CV cs.LG cs.NE</categories><comments>6 pages, 3 figures. To be published in Content-Based Multimedia
  Indexing (CBMI) 2021, Lille, France. This work was supported by the European
  Union's ERA-NET CHIST-ERA 2018 research and innovation programme under grant
  agreement ANR-19-CHR3-0008</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Visual attention can be defined as the behavioral and cognitive process of
selectively focusing on a discrete aspect of sensory cues while disregarding
other perceivable information. This biological mechanism, more specifically
saliency detection, has long been used in multimedia indexing to drive the
analysis only on relevant parts of images or videos for further processing.
  The recent advent of silicon retinas (or event cameras -- sensors that
measure pixel-wise changes in brightness and output asynchronous events
accordingly) raises the question of how to adapt attention and saliency to the
unconventional type of such sensors' output. Silicon retina aims to reproduce
the biological retina behaviour. In that respect, they produce punctual events
in time that can be construed as neural spikes and interpreted as such by a
neural network.
  In particular, Spiking Neural Networks (SNNs) represent an asynchronous type
of artificial neural network closer to biology than traditional artificial
networks, mainly because they seek to mimic the dynamics of neural membrane and
action potentials over time. SNNs receive and process information in the form
of spike trains. Therefore, they make for a suitable candidate for the
efficient processing and classification of incoming event patterns measured by
silicon retinas. In this paper, we review the biological background behind the
attentional mechanism, and introduce a case study of event videos
classification with SNNs, using a biology-grounded low-level computational
attention mechanism, with interesting preliminary results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14754</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14754</id><submitter>Chong Shangguan</submitter><version version="v1"><date>Mon, 31 May 2021 07:36:57 GMT</date><size>17kb</size></version><title>List-decoding and list-recovery of Reed-Solomon codes beyond the Johnson
  radius for any rate</title><authors>Eitan Goldberg and Chong Shangguan and Itzhak Tamo</authors><categories>cs.IT math.CO math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the limits of list-decoding and list-recovery of Reed-Solomon
(RS) codes is of prime interest in coding theory and has attracted a lot of
attention in recent decades. However, the best possible parameters for these
problems are still unknown, and in this paper, we take a step in this
direction. We show the existence of RS codes that are list-decodable or
list-recoverable beyond the Johnson radius for \emph{any} rate, with a
polynomial field size in the block length. In particular, we show that for any
$\epsilon\in (0,1)$ there exist RS codes that are list-decodable from radius
$1-\epsilon$ and rate less than $\frac{\epsilon}{2-\epsilon}$, with constant
list size. We deduce our results by extending and strengthening a recent result
of Ferber, Kwan, and Sauermann on puncturing codes with large minimum distance
and by utilizing the underlying code's linearity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14755</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14755</id><submitter>Dong An</submitter><version version="v1"><date>Mon, 31 May 2021 07:37:19 GMT</date><size>285kb</size><source_type>D</source_type></version><title>Parallel transport dynamics for mixed quantum states with applications
  to time-dependent density functional theory</title><authors>Dong An, Di Fang, Lin Lin</authors><categories>math.NA cs.NA physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direct simulation of the von Neumann dynamics for a general (pure or mixed)
quantum state can often be expensive. One prominent example is the real-time
time-dependent density functional theory (rt-TDDFT), a widely used framework
for the first principle description of many-electron dynamics in chemical and
materials systems. Practical rt-TDDFT calculations often avoid the direct
simulation of the von Neumann equation, and solve instead a set of
Schr\&quot;odinger equations, of which the dynamics is equivalent to that of the von
Neumann equation. However, the time step size employed by the Schr\&quot;odinger
dynamics is often much smaller. In order to improve the time step size and the
overall efficiency of the simulation, we generalize a recent work of the
parallel transport (PT) dynamics for simulating pure states [An, Lin,
Multiscale Model. Simul. 18, 612, 2020] to general quantum states. The PT
dynamics provides the optimal gauge choice, and can employ a time step size
comparable to that of the von Neumann dynamics. Going beyond the linear and
near adiabatic regime in previous studies, we find that the error of the PT
dynamics can be bounded by certain commutators between Hamiltonians, density
matrices, and their derived quantities. Such a commutator structure is not
present in the Schr\&quot;odinger dynamics. We demonstrate that the parallel
transport-implicit midpoint (PT-IM) method is a suitable method for simulating
the PT dynamics, especially when the spectral radius of the Hamiltonian is
large. The commutator structure of the error bound, and numerical results for
model rt-TDDFT calculations in both linear and nonlinear regimes, confirm the
advantage of the PT dynamics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14756</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14756</id><submitter>AprilPyone MaungMaung</submitter><version version="v1"><date>Mon, 31 May 2021 07:37:33 GMT</date><size>982kb</size><source_type>D</source_type></version><title>A Protection Method of Trained CNN Model with Secret Key from
  Unauthorized Access</title><authors>AprilPyone MaungMaung and Hitoshi Kiya</authors><categories>cs.CV cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel method for protecting convolutional neural
network (CNN) models with a secret key set so that unauthorized users without
the correct key set cannot access trained models. The method enables us to
protect not only from copyright infringement but also the functionality of a
model from unauthorized access without any noticeable overhead. We introduce
three block-wise transformations with a secret key set to generate learnable
transformed images: pixel shuffling, negative/positive transformation, and FFX
encryption. Protected models are trained by using transformed images. The
results of experiments with the CIFAR and ImageNet datasets show that the
performance of a protected model was close to that of non-protected models when
the key set was correct, while the accuracy severely dropped when an incorrect
key set was given. The protected model was also demonstrated to be robust
against various attacks. Compared with the state-of-the-art model protection
with passports, the proposed method does not have any additional layers in the
network, and therefore, there is no overhead during training and inference
processes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14758</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14758</id><submitter>Lu Xu</submitter><version version="v1"><date>Mon, 31 May 2021 07:42:21 GMT</date><size>4614kb</size><source_type>D</source_type></version><title>Low-Dose CT Denoising Using a Structure-Preserving Kernel Prediction
  Network</title><authors>Lu Xu, Yuwei Zhang, Ying Liu, Daoye Wang, Mu Zhou, Jimmy Ren,
  Zhaoxiang Ye</authors><categories>eess.IV cs.CV</categories><comments>ICIP2021</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Low-dose CT has been a key diagnostic imaging modality to reduce the
potential risk of radiation overdose to patient health. Despite recent
advances, CNN-based approaches typically apply filters in a spatially invariant
way and adopt similar pixel-level losses, which treat all regions of the CT
image equally and can be inefficient when fine-grained structures coexist with
non-uniformly distributed noises. To address this issue, we propose a
Structure-preserving Kernel Prediction Network (StructKPN) that combines the
kernel prediction network with a structure-aware loss function that utilizes
the pixel gradient statistics and guides the model towards spatially-variant
filters that enhance noise removal, prevent over-smoothing and preserve
detailed structures for different regions in CT imaging. Extensive experiments
demonstrated that our approach achieved superior performance on both synthetic
and non-synthetic datasets, and better preserves structures that are highly
desired in clinical screening and low-dose protocol optimization.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14759</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14759</id><submitter>Yun Wan</submitter><version version="v1"><date>Mon, 31 May 2021 07:44:04 GMT</date><size>1125kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 01:47:51 GMT</date><size>1113kb</size></version><title>The x-index: A new citation-distance-based index to measure academic
  influence</title><authors>Yun Wan, Feng Xiao, Bintong Chen, Lu Li</authors><categories>cs.DL cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important issue in the field of academic measurement is how to evaluate
academic influence scientifically and comprehensively, which can help
government and research organizations better allocate academic resources and
recruit researchers. It is generally accepted that using weighted citations to
measure academic influence is more reasonable than treating all citations
equally. Given the limitations of the existing c-index, the first index in
bibliometric literature that measures output based on the quantity and quality
of received citations, we propose the x-index, which assigns weight to each
citation according to its distance. By defining collaboration distance and
citation distance, we first analyze the properties of the collaboration network
and citation distance, then perform theoretical and empirical analyses on
c-index to reveal its shortcomings, finally, we suggest the x-index and conduct
experiments and analysis on the x-index. Experimental results demonstrate that
compared with the c-index, h-index, and g-index, the x-index shows a stronger
discriminatory power.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14760</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14760</id><submitter>Donghwan Lee</submitter><version version="v1"><date>Mon, 31 May 2021 07:46:51 GMT</date><size>119kb</size></version><title>Multi-Objective LQG Design with Primal-Dual Method</title><authors>Donghwan Lee and Do Wan Kim</authors><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to study a multi-objective linear quadratic
Gaussian (LQG) control problem. In particular, we consider an optimal control
problem minimizing a quadratic cost over a finite time horizon for linear
stochastic systems subject to control energy constraints. To solve the problem,
we suggest an efficient bisection line search algorithm which is
computationally efficient compared to other approaches such as the semidefinite
programming. The main idea is to use the Lagrangian function and
Karush-Kuhn-Tucker (KKT) optimality conditions to solve the constrained
optimization problem. The Lagrange multiplier is searched using the bisection
line search. Numerical examples are given to demonstrate the effectiveness of
the proposed methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14761</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14761</id><submitter>Guangsheng Bao</submitter><version version="v1"><date>Mon, 31 May 2021 07:47:10 GMT</date><size>794kb</size><source_type>D</source_type></version><title>G-Transformer for Document-level Machine Translation</title><authors>Guangsheng Bao, Yue Zhang, Zhiyang Teng, Boxing Chen and Weihua Luo</authors><categories>cs.CL cs.LG</categories><comments>Accepted by ACL2021 main track</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Document-level MT models are still far from satisfactory. Existing work
extend translation unit from single sentence to multiple sentences. However,
study shows that when we further enlarge the translation unit to a whole
document, supervised training of Transformer can fail. In this paper, we find
such failure is not caused by overfitting, but by sticking around local minima
during training. Our analysis shows that the increased complexity of
target-to-source attention is a reason for the failure. As a solution, we
propose G-Transformer, introducing locality assumption as an inductive bias
into Transformer, reducing the hypothesis space of the attention from target to
source. Experiments show that G-Transformer converges faster and more stably
than Transformer, achieving new state-of-the-art BLEU scores for both
non-pretraining and pre-training settings on three benchmark datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14762</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14762</id><submitter>Kun Zhou</submitter><version version="v1"><date>Mon, 31 May 2021 07:48:56 GMT</date><size>1552kb</size><source_type>D</source_type></version><title>Emotional Voice Conversion: Theory, Databases and ESD</title><authors>Kun Zhou, Berrak Sisman, Rui Liu, Haizhou Li</authors><categories>cs.CL</categories><comments>Submitted to Speech Communication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we first provide a review of the state-of-the-art emotional
voice conversion research, and the existing emotional speech databases. We then
motivate the development of a novel emotional speech database (ESD) that
addresses the increasing research need. With this paper, the ESD database is
now made available to the research community. The ESD database consists of 350
parallel utterances spoken by 10 native English and 10 native Chinese speakers
and covers 5 emotion categories (neutral, happy, angry, sad and surprise). More
than 29 hours of speech data were recorded in a controlled acoustic
environment. The database is suitable for multi-speaker and cross-lingual
emotional voice conversion studies. As case studies, we implement several
state-of-the-art emotional voice conversion systems on the ESD database. This
paper provides a reference study on ESD in conjunction with its release.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14764</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14764</id><submitter>Tomohiro Motoda</submitter><version version="v1"><date>Mon, 31 May 2021 07:53:34 GMT</date><size>2913kb</size><source_type>D</source_type></version><title>Bimanual Shelf Picking Planner Based on Collapse Prediction</title><authors>T. Motoda, D. Petit, W. Wan and K. Harada</authors><categories>cs.RO</categories><comments>6 pages with 9 figures and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In logistics warehouse, since many objects are randomly stacked on shelves,
it becomes difficult for a robot to safely extract one of the objects without
other objects falling from the shelf. In previous works, a robot needed to
extract the target object after rearranging the neighboring objects. In
contrast, humans extract an object from a shelf while supporting other
neighboring objects. In this paper, we propose a bimanual manipulation planner
based on collapse prediction trained with data generated from a physics
simulator, which can safely extract a single object while supporting the other
object. We confirmed that the proposed method achieves more than 80% success
rate for safe extraction by real-world experiments using a dual-arm
manipulator.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14766</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14766</id><submitter>Junjun Jiang</submitter><version version="v1"><date>Mon, 31 May 2021 07:55:30 GMT</date><size>33872kb</size><source_type>D</source_type></version><title>BaMBNet: A Blur-aware Multi-branch Network for Defocus Deblurring</title><authors>Pengwei Liang, Junjun Jiang, Xianming Liu, and Jiayi Ma</authors><categories>eess.IV cs.CV</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The defocus deblurring raised from the finite aperture size and exposure time
is an essential problem in the computational photography. It is very
challenging because the blur kernel is spatially varying and difficult to
estimate by traditional methods. Due to its great breakthrough in low-level
tasks, convolutional neural networks (CNNs) have been introduced to the defocus
deblurring problem and achieved significant progress. However, they apply the
same kernel for different regions of the defocus blurred images, thus it is
difficult to handle these nonuniform blurred images. To this end, this study
designs a novel blur-aware multi-branch network (BaMBNet), in which different
regions (with different blur amounts) should be treated differentially. In
particular, we estimate the blur amounts of different regions by the internal
geometric constraint of the DP data, which measures the defocus disparity
between the left and right views. Based on the assumption that different image
regions with different blur amounts have different deblurring difficulties, we
leverage different networks with different capacities (\emph{i.e.} parameters)
to process different image regions. Moreover, we introduce a meta-learning
defocus mask generation algorithm to assign each pixel to a proper branch. In
this way, we can expect to well maintain the information of the clear regions
while recovering the missing details of the blurred regions. Both quantitative
and qualitative experiments demonstrate that our BaMBNet outperforms the
state-of-the-art methods. Source code will be available at
https://github.com/junjun-jiang/BaMBNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14768</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14768</id><submitter>Wei Wang Dr.</submitter><version version="v1"><date>Mon, 31 May 2021 08:01:41 GMT</date><size>2294kb</size><source_type>D</source_type></version><title>Securing IoT Devices by Exploiting Backscatter Propagation Signatures</title><authors>Zhiqing Luo, Wei Wang, Qianyi Huang, Tao Jiang, and Qian Zhang</authors><categories>cs.CR</categories><comments>arXiv admin note: substantial text overlap with arXiv:1810.07058</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The low-power radio technologies open up many opportunities to facilitate
Internet-of-Things (IoT) into our daily life, while their minimalist design
also makes IoT devices vulnerable to many active attacks. Recent advances use
an antenna array to extract fine-grained physical-layer signatures to identify
the attackers, which adds burdens in terms of energy and hardware cost to IoT
devices. In this paper, we present ShieldScatter, a lightweight system that
attaches low-cost tags to single-antenna devices to shield the system from
active attacks. The key insight of ShieldScatter is to intentionally create
multi-path propagation signatures with the careful deployment of tags. These
signatures can be used to construct a sensitive profile to identify the
location of the signals' arrival, and thus detect the threat. In addition, we
also design a tag-random scheme and a multiple receivers combination approach
to detect a powerful attacker who has the strong priori knowledge of the
legitimate user. We prototype ShieldScatter with USRPs and tags to evaluate our
system in various environments. The results show that even when the powerful
attacker is close to the legitimate device, ShieldScatter can mitigate 95% of
attack attempts while triggering false alarms on just 7% of legitimate traffic.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14769</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14769</id><submitter>Petar Maksimovi\'c</submitter><version version="v1"><date>Mon, 31 May 2021 08:01:45 GMT</date><size>355kb</size></version><title>Gillian: A Multi-Language Platform for Unified Symbolic Analysis</title><authors>Petar Maksimovi\'c, Jos\'e Fragoso Santos, Sacha-\'Elie Ayoun,
  Philippa Gardner</authors><categories>cs.PL cs.LO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This is an evolving document describing the meta-theory, the implementation,
and the instantiations of Gillian, a multi-language symbolic analysis platform.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14772</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14772</id><submitter>Anis Elgabli</submitter><version version="v1"><date>Mon, 31 May 2021 08:15:44 GMT</date><size>728kb</size></version><title>Energy-Efficient and Federated Meta-Learning via Projected Stochastic
  Gradient Ascent</title><authors>Anis Elgabli, Chaouki Ben Issaid, Amrit S. Bedi, Mehdi Bennis, Vaneet
  Aggarwal</authors><categories>cs.LG cs.AI cs.DC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose an energy-efficient federated meta-learning
framework. The objective is to enable learning a meta-model that can be
fine-tuned to a new task with a few number of samples in a distributed setting
and at low computation and communication energy consumption. We assume that
each task is owned by a separate agent, so a limited number of tasks is used to
train a meta-model. Assuming each task was trained offline on the agent's local
data, we propose a lightweight algorithm that starts from the local models of
all agents, and in a backward manner using projected stochastic gradient ascent
(P-SGA) finds a meta-model. The proposed method avoids complex computations
such as computing hessian, double looping, and matrix inversion, while
achieving high performance at significantly less energy consumption compared to
the state-of-the-art methods such as MAML and iMAML on conducted experiments
for sinusoid regression and image classification tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14773</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14773</id><submitter>Yan Wang</submitter><version version="v1"><date>Mon, 31 May 2021 08:16:09 GMT</date><size>5560kb</size><source_type>D</source_type></version><title>Learning Inductive Attention Guidance for Partially Supervised
  Pancreatic Ductal Adenocarcinoma Prediction</title><authors>Yan Wang, Peng Tang, Yuyin Zhou, Wei Shen, Elliot K. Fishman, and Alan
  L. Yuille</authors><categories>cs.CV</categories><doi>10.1109/TMI.2021.3060066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pancreatic ductal adenocarcinoma (PDAC) is the third most common cause of
cancer death in the United States. Predicting tumors like PDACs (including both
classification and segmentation) from medical images by deep learning is
becoming a growing trend, but usually a large number of annotated data are
required for training, which is very labor-intensive and time-consuming. In
this paper, we consider a partially supervised setting, where cheap image-level
annotations are provided for all the training data, and the costly per-voxel
annotations are only available for a subset of them. We propose an Inductive
Attention Guidance Network (IAG-Net) to jointly learn a global image-level
classifier for normal/PDAC classification and a local voxel-level classifier
for semi-supervised PDAC segmentation. We instantiate both the global and the
local classifiers by multiple instance learning (MIL), where the attention
guidance, indicating roughly where the PDAC regions are, is the key to bridging
them: For global MIL based normal/PDAC classification, attention serves as a
weight for each instance (voxel) during MIL pooling, which eliminates the
distraction from the background; For local MIL based semi-supervised PDAC
segmentation, the attention guidance is inductive, which not only provides
bag-level pseudo-labels to training data without per-voxel annotations for MIL
training, but also acts as a proxy of an instance-level classifier.
Experimental results show that our IAG-Net boosts PDAC segmentation accuracy by
more than 5% compared with the state-of-the-arts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14774</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14774</id><submitter>Erfan Ghadery</submitter><version version="v1"><date>Mon, 31 May 2021 08:16:34 GMT</date><size>343kb</size><source_type>D</source_type></version><title>LIIR at SemEval-2021 task 6: Detection of Persuasion Techniques In Texts
  and Images using CLIP features</title><authors>Erfan Ghadery, Damien Sileo, Marie-Francine Moens</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We describe our approach for SemEval-2021 task 6 on detection of persuasion
techniques in multimodal content (memes). Our system combines pretrained
multimodal models (CLIP) and chained classifiers. Also, we propose to enrich
the data by a data augmentation technique. Our submission achieves a rank of
8/16 in terms of F1-micro and 9/16 with F1-macro on the test set.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14776</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14776</id><submitter>Mirko Trisolini</submitter><version version="v1"><date>Mon, 31 May 2021 08:17:04 GMT</date><size>3535kb</size></version><title>Fragmentation model and strewn field estimation for meteoroids entry</title><authors>Simone Limonta, Mirko Trisolini, Stefan Frey, Camilla Colombo</authors><categories>astro-ph.EP astro-ph.IM cs.NA math.NA</categories><comments>29 pages, 26 figures, published in Icarus</comments><doi>10.1016/j.icarus.2021.114553</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Everyday thousands of meteoroids enter the Earth's atmosphere. The vast
majority burn up harmlessly during the descent, but the larger objects survive,
occasionally experiencing intense fragmentation events, and reach the ground.
These events can pose a threat for a village or a small city; therefore, models
of asteroid fragmentation, along with accurate post-breakup trajectory and
strewn field estimation, are needed to enable a reliable risk assessment. In
this work, a methodology to describe meteoroids entry, fragmentation, descent,
and strewn field is presented by means of a continuum approach. At breakup, a
modified version of the NASA Standard Breakup Model is used to generate the
distribution of the fragments in terms of their area-to-mass ratio and ejection
velocity. This distribution, combined with the meteoroid state, is directly
propagated using the continuity equation coupled with the non-linear entry
dynamics. At each time step, the probability density evolution of the fragments
is reconstructed using GMM interpolation. Using this information is then
possible to estimate the meteoroid's ground impact probability. This approach
departs from the current state-of-the-art models: it has the flexibility to
include large fragmentation events while maintaining a continuum formulation
for a better physical representation of the phenomenon. The methodology is also
characterised by a modular structure, so that updated asteroids fragmentation
models can be readily integrated into the framework, allowing a continuously
improving prediction of re-entry and fragmentation events. The propagation of
the fragments' density and its reconstruction, currently considering only one
fragmentation point, is first compared against Monte Carlo simulations, and
then against real observations. Both deceleration due to atmospheric drag and
ablation due to aerothermodynamics effects have been considered.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14778</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14778</id><submitter>Peng Wang</submitter><version version="v1"><date>Mon, 31 May 2021 08:18:13 GMT</date><size>5523kb</size><source_type>D</source_type></version><title>Sketch and Refine: Towards Faithful and Informative Table-to-Text
  Generation</title><authors>Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang, Jingren
  Zhou, Hongxia Yang</authors><categories>cs.CL</categories><comments>13 pages, 2 figures. Accepted in ACL2021 Findings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Table-to-text generation refers to generating a descriptive text from a
key-value table. Traditional autoregressive methods, though can generate text
with high fluency, suffer from low coverage and poor faithfulness problems. To
mitigate these problems, we propose a novel Skeleton-based two-stage method
that combines both Autoregressive and Non-Autoregressive generations (SANA).
Our approach includes: (1) skeleton generation with an autoregressive pointer
network to select key tokens from the source table; (2) edit-based
non-autoregressive generation model to produce texts via iterative insertion
and deletion operations. By integrating hard constraints from the skeleton, the
non-autoregressive model improves the generation's coverage over the source
table and thus enhances its faithfulness. We conduct automatic and human
evaluations on both WikiPerson and WikiBio datasets. Experimental results
demonstrate that our method outperforms the previous state-of-the-art methods
in both automatic and human evaluation, especially on coverage and
faithfulness. In particular, we achieve PARENT-T recall of 99.47 in WikiPerson,
improving over the existing best results by more than 10 points.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14779</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14779</id><submitter>Shammur Absar Chowdhury</submitter><version version="v1"><date>Mon, 31 May 2021 08:20:38 GMT</date><size>585kb</size><source_type>D</source_type></version><title>Towards One Model to Rule All: Multilingual Strategy for Dialectal
  Code-Switching Arabic ASR</title><authors>Shammur Absar Chowdhury, Amir Hussein, Ahmed Abdelali, Ahmed Ali</authors><categories>cs.CL cs.HC cs.SD eess.AS</categories><comments>Submitted to INTERSPEECH 2021, Multilingual ASR, Multi-dialectal ASR,
  Code-Switching ASR, Arabic ASR, Conformer, Transformer, E2E ASR, Speech
  Recognition, ASR, Arabic, English, French</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  With the advent of globalization, there is an increasing demand for
multilingual automatic speech recognition (ASR), handling language and
dialectal variation of spoken content. Recent studies show its efficacy over
monolingual systems. In this study, we design a large multilingual end-to-end
ASR using self-attention based conformer architecture. We trained the system
using Arabic (Ar), English (En) and French (Fr) languages. We evaluate the
system performance handling: (i) monolingual (Ar, En and Fr); (ii)
multi-dialectal (Modern Standard Arabic, along with dialectal variation such as
Egyptian and Moroccan); (iii) code-switching -- cross-lingual (Ar-En/Fr) and
dialectal (MSA-Egyptian dialect) test cases, and compare with current
state-of-the-art systems. Furthermore, we investigate the influence of
different embedding/character representations including character vs
word-piece; shared vs distinct input symbol per language. Our findings
demonstrate the strength of such a model by outperforming state-of-the-art
monolingual dialectal Arabic and code-switching Arabic ASR.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14780</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14780</id><submitter>Matthias M\&quot;uller-Brockhausen</submitter><version version="v1"><date>Mon, 31 May 2021 08:21:03 GMT</date><size>1078kb</size><source_type>D</source_type></version><title>Procedural Content Generation: Better Benchmarks for Transfer
  Reinforcement Learning</title><authors>Matthias M\&quot;uller-Brockhausen, Mike Preuss, Aske Plaat</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The idea of transfer in reinforcement learning (TRL) is intriguing: being
able to transfer knowledge from one problem to another problem without learning
everything from scratch. This promises quicker learning and learning more
complex methods. To gain an insight into the field and to detect emerging
trends, we performed a database search. We note a surprisingly late adoption of
deep learning that starts in 2018. The introduction of deep learning has not
yet solved the greatest challenge of TRL: generalization. Transfer between
different domains works well when domains have strong similarities (e.g.
MountainCar to Cartpole), and most TRL publications focus on different tasks
within the same domain that have few differences. Most TRL applications we
encountered compare their improvements against self-defined baselines, and the
field is still missing unified benchmarks. We consider this to be a
disappointing situation. For the future, we note that: (1) A clear measure of
task similarity is needed. (2) Generalization needs to improve. Promising
approaches merge deep learning with planning via MCTS or introduce memory
through LSTMs. (3) The lack of benchmarking tools will be remedied to enable
meaningful comparison and measure progress. Already Alchemy and Meta-World are
emerging as interesting benchmark suites. We note that another development, the
increase in procedural content generation (PCG), can improve both benchmarking
and generalization in TRL.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14781</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14781</id><submitter>Yilin Niu</submitter><version version="v1"><date>Mon, 31 May 2021 08:21:52 GMT</date><size>6334kb</size><source_type>D</source_type></version><title>A Semantic-based Method for Unsupervised Commonsense Question Answering</title><authors>Yilin Niu, Fei Huang, Jiaming Liang, Wenkai Chen, Xiaoyan Zhu, Minlie
  Huang</authors><categories>cs.CL</categories><comments>Accepted by ACL 2021 (long paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised commonsense question answering is appealing since it does not
rely on any labeled task data. Among existing work, a popular solution is to
use pre-trained language models to score candidate choices directly conditioned
on the question or context. However, such scores from language models can be
easily affected by irrelevant factors, such as word frequencies, sentence
structures, etc. These distracting factors may not only mislead the model to
choose a wrong answer but also make it oversensitive to lexical perturbations
in candidate answers.
  In this paper, we present a novel SEmantic-based Question Answering method
(SEQA) for unsupervised commonsense question answering. Instead of directly
scoring each answer choice, our method first generates a set of plausible
answers with generative models (e.g., GPT-2), and then uses these plausible
answers to select the correct choice by considering the semantic similarity
between each plausible answer and each choice. We devise a simple, yet sound
formalism for this idea and verify its effectiveness and robustness with
extensive experiments. We evaluate the proposed method on four benchmark
datasets, and our method achieves the best results in unsupervised settings.
Moreover, when attacked by TextFooler with synonym replacement, SEQA
demonstrates much less performance drops than baselines, thereby indicating
stronger robustness.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14783</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14783</id><submitter>Marie-Laure Zollinger</submitter><version version="v1"><date>Mon, 31 May 2021 08:22:29 GMT</date><size>273kb</size><source_type>D</source_type></version><title>Electryo, In-person Voting with Transparent Voter Verifiability and
  Eligibility Verifiability</title><authors>Peter B. Roenne and Peter Y.A Ryan and Marie-Laure Zollinger</authors><categories>cs.CR</categories><comments>E-Vote-ID 2018 TUT Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selene is an e-voting protocol that allows voters to directly check their
individual vote, in cleartext, in the final tally via a tracker system, while
providing good coercion mitigation. This is in contrast to conventional,
end-to-end verifiable schemes in which the voter verifies the presence of an
encryption of her vote on the bulletin board. The Selene mechanism can be
applied to many e-voting schemes, but here we present an application to the
polling station context, resulting in a voter-verifiable electronic tally with
a paper audit trail. The system uses a smartcard-based public key system to
provide the individual verification and universal eligibility verifiability.
The paper record contains an encrypted link to the voter's identity, requiring
stronger assumptions on ballot privacy than normal paper voting, but with the
benefit of providing good auditability and dispute resolution as well as
supporting (comparison) risk limiting audits.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14784</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14784</id><submitter>Shen Cai</submitter><version version="v1"><date>Mon, 31 May 2021 08:24:09 GMT</date><size>1216kb</size><source_type>D</source_type></version><title>SN-Graph: a Minimalist 3D Object Representation for Classification</title><authors>Siyu Zhang, Hui Cao, Yuqi Liu, Shen Cai, Yanting Zhang, Yuanzhan Li,
  Xiaoyu Chi</authors><categories>cs.CV cs.LG</categories><comments>ICME 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using deep learning techniques to process 3D objects has achieved many
successes. However, few methods focus on the representation of 3D objects,
which could be more effective for specific tasks than traditional
representations, such as point clouds, voxels, and multi-view images. In this
paper, we propose a Sphere Node Graph (SN-Graph) to represent 3D objects.
Specifically, we extract a certain number of internal spheres (as nodes) from
the signed distance field (SDF), and then establish connections (as edges)
among the sphere nodes to construct a graph, which is seamlessly suitable for
3D analysis using graph neural network (GNN). Experiments conducted on the
ModelNet40 dataset show that when there are fewer nodes in the graph or the
tested objects are rotated arbitrarily, the classification accuracy of SN-Graph
is significantly higher than the state-of-the-art methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14785</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14785</id><submitter>Tianyu Pang</submitter><version version="v1"><date>Mon, 31 May 2021 08:24:53 GMT</date><size>6712kb</size><source_type>D</source_type></version><title>Adversarial Training with Rectified Rejection</title><authors>Tianyu Pang, Huishuai Zhang, Di He, Yinpeng Dong, Hang Su, Wei Chen,
  Jun Zhu, Tie-Yan Liu</authors><categories>cs.LG cs.CR cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial training (AT) is one of the most effective strategies for
promoting model robustness, whereas even the state-of-the-art adversarially
trained models struggle to exceed 60% robust test accuracy on CIFAR-10 without
additional data, which is far from practical. A natural way to break this
accuracy bottleneck is to introduce a rejection option, where confidence is a
commonly used certainty proxy. However, the vanilla confidence can overestimate
the model certainty if the input is wrongly classified. To this end, we propose
to use true confidence (T-Con) (i.e., predicted probability of the true class)
as a certainty oracle, and learn to predict T-Con by rectifying confidence. We
prove that under mild conditions, a rectified confidence (R-Con) rejector and a
confidence rejector can be coupled to distinguish any wrongly classified input
from correctly classified ones, even under adaptive attacks. We also quantify
that training R-Con to be aligned with T-Con could be an easier task than
learning robust classifiers. In our experiments, we evaluate our rectified
rejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under several
attacks, and demonstrate that the RR module is well compatible with different
AT frameworks on improving robustness, with little extra computation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14787</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14787</id><submitter>Seo-Hyun Lee</submitter><version version="v1"><date>Mon, 31 May 2021 08:25:57 GMT</date><size>1352kb</size><source_type>D</source_type></version><title>Voice of Your Brain: Cognitive Representations of Imagined Speech,Overt
  Speech, and Speech Perception Based on EEG</title><authors>Seo-Hyun Lee, Young-Eun Lee, Seong-Whan Lee</authors><categories>cs.HC</categories><comments>5 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every people has their own voice, likewise, brain signals dis-play distinct
neural representations for each individual. Al-though recent studies have
revealed the robustness of speech-related paradigms for efficient
brain-computer interface, the dis-tinction on their cognitive representations
with practical usabil-ity still remains to be discovered. Herein, we
investigate the dis-tinct brain patterns from electroencephalography (EEG)
duringimagined speech, overt speech, and speech perception in termsof subject
variations with its practical use of speaker identifica-tion from single
channel EEG. We performed classification ofnine subjects using deep neural
network that captures temporal-spectral-spatial features from EEG of imagined
speech, overtspeech, and speech perception. Furthermore, we demonstratedthe
underlying neural features of individual subjects while per-forming imagined
speech by comparing the functional connec-tivity and the EEG envelope features.
Our results demonstratethe possibility of subject identification from single
channel EEGof imagined speech and overt speech. Also, the comparison ofthe
three speech-related paradigms will provide valuable infor-mation for the
practical use of speech-related brain signals inthe further studies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14790</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14790</id><submitter>Simindokht Jahangard</submitter><version version="v1"><date>Mon, 31 May 2021 08:34:57 GMT</date><size>1725kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 12:48:51 GMT</date><size>1724kb</size></version><title>Predicting Driver Intention Using Deep Neural Network</title><authors>Mahdi Bonyani, Mina Rahmanian, Simindokht Jahangard</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve driving safety and avoid car accidents, Advanced Driver Assistance
Systems (ADAS) are given significant attention. Recent studies have focused on
predicting driver intention as a key part of these systems. In this study, we
proposed new framework in which 4 inputs are employed to anticipate diver
maneuver using Brain4Cars dataset and the maneuver prediction is achieved from
5, 4, 3, 2, 1 seconds before the actual action occurs. We evaluated our
framework in three scenarios: using only 1) inside view 2) outside view and 3)
both inside and outside view. We divided the dataset into training, validation
and test sets, also K-fold cross validation is utilized. Compared with
state-of-the-art studies, our architecture is faster and achieved higher
performance in second and third scenario. Accuracy, precision, recall and
f1-score as evaluation metrics were utilized and the result of 82.41%, 82.28%,
82,42% and 82.24% for outside view and 98.90%, 98.96%, 98.90% and 98.88% for
both inside and outside view were gained, respectively.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14796</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14796</id><submitter>Binbin Xie</submitter><version version="v1"><date>Mon, 31 May 2021 08:44:13 GMT</date><size>586kb</size><source_type>D</source_type></version><title>Improving Tree-Structured Decoder Training for Code Generation via
  Mutual Learning</title><authors>Binbin Xie, Jinsong Su, Yubin Ge, Xiang Li, Jianwei Cui, Junfeng Yao
  and Bin Wang</authors><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code generation aims to automatically generate a piece of code given an input
natural language utterance. Currently, among dominant models, it is treated as
a sequence-to-tree task, where a decoder outputs a sequence of actions
corresponding to the pre-order traversal of an Abstract Syntax Tree. However,
such a decoder only exploits the preorder traversal based preceding actions,
which are insufficient to ensure correct action predictions. In this paper, we
first throughly analyze the context modeling difference between neural code
generation models with different traversals based decodings (preorder traversal
vs breadth-first traversal), and then propose to introduce a mutual learning
framework to jointly train these models. Under this framework, we continuously
enhance both two models via mutual distillation, which involves synchronous
executions of two one-to-one knowledge transfers at each training step. More
specifically, we alternately choose one model as the student and the other as
its teacher, and require the student to fit the training data and the action
prediction distributions of its teacher. By doing so, both models can fully
absorb the knowledge from each other and thus could be improved simultaneously.
Experimental results and in-depth analysis on several benchmark datasets
demonstrate the effectiveness of our approach. We release our code at
https://github.com/DeepLearnXMU/CGML.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14797</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14797</id><submitter>Edouard Yvinec</submitter><version version="v1"><date>Mon, 31 May 2021 08:44:14 GMT</date><size>568kb</size><source_type>D</source_type></version><title>RED : Looking for Redundancies for Data-Free Structured Compression of
  Deep Neural Networks</title><authors>Edouard Yvinec, Arnaud Dapogny, Matthieu Cord and Kevin Bailly</authors><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Neural Networks (DNNs) are ubiquitous in today's computer vision
land-scape, despite involving considerable computational costs. The mainstream
approaches for runtime acceleration consist in pruning connections
(unstructured pruning) or, better, filters (structured pruning), both often
requiring data to re-train the model. In this paper, we present RED, a
data-free structured, unified approach to tackle structured pruning. First, we
propose a novel adaptive hashing of the scalar DNN weight distribution
densities to increase the number of identical neurons represented by their
weight vectors. Second, we prune the network by merging redundant neurons based
on their relative similarities, as defined by their distance. Third, we propose
a novel uneven depthwise separation technique to further prune convolutional
layers. We demonstrate through a large variety of benchmarks that RED largely
outperforms other data-free pruning methods, often reaching performance similar
to unconstrained, data-driven methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14799</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14799</id><submitter>Raqeeb Rasheed</submitter><version version="v1"><date>Mon, 31 May 2021 08:49:42 GMT</date><size>22kb</size></version><title>Resultant-based Elimination in Ore Algebra</title><authors>Raqeeb Rasheed</authors><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider resultant-based methods for elimination of indeterminates of Ore
polynomial systems in Ore algebra. We start with defining the concept of
resultant for bivariate Ore polynomials then compute it by the Dieudonne
determinant of the polynomial coefficients. Additionally, we apply
noncommutative versions of evaluation and interpolation techniques to the
computation process to improve the efficiency of the method. The implementation
of the algorithms will be performed in Maple to evaluate the performance of the
approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14802</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14802</id><submitter>Yafu Li</submitter><version version="v1"><date>Mon, 31 May 2021 09:04:29 GMT</date><size>6316kb</size><source_type>D</source_type></version><title>On Compositional Generalization of Neural Machine Translation</title><authors>Yafu Li, Yongjing Yin, Yulong Chen and Yue Zhang</authors><categories>cs.CL cs.AI cs.LG</categories><comments>To appear at the ACL 2021 main conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Modern neural machine translation (NMT) models have achieved competitive
performance in standard benchmarks such as WMT. However, there still exist
significant issues such as robustness, domain generalization, etc. In this
paper, we study NMT models from the perspective of compositional generalization
by building a benchmark dataset, CoGnition, consisting of 216k clean and
consistent sentence pairs. We quantitatively analyze effects of various factors
using compound translation error rate, then demonstrate that the NMT model
fails badly on compositional generalization, although it performs remarkably
well under traditional metrics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14803</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14803</id><submitter>Manish Shukla</submitter><version version="v1"><date>Mon, 31 May 2021 09:04:32 GMT</date><size>2982kb</size><source_type>D</source_type></version><title>Gradient-based Data Subversion Attack Against Binary Classifiers</title><authors>Rosni K Vasu, Sanjay Seetharaman, Shubham Malaviya, Manish Shukla,
  Sachin Lodha</authors><categories>cs.LG cs.AI cs.CR</categories><comments>26 pages, 3 Figures, 8 tables, adversarial attacks, data poisoning
  attacks, label contamination, transferability of attack, susceptibility</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Machine learning based data-driven technologies have shown impressive
performances in a variety of application domains. Most enterprises use data
from multiple sources to provide quality applications. The reliability of the
external data sources raises concerns for the security of the machine learning
techniques adopted. An attacker can tamper the training or test datasets to
subvert the predictions of models generated by these techniques. Data poisoning
is one such attack wherein the attacker tries to degrade the performance of a
classifier by manipulating the training data.
  In this work, we focus on label contamination attack in which an attacker
poisons the labels of data to compromise the functionality of the system. We
develop Gradient-based Data Subversion strategies to achieve model degradation
under the assumption that the attacker has limited-knowledge of the victim
model. We exploit the gradients of a differentiable convex loss function
(residual errors) with respect to the predicted label as a warm-start and
formulate different strategies to find a set of data instances to contaminate.
Further, we analyze the transferability of attacks and the susceptibility of
binary classifiers. Our experiments show that the proposed approach outperforms
the baselines and is computationally efficient.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14804</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14804</id><submitter>Jingbo Wang</submitter><version version="v1"><date>Mon, 31 May 2021 09:05:50 GMT</date><size>35241kb</size><source_type>D</source_type></version><title>Scene-aware Generative Network for Human Motion Synthesis</title><authors>Jingbo Wang, Sijie Yan, Bo Dai, Dahua LIn</authors><categories>cs.CV</categories><comments>Accepted by CVPR2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We revisit human motion synthesis, a task useful in various real world
applications, in this paper. Whereas a number of methods have been developed
previously for this task, they are often limited in two aspects: focusing on
the poses while leaving the location movement behind, and ignoring the impact
of the environment on the human motion. In this paper, we propose a new
framework, with the interaction between the scene and the human motion taken
into account. Considering the uncertainty of human motion, we formulate this
task as a generative task, whose objective is to generate plausible human
motion conditioned on both the scene and the human initial position. This
framework factorizes the distribution of human motions into a distribution of
movement trajectories conditioned on scenes and that of body pose dynamics
conditioned on both scenes and trajectories. We further derive a GAN based
learning approach, with discriminators to enforce the compatibility between the
human motion and the contextual scene as well as the 3D to 2D projection
constraints. We assess the effectiveness of the proposed method on two
challenging datasets, which cover both synthetic and real world environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14805</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14805</id><submitter>Murugesan Venkatapathi</submitter><version version="v1"><date>Mon, 31 May 2021 09:07:13 GMT</date><size>860kb</size><source_type>D</source_type></version><title>Circulant decomposition of a matrix and the eigenvalues of Toeplitz type
  matrices</title><authors>Hariprasad M. and Murugesan Venkatapathi</authors><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We begin by showing that a n*n matrix can be decomposed into a sum of 'n'
circulant matrices with appropriate relaxations. We use Fast-Fourier-Transform
(FFT) operations to perform a sparse similarity transformation representing
only the dominant circulant components, to evaluate all eigenvalues of dense
Toeplitz, block-Toeplitz and other periodic or quasi-periodic matrices, to a
reasonable approximation in O(n^2) arithmetic operations. This sparse
similarity transformation can be exploited for other evaluations as well.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14809</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14809</id><submitter>Xuancheng Huang</submitter><version version="v1"><date>Mon, 31 May 2021 09:12:38 GMT</date><size>300kb</size><source_type>D</source_type></version><title>Transfer Learning for Sequence Generation: from Single-source to
  Multi-source</title><authors>Xuancheng Huang, Jingfang Xu, Maosong Sun, and Yang Liu</authors><categories>cs.CL cs.AI</categories><comments>ACL2021 main track long paper</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Multi-source sequence generation (MSG) is an important kind of sequence
generation tasks that takes multiple sources, including automatic post-editing,
multi-source translation, multi-document summarization, etc. As MSG tasks
suffer from the data scarcity problem and recent pretrained models have been
proven to be effective for low-resource downstream tasks, transferring
pretrained sequence-to-sequence models to MSG tasks is essential. Although
directly finetuning pretrained models on MSG tasks and concatenating multiple
sources into a single long sequence is regarded as a simple method to transfer
pretrained models to MSG tasks, we conjecture that the direct finetuning method
leads to catastrophic forgetting and solely relying on pretrained
self-attention layers to capture cross-source information is not sufficient.
Therefore, we propose a two-stage finetuning method to alleviate the
pretrain-finetune discrepancy and introduce a novel MSG model with a fine
encoder to learn better representations in MSG tasks. Experiments show that our
approach achieves new state-of-the-art results on the WMT17 APE task and
multi-source translation task using the WMT14 test set. When adapted to
document-level translation, our framework outperforms strong baselines
significantly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14811</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14811</id><submitter>Koya Sakakibara</submitter><version version="v1"><date>Mon, 31 May 2021 09:14:58 GMT</date><size>893kb</size><source_type>D</source_type></version><title>A simple numerical method for Hele-Shaw type problems by the method of
  fundamental solutions</title><authors>Koya Sakakibara, Yusaku Shimoji, and Shigetoshi Yazaki</authors><categories>math.NA cs.NA</categories><comments>17 pages</comments><report-no>RIKEN-iTHEMS-Report-21</report-no><msc-class>76D27, 76E25, 65N80, 65N35, 35J05</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Hele-Shaw flows with time-dependent gaps create fingering patterns, and
magnetic fluids in Hele-Shaw cells create intriguing patterns.We propose a
simple numerical method for Hele-Shaw type problems by the method of
fundamental solutions.The method of fundamental solutions is one of the
mesh-free numerical solvers for potential problems, which provides a highly
accurate approximate solution despite its simplicity.Moreover, combining with
the asymptotic uniform distribution method, the numerical method satisfies the
volume-preserving property.We use Amano's method to arrange the singular points
in the method of fundamental solutions.We show several numerical results to
exemplify the effectiveness of our numerical scheme.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14813</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14813</id><submitter>Chong Li</submitter><version version="v1"><date>Mon, 31 May 2021 09:17:33 GMT</date><size>320kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 15:18:14 GMT</date><size>320kb</size><source_type>D</source_type></version><title>Exploration and Exploitation: Two Ways to Improve Chinese Spelling
  Correction Models</title><authors>Chong Li, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang</authors><categories>cs.CL</categories><comments>Accepted by ACL 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  A sequence-to-sequence learning with neural networks has empirically proven
to be an effective framework for Chinese Spelling Correction (CSC), which takes
a sentence with some spelling errors as input and outputs the corrected one.
However, CSC models may fail to correct spelling errors covered by the
confusion sets, and also will encounter unseen ones. We propose a method, which
continually identifies the weak spots of a model to generate more valuable
training instances, and apply a task-specific pre-training strategy to enhance
the model. The generated adversarial examples are gradually added to the
training set. Experimental results show that such an adversarial training
method combined with the pretraining strategy can improve both the
generalization and robustness of multiple CSC models across three different
datasets, achieving stateof-the-art performance for CSC task.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14815</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14815</id><submitter>Thiemo Wambsganss</submitter><version version="v1"><date>Mon, 31 May 2021 09:18:50 GMT</date><size>6499kb</size><source_type>D</source_type></version><title>Supporting Cognitive and Emotional Empathic Writing of Students</title><authors>Thiemo Wambsganss, Christina Niklaus, Matthias S\&quot;ollner, Siegfried
  Handschuh and Jan Marco Leimeister</authors><categories>cs.CL cs.AI cs.HC cs.LG</categories><comments>to be published in The Joint Conference of the 59th Annual Meeting of
  the Association for Computational Linguistics and the 11th International
  Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present an annotation approach to capturing emotional and cognitive
empathy in student-written peer reviews on business models in German. We
propose an annotation scheme that allows us to model emotional and cognitive
empathy scores based on three types of review components. Also, we conducted an
annotation study with three annotators based on 92 student essays to evaluate
our annotation scheme. The obtained inter-rater agreement of {\alpha}=0.79 for
the components and the multi-{\pi}=0.41 for the empathy scores indicate that
the proposed annotation scheme successfully guides annotators to a substantial
to moderate agreement. Moreover, we trained predictive models to detect the
annotated empathy structures and embedded them in an adaptive writing support
system for students to receive individual empathy feedback independent of an
instructor, time, and location. We evaluated our tool in a peer learning
exercise with 58 students and found promising results for perceived empathy
skill learning, perceived feedback accuracy, and intention to use. Finally, we
present our freely available corpus of 500 empathy-annotated, student-written
peer reviews on business models and our annotation guidelines to encourage
future research on the design and development of empathy support systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14816</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14816</id><submitter>Yasin Kumru</submitter><version version="v1"><date>Mon, 31 May 2021 09:23:47 GMT</date><size>1289kb</size></version><title>Ultrasonic Array Characterization in Multiscattering and Attenuating
  Media Using Pin Targets</title><authors>Yasin Kumru and Hayrettin K\&quot;oymen</authors><categories>eess.SY cs.SY</categories><comments>11 pages, 16 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach to characterize ultrasonic imaging arrays
using pin targets in commercial test phantoms. We used a 128-element phased
array transducer operating at 7.5 MHz with a fractional bandwidth of %70. We
also used a tissue-mimicking phantom in the measurements. This phantom consists
of pin targets with a 50-micrometer diameter. We excited the transducer with
pulsed and coded signals. We used Complementary Golay Sequences to code the
transmitted signal and Binary Phase Shift Keying for modulation. We
characterized the transducer array using the transfer function, line spread
function, range resolution, and beam width in an attenuating and scattering
medium. We showed that the pin targets, which are very thin compared to the
diffraction-limited focus of the transducer array, are suitable for the
transducer characterization under weak reflected signal conditions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14817</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14817</id><submitter>Marc Zeller</submitter><version version="v1"><date>Mon, 31 May 2021 09:28:38 GMT</date><size>1444kb</size><source_type>D</source_type></version><title>SQUADfps: Integrated Model-Based Machine Safety and Product Quality for
  Flexible Production Systems</title><authors>Chee Hung Koo, Stefan Rothbauer, Marian Vorderer, Kai Hoefig, Marc
  Zeller</authors><categories>cs.SE</categories><journal-ref>Papadopoulos Y., Aslansefat K., Katsaros P., Bozzano M. (eds)
  Model-Based Safety and Assessment. IMBSA 2019. Lecture Notes in Computer
  Science, vol 11842. Springer, Cham</journal-ref><doi>10.1007/978-3-030-32872-6_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Growing individualization of products up to lot-size-1 and high volatility of
product mixes lead to new challenges in the manufacturing domain, including the
need for frequent reconfiguration of the system and reacting to changing
orders. Thus, apart from functional aspects, safety aspects of the production
system as well as product quality assurance aspects must be addressed for
flexible and reconfigurable manufacturing systems at runtime. To cope with the
mentioned challenges, we present an integrated model-based approach SQUADfps
(machine Safety and product QUAlity for flexible proDuction systems) to support
the automatic conduct of the risk assessment of flexible production scenarios
in terms of safety as well as the process-FMEA to ensure that the requirements
w.r.t. the quality of the production process and the resulting product are met.
Our approach is based on a meta-model which captures all information needed to
conduct both risk assessment and process-FMEA dynamically during the runtime,
and thus enables flexible manufacturing scenarios with frequent changes of the
production system and orders up to a lot-size of one while guaranteeing safety
and product quality requirements. The automatically generated results will
assist human in making further decisions. To demonstrate the feasibility of our
approach, we apply it to a case study.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14818</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14818</id><submitter>Yacov Manevich</submitter><version version="v1"><date>Mon, 31 May 2021 09:31:24 GMT</date><size>6951kb</size><source_type>D</source_type></version><title>Redacting Transactions fromExecute-Order-Validate Blockchains</title><authors>Yacov Manevich, Artem Barger, Gal Assa</authors><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As user privacy gains popularity and attention, and starts to shape relations
between users and service providers, blockchain based solutions thrive for ways
to relax immutability without sacrificing consistency. This work answers that
need and presents the first design for a redactable execute-order-validate
blockchain, that grants users with the \emph{right to be forgotten}. The design
is easy to adopt, as we exemplify by implementing it on top of Hyperledger
Fabric. It modifies the block structure and extracts user data from the
hash-chain without loosening any correctness or liveness criteria. We evaluate
our design and show that it provides compliance with only a minimal performance
overhead, making it a feasible add-on to any execute-order-validate blockchain
system.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14820</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14820</id><submitter>Pierre Blanchart</submitter><version version="v1"><date>Mon, 31 May 2021 09:32:46 GMT</date><size>147kb</size><source_type>D</source_type></version><title>An exact counterfactual-example-based approach to tree-ensemble models
  interpretability</title><authors>Pierre Blanchart</authors><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Explaining the decisions of machine learning models is becoming a necessity
in many areas where trust in ML models decision is key to their
accreditation/adoption. The ability to explain models decisions also allows to
provide diagnosis in addition to the model decision, which is highly valuable
in scenarios such as fault detection. Unfortunately, high-performance models do
not exhibit the necessary transparency to make their decisions fully
understandable. And the black-boxes approaches, which are used to explain such
model decisions, suffer from a lack of accuracy in tracing back the exact cause
of a model decision regarding a given input. Indeed, they do not have the
ability to explicitly describe the decision regions of the model around that
input, which is necessary to determine what influences the model towards one
decision or the other. We thus asked ourselves the question: is there a
category of high-performance models among the ones currently used for which we
could explicitly and exactly characterise the decision regions in the input
feature space using a geometrical characterisation? Surprisingly we came out
with a positive answer for any model that enters the category of tree ensemble
models, which encompasses a wide range of high-performance models such as
XGBoost, LightGBM, random forests ... We could derive an exact geometrical
characterisation of their decision regions under the form of a collection of
multidimensional intervals. This characterisation makes it straightforward to
compute the optimal counterfactual (CF) example associated with a query point.
We demonstrate several possibilities of the approach, such as computing the CF
example based only on a subset of features. This allows to obtain more
plausible explanations by adding prior knowledge about which variables the user
can control. An adaptation to CF reasoning on regression problems is also
envisaged.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14822</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14822</id><submitter>Hiroshi Noji</submitter><version version="v1"><date>Mon, 31 May 2021 09:34:07 GMT</date><size>5344kb</size><source_type>D</source_type></version><title>Effective Batching for Recurrent Neural Network Grammars</title><authors>Hiroshi Noji, Yohei Oseki</authors><categories>cs.CL</categories><comments>Findings of ACL: ACL-IJCNLP 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a language model that integrates traditional symbolic operations and
flexible neural representations, recurrent neural network grammars (RNNGs) have
attracted great attention from both scientific and engineering perspectives.
However, RNNGs are known to be harder to scale due to the difficulty of batched
training. In this paper, we propose effective batching for RNNGs, where every
operation is computed in parallel with tensors across multiple sentences. Our
PyTorch implementation effectively employs a GPU and achieves x6 speedup
compared to the existing C++ DyNet implementation with model-independent
auto-batching. Moreover, our batched RNNG also accelerates inference and
achieves x20-150 speedup for beam search depending on beam sizes. Finally, we
evaluate syntactic generalization performance of the scaled RNNG against the
LSTM baseline, based on the large training data of 100M tokens from English
Wikipedia and the broad-coverage targeted syntactic evaluation benchmark. Our
RNNG implementation is available at https://github.com/aistairc/rnng-pytorch/.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14824</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14824</id><submitter>Thomas Baumhauer</submitter><version version="v1"><date>Mon, 31 May 2021 09:36:05 GMT</date><size>5845kb</size><source_type>D</source_type></version><title>Bounded logit attention: Learning to explain image classifiers</title><authors>Thomas Baumhauer and Djordje Slijepcevic and Matthias Zeppelzauer</authors><categories>cs.CV cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Explainable artificial intelligence is the attempt to elucidate the workings
of systems too complex to be directly accessible to human cognition through
suitable side-information referred to as &quot;explanations&quot;. We present a trainable
explanation module for convolutional image classifiers we call bounded logit
attention (BLA). The BLA module learns to select a subset of the convolutional
feature map for each input instance, which then serves as an explanation for
the classifier's prediction. BLA overcomes several limitations of the
instancewise feature selection method &quot;learning to explain&quot; (L2X) introduced by
Chen et al. (2018): 1) BLA scales to real-world sized image classification
problems, and 2) BLA offers a canonical way to learn explanations of variable
size. Due to its modularity BLA lends itself to transfer learning setups and
can also be employed as a post-hoc add-on to trained classifiers. Beyond
explainability, BLA may serve as a general purpose method for differentiable
approximation of subset selection. In a user study we find that BLA
explanations are preferred over explanations generated by the popular
(Grad-)CAM method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14826</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14826</id><submitter>WenCheng Li</submitter><version version="v1"><date>Mon, 31 May 2021 09:38:34 GMT</date><size>387kb</size><source_type>D</source_type></version><title>Speaker Identification from Raw Waveform with LineNet</title><authors>Wencheng Li</authors><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker Identification using i-vector has gradually been replaced by speaker
Identification using deep learning. Speaker Identification based on
Convolutional Neural Networks (CNNs) has been widely used in recent years,
which learn low-level speech representations from raw waveforms. On this basis,
a CNN architecture called SincNet proposes a kind of unique convolutional
layer, which has achieved band-pass filters. Compared with standard CNNs,
SincNet learns the low and high cutoff frequencies of each filter.This paper
proposes an improved CNNs architecture called LineNet, which encourages the
first convolutional layer to implement more specific filters than SincNet.
LineNet parameterizes the frequency domain shape and can realize band-pass
filters by learning some deformation points in frequency domain. Compared with
standard CNN, LineNet can learn the characteristics of each filter. Compared
with SincNet, LineNet can learn more characteristic parameters, instead of only
low and high cutoff frequencies. This provides a personalized filter bank for
different tasks. As a result, our experiments show that the LineNet converges
faster than standard CNN and performs better than SincNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14829</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14829</id><submitter>Stephen James</submitter><version version="v1"><date>Mon, 31 May 2021 09:44:16 GMT</date><size>3876kb</size><source_type>D</source_type></version><title>Q-attention: Enabling Efficient Learning for Vision-based Robotic
  Manipulation</title><authors>Stephen James and Andrew J. Davison</authors><categories>cs.RO cs.AI cs.CV cs.LG</categories><comments>Videos and code found at: https://sites.google.com/view/q-attention</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the success of reinforcement learning methods, they have yet to have
their breakthrough moment when applied to a broad range of robotic manipulation
tasks. This is partly due to the fact that reinforcement learning algorithms
are notoriously difficult and time consuming to train, which is exacerbated
when training from images rather than full-state inputs. As humans perform
manipulation tasks, our eyes closely monitor every step of the process with our
gaze focusing sequentially on the objects being manipulated. With this in mind,
we present our Attention-driven Robotic Manipulation (ARM) algorithm, which is
a general manipulation algorithm that can be applied to a range of
sparse-rewarded tasks, given only a small number of demonstrations. ARM splits
the complex task of manipulation into a 3 stage pipeline: (1) a Q-attention
agent extracts interesting pixel locations from RGB and point cloud inputs, (2)
a next-best pose agent that accepts crops from the Q-attention agent and
outputs poses, and (3) a control agent that takes the goal pose and outputs
joint actions. We show that current learning algorithms fail on a range of
RLBench tasks, whilst ARM is successful.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14830</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14830</id><submitter>Zhiguo Ding</submitter><version version="v1"><date>Mon, 31 May 2021 09:44:25 GMT</date><size>129kb</size></version><title>Advantages of NOMA for Multi-User BackCom Networks</title><authors>Zhiguo Ding and H. Vincent Poor</authors><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Ambient backscatter communication (BackCom) is faced with the challenge that
a single BackCom device can occupy multiple orthogonal resource blocks
unintentionally. As a result, in order to avoid co-channel interference, a
conventional approach is to serve multiple BackCom devices in different time
slots, which reduces both spectral efficiency and connectivity. This letter
demonstrates that the use of non-orthogonal multiple access (NOMA) can
efficiently improve the system throughput and support massive connectivity in
ambient BackCom networks. In particular, two transceiver design approaches are
developed in the letter to realize different tradeoffs between system
performance and complexity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14831</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14831</id><submitter>Chennakesava Kadapa</submitter><version version="v1"><date>Mon, 31 May 2021 09:45:02 GMT</date><size>1111kb</size><source_type>D</source_type></version><title>Insights into the performance of loosely-coupled FSI schemes based on
  Robin boundary conditions</title><authors>Chennakesava Kadapa</authors><categories>cs.CE cs.NA math.NA</categories><comments>20 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Robin boundary conditions are a natural consequence of employing Nitsche's
method for imposing the kinematic velocity constraint at the fluid-solid
interface. Loosely-coupled FSI schemes based on Dirichlet-Robin or Robin-Robin
coupling have been demonstrated to improve the stability of such schemes with
respect to added-mass. This paper aims to offer some numerical insights into
the performance characteristics of such loosely-coupled FSI schemes based on
Robin boundary conditions. Using numerical examples, we demonstrate that the
improved stability due to the added damping term is actually at the expense of
important dynamic characteristics of the structural sub-problem.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14835</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14835</id><submitter>Christoph Hertrich</submitter><version version="v1"><date>Mon, 31 May 2021 09:49:14 GMT</date><size>34kb</size></version><title>Towards Lower Bounds on the Depth of ReLU Neural Networks</title><authors>Christoph Hertrich, Amitabh Basu, Marco Di Summa, Martin Skutella</authors><categories>cs.LG cs.DM cs.NE math.CO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We contribute to a better understanding of the class of functions that is
represented by a neural network with ReLU activations and a given architecture.
Using techniques from mixed-integer optimization, polyhedral theory, and
tropical geometry, we provide a mathematical counterbalance to the universal
approximation theorems which suggest that a single hidden layer is sufficient
for learning tasks. In particular, we investigate whether the class of exactly
representable functions strictly increases by adding more layers (with no
restrictions on size). This problem has potential impact on algorithmic and
statistical aspects because of the insight it provides into the class of
functions represented by neural hypothesis classes. However, to the best of our
knowledge, this question has not been investigated in the neural network
literature. We also present upper bounds on the sizes of neural networks
required to represent functions in these neural hypothesis classes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14838</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14838</id><submitter>Francesco Poggi</submitter><version version="v1"><date>Mon, 31 May 2021 09:51:39 GMT</date><size>495kb</size><source_type>D</source_type></version><title>Does the Venue of Scientific Conferences Leverage their Impact? A Large
  Scale study on Computer Science Conferences</title><authors>Luca Bedogni and Giacomo Cabri and Riccardo Martoglia and Francesco
  Poggi</authors><categories>cs.DL cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Background: Conferences bring scientists together and provide one of the most
timely means for disseminating new ideas and cutting-edge works.The importance
of conferences in scientific areas is testified by quantitative indicators. In
Computer Science, for instance, almost two out of three papers published on
Scopus are conference papers. Objective/Purpose: The main goal of this paper is
to investigate a novel research question: is there any correlation between the
impact of a scientific conference and the venue where it took place? Approach:
In order to measure the impact of conferences we conducted a large scale
analysis on the bibliographic data extracted from 3,838 Computer Science
conference series and over 2.5 million papers spanning more than 30 years of
research. To quantify the &quot;touristicity&quot; of a venue we exploited some
indicators such as the size of the Wikipedia page for the city hosting the
venue and other indexes from reports of the World Economic Forum.
Results/Findings: We found out that the two aspects are related, and the
correlation with conference impact is stronger when considering country-wide
touristic indicators, such as the Travel&amp;Tourism Competitiveness Index.
More-over the almost linear correlation with the Tourist Service Infrastructure
index attests the specific importance of tourist/accommodation facilities in a
given country. Conclusions: This is the first attempt to focus on the
relationship of venue characteristics to conference papers. The results open up
new possibilities, such as allowing conference organizers and authors to
estimate in advance the impact of conferences, thus supporting them in their
decisions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14839</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14839</id><submitter>David Peer</submitter><version version="v1"><date>Mon, 31 May 2021 09:52:41 GMT</date><size>576kb</size><source_type>D</source_type></version><title>Greedy Layer Pruning: Decreasing Inference Time of Transformer Models</title><authors>David Peer, Sebastian Stabinger, Stefan Engl, Antonio
  Rodriguez-Sanchez</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fine-tuning transformer models after unsupervised pre-training reaches a very
high performance on many different NLP tasks. Unfortunately, transformers
suffer from long inference times which greatly increases costs in production
and is a limiting factor for the deployment into embedded devices. One possible
solution is to use knowledge distillation, which solves this problem by
transferring information from large teacher models to smaller student models,
but as it needs an additional expensive pre-training phase, this solution is
computationally expensive and can be financially prohibitive for smaller
academic research groups. Another solution is to use layer-wise pruning
methods, which reach high compression rates for transformer models and avoids
the computational load of the pre-training distillation stage. The price to pay
is that the performance of layer-wise pruning algorithms is not on par with
state-of-the-art knowledge distillation methods. In this paper, greedy layer
pruning (GLP) is introduced to (1) outperform current state-of-the-art for
layer-wise pruning (2) close the performance gap when compared to knowledge
distillation, while (3) using only a modest budget. More precisely, with the
methodology presented it is possible to prune and evaluate competitive models
on the whole GLUE benchmark with a budget of just $\$300$. Our source code is
available on https://github.com/deepopinion/greedy-layer-pruning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14840</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14840</id><submitter>Tesla Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 09:53:33 GMT</date><size>10kb</size></version><title>Elegant elaboration with function invocation</title><authors>Tesla Zhang</authors><categories>cs.PL</categories><comments>6 pages, 3 figures</comments><acm-class>D.3.3</acm-class><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present an elegant design of the core language in a dependently-typed
lambda calculus with $\delta$-reduction and an elaboration algorithm.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14844</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14844</id><submitter>Christian Rathgeb</submitter><version version="v1"><date>Mon, 31 May 2021 09:58:51 GMT</date><size>1055kb</size><source_type>D</source_type></version><title>Demographic Fairness in Biometric Systems: What do the Experts say?</title><authors>Christian Rathgeb and Pawel Drozdowski and Naser Damer and Dinusha C.
  Frings and Christoph Busch</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic decision systems have frequently been labelled as &quot;biased&quot;,
&quot;racist&quot;, &quot;sexist&quot;, or &quot;unfair&quot; by numerous media outlets, organisations, and
researchers. There is an ongoing debate about whether such assessments are
justified and whether citizens and policymakers should be concerned. These and
other related matters have recently become a hot topic in the context of
biometric technologies, which are ubiquitous in personal, commercial, and
governmental applications. Biometrics represent an essential component of many
surveillance, access control, and operational identity management systems, thus
directly or indirectly affecting billions of people all around the world.
  Recently, the European Association for Biometrics organised an event series
with &quot;demographic fairness in biometric systems&quot; as an overarching theme. The
events featured presentations by international experts from academic, industry,
and governmental organisations and facilitated interactions and discussions
between the experts and the audience. Further consultation of experts was
undertaken by means of a questionnaire. This work summarises opinions of
experts and findings of said events on the topic of demographic fairness in
biometric systems including several important aspects such as the developments
of evaluation metrics and standards as well as related issues, e.g. the need
for transparency and explainability in biometric systems or legal and ethical
issues.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14845</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14845</id><submitter>Muhammad Bilal</submitter><version version="v1"><date>Mon, 31 May 2021 09:59:43 GMT</date><size>182kb</size><source_type>D</source_type></version><title>With Great Freedom Comes Great Opportunity: Rethinking Resource
  Allocation for Serverless Functions</title><authors>Muhammad Bilal and Marco Canini and Rodrigo Fonseca and Rodrigo
  Rodrigues</authors><categories>cs.DC cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current serverless offerings give users a limited degree of flexibility for
configuring the resources allocated to their function invocations by either
coupling memory and CPU resources together or providing no knobs at all. These
configuration choices simplify resource allocation decisions on behalf of
users, but at the same time, create deployments that are resource inefficient.
  In this paper, we take a principled approach to the problem of resource
allocation for serverless functions, allowing this choice to be made in an
automatic way that leads to the best combination of performance and cost. In
particular, we systematically explore the opportunities that come with
decoupling memory and CPU resource allocations and also enabling the use of
different VM types. We find a rich trade-off space between performance and
cost. The provider can use this in a number of ways: from exposing all these
parameters to the user, to eliciting preferences for performance and cost from
users, or by simply offering the same performance with lower cost. This
flexibility can also enable the provider to optimize its resource utilization
and enable a cost-effective service with predictable performance.
  Our results show that, by decoupling memory and CPU allocation, there is
potential to have up to 40% lower execution cost than the preset coupled
configurations that are the norm in current serverless offerings. Similarly,
making the correct choice of VM instance type can provide up to 50% better
execution time. Furthermore, we demonstrate that providers can utilize
different instance types for the same functions to maximize resource
utilization while providing performance within 10-20% of the best resource
configuration for each respective function.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14848</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14848</id><submitter>Huy Trinh Quoc</submitter><version version="v1"><date>Mon, 31 May 2021 10:02:52 GMT</date><size>259kb</size></version><title>Refined Deep Neural Network and U-Net for Polyps Segmentation</title><authors>Quoc-Huy Trinh, Minh-Van Nguyen, Thiet-Gia Huynh, Minh-Triet Tran</authors><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Medico: Multimedia Task 2020 focuses on developing an efficient and
accurate computer-aided diagnosis system for automatic segmentation [3]. We
participate in task 1, Polyps segmentation task, which is to develop algorithms
for segmenting polyps on a comprehensive dataset. In this task, we propose
methods combining Residual module, Inception module, Adaptive Convolutional
neural network with U-Net model, and PraNet for semantic segmentation of
various types of polyps in endoscopic images. We select 5 runs with different
architecture and parameters in our methods. Our methods show potential results
in accuracy and efficiency through multiple experiments, and our team is in the
Top 3 best results with a Jaccard index of 0.765.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14849</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14849</id><submitter>Albert Zeyer</submitter><version version="v1"><date>Mon, 31 May 2021 10:03:14 GMT</date><size>591kb</size><source_type>D</source_type></version><title>Why does CTC result in peaky behavior?</title><authors>Albert Zeyer and Ralf Schl\&quot;uter and Hermann Ney</authors><categories>cs.LG cs.AI cs.CL cs.NE cs.SD eess.AS math.ST stat.TH</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The peaky behavior of CTC models is well known experimentally. However, an
understanding about why peaky behavior occurs is missing, and whether this is a
good property. We provide a formal analysis of the peaky behavior and gradient
descent convergence properties of the CTC loss and related training criteria.
Our analysis provides a deep understanding why peaky behavior occurs and when
it is suboptimal. On a simple example which should be trivial to learn for any
model, we prove that a feed-forward neural network trained with CTC from
uniform initialization converges towards peaky behavior with a 100% error rate.
Our analysis further explains why CTC only works well together with the blank
label. We further demonstrate that peaky behavior does not occur on other
related losses including a label prior model, and that this improves
convergence.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14850</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14850</id><submitter>Lin Zheng</submitter><version version="v1"><date>Mon, 31 May 2021 10:06:42 GMT</date><size>6215kb</size><source_type>D</source_type></version><title>Cascaded Head-colliding Attention</title><authors>Lin Zheng, Zhiyong Wu, Lingpeng Kong</authors><categories>cs.CL cs.LG</categories><comments>ACL 2021 Camera-ready version</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transformers have advanced the field of natural language processing (NLP) on
a variety of important tasks. At the cornerstone of the Transformer
architecture is the multi-head attention (MHA) mechanism which models pairwise
interactions between the elements of the sequence. Despite its massive success,
the current framework ignores interactions among different heads, leading to
the problem that many of the heads are redundant in practice, which greatly
wastes the capacity of the model. To improve parameter efficiency, we
re-formulate the MHA as a latent variable model from a probabilistic
perspective. We present cascaded head-colliding attention (CODA) which
explicitly models the interactions between attention heads through a
hierarchical variational distribution. We conduct extensive experiments and
demonstrate that CODA outperforms the transformer baseline, by $0.6$ perplexity
on \texttt{Wikitext-103} in language modeling, and by $0.6$ BLEU on
\texttt{WMT14 EN-DE} in machine translation, due to its improvements on the
parameter efficiency.\footnote{Our implementation is publicly available at
\url{https://github.com/LZhengisme/CODA}.}
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14857</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14857</id><submitter>Harim Jung</submitter><version version="v1"><date>Mon, 31 May 2021 10:19:20 GMT</date><size>1050kb</size><source_type>D</source_type></version><title>Learning Free-Form Deformation for 3D Face Reconstruction from
  In-The-Wild Images</title><authors>Harim Jung, Myeong-Seok Oh, Seong-Whan Lee</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The 3D Morphable Model (3DMM), which is a Principal Component Analysis (PCA)
based statistical model that represents a 3D face using linear basis functions,
has shown promising results for reconstructing 3D faces from single-view
in-the-wild images. However, 3DMM has restricted representation power due to
the limited number of 3D scans and the global linear basis. To address the
limitations of 3DMM, we propose a straightforward learning-based method that
reconstructs a 3D face mesh through Free-Form Deformation (FFD) for the first
time. FFD is a geometric modeling method that embeds a reference mesh within a
parallelepiped grid and deforms the mesh by moving the sparse control points of
the grid. As FFD is based on mathematically defined basis functions, it has no
limitation in representation power. Thus, we can recover accurate 3D face
meshes by estimating appropriate deviation of control points as deformation
parameters. Although both 3DMM and FFD are parametric models, it is difficult
to predict the effect of the 3DMM parameters on the face shape, while the
deformation parameters of FFD are interpretable in terms of their effect on the
final shape of the mesh. This practical advantage of FFD allows the resulting
mesh and control points to serve as a good starting point for 3D face modeling,
in that ordinary users can fine-tune the mesh by using widely available 3D
software tools. Experiments on multiple datasets demonstrate how our method
successfully estimates the 3D face geometry and facial expressions from 2D face
images, achieving comparable performance to the state-of-the-art methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14859</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14859</id><submitter>Samarth Sinha</submitter><version version="v1"><date>Mon, 31 May 2021 10:26:32 GMT</date><size>13105kb</size><source_type>D</source_type></version><title>Consistency Regularization for Variational Auto-Encoders</title><authors>Samarth Sinha, Adji B. Dieng</authors><categories>cs.LG cs.CV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Variational auto-encoders (VAEs) are a powerful approach to unsupervised
learning. They enable scalable approximate posterior inference in
latent-variable models using variational inference (VI). A VAE posits a
variational family parameterized by a deep neural network called an encoder
that takes data as input. This encoder is shared across all the observations,
which amortizes the cost of inference. However the encoder of a VAE has the
undesirable property that it maps a given observation and a
semantics-preserving transformation of it to different latent representations.
This &quot;inconsistency&quot; of the encoder lowers the quality of the learned
representations, especially for downstream tasks, and also negatively affects
generalization. In this paper, we propose a regularization method to enforce
consistency in VAEs. The idea is to minimize the Kullback-Leibler (KL)
divergence between the variational distribution when conditioning on the
observation and the variational distribution when conditioning on a random
semantic-preserving transformation of this observation. This regularization is
applicable to any VAE. In our experiments we apply it to four different VAE
variants on several benchmark datasets and found it always improves the quality
of the learned representations but also leads to better generalization. In
particular, when applied to the Nouveau Variational Auto-Encoder (NVAE), our
regularization method yields state-of-the-art performance on MNIST and
CIFAR-10. We also applied our method to 3D data and found it learns
representations of superior quality as measured by accuracy on a downstream
classification task.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14860</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14860</id><submitter>Martin Vu</submitter><version version="v1"><date>Mon, 31 May 2021 10:27:59 GMT</date><size>424kb</size></version><title>Definability Results for Top-Down Tree Transducers</title><authors>Sebastian Maneth, Helmut Seidl, Martin Vu</authors><categories>cs.FL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We prove that for a given deterministic top-down transducer with look-ahead
it is decidable whether or not its translation is definable (1)~by a linear
top-down tree transducer or (2)~by a tree homomorphism. We present algorithms
that construct equivalent such transducers if they exist.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14866</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14866</id><submitter>Alexander Camuto</submitter><version version="v1"><date>Mon, 31 May 2021 10:39:25 GMT</date><size>433kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 08:59:58 GMT</date><size>454kb</size><source_type>D</source_type></version><title>Variational Autoencoders: A Harmonic Perspective</title><authors>Alexander Camuto, Matthew Willetts</authors><categories>stat.ML cs.LG eess.SP</categories><comments>18 pages including Appendix, 7 Figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work we study Variational Autoencoders (VAEs) from the perspective of
harmonic analysis. By viewing a VAE's latent space as a Gaussian Space, a
variety of measure space, we derive a series of results that show that the
encoder variance of a VAE controls the frequency content of the functions
parameterised by the VAE encoder and decoder neural networks. In particular we
demonstrate that larger encoder variances reduce the high frequency content of
these functions. Our analysis allows us to show that increasing this variance
effectively induces a soft Lipschitz constraint on the decoder network of a
VAE, which is a core contributor to the adversarial robustness of VAEs. We
further demonstrate that adding Gaussian noise to the input of a VAE allows us
to more finely control the frequency content and the Lipschitz constant of the
VAE encoder networks. To support our theoretical analysis we run experiments
with VAEs with small fully-connected neural networks and with larger
convolutional networks, demonstrating empirically that our theory holds for a
variety of neural network architectures.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14867</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14867</id><submitter>Claudio Hartmann</submitter><version version="v1"><date>Mon, 31 May 2021 10:44:05 GMT</date><size>579kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 08:46:20 GMT</date><size>581kb</size><source_type>D</source_type></version><title>Accurate and Efficient Time Series Matching by Season- and Trend-aware
  Symbolic Approximation -- Extended Version Including Additional Evaluation
  and Proofs</title><authors>Lars Kegel (1), Claudio Hartmann (1), Maik Thiele (1), Wolfgang Lehner
  (1) ((1) TU Dresden)</authors><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Processing and analyzing time series data\-sets have become a central issue
in many domains requiring data management systems to support time series as a
native data type. A crucial prerequisite of these systems is time series
matching, which still is a challenging problem. A time series is a
high-dimensional data type, its representation is storage-, and its comparison
is time-consuming. Among the representation techniques that tackle these
challenges, the symbolic aggregate approximation (SAX) is the current state of
the art. This technique reduces a time series to a low-dimensional space by
segmenting it and discretizing each segment into a small symbolic alphabet.
However, SAX ignores the deterministic behavior of time series such as cyclical
repeating patterns or trend component affecting all segments and leading to a
distortion of the symbolic distribution. In this paper, we present a season-
and a trend-aware symbolic approximation. We show that this improves the
symbolic distribution and increase the representation accuracy without
increasing its memory footprint. Most importantly, this enables a more
efficient time series matching by providing a match up to three orders of
magnitude faster than SAX.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14869</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14869</id><submitter>Rikke Bjerg Jensen</submitter><version version="v1"><date>Mon, 31 May 2021 10:46:56 GMT</date><size>48kb</size><source_type>D</source_type></version><title>Collective Information Security in Large-Scale Urban Protests: the Case
  of Hong Kong</title><authors>Martin R. Albrecht, Jorge Blasco, Rikke Bjerg Jensen and Lenka
  Marekov\'a</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Anti-Extradition Law Amendment Bill protests in Hong Kong present a rich
context for exploring information security practices among protesters due to
their large-scale urban setting and highly digitalised nature. We conducted
in-depth, semi-structured interviews with 11 participants of these protests.
Research findings reveal how protesters favoured Telegram and relied on its
security for internal communication and organisation of on-the-ground
collective action; were organised in small private groups and large public
groups to enable collective action; adopted tactics and technologies that
enable pseudonymity; and developed a variety of strategies to detect
compromises and to achieve forms of forward secrecy and post-compromise
security when group members were (presumed) arrested. We further show how group
administrators had assumed the roles of leaders in these 'leaderless' protests
and were critical to collective protest efforts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14874</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14874</id><submitter>Zhou Yang</submitter><version version="v1"><date>Mon, 31 May 2021 10:55:29 GMT</date><size>876kb</size><source_type>D</source_type></version><title>BiasRV: Uncovering Biased Sentiment Predictions at Runtime</title><authors>Zhou Yang, Muhammad Hilmi Asyrofi and David Lo</authors><categories>cs.SE</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sentiment analysis (SA) systems, though widely applied in many domains, have
been demonstrated to produce biased results. Some research works have been done
in automatically generating test cases to reveal unfairness in SA systems, but
the community still lacks tools that can monitor and uncover biased predictions
at runtime. This paper fills this gap by proposing BiasRV, the first tool to
raise an alarm when a deployed SA system makes a biased prediction on a given
input text. To implement this feature, BiasRV dynamically extracts a template
from an input text and from the template generates gender-discriminatory
mutants (semantically-equivalent texts that only differ in gender information).
Based on popular metrics used to evaluate the overall fairness of an SA system,
we define distributional fairness property for an individual prediction of an
SA system. This property specifies a requirement that for one piece of text,
mutants from different gender classes should be treated similarly as a whole.
Verifying the distributional fairness property causes much overhead to the
running system. To run more efficiently, BiasRV adopts a two-step heuristic:
(1) sampling several mutants from each gender and checking if the system
predicts them as of the same sentiment, (2) checking distributional fairness
only when sampled mutants have conflicting results. Experiments show that
compared to directly checking the distributional fairness property for each
input text, our two-step heuristic can decrease overhead used for analyzing
mutants by 73.81% while only resulting in 6.7% of biased predictions being
missed. Besides, BiasRV can be used conveniently without knowing the
implementation of SA systems. Future researchers can easily extend BiasRV to
detect more types of bias, e.g. race and occupation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14875</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14875</id><submitter>Jakaria Rabbi</submitter><version version="v1"><date>Mon, 31 May 2021 10:58:58 GMT</date><size>2941kb</size><source_type>D</source_type></version><title>Bangla Natural Language Processing: A Comprehensive Review of Classical,
  Machine Learning, and Deep Learning Based Methods</title><authors>Ovishake Sen, Mohtasim Fuad, MD. Nazrul Islam, Jakaria Rabbi, MD.
  Kamrul Hasan, Awal Ahmed Fime, Md. Tahmid Hasan Fuad, Delowar Sikder, and MD.
  Akil Raihan Iftee</authors><categories>cs.CL cs.AI cs.LG</categories><comments>This preprint will be submitted to IEEE Access Journal and it
  contains total of 41 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bangla language is the seventh most spoken language, with 265 million
native and non-native speakers worldwide. However, English is the predominant
language for online resources and technical knowledge, journals, and
documentation. Consequently, many Bangla-speaking people, who have limited
command of English, face hurdles to utilize English resources. To bridge the
gap between limited support and increasing demand, researchers conducted many
experiments and developed valuable tools and techniques to create and process
Bangla language materials. Many efforts are also ongoing to make it easy to use
the Bangla language in the online and technical domains. There are some review
papers to understand the past, previous, and future Bangla Natural Language
Processing (BNLP) trends. The studies are mainly concentrated on the specific
domains of BNLP, such as sentiment analysis, speech recognition, optical
character recognition, and text summarization. There is an apparent scarcity of
resources that contain a comprehensive study of the recent BNLP tools and
methods. Therefore, in this paper, we present a thorough review of 71 BNLP
research papers and categorize them into 11 categories, namely Information
Extraction, Machine Translation, Named Entity Recognition, Parsing, Parts of
Speech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake
Detection, Text Summarization, Word Sense Disambiguation, and Speech Processing
and Recognition. We study articles published between 1999 to 2021, and 50\% of
the papers were published after 2015. We discuss Classical, Machine Learning
and Deep Learning approaches with different datasets while addressing the
limitations and current and future trends of the BNLP.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14876</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14876</id><submitter>Nestor Cabello</submitter><version version="v1"><date>Mon, 31 May 2021 10:59:11 GMT</date><size>16270kb</size><source_type>D</source_type></version><title>Fast, Accurate and Interpretable Time Series Classification Through
  Randomization</title><authors>Nestor Cabello, Elham Naghizade, Jianzhong Qi, Lars Kulik</authors><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time series classification (TSC) aims to predict the class label of a given
time series, which is critical to a rich set of application areas such as
economics and medicine. State-of-the-art TSC methods have mostly focused on
classification accuracy and efficiency, without considering the
interpretability of their classifications, which is an important property
required by modern applications such as appliance modeling and legislation such
as the European General Data Protection Regulation. To address this gap, we
propose a novel TSC method - the Randomized-Supervised Time Series Forest
(r-STSF). r-STSF is highly efficient, achieves state-of-the-art classification
accuracy and enables interpretability. r-STSF takes an efficient interval-based
approach to classify time series according to aggregate values of
discriminatory sub-series (intervals). To achieve state-of-the-art accuracy,
r-STSF builds an ensemble of randomized trees using the discriminatory
sub-series. It uses four time series representations, nine aggregation
functions and a supervised binary-inspired search combined with a feature
ranking metric to identify highly discriminatory sub-series. The discriminatory
sub-series enable interpretable classifications. Experiments on extensive
datasets show that r-STSF achieves state-of-the-art accuracy while being orders
of magnitude faster than most existing TSC methods. It is the only classifier
from the state-of-the-art group that enables interpretability. Our findings
also highlight that r-STSF is the best TSC method when classifying complex time
series datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14877</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14877</id><submitter>Thanh Vinh Vo</submitter><version version="v1"><date>Mon, 31 May 2021 11:02:37 GMT</date><size>2560kb</size><source_type>D</source_type></version><title>Adaptive Multi-Source Causal Inference</title><authors>Thanh Vinh Vo, Pengfei Wei, Trong Nghia Hoang, Tze-Yun Leong</authors><categories>cs.LG cs.AI stat.ME</categories><comments>Preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data scarcity is a tremendous challenge in causal effect estimation. In this
paper, we propose to exploit additional data sources to facilitate estimating
causal effects in the target population. Specifically, we leverage additional
source datasets which share similar causal mechanisms with the target
observations to help infer causal effects of the target population. We propose
three levels of knowledge transfer, through modelling the outcomes, treatments,
and confounders. To achieve consistent positive transfer, we introduce
learnable parametric transfer factors to adaptively control the transfer
strength, and thus achieving a fair and balanced knowledge transfer between the
sources and the target. The proposed method can infer causal effects in the
target population without prior knowledge of data discrepancy between the
additional data sources and the target. Experiments on both synthetic and
real-world datasets show the effectiveness of the proposed method as compared
with recent baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14878</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14878</id><submitter>Mingjun Zhao</submitter><version version="v1"><date>Mon, 31 May 2021 11:04:13 GMT</date><size>42kb</size><source_type>D</source_type></version><title>Verdi: Quality Estimation and Error Detection for Bilingual</title><authors>Mingjun Zhao, Haijiang Wu, Di Niu, Zixuan Wang, Xiaoli Wang</authors><categories>cs.CL cs.AI</categories><comments>Accepted by The Web Conference 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Translation Quality Estimation is critical to reducing post-editing efforts
in machine translation and to cross-lingual corpus cleaning. As a research
problem, quality estimation (QE) aims to directly estimate the quality of
translation in a given pair of source and target sentences, and highlight the
words that need corrections, without referencing to golden translations. In
this paper, we propose Verdi, a novel framework for word-level and
sentence-level post-editing effort estimation for bilingual corpora. Verdi
adopts two word predictors to enable diverse features to be extracted from a
pair of sentences for subsequent quality estimation, including a
transformer-based neural machine translation (NMT) model and a pre-trained
cross-lingual language model (XLM). We exploit the symmetric nature of
bilingual corpora and apply model-level dual learning in the NMT predictor,
which handles a primal task and a dual task simultaneously with weight sharing,
leading to stronger context prediction ability than single-direction NMT
models. By taking advantage of the dual learning scheme, we further design a
novel feature to directly encode the translated target information without
relying on the source context. Extensive experiments conducted on WMT20 QE
tasks demonstrate that our method beats the winner of the competition and
outperforms other baseline methods by a great margin. We further use the
sentence-level scores provided by Verdi to clean a parallel corpus and observe
benefits on both model performance and training efficiency.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14879</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14879</id><submitter>Boyuan Zheng</submitter><version version="v1"><date>Mon, 31 May 2021 11:04:17 GMT</date><size>386kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 10:45:27 GMT</date><size>386kb</size><source_type>D</source_type></version><title>SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning</title><authors>Boyuan Zheng, Xiaoyu Yang, Yu-Ping Ruan, Zhenhua Ling, Quan Liu, Si
  Wei, Xiaodan Zhu</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces the SemEval-2021 shared task 4: Reading Comprehension
of Abstract Meaning (ReCAM). This shared task is designed to help evaluate the
ability of machines in representing and understanding abstract concepts. Given
a passage and the corresponding question, a participating system is expected to
choose the correct answer from five candidates of abstract concepts in a
cloze-style machine reading comprehension setup. Based on two typical
definitions of abstractness, i.e., the imperceptibility and nonspecificity, our
task provides three subtasks to evaluate the participating models.
Specifically, Subtask 1 aims to evaluate how well a system can model concepts
that cannot be directly perceived in the physical world. Subtask 2 focuses on
models' ability in comprehending nonspecific concepts located high in a
hypernym hierarchy given the context of a passage. Subtask 3 aims to provide
some insights into models' generalizability over the two types of abstractness.
During the SemEval-2021 official evaluation period, we received 23 submissions
to Subtask 1 and 28 to Subtask 2. The participating teams additionally made 29
submissions to Subtask 3. The leaderboard and competition website can be found
at https://competitions.codalab.org/competitions/26153. The data and baseline
code are available at
https://github.com/boyuanzheng010/SemEval2021-Reading-Comprehension-of-Abstract-Meaning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14880</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14880</id><submitter>Gaochen Wu</submitter><version version="v1"><date>Mon, 31 May 2021 11:05:30 GMT</date><size>457kb</size></version><title>A Multilingual Modeling Method for Span-Extraction Reading Comprehension</title><authors>Gaochen Wu, Bin Xu, Dejie Chang, Bangchang Liu</authors><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Span-extraction reading comprehension models have made tremendous advances
enabled by the availability of large-scale, high-quality training datasets.
Despite such rapid progress and widespread application, extractive reading
comprehension datasets in languages other than English remain scarce, and
creating such a sufficient amount of training data for each language is costly
and even impossible. An alternative to creating large-scale high-quality
monolingual span-extraction training datasets is to develop multilingual
modeling approaches and systems which can transfer to the target language
without requiring training data in that language. In this paper, in order to
solve the scarce availability of extractive reading comprehension training data
in the target language, we propose a multilingual extractive reading
comprehension approach called XLRC by simultaneously modeling the existing
extractive reading comprehension training data in a multilingual environment
using self-adaptive attention and multilingual attention. Specifically, we
firstly construct multilingual parallel corpora by translating the existing
extractive reading comprehension datasets (i.e., CMRC 2018) from the target
language (i.e., Chinese) into different language families (i.e., English).
Secondly, to enhance the final target representation, we adopt self-adaptive
attention (SAA) to combine self-attention and inter-attention to extract the
semantic relations from each pair of the target and source languages.
Furthermore, we propose multilingual attention (MLA) to learn the rich
knowledge from various language families. Experimental results show that our
model outperforms the state-of-the-art baseline (i.e., RoBERTa_Large) on the
CMRC 2018 task, which demonstrate the effectiveness of our proposed
multi-lingual modeling approach and show the potentials in multilingual NLP
tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14881</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14881</id><submitter>Zhou Yang</submitter><version version="v1"><date>Mon, 31 May 2021 11:05:56 GMT</date><size>514kb</size><source_type>D</source_type></version><title>CrossASR++: A Modular Differential Testing Framework for Automatic
  Speech Recognition</title><authors>Muhammad Hilmi Asyrofi, Zhou Yang and David Lo</authors><categories>cs.SE</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developers need to perform adequate testing to ensure the quality of
Automatic Speech Recognition (ASR) systems. However, manually collecting
required test cases is tedious and time-consuming. Our recent work proposes
CrossASR, a differential testing method for ASR systems. This method first
utilizes Text-to-Speech (TTS) to generate audios from texts automatically and
then feed these audios into different ASR systems for cross-referencing to
uncover failed test cases. It also leverages a failure estimator to find
failing test cases more efficiently. Such a method is inherently
self-improvable: the performance can increase by leveraging more advanced TTS
and ASR systems. So in this accompanying tool demo paper, we devote more
engineering and propose CrossASR++, an easy-to-use ASR testing tool that can be
conveniently extended to incorporate different TTS and ASR systems, and failure
estimators. We also make CrossASR++ chunk texts from a given corpus dynamically
and enable the estimator to work in a more effective and flexible way. We
demonstrate that the new features can help CrossASR++ discover more failed test
cases. Using the same TTS and ASR systems, CrossASR++ can uncover 26.2% more
failed test cases for 4 ASRs than the original tool. Moreover, by simply adding
one more ASR for cross-referencing, we can increase the number of failed test
cases uncovered for each of the 4 ASR systems by 25.07%, 39.63%, 20.9\% and
8.17% respectively. We also extend CrossASR++ with 5 additional failure
estimators. Compared to worst estimator, the best one can discover 10.41% more
failed test cases within the same amount of time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14882</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14882</id><submitter>Carla Groenland</submitter><version version="v1"><date>Mon, 31 May 2021 11:08:12 GMT</date><size>322kb</size><source_type>D</source_type></version><title>Parameterized Problems Complete for Nondeterministic FPT time and
  Logarithmic Space</title><authors>Hans L. Bodlaender and Carla Groenland and Jesper Nederlof and
  C\'eline M. F. Swennenhuis</authors><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let XNLP be the class of parameterized problems such that an instance of size
$n$ with parameter $k$ can be solved nondeterministically in time
$f(k)n^{O(1)}$ and space $f(k)\log(n)$ (for some computable function $f$). We
give a wide variety of XNLP-complete problems, such as {\sc List Coloring} and
{\sc Precoloring Extension} with pathwidth as parameter, {\sc Scheduling of
Jobs with Precedence Constraints}, with both number of machines and partial
order width as parameter, {\sc Bandwidth} and variants of {\sc Weighted
CNF-Satisfiability} and reconfiguration problems. In particular, this implies
that all these problems are $W[t]$-hard for all $t$. This also answers a long
standing question on the parameterized complexity of the {\sc Bandwidth}
problem.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14884</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14884</id><submitter>Nicolas Boull\'e</submitter><version version="v1"><date>Mon, 31 May 2021 11:12:38 GMT</date><size>2840kb</size><source_type>D</source_type></version><title>Control of bifurcation structures using shape optimization</title><authors>Nicolas Boull\'e, Patrick E. Farrell, Alberto Paganini</authors><categories>math.NA cs.NA math.OC</categories><comments>16 pages, 10 figures</comments><msc-class>65P30, 65P40, 37M20, 65K10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems in engineering can be understood as controlling the bifurcation
structure of a given device. For example, one may wish to delay the onset of
instability, or bring forward a bifurcation to enable rapid switching between
states. We propose a numerical technique for controlling the bifurcation
diagram of a nonlinear partial differential equation by varying the shape of
the domain. Specifically, we are able to delay or advance a given bifurcation
point to a given parameter value, often to within machine precision. The
algorithm consists of solving a shape optimization problem constrained by an
augmented system of equations, the Moore--Spence system, that characterize the
location of the bifurcation points. Numerical experiments on the Allen--Cahn,
Navier--Stokes, and hyperelasticity equations demonstrate the effectiveness of
this technique in a wide range of settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14887</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14887</id><submitter>Yasir Mahmood</submitter><version version="v1"><date>Mon, 31 May 2021 11:21:06 GMT</date><size>191kb</size><source_type>D</source_type></version><title>Parameterised Complexity of Propositional Logic in Team Semantics</title><authors>Yasir Mahmood and Jonni Virtema</authors><categories>cs.LO cs.CC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work we analyse the parameterised complexity of propositional
inclusion (PINC) and independence logic (PIND). The problems of interest are
model checking (MC) and satisfiability (SAT). The complexity of these problems
is well understood in the classical (non-parameterised) setting. Mahmood and
Meier (FoIKS 2020) recently studied the parameterised complexity of
propositional dependence logic (PDL). As a continuation of their work, we
classify inclusion and independence logic and thereby come closer to completing
the picture with respect to the parametrised complexity for the three most
studied logics in the propositional team semantics setting. We present results
for each problem with respect to 8 different parameterisations. It turns out
that for a team-based logic L such that L-atoms can be evaluated in polynomial
time, then MC parameterised by teamsize is FPT. As a corollary, we get an FPT
membership under the following parameterisations: formula-size, formula-depth,
treewidth, and number of variables. The parameter teamsize shows interesting
behavior for SAT. For PINC, the parameter teamsize is not meaningful, whereas
for PDL and PIND the satisfiability is paraNP-complete. Finally, we prove that
when parameterised by arity, both MC and SAT are paraNP-complete for each of
the considered logics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14888</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14888</id><submitter>Ana-Maria Bucur</submitter><version version="v1"><date>Mon, 31 May 2021 11:25:07 GMT</date><size>598kb</size><source_type>D</source_type></version><title>An Exploratory Analysis of the Relation Between Offensive Language and
  Mental Health</title><authors>Ana-Maria Bucur, Marcos Zampieri, and Liviu P. Dinu</authors><categories>cs.CL</categories><comments>Accepted to Findings of the Association for Computational
  Linguistics: ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we analyze the interplay between the use of offensive language
and mental health. We acquired publicly available datasets created for
offensive language identification and depression detection and we train
computational models to compare the use of offensive language in social media
posts written by groups of individuals with and without self-reported
depression diagnosis. We also look at samples written by groups of individuals
whose posts show signs of depression according to recent related studies. Our
analysis indicates that offensive language is more frequently used in the
samples written by individuals with self-reported depression as well as
individuals showing signs of depression. The results discussed here open new
avenues in research in politeness/offensiveness and mental health.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14890</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14890</id><submitter>Kulin Shah</submitter><version version="v1"><date>Mon, 31 May 2021 11:31:30 GMT</date><size>757kb</size><source_type>D</source_type></version><title>Rawlsian Fair Adaptation of Deep Learning Classifiers</title><authors>Kulin Shah, Pooja Gupta, Amit Deshpande, Chiranjib Bhattacharyya</authors><categories>cs.LG cs.CY stat.ML</categories><comments>24 figures, 19 figures</comments><doi>10.1145/3461702.3462592</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Group-fairness in classification aims for equality of a predictive utility
across different sensitive sub-populations, e.g., race or gender. Equality or
near-equality constraints in group-fairness often worsen not only the aggregate
utility but also the utility for the least advantaged sub-population. In this
paper, we apply the principles of Pareto-efficiency and least-difference to the
utility being accuracy, as an illustrative example, and arrive at the Rawls
classifier that minimizes the error rate on the worst-off sensitive
sub-population. Our mathematical characterization shows that the Rawls
classifier uniformly applies a threshold to an ideal score of features, in the
spirit of fair equality of opportunity. In practice, such a score or a feature
representation is often computed by a black-box model that has been useful but
unfair. Our second contribution is practical Rawlsian fair adaptation of any
given black-box deep learning model, without changing the score or feature
representation it computes. Given any score function or feature representation
and only its second-order statistics on the sensitive sub-populations, we seek
a threshold classifier on the given score or a linear threshold classifier on
the given feature representation that achieves the Rawls error rate restricted
to this hypothesis class. Our technical contribution is to formulate the above
problems using ambiguous chance constraints, and to provide efficient
algorithms for Rawlsian fair adaptation, along with provable upper bounds on
the Rawls error rate. Our empirical results show significant improvement over
state-of-the-art group-fair algorithms, even without retraining for fairness.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14891</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14891</id><submitter>Kyungseo Min</submitter><version version="v1"><date>Mon, 31 May 2021 11:31:45 GMT</date><size>2034kb</size><source_type>D</source_type></version><title>ACNet: Mask-Aware Attention with Dynamic Context Enhancement for Robust
  Acne Detection</title><authors>Kyungseo Min, Gun-Hee Lee, Seong-Whan Lee</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Computer-aided diagnosis has recently received attention for its advantage of
low cost and time efficiency. Although deep learning played a major role in the
recent success of acne detection, there are still several challenges such as
color shift by inconsistent illumination, variation in scales, and high density
distribution. To address these problems, we propose an acne detection network
which consists of three components, specifically: Composite Feature Refinement,
Dynamic Context Enhancement, and Mask-Aware Multi-Attention. First, Composite
Feature Refinement integrates semantic information and fine details to enrich
feature representation, which mitigates the adverse impact of imbalanced
illumination. Then, Dynamic Context Enhancement controls different receptive
fields of multi-scale features for context enhancement to handle scale
variation. Finally, Mask-Aware Multi-Attention detects densely arranged and
small acne by suppressing uninformative regions and highlighting probable acne
regions. Experiments are performed on acne image dataset ACNE04 and natural
image dataset PASCAL VOC 2007. We demonstrate how our method achieves the
state-of-the-art result on ACNE04 and competitive performance with previous
state-of-the-art methods on the PASCAL VOC 2007.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14894</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14894</id><submitter>Jan K\v{r}et\'insk\'y</submitter><version version="v1"><date>Mon, 31 May 2021 11:35:42 GMT</date><size>28kb</size></version><title>LTL-Constrained Steady-State Policy Synthesis</title><authors>Jan K\v{r}et\'insk\'y</authors><categories>cs.AI cs.LO cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Decision-making policies for agents are often synthesized with the constraint
that a formal specification of behaviour is satisfied. Here we focus on
infinite-horizon properties. On the one hand, Linear Temporal Logic (LTL) is a
popular example of a formalism for qualitative specifications. On the other
hand, Steady-State Policy Synthesis (SSPS) has recently received considerable
attention as it provides a more quantitative and more behavioural perspective
on specifications, in terms of the frequency with which states are visited.
Finally, rewards provide a classic framework for quantitative properties. In
this paper, we study Markov decision processes (MDP) with the specification
combining all these three types. The derived policy maximizes the reward among
all policies ensuring the LTL specification with the given probability and
adhering to the steady-state constraints. To this end, we provide a unified
solution reducing the multi-type specification to a multi-dimensional long-run
average reward. This is enabled by Limit-Deterministic B\&quot;uchi Automata (LDBA),
recently studied in the context of LTL model checking on MDP, and allows for an
elegant solution through a simple linear programme. The algorithm also extends
to the general $\omega$-regular properties and runs in time polynomial in the
sizes of the MDP as well as the LDBA.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14895</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14895</id><submitter>Yizhe Wu</submitter><version version="v1"><date>Mon, 31 May 2021 11:37:37 GMT</date><size>910kb</size><source_type>D</source_type></version><title>APEX: Unsupervised, Object-Centric Scene Segmentation and Tracking for
  Robot Manipulation</title><authors>Yizhe Wu, Oiwi Parker Jones, Martin Engelcke, and Ingmar Posner</authors><categories>cs.RO</categories><comments>8 pages, 5 figures</comments><msc-class>I.2.9</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in unsupervised learning for object detection, segmentation,
and tracking hold significant promise for applications in robotics. A common
approach is to frame these tasks as inference in probabilistic latent-variable
models. In this paper, however, we show that the current state-of-the-art
struggles with visually complex scenes such as typically encountered in robot
manipulation tasks. We propose APEX, a new latent-variable model which is able
to segment and track objects in more realistic scenes featuring objects that
vary widely in size and texture, including the robot arm itself. This is
achieved by a principled mask normalisation algorithm and a high-resolution
scene encoder. To evaluate our approach, we present results on the real-world
Sketchy dataset. This dataset, however, does not contain ground truth masks and
object IDs for a quantitative evaluation. We thus introduce the Panda Pushing
Dataset (P2D) which shows a Panda arm interacting with objects on a table in
simulation and which includes ground-truth segmentation masks and object IDs
for tracking. In both cases, APEX comprehensively outperforms the current
state-of-the-art in unsupervised object segmentation and tracking. We
demonstrate the efficacy of our segmentations for robot skill execution on an
object arrangement task, where we also achieve the best or comparable
performance among all the baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14897</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14897</id><submitter>Shuai Bai</submitter><version version="v1"><date>Mon, 31 May 2021 11:42:03 GMT</date><size>6825kb</size><source_type>D</source_type></version><title>Connecting Language and Vision for Natural Language-Based Vehicle
  Retrieval</title><authors>Shuai Bai, Zhedong Zheng, Xiaohan Wang, Junyang Lin, Zhu Zhang, Chang
  Zhou, Yi Yang, Hongxia Yang</authors><categories>cs.CV</categories><comments>CVPR 2021 AI CITY CHALLENGE Natural Language-Based Vehicle Retrieval
  Top 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicle search is one basic task for the efficient traffic management in
terms of the AI City. Most existing practices focus on the image-based vehicle
matching, including vehicle re-identification and vehicle tracking. In this
paper, we apply one new modality, i.e., the language description, to search the
vehicle of interest and explore the potential of this task in the real-world
scenario. The natural language-based vehicle search poses one new challenge of
fine-grained understanding of both vision and language modalities. To connect
language and vision, we propose to jointly train the state-of-the-art vision
models with the transformer-based language model in an end-to-end manner.
Except for the network structure design and the training strategy, several
optimization objectives are also re-visited in this work. The qualitative and
quantitative experiments verify the effectiveness of the proposed method. Our
proposed method has achieved the 1st place on the 5th AI City Challenge,
yielding competitive performance 18.69% MRR accuracy on the private test set.
We hope this work can pave the way for the future study on using language
description effectively and efficiently for real-world vehicle retrieval
systems. The code will be available at
https://github.com/ShuaiBai623/AIC2021-T5-CLV.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14898</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14898</id><submitter>Igor Mozeti\v{c}</submitter><version version="v1"><date>Mon, 31 May 2021 11:43:19 GMT</date><size>441kb</size><source_type>D</source_type></version><title>Retweet communities reveal the main sources of hate speech</title><authors>Bojan Evkoski, Andraz Pelicon, Igor Mozetic, Nikola Ljubesic, Petra
  Kralj Novak</authors><categories>cs.SI cs.CY cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address a challenging problem of identifying main sources of hate speech
on Twitter. On one hand, we carefully annotate a large set of tweets for hate
speech, and deploy advanced deep learning to produce high quality hate speech
classification models. On the other hand, we create retweet networks, detect
communities and monitor their evolution through time. This combined approach is
applied to three years of Slovenian Twitter data. We report a number of
interesting results. Hate speech is dominated by offensive tweets, related to
political and ideological issues. The share of unacceptable tweets is
moderately increasing with time, from the initial 20% to 30% by the end of
2020. Unacceptable tweets are retweeted significantly more often than
acceptable tweets. About 60% of unacceptable tweets are produced by a single
right-wing community of only moderate size. Institutional Twitter accounts and
media accounts post significantly less unacceptable tweets than individual
accounts. However, the main sources of unacceptable tweets are anonymous
accounts, and accounts that were suspended or closed during the last three
years.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14900</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14900</id><submitter>Paavo Parmas</submitter><version version="v1"><date>Mon, 31 May 2021 11:53:08 GMT</date><size>665kb</size><source_type>D</source_type></version><title>A unified view of likelihood ratio and reparameterization gradients</title><authors>Paavo Parmas and Masashi Sugiyama</authors><categories>cs.LG cs.AI stat.ML</categories><comments>AISTATS2021; Earlier paper was split in two (arXiv:1910.06419). Refer
  to the current paper for the unified view, but see the earlier paper for
  discussion on an importance sampling technique</comments><journal-ref>In International Conference on Artificial Intelligence and
  Statistics (pp. 4078-4086). PMLR (2021, March)</journal-ref><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Reparameterization (RP) and likelihood ratio (LR) gradient estimators are
used to estimate gradients of expectations throughout machine learning and
reinforcement learning; however, they are usually explained as simple
mathematical tricks, with no insight into their nature. We use a first
principles approach to explain that LR and RP are alternative methods of
keeping track of the movement of probability mass, and the two are connected
via the divergence theorem. Moreover, we show that the space of all possible
estimators combining LR and RP can be completely parameterized by a flow field
$u(x)$ and an importance sampling distribution $q(x)$. We prove that there
cannot exist a single-sample estimator of this type outside our characterized
space, thus, clarifying where we should be searching for better Monte Carlo
gradient estimators.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14901</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14901</id><submitter>Marie-Laure Zollinger</submitter><version version="v1"><date>Mon, 31 May 2021 11:56:09 GMT</date><size>297kb</size><source_type>D</source_type></version><title>User Experience Design for E-Voting: How mental models align with
  security mechanisms</title><authors>Marie-Laure Zollinger and Verena Distler and Peter B. Roenne and Peter
  Y. A. Ryan and Carine Lallemand and Vincent Koenig</authors><categories>cs.HC</categories><comments>E-Vote-ID 2019 TalTech Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a mobile application for vote-casting and
vote-verification based on the Selene e-voting protocol and explains how it was
developed and implemented using the User Experience Design process. The
resulting interface was tested with 38 participants, and user experience data
was collected via questionnaires and semi-structured interviews on user
experience and perceived security. Results concerning the impact of displaying
security mechanisms on UX were presented in a complementary paper. Here we
expand on this analysis by studying the mental models revealed during the
interviews and compare them with theoretical security notions. Finally, we
propose a list of improvements for designs of future voting protocols.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14903</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14903</id><submitter>Pawe{\l} Gawrychowski</submitter><version version="v1"><date>Mon, 31 May 2021 12:06:09 GMT</date><size>2432kb</size><source_type>D</source_type></version><title>Lower Bounds for the Number of Repetitions in 2D Strings</title><authors>Pawe{\l} Gawrychowski, Samah Ghazawi, Gad M. Landau</authors><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-dimensional string is simply a two-dimensional array. We continue the
study of the combinatorial properties of repetitions in such strings over the
binary alphabet, namely the number of distinct tandems, distinct quartics, and
runs. First, we construct an infinite family of $n\times n$ 2D strings with
$\Omega(n^{3})$ distinct tandems. Second, we construct an infinite family of
$n\times n$ 2D strings with $\Omega(n^{2}\log n)$ distinct quartics. Third, we
construct an infinite family of $n\times n$ 2D strings with $\Omega(n^{2}\log
n)$ runs. This resolves an open question of Charalampopoulos, Radoszewski,
Rytter, Wale\'n, and Zuba [ESA 2020], who asked if the number of distinct
quartics and runs in an $n\times n$ 2D string is $\mathcal{O}(n^{2})$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14909</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14909</id><submitter>Giovanni Gabbolini</submitter><version version="v1"><date>Mon, 31 May 2021 12:23:16 GMT</date><size>1752kb</size><source_type>D</source_type></version><title>Generating Interesting Song-to-Song Segues With Dave</title><authors>Giovanni Gabbolini and Derek Bridge</authors><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel domain-independent algorithm for generating interesting
item-to-item textual connections, or segues. Pivotal to our contribution is the
introduction of a scoring function for segues, based on their
&quot;interestingness&quot;. We provide an implementation of our algorithm in the music
domain. We refer to our implementation as Dave. Dave is able to generate 1553
different types of segues, that can be broadly categorized as either
informative or funny. We evaluate Dave by comparing it against a curated source
of song-to-song segues, called The Chain. In the case of informative segues, we
find that Dave can produce segues of the same quality, if not better, than
those to be found in The Chain. And, we report positive correlation between the
values produced by our scoring function and human perceptions of segue quality.
The results highlight the validity of our method, and open future directions in
the application of segues to recommender systems research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14913</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14913</id><submitter>Huayang Li</submitter><version version="v1"><date>Mon, 31 May 2021 12:27:39 GMT</date><size>427kb</size><source_type>D</source_type></version><title>GWLAN: General Word-Level AutocompletioN for Computer-Aided Translation</title><authors>Huayang Li, Lemao Liu, Guoping Huang, Shuming Shi</authors><categories>cs.CL</categories><comments>Accepted into the main conference of ACL 2021. arXiv admin note: text
  overlap with arXiv:2105.13072</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-aided translation (CAT), the use of software to assist a human
translator in the translation process, has been proven to be useful in
enhancing the productivity of human translators. Autocompletion, which suggests
translation results according to the text pieces provided by human translators,
is a core function of CAT. There are two limitations in previous research in
this line. First, most research works on this topic focus on sentence-level
autocompletion (i.e., generating the whole translation as a sentence based on
human input), but word-level autocompletion is under-explored so far. Second,
almost no public benchmarks are available for the autocompletion task of CAT.
This might be among the reasons why research progress in CAT is much slower
compared to automatic MT. In this paper, we propose the task of general
word-level autocompletion (GWLAN) from a real-world CAT scenario, and construct
the first public benchmark to facilitate research in this topic. In addition,
we propose an effective method for GWLAN and compare it with several strong
baselines. Experiments demonstrate that our proposed method can give
significantly more accurate predictions than the baseline methods on our
benchmark datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14914</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14914</id><submitter>Prashanth Ramadoss</submitter><version version="v1"><date>Mon, 31 May 2021 12:30:30 GMT</date><size>1209kb</size><source_type>D</source_type></version><title>DILIGENT-KIO: A Proprioceptive Base Estimator for Humanoid Robots using
  Extended Kalman Filtering on Matrix Lie Groups</title><authors>Prashanth Ramadoss, Giulio Romualdi, Stefano Dafarra, Francisco Javier
  Andrade Chavez, Silvio Traversaro, Daniele Pucci</authors><categories>cs.RO</categories><comments>Accepted to the IEEE International Conference on Robotics and
  Automation (ICRA) 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a contact-aided inertial-kinematic floating base
estimation for humanoid robots considering an evolution of the state and
observations over matrix Lie groups. This is achieved through the application
of a geometrically meaningful estimator which is characterized by concentrated
Gaussian distributions. The configuration of a floating base system like a
humanoid robot usually requires the knowledge of an additional six degrees of
freedom which describes its base position-and-orientation. This quantity
usually cannot be measured and needs to be estimated. A matrix Lie group,
encapsulating the position-and-orientation and linear velocity of the base
link, feet positions-and-orientations and Inertial Measurement Units' biases,
is used to represent the state while relative positions-and-orientations of
contact feet from forward kinematics are used as observations. The proposed
estimator exhibits fast convergence for large initialization errors owing to
choice of uncertainty parametrization. An experimental validation is done on
the iCub humanoid platform.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14915</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14915</id><submitter>Hamed Rahimi</submitter><version version="v1"><date>Mon, 31 May 2021 12:33:27 GMT</date><size>497kb</size><source_type>D</source_type></version><title>SMASH: a Semantic-enabled Multi-agent Approach for Self-adaptation of
  Human-centered IoT</title><authors>Hamed Rahimi, Iago Felipe Trentin, Fano Ramparany, Olivier Boissier</authors><categories>cs.AI cs.HC</categories><comments>Submitted to PAAMS 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, IoT devices have an enlarging scope of activities spanning from
sensing, computing to acting and even more, learning, reasoning and planning.
As the number of IoT applications increases, these objects are becoming more
and more ubiquitous. Therefore, they need to adapt their functionality in
response to the uncertainties of their environment to achieve their goals. In
Human-centered IoT, objects and devices have direct interactions with human
beings and have access to online contextual information. Self-adaptation of
such applications is a crucial subject that needs to be addressed in a way that
respects human goals and human values. Hence, IoT applications must be equipped
with self-adaptation techniques to manage their run-time uncertainties locally
or in cooperation with each other. This paper presents SMASH: a multi-agent
approach for self-adaptation of IoT applications in human-centered
environments. In this paper, we have considered the Smart Home as the case
study of smart environments. SMASH agents are provided with a 4-layer
architecture based on the BDI agent model that integrates human values with
goal-reasoning, planning, and acting. It also takes advantage of a
semantic-enabled platform called Home'In to address interoperability issues
among non-identical agents and devices with heterogeneous protocols and data
formats. This approach is compared with the literature and is validated by
developing a scenario as the proof of concept. The timely responses of SMASH
agents show the feasibility of the proposed approach in human-centered
environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14917</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14917</id><submitter>Marcos Netto</submitter><version version="v1"><date>Mon, 31 May 2021 12:36:46 GMT</date><size>80kb</size></version><title>Measurement placement in electric power transmission and distribution
  grids: Review of methods and opportunities</title><authors>Marcos Netto and Venkat Krishnan and Yingchen Zhang and Lamine Mili</authors><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sensing and measurement systems are a quintessential piece to the safe and
reliable operation of electric power grids. Their strategic placement is of
ultimate importance because it is not economically viable to install
measurement systems on every node and branch of a power grid, though they need
to be monitored. An overwhelming number of strategies have been developed to
meet oftentimes multiple conflicting objectives. The prime challenge in
formulating the problem lies in developing a heuristic or an optimization model
that, though mathematically tractable and constrained in cost, leads to
trustworthy technical solutions. Besides, large-scale, long-term deployments
pose additional challenges because the boundary conditions change as
technologies evolve. For instance, the advent of new technologies in sensing
and measurement, as well as in communications and networking, might impact the
cost and performance of available solutions and shift initially set conditions.
Also, the placement strategies developed for transmission grids might not be
suitable for distribution grids, and vice versa, due to unique characteristics.
Therefore, the strategies need to be flexible, to a certain extent, because no
two power grids are alike. Despite the extensive literature on the present
topic, the focus of published works tends to be on a specific subject, such as
optimal placement of measurements to assure observability in transmission
grids. There is a dearth of work providing a comprehensive picture for
developing optimal placement strategies. Because of the ongoing efforts on the
modernization of electric power grids, there is a need to consolidate the
status quo while exposing its limitations to inform policymakers, industry
stakeholders, and researchers on the research-and-development needs to push the
boundaries for innovation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14918</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14918</id><submitter>Sandro Reia</submitter><version version="v1"><date>Mon, 31 May 2021 12:37:09 GMT</date><size>2713kb</size><source_type>D</source_type></version><title>Long-term Scientific Impact Revisited</title><authors>Sandro M. Reia, Jos\'e F. Fontanari</authors><categories>cs.DL cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Citation based measures are widely used as quantitative proxies for
subjective factors such as the importance of a paper or even the worth of
individual researchers. Here we analyze the citation histories of $4669$ papers
published in journals of the American Physical Society between $1960$ and
$1968$ and argue that state-of-the-art models of citation dynamics and
algorithms for forecasting nonstationary time series are very likely to fail to
predict the long-term ($50$ years after publication) citation counts of
highly-cited papers using citation data collected in a short period (say, $10$
years) after publication. This is so because those papers do not exhibit
distinctive short-term citation patterns, although their long-term citation
patterns clearly set them apart from the other papers. We conclude that even if
one accepts that citation counts are proxies for the quality of papers, they
are not useful evaluative tools since the short-term counts are not informative
about the long-term counts in the case of highly-cited papers.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14921</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14921</id><submitter>Jussi Karlgren</submitter><version version="v1"><date>Mon, 31 May 2021 12:40:10 GMT</date><size>11kb</size></version><title>How Lexical Gold Standards Have Effects On The Usefulness Of Text
  Analysis Tools For Digital Scholarship</title><authors>Jussi Karlgren</authors><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes how the current lexical similarity and analogy gold
standards are built to conform to certain ideas about what the models they are
designed to evaluate are used for. Topical relevance has always been the most
important target notion for information access tools and related language
technology technologies, and while this has proven a useful starting point for
much of what information technology is used for, it does not always align well
with other uses to which technologies are being put, most notably use cases
from digital scholarship in the humanities or social sciences. This paper
argues for more systematic formulation of requirements from the digital
humanities and social sciences and more explicit description of the assumptions
underlying model design.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14923</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14923</id><submitter>Bestoun Ahmed Dr.</submitter><version version="v1"><date>Mon, 31 May 2021 12:42:15 GMT</date><size>1035kb</size></version><title>Hybrid Henry Gas Solubility Optimization Algorithm with Dynamic
  Cluster-to-Algorithm Mapping for Search-based Software Engineering Problems</title><authors>Kamal Z. Zamli, Md. Abdul Kader, Saiful Azad, Bestoun S. Ahmed</authors><categories>cs.AI</categories><comments>31 pages</comments><journal-ref>Neural Computing and Applications 2021</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper discusses a new variant of the Henry Gas Solubility Optimization
(HGSO) Algorithm, called Hybrid HGSO (HHGSO). Unlike its predecessor, HHGSO
allows multiple clusters serving different individual meta-heuristic algorithms
(i.e., with its own defined parameters and local best) to coexist within the
same population. Exploiting the dynamic cluster-to-algorithm mapping via
penalized and reward model with adaptive switching factor, HHGSO offers a novel
approach for meta-heuristic hybridization consisting of Jaya Algorithm, Sooty
Tern Optimization Algorithm, Butterfly Optimization Algorithm, and Owl Search
Algorithm, respectively. The acquired results from the selected two case
studies (i.e., involving team formation problem and combinatorial test suite
generation) indicate that the hybridization has notably improved the
performance of HGSO and gives superior performance against other competing
meta-heuristic and hyper-heuristic algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14924</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14924</id><submitter>Runxin Xu</submitter><version version="v1"><date>Mon, 31 May 2021 12:45:03 GMT</date><size>5707kb</size><source_type>D</source_type></version><title>Document-level Event Extraction via Heterogeneous Graph-based
  Interaction Model with a Tracker</title><authors>Runxin Xu, Tianyu Liu, Lei Li, Baobao Chang</authors><categories>cs.CL cs.AI</categories><comments>Accepted by ACL-IJCNLP 2021 main conference (Long Paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Document-level event extraction aims to recognize event information from a
whole piece of article. Existing methods are not effective due to two
challenges of this task: a) the target event arguments are scattered across
sentences; b) the correlation among events in a document is non-trivial to
model. In this paper, we propose Heterogeneous Graph-based Interaction Model
with a Tracker (GIT) to solve the aforementioned two challenges. For the first
challenge, GIT constructs a heterogeneous graph interaction network to capture
global interactions among different sentences and entity mentions. For the
second, GIT introduces a Tracker module to track the extracted events and hence
capture the interdependency among the events. Experiments on a large-scale
dataset (Zheng et al., 2019) show GIT outperforms the previous methods by 2.8
F1. Further analysis reveals GIT is effective in extracting multiple correlated
events and event arguments that scatter across the document. Our code is
available at https://github.com/RunxinXu/GIT.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14927</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14927</id><submitter>Mikael Jacquemont</submitter><version version="v1"><date>Mon, 31 May 2021 12:51:42 GMT</date><size>668kb</size><source_type>D</source_type></version><title>First Full-Event Reconstruction from Imaging Atmospheric Cherenkov
  Telescope Real Data with Deep Learning</title><authors>Mika\&quot;el Jacquemont (LAPP), Thomas Vuillaume (LAPP), Alexandre Benoit
  (LISTIC), Gilles Maurin (LAPP), Patrick Lambert (LISTIC), Giovanni Lamanna
  (LAPP)</authors><categories>astro-ph.IM cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cherenkov Telescope Array is the future of ground-based gamma-ray
astronomy. Its first prototype telescope built on-site, the Large Size
Telescope 1, is currently under commissioning and taking its first scientific
data. In this paper, we present for the first time the development of a
full-event reconstruction based on deep convolutional neural networks and its
application to real data. We show that it outperforms the standard analysis,
both on simulated and on real data, thus validating the deep approach for the
CTA data analysis. This work also illustrates the difficulty of moving from
simulated data to actual data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14931</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14931</id><submitter>Jian Chen</submitter><version version="v1"><date>Thu, 20 May 2021 19:16:04 GMT</date><size>12321kb</size><source_type>D</source_type></version><title>Document Domain Randomization for Deep Learning Document Layout
  Extraction</title><authors>Meng Ling and Jian Chen and Torsten M\&quot;oller and Petra Isenberg and
  Tobias Isenberg and Michael Sedlmair and Robert S. Laramee and Han-Wei Shen
  and Jian Wu and C. Lee Giles</authors><categories>cs.CV cs.IR cs.LG</categories><comments>Main paper to appear in ICDAR 2021 (16th International Conference on
  Document Analysis and Recognition). This version contains additional
  materials. The associated test data is hosted on IEEE Data Port:
  http://doi.org/10.21227/326q-bf39</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present document domain randomization (DDR), the first successful transfer
of convolutional neural networks (CNNs) trained only on graphically rendered
pseudo-paper pages to real-world document segmentation. DDR renders
pseudo-document pages by modeling randomized textual and non-textual contents
of interest, with user-defined layout and font styles to support joint learning
of fine-grained classes. We demonstrate competitive results using our DDR
approach to extract nine document classes from the benchmark CS-150 and papers
published in two domains, namely annual meetings of Association for
Computational Linguistics (ACL) and IEEE Visualization (VIS). We compare DDR to
conditions of style mismatch, fewer or more noisy samples that are more easily
obtained in the real world. We show that high-fidelity semantic information is
not necessary to label semantic classes but style mismatch between train and
test can lower model accuracy. Using smaller training samples had a slightly
detrimental effect. Finally, network models still achieved high test accuracy
when correct labels are diluted towards confusing labels; this behavior hold
across several classes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14932</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14932</id><submitter>Qiumei Cheng</submitter><version version="v1"><date>Mon, 31 May 2021 12:57:16 GMT</date><size>164kb</size><source_type>D</source_type></version><title>STEP: Spatial-Temporal Network Security Event Prediction</title><authors>Qiumei Cheng, Yi Shen, Dezhang Kong, Chunming Wu</authors><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network security events prediction helps network operators to take response
strategies from a proactive perspective, and reduce the cost caused by network
attacks, which is of great significance for maintaining the security of the
entire network. Most of the existing event prediction methods rely on temporal
characteristics and are dedicated to exploring time series predictions, but
ignoring the spatial relationship between hosts. This paper combines the
temporal and spatial characteristics of security events and proposes a
spatial-temporal event prediction model, named STEP. In particular, STEP
formulates the security events prediction into a spatial-temporal sequence
prediction. STEP utilizes graph convolution operation to capture the spatial
characteristics of hosts in the network, and adopts the long short term memory
(LSTM) to capture the dynamic temporal dependency of events. This paper
verifies the proposed STEP scheme on two public data sets. The experimental
results show that the prediction accuracy of security events under STEP is
higher than that of benchmark models such as LSTM, ConvLSTM. Besides, STEP
achieves high prediction accuracy when we predict events from different lengths
of sequence.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14933</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14933</id><submitter>Thabang Lebese</submitter><version version="v1"><date>Mon, 31 May 2021 12:58:17 GMT</date><size>1058kb</size><source_type>D</source_type></version><title>The use of Generative Adversarial Networks to characterise new physics
  in multi-lepton final states at the LHC</title><authors>Thabang Lebese, Bruce Mellado, Xifeng Ruan</authors><categories>hep-ph cs.LG hep-ex</categories><comments>18 pages, 5 figures, 1 table, journal (JHEP)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Semi-supervision in Machine Learning can be used in searches for new physics
where the signal plus background regions are not labelled. This strongly
reduces model dependency in the search for signals Beyond the Standard Model.
This approach displays the drawback in that over-fitting can give rise to fake
signals. Tossing toy Monte Carlo (MC) events can be used to estimate the
corresponding trials factor through a frequentist inference. However, MC events
that are based on full detector simulations are resource intensive. Generative
Adversarial Networks (GANs) can be used to mimic MC generators. GANs are
powerful generative models, but often suffer from training instability. We
henceforth show a review of GANs. We advocate the use of Wasserstein GAN (WGAN)
with weight clipping and WGAN with gradient penalty (WGAN-GP) where the norm of
gradient of the critic is penalized with respect to its input. Following the
emergence of multi-lepton anomalies at the LHC, we apply GANs for the
generation of di-leptons final states in association with b-quarks at the LHC.
A good agreement between the MC events and the WGAN-GP events is found for the
observables selected in the study.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14934</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14934</id><submitter>Akhilesh Sanjay Khope</submitter><version version="v1"><date>Sun, 23 May 2021 04:28:39 GMT</date><size>5970kb</size><source_type>D</source_type></version><title>Review Of Integrated Photonic Elastic WDM Switches For Data Centers</title><authors>Akhilesh S P Khope, Anirban Samanta, Xian Xiao, Ben Yoo, John E Bowers</authors><categories>cs.ET physics.optics</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this review paper, we present an elaborate discussion on wavelength
selective switches and their demonstrations. We also review packaging and
electronic photonic integration of switches; a topic neglected in other review
papers. We also cover wavelength locking which is paramount in switching
networks with many tunable filters.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14935</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14935</id><submitter>Dalila Tamzalit</submitter><version version="v1"><date>Mon, 31 May 2021 13:01:06 GMT</date><size>435kb</size></version><title>Microservice Maturity of Organizations: towards an assessment framework</title><authors>Jean-Philippe Gouigoux, Dalila Tamzalit (IUT Nantes, LS2N), Joost
  Noppen</authors><categories>cs.SE</categories><proxy>ccsd</proxy><journal-ref>International Conference on Research Challenges in Information
  Science, May 2021, Virtual, Cyprus. pp.523-540</journal-ref><doi>10.1007/978-3-030-75018-3_34</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This early work aims to allow organizations to diagnose their capacity to
properly adopt microservices through initial milestones of a Microservice
Maturity Model (MiMMo). The objective is to prepare the way towards a general
framework to help companies and industries to determine their microservices
maturity. Organizations lean more and more on distributed web applications and
Line of Business software. This is particularly relevant during the current
Covid-19 crisis, where companies are even more challenged to offer their
services online, targeting a very high level of responsiveness in the face of
rapidly increasing and diverse demands. For this, microservices remain the most
suitable delivery application architectural style. They allow agility not only
on the technical application, as often considered, but on the enterprise
architecture as a whole, influencing the actual financial business of the
company. However, microservices adoption is highly risk-prone and complex.
Before they establish an appropriate migration plan, first and foremost,
companies must assess their degree of readiness to adopt microservices. For
this, MiMMo, a Microservices Maturity Model framework assessment, is proposed
to help companies assess their readiness for the microservice architectural
style, based on their actual situation. MiMMo results from observations of and
experience with about thirty organizations writing software. It conceptualizes
and generalizes the progression paths they have followed to adopt microservices
appropriately. Using the model, an organization can evaluate itself in two
dimensions and five maturity levels and thus: (i) benchmark itself on its
current use of microservices; (ii) project the next steps it needs to achieve a
higher maturity level and (iii) analyze how it has evolved and maintain a
global coherence between technical and business stakes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14937</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14937</id><submitter>Wanxin Jin</submitter><version version="v1"><date>Mon, 31 May 2021 13:03:00 GMT</date><size>1516kb</size><source_type>D</source_type></version><title>Safe Pontryagin Differentiable Programming</title><authors>Wanxin Jin, Shaoshuai Mou, George J. Pappas</authors><categories>cs.LG cs.RO cs.SY eess.SY</categories><comments>We have developed the implementation codes of Safe PDP as a
  stand-alone package, available at https://github.com/wanxinjin/Safe-PDP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Safe Pontryagin Differentiable Programming (Safe PDP)
methodology, which establishes a theoretical and algorithmic safe
differentiable framework to solve a broad class of safety-critical learning and
control tasks -- problems that require the guarantee of both immediate and
long-term constraint satisfaction at any stage of the learning and control
progress. In the spirit of interior-point methods, Safe PDP handles different
types of state and input constraints by incorporating them into the cost and
loss through barrier functions. We prove the following fundamental features of
Safe PDP: first, both the constrained solution and its gradient in backward
pass can be approximated by solving a more efficient unconstrained counterpart;
second, the approximation for both the solution and its gradient can be
controlled for arbitrary accuracy using a barrier parameter; and third,
importantly, any intermediate results throughout the approximation and
optimization are strictly respecting all constraints, thus guaranteeing safety
throughout the entire learning and control process. We demonstrate the
capabilities of Safe PDP in solving various safe learning and control tasks,
including safe policy optimization, safe motion planning, and learning MPCs
from demonstrations, on different challenging control systems such as 6-DoF
maneuvering quadrotor and 6-DoF rocket powered landing.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14940</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14940</id><submitter>Zae Myung Kim</submitter><version version="v1"><date>Mon, 31 May 2021 13:15:55 GMT</date><size>8930kb</size><source_type>D</source_type></version><title>Do Multilingual Neural Machine Translation Models Contain Language Pair
  Specific Attention Heads?</title><authors>Zae Myung Kim, Laurent Besacier, Vassilina Nikoulina, Didier Schwab</authors><categories>cs.CL cs.AI cs.LG</categories><comments>10 pages, accepted at Findings of ACL 2021 (short)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies on the analysis of the multilingual representations focus on
identifying whether there is an emergence of language-independent
representations, or whether a multilingual model partitions its weights among
different languages. While most of such work has been conducted in a
&quot;black-box&quot; manner, this paper aims to analyze individual components of a
multilingual neural translation (NMT) model. In particular, we look at the
encoder self-attention and encoder-decoder attention heads (in a many-to-one
NMT model) that are more specific to the translation of a certain language pair
than others by (1) employing metrics that quantify some aspects of the
attention weights such as &quot;variance&quot; or &quot;confidence&quot;, and (2) systematically
ranking the importance of attention heads with respect to translation quality.
Experimental results show that surprisingly, the set of most important
attention heads are very similar across the language pairs and that it is
possible to remove nearly one-third of the less important heads without hurting
the translation quality greatly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14943</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14943</id><submitter>Christof Paar</submitter><version version="v1"><date>Mon, 31 May 2021 13:21:52 GMT</date><size>1188kb</size></version><title>An Exploratory Study of Hardware Reverse Engineering Technical and
  Cognitive Processes</title><authors>Steffen Becker and Carina Wiesen and Nils Albartus and Nikol Rummel
  and Christof Paar</authors><categories>cs.CR cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the internals of Integrated Circuits (ICs), referred to as
Hardware Reverse Engineering (HRE), is of interest to both legitimate and
malicious parties. HRE is a complex process in which semi-automated steps are
interwoven with human sense-making processes. Currently, little is known about
the technical and cognitive processes which determine the success of HRE.
  This paper performs an initial investigation on how reverse engineers solve
problems, how manual and automated analysis methods interact, and which
cognitive factors play a role. We present the results of an exploratory
behavioral study with eight participants that was conducted after they had
completed a 14-week training. We explored the validity of our findings by
comparing them with the behavior (strategies applied and solution time) of an
HRE expert. The participants were observed while solving a realistic HRE task.
We tested cognitive abilities of our participants and collected large sets of
behavioral data from log files. By comparing the least and most efficient
reverse engineers, we were able to observe successful strategies. Moreover, our
analyses suggest a phase model for reverse engineering, consisting of three
phases. Our descriptive results further indicate that the cognitive factor
Working Memory (WM) might play a role in efficiently solving HRE problems. Our
exploratory study builds the foundation for future research in this topic and
outlines ideas for designing cognitively difficult countermeasures (&quot;cognitive
obfuscation&quot;) against HRE.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14944</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14944</id><submitter>Anh Nguyen</submitter><version version="v1"><date>Mon, 31 May 2021 13:23:50 GMT</date><size>21732kb</size><source_type>D</source_type></version><title>The effectiveness of feature attribution methods and its correlation
  with automatic evaluation scores</title><authors>Giang Nguyen, Daeyoung Kim, Anh Nguyen</authors><categories>cs.CV cs.AI cs.HC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Explaining the decisions of an Artificial Intelligence (AI) model is
increasingly critical in many real-world, high-stake applications. Hundreds of
papers have either proposed new feature attribution methods, discussed or
harnessed these tools in their work. However, despite humans being the target
end-users, most attribution methods were only evaluated on proxy
automatic-evaluation metrics. In this paper, we conduct the first, large-scale
user study on 320 lay and 11 expert users to shed light on the effectiveness of
state-of-the-art attribution methods in assisting humans in ImageNet
classification, Stanford Dogs fine-grained classification, and these two tasks
but when the input image contains adversarial perturbations. We found that, in
overall, feature attribution is surprisingly not more effective than showing
humans nearest training-set examples. On a hard task of fine-grained dog
categorization, presenting attribution maps to humans does not help, but
instead hurts the performance of human-AI teams compared to AI alone.
Importantly, we found automatic attribution-map evaluation measures to
correlate poorly with the actual human-AI team performance. Our findings
encourage the community to rigorously test their methods on the downstream
human-in-the-loop applications and to rethink the existing evaluation metrics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14950</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14950</id><submitter>Gonzalo Javier Anaya L\'opez</submitter><version version="v1"><date>Mon, 31 May 2021 13:33:03 GMT</date><size>319kb</size><source_type>D</source_type></version><title>A New Transmit Antenna Selection Technique for Physical Layer Security
  with Strong Eavesdropping</title><authors>Gonzalo J. Anaya-L\'opez, J. Carlos Ruiz-Sicilia and F. Javier
  L\'opez-Mart\'inez</authors><categories>cs.IT math.IT</categories><comments>4 pages, 4 figures, journal article.This work has been submitted to
  the IEEE for possible publication. Copyright may be transferred without
  notice, after which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new transmit antenna selection (TAS) technique that can be
beneficial for physical layer security purposes. Specifically, we show that the
conventional TAS criterion based on the legitimate channel state information
(CSI) is not recommended when the average signal-to-noise ratio for the
illegitimate user becomes comparable or superior to that of the legitimate
user. We illustrate that an eavesdropper's based antenna selection technique
outperforms conventional TAS, without explicit knowledge of the eavesdropper's
instantaneous CSI. Analytical expressions and simulation results to support
this comparison are given, showing how this new TAS scheme is a better choice
in scenarios with a strong eavesdropper.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14951</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14951</id><submitter>Bahjat Kawar</submitter><version version="v1"><date>Mon, 31 May 2021 13:33:21 GMT</date><size>13961kb</size><source_type>D</source_type></version><title>SNIPS: Solving Noisy Inverse Problems Stochastically</title><authors>Bahjat Kawar, Gregory Vaksman, Michael Elad</authors><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce a novel stochastic algorithm dubbed SNIPS, which
draws samples from the posterior distribution of any linear inverse problem,
where the observation is assumed to be contaminated by additive white Gaussian
noise. Our solution incorporates ideas from Langevin dynamics and Newton's
method, and exploits a pre-trained minimum mean squared error (MMSE) Gaussian
denoiser. The proposed approach relies on an intricate derivation of the
posterior score function that includes a singular value decomposition (SVD) of
the degradation operator, in order to obtain a tractable iterative algorithm
for the desired sampling. Due to its stochasticity, the algorithm can produce
multiple high perceptual quality samples for the same noisy observation. We
demonstrate the abilities of the proposed paradigm for image deblurring,
super-resolution, and compressive sensing. We show that the samples produced
are sharp, detailed and consistent with the given measurements, and their
diversity exposes the inherent uncertainty in the inverse problem being solved.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14953</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14953</id><submitter>Noseong Park</submitter><version version="v1"><date>Mon, 31 May 2021 13:39:42 GMT</date><size>1133kb</size><source_type>D</source_type></version><title>ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential Equations</title><authors>Sheo Yon Jhin, Minju Jo, Taeyong Kong, Jinsung Jeon, Noseong Park</authors><categories>cs.LG</categories><comments>Accepted by KDD 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Neural ordinary differential equations (NODEs) presented a new paradigm to
construct (continuous-time) neural networks. While showing several good
characteristics in terms of the number of parameters and the flexibility in
constructing neural networks, they also have a couple of well-known
limitations: i) theoretically NODEs learn homeomorphic mapping functions only,
and ii) sometimes NODEs show numerical instability in solving integral
problems. To handle this, many enhancements have been proposed. To our
knowledge, however, integrating attention into NODEs has been overlooked for a
while. To this end, we present a novel method of attentive dual co-evolving
NODE (ACE-NODE): one main NODE for a downstream machine learning task and the
other for providing attention to the main NODE. Our ACE-NODE supports both
pairwise and elementwise attention. In our experiments, our method outperforms
existing NODE-based and non-NODE-based baselines in almost all cases by
non-trivial margins.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14954</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14954</id><submitter>Yuan Gan</submitter><version version="v1"><date>Mon, 31 May 2021 13:40:41 GMT</date><size>410kb</size><source_type>D</source_type></version><title>VidFace: A Full-Transformer Solver for Video FaceHallucination with
  Unaligned Tiny Snapshots</title><authors>Yuan Gan, Yawei Luo, Xin Yu, Bang Zhang, Yi Yang</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the task of hallucinating an authentic
high-resolution (HR) human face from multiple low-resolution (LR) video
snapshots. We propose a pure transformer-based model, dubbed VidFace, to fully
exploit the full-range spatio-temporal information and facial structure cues
among multiple thumbnails. Specifically, VidFace handles multiple snapshots all
at once and harnesses the spatial and temporal information integrally to
explore face alignments across all the frames, thus avoiding accumulating
alignment errors. Moreover, we design a recurrent position embedding module to
equip our transformer with facial priors, which not only effectively
regularises the alignment mechanism but also supplants notorious pre-training.
Finally, we curate a new large-scale video face hallucination dataset from the
public Voxceleb2 benchmark, which challenges prior arts on tackling unaligned
and tiny face snapshots. To the best of our knowledge, we are the first attempt
to develop a unified transformer-based solver tailored for video-based face
hallucination. Extensive experiments on public video face benchmarks show that
the proposed method significantly outperforms the state of the arts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14956</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14956</id><submitter>Massimiliano Luca</submitter><version version="v1"><date>Mon, 31 May 2021 13:41:47 GMT</date><size>194kb</size><source_type>D</source_type></version><title>Leveraging Mobile Phone Data for Migration Flows</title><authors>Massimiliano Luca, Gianni Barlacchi, Nuria Oliver, Bruno Lepri</authors><categories>cs.CY</categories><comments>To appear as a book chapter in &quot;Data Science for Migration and
  Mobility Studies&quot; edited by Dr. Emre Eren Korkmaz, Dr. Albert Ali Salah</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistics on migration flows are often derived from census data, which
suffer from intrinsic limitations, including costs and infrequent sampling.
When censuses are used, there is typically a time gap - up to a few years -
between the data collection process and the computation and publication of
relevant statistics. This gap is a significant drawback for the analysis of a
phenomenon that is continuously and rapidly changing. Alternative data sources,
such as surveys and field observations, also suffer from reliability, costs,
and scale limitations. The ubiquity of mobile phones enables an accurate and
efficient collection of up-to-date data related to migration. Indeed, passively
collected data by the mobile network infrastructure via aggregated,
pseudonymized Call Detail Records (CDRs) is of great value to understand human
migrations. Through the analysis of mobile phone data, we can shed light on the
mobility patterns of migrants, detect spontaneous settlements and understand
the daily habits, levels of integration, and human connections of such
vulnerable social groups. This Chapter discusses the importance of leveraging
mobile phone data as an alternative data source to gather precious and
previously unavailable insights on various aspects of migration. Also, we
highlight pending challenges that would need to be addressed before we can
effectively benefit from the availability of mobile phone data to help make
better decisions that would ultimately improve millions of people's lives.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14961</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14961</id><submitter>Vin\'icius L. de Lima</submitter><version version="v1"><date>Mon, 31 May 2021 13:46:01 GMT</date><size>33kb</size></version><title>Exact solution of network flow models with strong relaxations</title><authors>Vin\'icius L. de Lima and Manuel Iori and Fl\'avio K. Miyazawa</authors><categories>math.OC cs.DS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address the solution of Mixed Integer Linear Programming (MILP) models
with strong relaxations that are derived from Dantzig-Wolfe decompositions and
allow a pseudo-polynomial pricing algorithm. We exploit their network-flow
characterization and provide a framework based on column generation,
reduced-cost variable-fixing, and a highly asymmetric branching scheme that
allows us to take advantage of the potential of the current MILP solvers. We
apply our framework to a variety of cutting and packing problems from the
literature. The efficiency of the framework is proved by extensive
computational experiments, in which a significant number of open instances
could be solved to proven optimality for the first time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14962</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14962</id><submitter>Yi Xu</submitter><version version="v1"><date>Mon, 31 May 2021 13:46:11 GMT</date><size>4245kb</size><source_type>D</source_type></version><title>Boosting the Performance of Video Compression Artifact Reduction with
  Reference Frame Proposals and Frequency Domain Information</title><authors>Yi Xu, Minyi Zhao, Jing Liu, Xinjian Zhang, Longwen Gao, Shuigeng
  Zhou, Huyang Sun</authors><categories>eess.IV cs.CV</categories><comments>CPVR Workshop, NTIRE 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many deep learning based video compression artifact removal algorithms have
been proposed to recover high-quality videos from low-quality compressed
videos. Recently, methods were proposed to mine spatiotemporal information via
utilizing multiple neighboring frames as reference frames. However, these
post-processing methods take advantage of adjacent frames directly, but neglect
the information of the video itself, which can be exploited. In this paper, we
propose an effective reference frame proposal strategy to boost the performance
of the existing multi-frame approaches. Besides, we introduce a loss based on
fast Fourier transformation~(FFT) to further improve the effectiveness of
restoration. Experimental results show that our method achieves better fidelity
and perceptual performance on MFQE 2.0 dataset than the state-of-the-art
methods. And our method won Track 1 and Track 2, and was ranked the 2nd in
Track 3 of NTIRE 2021 Quality enhancement of heavily compressed videos
Challenge.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14964</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14964</id><submitter>Viswanathan Ramachandran</submitter><version version="v1"><date>Mon, 31 May 2021 13:47:33 GMT</date><size>15kb</size></version><title>A Capacity Region Outer Bound for the Two-User Dispersive Nonlinear
  Fiber Optical Channel</title><authors>Viswanathan Ramachandran, Astrid Barreiro, Gabriele Liga, Alex
  Alvarado</authors><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study a nonlinear fiber optical channel impaired by cross-phase modulation
and dispersion from the viewpoint of an interference channel. We characterize
an outer bound on the capacity region of simultaneously achievable rate pairs,
assuming a two-user perturbative channel model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14969</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14969</id><submitter>Noseong Park</submitter><version version="v1"><date>Mon, 31 May 2021 13:58:55 GMT</date><size>980kb</size><source_type>D</source_type></version><title>OCT-GAN: Neural ODE-based Conditional Tabular GANs</title><authors>Jayoung Kim, Jinsung Jeon, Jaehoon Lee, Jihyeon Hyeong, Noseong Park</authors><categories>cs.LG</categories><comments>Accepted by WWW 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Synthesizing tabular data is attracting much attention these days for various
purposes. With sophisticate synthetic data, for instance, one can augment its
training data. For the past couple of years, tabular data synthesis techniques
have been greatly improved. Recent work made progress to address many problems
in synthesizing tabular data, such as the imbalanced distribution and
multimodality problems. However, the data utility of state-of-the-art methods
is not satisfactory yet. In this work, we significantly improve the utility by
designing our generator and discriminator based on neural ordinary differential
equations (NODEs). After showing that NODEs have theoretically preferred
characteristics for generating tabular data, we introduce our designs. The
NODE-based discriminator performs a hidden vector evolution trajectory-based
classification rather than classifying with a hidden vector at the last layer
only. Our generator also adopts an ODE layer at the very beginning of its
architecture to transform its initial input vector (i.e., the concatenation of
a noisy vector and a condition vector in our case) onto another latent vector
space suitable for the generation process. We conduct experiments with 13
datasets, including but not limited to insurance fraud detection, online news
article prediction, and so on, and our presented method outperforms other
state-of-the-art tabular data synthesis methods in many cases of our
classification, regression, and clustering experiments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14974</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14974</id><submitter>Yingqian Wang</submitter><version version="v1"><date>Mon, 31 May 2021 14:04:58 GMT</date><size>15055kb</size><source_type>D</source_type></version><title>Non-Convex Tensor Low-Rank Approximation for Infrared Small Target
  Detection</title><authors>Ting Liu, Jungang Yang, Boyang Li, Chao Xiao, Yang Sun, Yingqian Wang,
  Wei An</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infrared small target detection plays an important role in many infrared
systems. Recently, many infrared small target detection methods have been
proposed, in which the lowrank model has been used as a powerful tool. However,
most low-rank-based methods assign the same weights for different singular
values, which will lead to inaccurate background estimation. Considering that
different singular values have different importance and should be treated
discriminatively, in this paper, we propose a non-convex tensor low-rank
approximation (NTLA) method for infrared small target detection. In our method,
NTLA adaptively assigns different weights to different singular values for
accurate background estimation. Based on the proposed NTLA, we use the
asymmetric spatial-temporal total variation (ASTTV) to thoroughly describe
background feature, which can achieve good background estimation and detection
in complex scenes. Compared with the traditional total variation approach,
ASTTV exploits different smoothness strength for spatial and temporal
regularization. We develop an efficient algorithm to find the optimal solution
of the proposed model. Compared with some state-of-the-art methods, the
proposed method achieve an improvement in different evaluation metrics.
Extensive experiments on both synthetic and real data demonstrate the proposed
method provide a more robust detection in complex situations with low false
rates.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14975</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14975</id><submitter>Shuai Wang</submitter><version version="v1"><date>Mon, 31 May 2021 14:05:27 GMT</date><size>268kb</size><source_type>D</source_type></version><title>Privileged Graph Distillation for Cold Start Recommendation</title><authors>Shuai Wang, Kun Zhang, Le Wu, Haiping Ma, Richang Hong, Meng Wang</authors><categories>cs.IR cs.LG</categories><comments>10 pages,5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The cold start problem in recommender systems is a long-standing challenge,
which requires recommending to new users (items) based on attributes without
any historical interaction records. In these recommendation systems, warm users
(items) have privileged collaborative signals of interaction records compared
to cold start users (items), and these Collaborative Filtering (CF) signals are
shown to have competing performance for recommendation. Many researchers
proposed to learn the correlation between collaborative signal embedding space
and the attribute embedding space to improve the cold start recommendation, in
which user and item categorical attributes are available in many online
platforms. However, the cold start recommendation is still limited by two
embedding spaces modeling and simple assumptions of space transformation. As
user-item interaction behaviors and user (item) attributes naturally form a
heterogeneous graph structure, in this paper, we propose a privileged graph
distillation model~(PGD). The teacher model is composed of a heterogeneous
graph structure for warm users and items with privileged CF links. The student
model is composed of an entity-attribute graph without CF links. Specifically,
the teacher model can learn better embeddings of each entity by injecting
complex higher-order relationships from the constructed heterogeneous graph.
The student model can learn the distilled output with privileged CF embeddings
from the teacher embeddings. Our proposed model is generally applicable to
different cold start scenarios with new user, new item, or new user-new item.
Finally, extensive experimental results on the real-world datasets clearly show
the effectiveness of our proposed model on different types of cold start
problems, with average $6.6\%, 5.6\%, $ and $17.1\%$ improvement over
state-of-the-art baselines on three datasets, respectively.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14980</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14980</id><submitter>Xin Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 14:11:08 GMT</date><size>193kb</size><source_type>D</source_type></version><title>Crowdsourcing Learning as Domain Adaptation: A Case Study on Named
  Entity Recognition</title><authors>Xin Zhang, Guangwei Xu, Yueheng Sun, Meishan Zhang, Pengjun Xie</authors><categories>cs.CL cs.HC cs.LG</categories><comments>Accepted by ACL-IJCNLP 2021 (long paper), accepted version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing is regarded as one prospective solution for effective
supervised learning, aiming to build large-scale annotated training data by
crowd workers. Previous studies focus on reducing the influences from the
noises of the crowdsourced annotations for supervised models. We take a
different point in this work, regarding all crowdsourced annotations as
gold-standard with respect to the individual annotators. In this way, we find
that crowdsourcing could be highly similar to domain adaptation, and then the
recent advances of cross-domain methods can be almost directly applied to
crowdsourcing. Here we take named entity recognition (NER) as a study case,
suggesting an annotator-aware representation learning model that inspired by
the domain adaptation methods which attempt to capture effective domain-aware
features. We investigate both unsupervised and supervised crowdsourcing
learning, assuming that no or only small-scale expert annotations are
available. Experimental results on a benchmark crowdsourced NER dataset show
that our method is highly effective, leading to a new state-of-the-art
performance. In addition, under the supervised setting, we can achieve
impressive performance gains with only a very small scale of expert
annotations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14981</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14981</id><submitter>Stefan Sauter</submitter><version version="v1"><date>Mon, 31 May 2021 14:11:09 GMT</date><size>763kb</size></version><title>Critical Functions and Inf-Sup Stability of Crouzeix-Raviart Elements</title><authors>C. Carstensen, S. Sauter</authors><categories>math.NA cs.NA</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove that Crouzeix-Raviart finite elements of polynomial
order $p\geq5$, $p$ odd, are inf-sup stable for the Stokes problem on
triangulations. For $p\geq4$, $p$ even, the stability was proved by \'{A}.
Baran and G. Stoyan in 2007 by using the \textit{macroelement technique,} a
\textit{dimension formula}, the concept of \textit{critical points} in a
triangulation and a representation of the corresponding \textit{critical
functions}. Baran and Stoyan proved that these critical functions belong to the
range of the divergence operator applied to Crouzeix-Raviart velocity functions
and the macroelement technique implies the inf-sup stability.
  The generalization of this theory to cover odd polynomial orders $p\geq5$ is
involved; one reason is that the macroelement classes, which have been used for
even $p$, are unsuitable for odd $p$. In this paper, we introduce a new and
simple representation of non-conforming Crouzeix-Raviart basis functions of odd
degree. We employ only one type of macroelement and derive representations of
all possible critical functions. Finally, we show that they are in the range of
the divergence operator applied to Crouzeix-Raviart velocities from which the
stability of the discretization follows.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14984</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14984</id><submitter>Marc Zeller</submitter><version version="v1"><date>Mon, 31 May 2021 14:13:25 GMT</date><size>325kb</size></version><title>WAP: Digital Dependability Identities</title><authors>Daniel Schneider, Mario Trapp, Yiannis Papadopoulos, Eric Armengaud,
  Marc Zeller, Kai Hoefig</authors><categories>cs.OH</categories><journal-ref>2015 IEEE 26th International Symposium on Software Reliability
  Engineering (ISSRE)</journal-ref><doi>10.1109/ISSRE.2015.7381825</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber-Physical Systems (CPS) provide enormous potential for innovation but a
precondition for this is that the issue of dependability has been addressed.
This paper presents the concept of a Digital Dependability Identity (DDI) of a
component or system as foundation for assuring the dependability of CPS. A DDI
is an analyzable and potentially executable model of information about the
dependability of a component or system. We argue that DDIs must fulfill a
number of properties including being universally useful across supply chains,
enabling off-line certification of systems where possible, and providing
capabilities for in-field certification of safety of CPS. In this paper, we
focus on system safety as one integral part of dependability and as a practical
demonstration of the concept, we present an initial implementation of DDIs in
the form of Conditional Safety Certificates (also known as ConSerts). We
explain ConSerts and their practical operationalization based on an
illustrative example.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14986</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14986</id><submitter>Mohammad Eslami</submitter><version version="v1"><date>Mon, 31 May 2021 14:16:28 GMT</date><size>5152kb</size></version><title>Feasibility Assessment of Multitasking in MRI Neuroimaging Analysis:
  Tissue Segmentation, Cross-Modality Conversion and Bias correction</title><authors>Mohammad Eslami, Solale Tabarestani, Malek Adjouadi</authors><categories>eess.IV cs.CV cs.LG physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuroimaging is essential in brain studies for the diagnosis and
identification of disease, structure, and function of the brain in its healthy
and disease states. Literature shows that there are advantages of multitasking
with some deep learning (DL) schemes in challenging neuroimaging applications.
This study examines the feasibility of using multitasking in three different
applications, including tissue segmentation, cross-modality conversion, and
bias-field correction. These applications reflect five different scenarios in
which multitasking is explored and 280 training and testing sessions conducted
for empirical evaluations. Two well-known networks, U-Net as a well-known
convolutional neural network architecture, and a closed architecture based on
the conditional generative adversarial network are implemented. Different
metrics such as the normalized cross-correlation coefficient and Dice scores
are used for comparison of methods and results of the different experiments.
Statistical analysis is also provided by paired t-test. The present study
explores the pros and cons of these methods and their practical impacts on
multitasking in different implementation scenarios. This investigation shows
that bias correction and cross-modality conversion applications are
significantly easier than the segmentation application, and having multitasking
with segmentation is not reasonable if one of them is identified as the main
target application. However, when the main application is the segmentation of
tissues, multitasking with cross-modality conversion is beneficial, especially
for the U-net architecture.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14987</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14987</id><submitter>Stefan Sauter</submitter><version version="v1"><date>Mon, 31 May 2021 14:17:28 GMT</date><size>21kb</size></version><title>Crouzeix-Raviart triangular elements are inf-sup stable</title><authors>C. Carstensen, S. Sauter</authors><categories>math.NA cs.NA</categories><comments>17</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Crouzeix-Raviart triangular finite elements are $\inf$-$\sup$ stable for
the Stokes equations for any mesh with at least one interior vertex. This
result affirms a {\em conjecture of Crouzeix-Falk} from 1989 for $p=3$. Our
proof applies to {\em any odd degree} $p\ge 3$ and hence Crouzeix-Raviart
triangular finite elements of degree $p$ in two dimensions and the piecewise
polynomials of degree $p-1$ with vanishing integral form a stable Stokes pair
{\em for all positive integers} $p$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14988</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14988</id><submitter>Douglas Stinson</submitter><version version="v1"><date>Mon, 31 May 2021 14:19:27 GMT</date><size>16kb</size><source_type>D</source_type></version><title>Asymmetric All-or-nothing Transforms</title><authors>Navid Nasr Esfahani and Douglas R. Stinson</authors><categories>math.CO cs.CR</categories><msc-class>05B30, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we initiate a study of asymmetric all-or-nothing transforms
(or asymmetric AONTs). A (symmetric) $t$-all-or-nothing transform is a
bijective mapping defined on the set of $s$-tuples over a specified finite
alphabet. It is required that knowledge of all but $t$ outputs leaves any $t$
inputs completely undetermined. There have been numerous papers developing the
theory of AONTs as well as presenting various applications of AONTs in
cryptography and information security.
  In this paper, we replace the parameter $t$ by two parameters $t_o$ and
$t_i$, where $t_i \leq t_o$. The requirement is that knowledge of all but $t_o$
outputs leaves any $t_i$ inputs completely undetermined. When $t_i &lt; t_o$, we
refer to the AONT as asymmetric.
  We give several constructions and bounds for various classes of asymmetric
AONTs, especially those with $t_i = 1$ or $t_i = 2$. We pay particular
attention to linear transforms, where the alphabet is a finite field
$\mathbb{F}_q$ and the mapping is linear.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14989</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14989</id><submitter>Ziping Xu</submitter><version version="v1"><date>Mon, 31 May 2021 14:21:52 GMT</date><size>1575kb</size><source_type>D</source_type></version><title>Representation Learning Beyond Linear Prediction Functions</title><authors>Ziping Xu and Ambuj Tewari</authors><categories>stat.ML cs.LG</categories><comments>1 Figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent papers on the theory of representation learning has shown the
importance of a quantity called diversity when generalizing from a set of
source tasks to a target task. Most of these papers assume that the function
mapping shared representations to predictions is linear, for both source and
target tasks. In practice, researchers in deep learning use different numbers
of extra layers following the pretrained model based on the difficulty of the
new task. This motivates us to ask whether diversity can be achieved when
source tasks and the target task use different prediction function spaces
beyond linear functions. We show that diversity holds even if the target task
uses a neural network with multiple layers, as long as source tasks use linear
functions. If source tasks use nonlinear prediction functions, we provide a
negative result by showing that depth-1 neural networks with ReLu activation
function need exponentially many source tasks to achieve diversity. For a
general function class, we find that eluder dimension gives a lower bound on
the number of tasks required for diversity. Our theoretical results imply that
simpler tasks generalize better. Though our theoretical results are shown for
the global minimizer of empirical risks, their qualitative predictions still
hold true for gradient-based optimization algorithms as verified by our
simulations on deep neural networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14990</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14990</id><submitter>Giuseppa Castiglione</submitter><version version="v1"><date>Mon, 31 May 2021 14:22:20 GMT</date><size>15kb</size></version><title>A new distance based on minimal absent words and applications to
  biological sequences</title><authors>Giuseppa Castiglione, Jia Gao, Sabrina Mantaci, Antonio Restivo</authors><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A minimal absent word of a sequence x, is a sequence yt hat is not a factorof
x, but all of its proper factors are factors of x as well. The set of minimal
absent words uniquely defines the sequence itself. In recent times minimal
absent words have been used in order to compare sequences. In fact, to do this,
one can compare the sets of their minimal absent words. Chairungasee and
Crochemorein [2] define a distance between pairs of sequences x and y, where
the symmetric difference of the sets of minimal absent words of x and y is
involved. Here, weconsider a different distance, introduced in [1], based on a
specific subset of such symmetric difference that, in our opinion, better
capture the different features ofthe considered sequences. We show the result
of some experiments where the distance is tested on a dataset of genetic
sequences by 11 living species, in order to compare the new distance with the
ones existing in literature.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14992</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14992</id><submitter>Marc Zeller</submitter><version version="v1"><date>Mon, 31 May 2021 14:23:53 GMT</date><size>176kb</size></version><title>INSiDER: Incorporation of system and safety analysis models using a
  dedicated reference model</title><authors>Marc Zeller, Kai Hoefig</authors><categories>cs.OH</categories><journal-ref>2016 Annual Reliability and Maintainability Symposium (RAMS)</journal-ref><doi>10.1109/RAMS.2016.7448074</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to enable model-based, iterative design of safety-relevant systems,
an efficient incorporation of safety and system engineering is a pressing need.
Our approach interconnects system design and safety analysis models efficiently
using a dedicated reference model. Since all information are available in a
structured way, traceability between the model elements and consistency checks
enable automated synchronization to guarantee that information within both kind
of models are consistent during the development life-cycle.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14993</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14993</id><submitter>Henry Bradler</submitter><version version="v1"><date>Mon, 31 May 2021 14:29:02 GMT</date><size>4270kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 12:59:51 GMT</date><size>3667kb</size><source_type>D</source_type></version><title>Urban Traffic Surveillance (UTS): A fully probabilistic 3D tracking
  approach based on 2D detections</title><authors>Henry Bradler, Adrian Kretz and Rudolf Mester</authors><categories>cs.CV</categories><comments>Accepted at the 2021 IEEE Intelligent Vehicles Symposium (IV),
  Nagoya, Japan, July 11-17, 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urban Traffic Surveillance (UTS) is a surveillance system based on a
monocular and calibrated video camera that detects vehicles in an urban traffic
scenario with dense traffic on multiple lanes and vehicles performing sharp
turning maneuvers. UTS then tracks the vehicles using a 3D bounding box
representation and a physically reasonable 3D motion model relying on an
unscented Kalman filter based approach. Since UTS recovers positions, shape and
motion information in a three-dimensional world coordinate system, it can be
employed to recognize diverse traffic violations or to supply intelligent
vehicles with valuable traffic information. We build on YOLOv3 as a detector
yielding 2D bounding boxes and class labels for each vehicle. A 2D detector
renders our system much more independent to different camera perspectives as a
variety of labeled training data is available. This allows for a good
generalization while also being more hardware efficient. The task of 3D
tracking based on 2D detections is supported by integrating class specific
prior knowledge about the vehicle shape. We quantitatively evaluate UTS using
self generated synthetic data and ground truth from the CARLA simulator, due to
the non-existence of datasets with an urban vehicle surveillance setting and
labeled 3D bounding boxes. Additionally, we give a qualitative impression of
how UTS performs on real-world data. Our implementation is capable of operating
in real time on a reasonably modern workstation. To the best of our knowledge,
UTS is to date the only 3D vehicle tracking system in a surveillance scenario
(static camera observing moving targets).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14994</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14994</id><submitter>Kirill Muravyev</submitter><version version="v1"><date>Mon, 31 May 2021 14:30:36 GMT</date><size>8710kb</size><source_type>D</source_type></version><title>MAOMaps: A Photo-Realistic Benchmark For vSLAM and Map Merging Quality
  Assessment</title><authors>Andrey Bokovoy, Kirill Muravyev and Konstantin Yakovlev (Federal
  Research Center for Computer Science and Control of Russian Academy of
  Sciences)</authors><categories>cs.CV cs.RO</categories><comments>submitted to ECMR-2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Running numerous experiments in simulation is a necessary step before
deploying a control system on a real robot. In this paper we introduce a novel
benchmark that is aimed at quantitatively evaluating the quality of
vision-based simultaneous localization and mapping (vSLAM) and map merging
algorithms. The benchmark consists of both a dataset and a set of tools for
automatic evaluation. The dataset is photo-realistic and provides both the
localization and the map ground truth data. This makes it possible to evaluate
not only the localization part of the SLAM pipeline but the mapping part as
well. To compare the vSLAM-built maps and the ground-truth ones we introduce a
novel way to find correspondences between them that takes the SLAM context into
account (as opposed to other approaches like nearest neighbors). The benchmark
is ROS-compatable and is open-sourced to the community.
  The data and the code are available at: \texttt{github.com/CnnDepth/MAOMaps}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14995</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14995</id><submitter>Shuhao Cao</submitter><version version="v1"><date>Mon, 31 May 2021 14:30:53 GMT</date><size>2579kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 16:06:10 GMT</date><size>2581kb</size><source_type>D</source_type></version><title>Choose a Transformer: Fourier or Galerkin</title><authors>Shuhao Cao</authors><categories>cs.LG cs.NA math.NA</categories><msc-class>68T99, 65D15, 65M99, 65N99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply the self-attention from the state-of-the-art
Transformer in Attention Is All You Need the first time to a data-driven
operator learning problem related to partial differential equations. We put
together an effort to explain the heuristics of, and improve the efficacy of
the self-attention by demonstrating that the softmax normalization in the
scaled dot-product attention is sufficient but not necessary, and have proved
the approximation capacity of a linear variant as a Petrov-Galerkin projection.
A new layer normalization scheme is proposed to allow a scaling to propagate
through attention layers, which helps the model achieve remarkable accuracy in
operator learning tasks with unnormalized data. Finally, we present three
operator learning experiments, including the viscid Burgers' equation, an
interface Darcy flow, and an inverse interface coefficient identification
problem. All experiments validate the improvements of the newly proposed simple
attention-based operator learner over their softmax-normalized counterparts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.14998</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.14998</id><submitter>Elisheva Shamash</submitter><version version="v1"><date>Mon, 31 May 2021 14:32:32 GMT</date><size>300kb</size><source_type>D</source_type></version><title>Incomplete Information VCG Contracts for Common Agency</title><authors>Tal Alon, Ron Lavi, Elisheva S. Shamash, Inbal Talgam-Cohen</authors><categories>cs.GT</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We study contract design for welfare maximization in the well known &quot;common
agency&quot; model of [Bernheim and Whinston, 1986]. This model combines the
challenges of coordinating multiple principals with the fundamental challenge
of contract design: that principals have incomplete information of the agent's
choice of action. Motivated by the significant social inefficiency of standard
contracts for such settings (which we formally quantify using a price of
anarchy/stability analysis), we investigate whether and how a recent toolbox
developed for the first set of challenges under a complete-information
assumption, VCG contracts [Lavi and Shamash, 2019], can be extended to
incomplete information.
  We define and characterize the class of &quot;incomplete information VCG contracts
(IIVCG)&quot;, and show it is the unique class guaranteeing truthfulness of the
principals and welfare maximization by the agent. Our results reveal an
inherent tradeoff between two important properties required to ensure
participation in the contract: individual rationality (for the principals) and
limited liability (for the agent). We design a polynomial-time algorithm for
determining whether a setting has an IIVCG contract with both properties. As
our main result we design a polynomial-time &quot;algorithmic IIVCG&quot; contract: given
valuation reports from the principals it returns, if possible for the setting,
a payment scheme for the agent that constitutes an IIVCG contract with all
desired properties. We also give a sufficient graph-theoretic condition on the
population of principals that ensures the existence of such an IIVCG contract.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15002</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15002</id><submitter>Marc Zeller</submitter><version version="v1"><date>Mon, 31 May 2021 14:36:06 GMT</date><size>3948kb</size></version><title>ArChes -- Automatic generation of component fault trees from continuous
  function charts</title><authors>Marc Zeller, Kai Hoefig, Jean-Pascal Schwinn</authors><categories>cs.SE</categories><comments>2017 IEEE 15th International Conference on Industrial Informatics
  (INDIN)</comments><doi>10.1109/INDIN.2017.8104836</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing size and complexity of software in embedded systems poses new
challenges to the safety assessment of embedded control systems. In industrial
practice, the control software is mostly treated as a black box during the
system's safety analysis. The appropriate representation of the failure
propagation of the software is a pressing need in order to increase the
accuracy of safety analyses. However, it also increase the effort for creating
and maintaining the safety analysis models (such as fault trees) significantly.
In this work, we present a method to automatically generate Component Fault
Trees from Continuous Function Charts. This method aims at generating the
failure propagation model of the detailed software specification. Hence,
control software can be included into safety analyses without additional manual
effort required to construct the safety analysis models of the software.
Moreover, safety analyses created during early system specification phases can
be verified by comparing it with the automatically generated one in the
detailed specification phased.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15004</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15004</id><submitter>Florent Krzakala</submitter><version version="v1"><date>Mon, 31 May 2021 14:39:08 GMT</date><size>194kb</size><source_type>D</source_type></version><title>Generalization Error Rates in Kernel Regression: The Crossover from the
  Noiseless to Noisy Regime</title><authors>Hugo Cui, Bruno Loureiro, Florent Krzakala, Lenka Zdeborov\'a</authors><categories>stat.ML cond-mat.dis-nn cs.LG</categories><comments>22 pages, 10 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this manuscript we consider Kernel Ridge Regression (KRR) under the
Gaussian design. Exponents for the decay of the excess generalization error of
KRR have been reported in various works under the assumption of power-law decay
of eigenvalues of the features co-variance. These decays were, however,
provided for sizeably different setups, namely in the noiseless case with
constant regularization and in the noisy optimally regularized case.
Intermediary settings have been left substantially uncharted. In this work, we
unify and extend this line of work, providing characterization of all regimes
and excess error decay rates that can be observed in terms of the interplay of
noise and regularization. In particular, we show the existence of a transition
in the noisy setting between the noiseless exponents to its noisy values as the
sample complexity is increased. Finally, we illustrate how this crossover can
also be observed on real data sets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15005</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15005</id><submitter>Weiming Feng</submitter><version version="v1"><date>Mon, 31 May 2021 14:40:34 GMT</date><size>152kb</size></version><title>Rapid mixing of Glauber dynamics via spectral independence for all
  degrees</title><authors>Xiaoyu Chen, Weiming Feng, Yitong Yin, Xinyuan Zhang</authors><categories>math-ph cs.DS math.MP math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an optimal $\Omega(n^{-1})$ lower bound on the spectral gap of
Glauber dynamics for anti-ferromagnetic two-spin systems with $n$ vertices in
the tree uniqueness regime. This spectral gap holds for all, including
unbounded, maximum degree $\Delta$. Consequently, we have the following mixing
time bounds for the models satisfying the uniqueness condition with a slack
$\delta\in(0,1)$:
  $\bullet$ $C(\delta) n^2\log n$ mixing time for the hardcore model with
fugacity $\lambda\le (1-\delta)\lambda_c(\Delta)= (1-\delta)\frac{(\Delta -
1)^{\Delta - 1}}{(\Delta - 2)^\Delta}$;
  $\bullet$ $C(\delta) n^2$ mixing time for the Ising model with edge activity
$\beta\in\left[\frac{\Delta-2+\delta}{\Delta-\delta},\frac{\Delta-\delta}{\Delta-2+\delta}\right]$;
  where the maximum degree $\Delta$ may depend on the number of vertices $n$,
and $C(\delta)$ depends only on $\delta$.
  Our proof is built upon the recently developed connections between the
Glauber dynamics for spin systems and the high-dimensional expander walks. In
particular, we prove a stronger notion of spectral independence, called the
complete spectral independence, and use a novel Markov chain called the field
dynamics to connect this stronger spectral independence to the rapid mixing of
Glauber dynamics for all degrees.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15007</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15007</id><submitter>Anamay Chaturvedi</submitter><version version="v1"><date>Mon, 31 May 2021 14:41:40 GMT</date><size>67kb</size></version><title>Locally Private $k$-Means Clustering with Constant Multiplicative
  Approximation and Near-Optimal Additive Error</title><authors>Anamay Chaturvedi, Matthew Jones, Huy L. Nguyen</authors><categories>cs.DS cs.CR cs.LG</categories><comments>61 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Given a data set of size $n$ in $d'$-dimensional Euclidean space, the
$k$-means problem asks for a set of $k$ points (called centers) so that the sum
of the $\ell_2^2$-distances between points of a given data set of size $n$ and
the set of $k$ centers is minimized. Recent work on this problem in the locally
private setting achieves constant multiplicative approximation with additive
error $\tilde{O} (n^{1/2 + a} \cdot k \cdot \max \{\sqrt{d}, \sqrt{k} \})$ and
proves a lower bound of $\Omega(\sqrt{n})$ on the additive error for any
solution with a constant number of rounds. In this work we bridge the gap
between the exponents of $n$ in the upper and lower bounds on the additive
error with two new algorithms. Given any $\alpha&gt;0$, our first algorithm
achieves a multiplicative approximation guarantee which is at most a
$(1+\alpha)$ factor greater than that of any non-private $k$-means clustering
algorithm with $k^{\tilde{O}(1/\alpha^2)} \sqrt{d' n} \mbox{poly}\log n$
additive error. Given any $c&gt;\sqrt{2}$, our second algorithm achieves $O(k^{1 +
\tilde{O}(1/(2c^2-1))} \sqrt{d' n} \mbox{poly} \log n)$ additive error with
constant multiplicative approximation. Both algorithms go beyond the
$\Omega(n^{1/2 + a})$ factor that occurs in the additive error for arbitrarily
small parameters $a$ in previous work, and the second algorithm in particular
shows for the first time that it is possible to solve the locally private
$k$-means problem in a constant number of rounds with constant factor
multiplicative approximation and polynomial dependence on $k$ in the additive
error arbitrarily close to linear.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15010</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15010</id><submitter>Sizhe Chen</submitter><version version="v1"><date>Mon, 31 May 2021 14:45:10 GMT</date><size>3778kb</size><source_type>D</source_type></version><title>QueryNet: An Efficient Attack Framework with Surrogates Carrying
  Multiple Identities</title><authors>Sizhe Chen, Zhehao Huang, Qinghua Tao, Xiaolin Huang</authors><categories>cs.LG cs.CR</categories><comments>QueryNet reduces queries by about an order of magnitude against SOTA
  black-box attacks. 21 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Neural Networks (DNNs) are acknowledged as vulnerable to adversarial
attacks, while the existing black-box attacks require extensive queries on the
victim DNN to achieve high success rates. For query-efficiency, surrogate
models of the victim are adopted as transferable attackers in consideration of
their Gradient Similarity (GS), i.e., surrogates' attack gradients are similar
to the victim's ones to some extent. However, it is generally neglected to
exploit their similarity on outputs, namely the Prediction Similarity (PS), to
filter out inefficient queries. To jointly utilize and also optimize
surrogates' GS and PS, we develop QueryNet, an efficient attack network that
can significantly reduce queries. QueryNet crafts several transferable
Adversarial Examples (AEs) by surrogates, and then decides also by surrogates
on the most promising AE, which is then sent to query the victim. That is to
say, in QueryNet, surrogates are not only exploited as transferable attackers,
but also as transferability evaluators for AEs. The AEs are generated using
surrogates' GS and evaluated based on their FS, and therefore, the query
results could be back-propagated to optimize surrogates' parameters and also
their architectures, enhancing both the GS and the FS. QueryNet has significant
query-efficiency, i.e., reduces queries by averagely about an order of
magnitude compared to recent SOTA methods according to our comprehensive and
real-world experiments: 11 victims (including 2 commercial models) on
MNIST/CIFAR10/ImageNet, allowing only 8-bit image queries, and no access to the
victim's training data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15012</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15012</id><submitter>Noseong Park</submitter><version version="v1"><date>Mon, 31 May 2021 14:48:40 GMT</date><size>4707kb</size><source_type>D</source_type></version><title>Large-Scale Data-Driven Airline Market Influence Maximization</title><authors>Duanshun Li, Jing Liu, Jinsung Jeon, Seoyoung Hong, Thai Le, Dongwon
  Lee, Noseong Park</authors><categories>cs.LG</categories><comments>Accepted by KDD 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We present a prediction-driven optimization framework to maximize the market
influence in the US domestic air passenger transportation market by adjusting
flight frequencies. At the lower level, our neural networks consider a wide
variety of features, such as classical air carrier performance features and
transportation network features, to predict the market influence. On top of the
prediction models, we define a budget-constrained flight frequency optimization
problem to maximize the market influence over 2,262 routes. This problem falls
into the category of the non-linear optimization problem, which cannot be
solved exactly by conventional methods. To this end, we present a novel
adaptive gradient ascent (AGA) method. Our prediction models show two to eleven
times better accuracy in terms of the median root-mean-square error (RMSE) over
baselines. In addition, our AGA optimization method runs 690 times faster with
a better optimization result (in one of our largest scale experiments) than a
greedy algorithm.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15013</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15013</id><submitter>Jianhong Wang</submitter><version version="v1"><date>Mon, 31 May 2021 14:50:52 GMT</date><size>12341kb</size><source_type>D</source_type></version><title>SHAQ: Incorporating Shapley Value Theory into Q-Learning for Multi-Agent
  Reinforcement Learning</title><authors>Jianhong Wang, Jinxin Wang, Yuan Zhang, Yunjie Gu, Tae-Kyun Kim</authors><categories>cs.LG cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Value factorisation proves to be a very useful technique in multi-agent
reinforcement learning (MARL), but the underlying mechanism is not yet fully
understood. This paper explores a theoretic basis for value factorisation. We
generalise the Shapley value in the coalitional game theory to a Markov convex
game (MCG) and use it to guide value factorisation in MARL. We show that the
generalised Shapley value possesses several features such as (1) accurate
estimation of the maximum global value, (2) fairness in the factorisation of
the global value, and (3) being sensitive to dummy agents. The proposed theory
yields a new learning algorithm called Sharpley Q-learning (SHAQ), which
inherits the important merits of ordinary Q-learning but extends it to MARL. In
comparison with prior-arts, SHAQ has a much weaker assumption (MCG) that is
more compatible with real-world problems, but has superior explainability and
performance in many cases. We demonstrated SHAQ and verified the theoretic
claims on Predator-Prey and StarCraft Multi-Agent Challenge (SMAC).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15014</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15014</id><submitter>Lenny Renault</submitter><version version="v1"><date>Mon, 31 May 2021 14:53:12 GMT</date><size>108kb</size></version><title>Singing Language Identification using a Deep Phonotactic Approach</title><authors>Lenny Renault, Andrea Vaglio, Romain Hennequin</authors><categories>cs.SD cs.IR eess.AS</categories><comments>5 pages, 1 figure, ICASSP 2021</comments><journal-ref>ICASSP 2021 - 2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), pp. 271-275</journal-ref><doi>10.1109/ICASSP39728.2021.9414203</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Extensive works have tackled Language Identification (LID) in the speech
domain, however their application to the singing voice trails and performances
on Singing Language Identification (SLID) can be improved leveraging recent
progresses made in other singing related tasks. This work presents a modernized
phonotactic system for SLID on polyphonic music: phoneme recognition is
performed with a Connectionist Temporal Classification (CTC)-based acoustic
model trained with multilingual data, before language classification with a
recurrent model based on the phonemes estimation. The full pipeline is trained
and evaluated with a large and publicly available dataset, with unprecedented
performances. First results of SLID with out-of-set languages are also
presented.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15015</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15015</id><submitter>Marc Zeller</submitter><version version="v1"><date>Mon, 31 May 2021 14:54:05 GMT</date><size>398kb</size></version><title>Model-Based Reliability and Safety: Reducing the Complexity of Safety
  Analyses Using Component Fault Trees</title><authors>Kai Hoefig, Andreas Joanni, Marc Zeller, Francesco Montrone, Martin
  Rothfelder, Rakshith Amarnath, Peter Munk, Arne Nordmann</authors><categories>cs.SE</categories><journal-ref>2018 Annual Reliability and Maintainability Symposium (RAMS)</journal-ref><doi>10.1109/RAM.2018.8463058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of mission or safety critical software systems in many
application domains of embedded systems is continuously growing, and so is the
effort and complexity for reliability and safety analysis. Model driven
development is currently one of the key approaches to cope with increasing
development complexity, in general. Applying similar concepts to reliability,
availability, maintainability and safety (RAMS) analysis activities is a
promising approach to extend the advantages of model driven development to
safety engineering activities aiming at a reduction of development costs, a
higher product quality and a shorter time-to-market. Nevertheless, many
model-based safety or reliability engineering approaches aim at reducing the
analysis complexity but applications or case studies are rare. Therefore we
present here a large scale industrial case study which shows the benefits of
the application of component fault trees when it comes to complex safety
mechanisms. We compare the methodology of component fault trees against classic
fault trees and summarize benefits and drawbacks of both modeling
methodologies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15018</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15018</id><submitter>Giambattista Albora</submitter><version version="v1"><date>Mon, 31 May 2021 14:59:37 GMT</date><size>983kb</size></version><title>Product Progression: a machine learning approach to forecasting
  industrial upgrading</title><authors>Giambattista Albora, Luciano Pietronero, Andrea Tacchella, Andrea
  Zaccaria</authors><categories>cs.LG</categories><comments>17 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Economic complexity methods, and in particular relatedness measures, lack a
systematic evaluation and comparison framework. We argue that out-of-sample
forecast exercises should play this role, and we compare various machine
learning models to set the prediction benchmark. We find that the key object to
forecast is the activation of new products, and that tree-based algorithms
clearly overperform both the quite strong auto-correlation benchmark and the
other supervised algorithms. Interestingly, we find that the best results are
obtained in a cross-validation setting, when data about the predicted country
was excluded from the training set. Our approach has direct policy
implications, providing a quantitative and scientifically tested measure of the
feasibility of introducing a new product in a given country.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15021</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15021</id><submitter>Songlin Yang</submitter><version version="v1"><date>Mon, 31 May 2021 15:00:03 GMT</date><size>5383kb</size><source_type>D</source_type></version><title>Neural Bi-Lexicalized PCFG Induction</title><authors>Songlin Yang, Yanpeng Zhao, Kewei Tu</authors><categories>cs.CL</categories><comments>To appear in ACL 2021 main conference</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Neural lexicalized PCFGs (L-PCFGs) have been shown effective in grammar
induction. However, to reduce computational complexity, they make a strong
independence assumption on the generation of the child word and thus bilexical
dependencies are ignored. In this paper, we propose an approach to parameterize
L-PCFGs without making implausible independence assumptions. Our approach
directly models bilexical dependencies and meanwhile reduces both learning and
representation complexities of L-PCFGs. Experimental results on the English WSJ
dataset confirm the effectiveness of our approach in improving both running
speed and unsupervised parsing performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15022</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15022</id><submitter>Anum Talpur</submitter><version version="v1"><date>Mon, 31 May 2021 15:01:35 GMT</date><size>4716kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 13:38:15 GMT</date><size>1686kb</size></version><title>Reinforcement Learning-based Dynamic Service Placement in Vehicular
  Networks</title><authors>Anum Talpur and Mohan Gurusamy</authors><categories>cs.NI cs.LG</categories><comments>Accepted and presented in IEEE 93rd Vehicular Technology Conference
  VTC2021-Spring</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of technologies such as 5G and mobile edge computing has
enabled provisioning of different types of services with different resource and
service requirements to the vehicles in a vehicular network.The growing
complexity of traffic mobility patterns and dynamics in the requests for
different types of services has made service placement a challenging task. A
typical static placement solution is not effective as it does not consider the
traffic mobility and service dynamics. In this paper, we propose a
reinforcement learning-based dynamic (RL-Dynamic) service placement framework
to find the optimal placement of services at the edge servers while considering
the vehicle's mobility and dynamics in the requests for different types of
services. We use SUMO and MATLAB to carry out simulation experiments. In our
learning framework, for the decision module, we consider two alternative
objective functions-minimizing delay and minimizing edge server utilization. We
developed an ILP based problem formulation for the two objective functions. The
experimental results show that 1) compared to static service placement,
RL-based dynamic service placement achieves fair utilization of edge server
resources and low service delay, and 2) compared to delay-optimized placement,
server utilization optimized placement utilizes resources more effectively,
achieving higher fairness with lower edge-server utilization.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15023</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15023</id><submitter>Zolt\'an Zvara</submitter><version version="v1"><date>Mon, 31 May 2021 15:04:18 GMT</date><size>8346kb</size><source_type>D</source_type></version><title>System-aware dynamic partitioning for batch and streaming workloads</title><authors>Zolt\'an Zvara, P\'eter G.N. Szab\'o, Bal\'azs Barnab\'as L\'or\'ant
  and Andr\'as A. Bencz\'ur</authors><categories>cs.DC</categories><comments>14 pages, 8 figures</comments><acm-class>C.4; C.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  When processing data streams with highly skewed and nonstationary key
distributions, we often observe overloaded partitions when the hash
partitioning fails to balance data correctly. To avoid slow tasks that delay
the completion of the whole stage of computation, it is necessary to apply
adaptive, on-the-fly partitioning that continuously recomputes an optimal
partitioner, given the observed key distribution. While such solutions exist
for batch processing of static data sets and stateless stream processing, the
task is difficult for long-running stateful streaming jobs where key
distribution changes over time. Careful checkpointing and operator state
migration is necessary to change the partitioning while the operation is
running.
  Our key result is a lightweight on-the-fly Dynamic Repartitioning (DR) module
for distributed data processing systems (DDPS), including Apache Spark and
Flink, which improves the performance with negligible overhead. DR can
adaptively repartition data during execution using our Key Isolator Partitioner
(KIP). In our experiments with real workloads and power-law distributions, we
reach a speedup of 1.5-6 for a variety of Spark and Flink jobs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15024</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15024</id><submitter>Thanh Binh Nguyen</submitter><version version="v1"><date>Mon, 31 May 2021 15:04:43 GMT</date><size>878kb</size><source_type>D</source_type></version><title>OASIS: An Active Framework for Set Inversion</title><authors>Binh T. Nguyen, Duy M. Nguyen, Lam Si Tung Ho, Vu Dinh</authors><categories>cs.LG</categories><comments>13 pages, 8 figures</comments><journal-ref>Frontiers in Artificial Intelligence and Applications, 2018</journal-ref><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this work, we introduce a novel method for solving the set inversion
problem by formulating it as a binary classification problem. Aiming to develop
a fast algorithm that can work effectively with high-dimensional and
computationally expensive nonlinear models, we focus on active learning, a
family of new and powerful techniques which can achieve the same level of
accuracy with fewer data points compared to traditional learning methods.
Specifically, we propose OASIS, an active learning framework using Support
Vector Machine algorithms for solving the problem of set inversion. Our method
works well in high dimensions and its computational cost is relatively robust
to the increase of dimension. We illustrate the performance of OASIS by several
simulation studies and show that our algorithm outperforms VISIA, the
state-of-the-art method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15028</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15028</id><submitter>Gennaro Vessio Dr.</submitter><version version="v1"><date>Mon, 31 May 2021 15:09:05 GMT</date><size>11841kb</size><source_type>D</source_type></version><title>ArtGraph: Towards an Artistic Knowledge Graph</title><authors>Giovanna Castellano, Giovanni Sansaro, Gennaro Vessio</authors><categories>cs.CV</categories><comments>Submitted to DS2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents our ongoing work towards ArtGraph: an artistic knowledge
graph based on WikiArt and DBpedia. Automatic art analysis has seen an
ever-increasing interest from the pattern recognition and computer vision
community. However, most of the current work is mainly based solely on
digitized artwork images, sometimes supplemented with some metadata and textual
comments. A knowledge graph that integrates a rich body of information about
artworks, artists, painting schools, etc., in a unified structured framework
can provide a valuable resource for more powerful information retrieval and
knowledge discovery tools in the artistic domain.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15029</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15029</id><submitter>Andrea Fronzetti Colladon PhD</submitter><version version="v1"><date>Mon, 24 May 2021 14:14:04 GMT</date><size>766kb</size></version><title>Aristotle Said &quot;Happiness is a State of Activity&quot; -- Predicting Mood
  through Body Sensing with Smartwatches</title><authors>P. A. Gloor, A. Fronzetti Colladon, F. Grippa, P. Budner, J. Eirich</authors><categories>cs.HC cs.LG</categories><acm-class>I.2.0; H.4.0</acm-class><journal-ref>Journal of Systems Science and Systems Engineering 27(5), 586-612
  (2018)</journal-ref><doi>10.1007/s11518-018-5383-7</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We measure and predict states of Activation and Happiness using a body
sensing application connected to smartwatches. Through the sensors of
commercially available smartwatches we collect individual mood states and
correlate them with body sensing data such as acceleration, heart rate, light
level data, and location, through the GPS sensor built into the smartphone
connected to the smartwatch. We polled users on the smartwatch for seven weeks
four times per day asking for their mood state. We found that both Happiness
and Activation are negatively correlated with heart beats and with the levels
of light. People tend to be happier when they are moving more intensely and are
feeling less activated during weekends. We also found that people with a lower
Conscientiousness and Neuroticism and higher Agreeableness tend to be happy
more frequently. In addition, more Activation can be predicted by lower
Openness to experience and higher Agreeableness and Conscientiousness. Lastly,
we find that tracking people's geographical coordinates might play an important
role in predicting Happiness and Activation. The methodology we propose is a
first step towards building an automated mood tracking system, to be used for
better teamwork and in combination with social network analysis studies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15030</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15030</id><submitter>Chandresh Maurya</submitter><version version="v1"><date>Sat, 22 May 2021 07:03:50 GMT</date><size>1592kb</size><source_type>D</source_type></version><title>Digital Contact Tracing for Covid 19</title><authors>Chandresh Kumar Maurya, Seemandhar Jain, Vishal Thakre</authors><categories>cs.HC cs.CY cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The COVID19 pandemic created a worldwide emergency as it is estimated that
such a large number of infections are due to human-to-human transmission of the
COVID19. As a necessity, there is a need to track users who came in contact
with users having travel history, asymptomatic and not yet symptomatic, but
they can be in the future. To solve this problem, the present work proposes a
solution for contact tracing based on assisted GPS and cloud computing
technologies. An application is developed to collect each user's assisted GPS
coordinates once all the users install this application. This application
periodically sends assisted GPS data to the cloud. To determine which devices
are within the permissible limit of 5m, we perform clustering over assisted GPS
coordinates and track the clusters for about t mins to allow the measure of
spread. We assume that it takes around 3 or 5 mins to get the virus from an
infected object. For clustering, the proposed M way like tree data structure
stores the assisted GPS coordinates in degree, minute, and second format. Thus,
every user is mapped to a leaf node of the tree. We split the &quot;seconds&quot; part of
the assisted GPS location into m equal parts, which amount to d meter in
latitude(longitude). Hence, two users who are within d meter range will map to
the same leaf node. Thus, by mapping assisted GPS locations every t mins, we
can find out how many users came in contact with a particular user for at least
t mins. Our work's salient feature is that it runs in linear time O(n) for n
users in the static case, i.e., when users are not moving. We also propose a
variant of our solution to handle the dynamic case, that is, when users are
moving. Besides, the proposed solution offers potential hotspot detection and
safe-route recommendation as an additional feature, and proof of concept is
presented through experiments on simulated data of 10M users.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15032</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15032</id><submitter>Alexander Braun</submitter><version version="v1"><date>Mon, 31 May 2021 15:12:27 GMT</date><size>60kb</size></version><title>Truthful Mechanisms for Two-Sided Markets via Prophet Inequalities</title><authors>Alexander Braun and Thomas Kesselheim</authors><categories>cs.GT cs.DS</categories><comments>An extended abstract will appear at EC 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design novel mechanisms for welfare-maximization in two-sided markets.
That is, there are buyers willing to purchase items and sellers holding items
initially, both acting rationally and strategically in order to maximize
utility. Our mechanisms are designed based on a powerful correspondence between
two-sided markets and prophet inequalities. They satisfy individual
rationality, dominant-strategy incentive compatibility, budget-balance
constraints and give constant-factor approximations to the optimal social
welfare.
  We improve previous results in several settings: Our main focus is on matroid
double auctions, where the set of buyers who obtain an item needs to be
independent in a matroid. We construct two mechanisms, the first being a
$1/3$-approximation of the optimal social welfare satisfying strong
budget-balance and requiring the agents to trade in a customized order, the
second being a $1/2$-approximation, weakly budget-balanced and able to deal
with online arrival determined by an adversary. In addition, we construct
constant-factor approximations in two-sided markets when buyers need to fulfill
a knapsack constraint. Also, in combinatorial double auctions, where buyers
have valuation functions over item bundles instead of being interested in only
one item, using similar techniques, we design a mechanism which is a
$1/2$-approximation of the optimal social welfare, strongly budget-balanced and
can deal with online arrival of agents in an adversarial order.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15033</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15033</id><submitter>Mosha Chen</submitter><version version="v1"><date>Mon, 31 May 2021 15:12:49 GMT</date><size>651kb</size><source_type>D</source_type></version><title>DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph
  Construction</title><authors>Dejie Chang, Mosha Chen, Chaozhen Liu, Liping Liu, Dongdong Li, Wei
  Li, Fei Kong, Bangchang Liu, Xiaobin Luo, Ji Qi, Qiao Jin, Bin Xu</authors><categories>cs.CL cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Knowledge Graph has been proven effective in modeling structured information
and conceptual knowledge, especially in the medical domain. However, the lack
of high-quality annotated corpora remains a crucial problem for advancing the
research and applications on this task. In order to accelerate the research for
domain-specific knowledge graphs in the medical domain, we introduce DiaKG, a
high-quality Chinese dataset for Diabetes knowledge graph, which contains
22,050 entities and 6,890 relations in total. We implement recent typical
methods for Named Entity Recognition and Relation Extraction as a benchmark to
evaluate the proposed dataset thoroughly. Empirical results show that the DiaKG
is challenging for most existing methods and further analysis is conducted to
discuss future research direction for improvements. We hope the release of this
dataset can assist the construction of diabetes knowledge graphs and facilitate
AI-based applications.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15034</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15034</id><submitter>Fei Tang</submitter><version version="v1"><date>Mon, 31 May 2021 15:13:00 GMT</date><size>57kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 07:14:13 GMT</date><size>57kb</size><source_type>D</source_type></version><title>A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]</title><authors>Fei Tang, Michael Kopp</authors><categories>q-bio.NC cs.AI cs.CV cs.LG</categories><comments>1 page, 8 formulae</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In their recent paper titled &quot;Large Associative Memory Problem in
Neurobiology and Machine Learning&quot; [arXiv:2008.06996] the authors gave a
biologically plausible microscopic theory from which one can recover many dense
associative memory models discussed in the literature. We show that the layers
of the recent &quot;MLP-mixer&quot; [arXiv:2105.01601] as well as the essentially
equivalent model in [arXiv:2105.02723] are amongst them.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15035</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15035</id><submitter>Anum Talpur</submitter><version version="v1"><date>Mon, 31 May 2021 15:15:03 GMT</date><size>4092kb</size><source_type>D</source_type></version><title>Machine Learning for Security in Vehicular Networks: A Comprehensive
  Survey</title><authors>Anum Talpur and Mohan Gurusamy</authors><categories>cs.LG cs.CR cs.NI</categories><comments>Submitted in IEEE Communications Surveys &amp; Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Learning (ML) has emerged as an attractive and viable technique to
provide effective solutions for a wide range of application domains. An
important application domain is vehicular networks wherein ML-based approaches
are found to be very useful to address various problems. The use of wireless
communication between vehicular nodes and/or infrastructure makes it vulnerable
to different types of attacks. In this regard, ML and its variants are gaining
popularity to detect attacks and deal with different kinds of security issues
in vehicular communication. In this paper, we present a comprehensive survey of
ML-based techniques for different security issues in vehicular networks. We
first briefly introduce the basics of vehicular networks and different types of
communications. Apart from the traditional vehicular networks, we also consider
modern vehicular network architectures. We propose a taxonomy of security
attacks in vehicular networks and discuss various security challenges and
requirements. We classify the ML techniques developed in the literature
according to their use in vehicular network applications. We explain the
solution approaches and working principles of these ML techniques in addressing
various security challenges and provide insightful discussion. The limitations
and challenges in using ML-based methods in vehicular networks are discussed.
Finally, we present observations and lessons learned before we conclude our
work.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15037</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15037</id><submitter>Fuhui Zhou</submitter><version version="v1"><date>Mon, 31 May 2021 15:18:58 GMT</date><size>4839kb</size><source_type>D</source_type></version><title>A Novel Automatic Modulation Classification Scheme Based on Multi-Scale
  Networks</title><authors>Hao Zhang, Fuhui Zhou, Qihui Wu, Wei Wu, Rose Qingyang Hu</authors><categories>eess.SP cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automatic modulation classification enables intelligent communications and it
is of crucial importance in today's and future wireless communication networks.
Although many automatic modulation classification schemes have been proposed,
they cannot tackle the intra-class diversity problem caused by the dynamic
changes of the wireless communication environment. In order to overcome this
problem, inspired by face recognition, a novel automatic modulation
classification scheme is proposed by using the multi-scale network in this
paper. Moreover, a novel loss function that combines the center loss and the
cross entropy loss is exploited to learn both discriminative and separable
features in order to further improve the classification performance. Extensive
simulation results demonstrate that our proposed automatic modulation
classification scheme can achieve better performance than the benchmark schemes
in terms of the classification accuracy. The influence of the network
parameters and the loss function with the two-stage training strategy on the
classification accuracy of our proposed scheme are investigated.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15039</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15039</id><submitter>Luca Cardelli</submitter><version version="v1"><date>Mon, 31 May 2021 15:21:46 GMT</date><size>225kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 15:16:36 GMT</date><size>225kb</size></version><title>Sequenceable Event Recorders</title><authors>Luca Cardelli</authors><categories>cs.DS cs.ET</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With recent high-throughput technology we can synthesize large heterogeneous
collections of DNA structures, and also read them all out precisely in a single
procedure. Can we use these tools, not only to do things faster, but also to
devise new techniques and algorithms? In this paper we examine some DNA
algorithms that assume high-throughput synthesis and sequencing. We aim to
monitor, record, and read out the order in which a number $N$ of events occur,
using $N^2$ redundant detectors, and (after sequencing) reconstructing the
order by transitive reduction.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15041</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15041</id><submitter>Francisco Luis Giambelluca</submitter><version version="v1"><date>Mon, 31 May 2021 15:26:09 GMT</date><size>1173kb</size></version><title>Scorpion detection and classification systems based on computer vision
  and deep learning for health security purposes</title><authors>Francisco Luis Giambelluca, Marcelo A. Cappelletti, Jorge Osio, Luis
  A. Giambelluca</authors><categories>cs.CV cs.AI eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, two novel automatic and real-time systems for the detection
and classification of two genera of scorpions found in La Plata city
(Argentina) were developed using computer vision and deep learning techniques.
The object detection technique was implemented with two different methods, YOLO
(You Only Look Once) and MobileNet, based on the shape features of the
scorpions. High accuracy values of 88% and 91%, and high recall values of 90%
and 97%, have been achieved for both models, respectively, which guarantees
that they can successfully detect scorpions. In addition, the MobileNet method
has been shown to have excellent performance to detect scorpions within an
uncontrolled environment and to perform multiple detections. The MobileNet
model was also used for image classification in order to successfully
distinguish between dangerous scorpion (Tityus) and non-dangerous scorpion
(Bothriurus) with the purpose of providing a health security tool. Applications
for smartphones were developed, with the advantage of the portability of the
systems, which can be used as a help tool for emergency services, or for
biological research purposes. The developed systems can be easily scalable to
other genera and species of scorpions to extend the region where these
applications can be used.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15053</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15053</id><submitter>Tom Hosking</submitter><version version="v1"><date>Mon, 31 May 2021 15:37:38 GMT</date><size>8466kb</size><source_type>D</source_type></version><title>Factorising Meaning and Form for Intent-Preserving Paraphrasing</title><authors>Tom Hosking, Mirella Lapata</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a method for generating paraphrases of English questions that
retain the original intent but use a different surface form. Our model combines
a careful choice of training objective with a principled information
bottleneck, to induce a latent encoding space that disentangles meaning and
form. We train an encoder-decoder model to reconstruct a question from a
paraphrase with the same meaning and an exemplar with the same surface form,
leading to separated encoding spaces. We use a Vector-Quantized Variational
Autoencoder to represent the surface form as a set of discrete latent
variables, allowing us to use a classifier to select a different surface form
at test time. Crucially, our method does not require access to an external
source of target exemplars. Extensive experiments and a human evaluation show
that we are able to generate paraphrases with a better tradeoff between
semantic preservation and syntactic novelty compared to previous methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15054</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15054</id><submitter>Prithviraj Ammanabrolu</submitter><version version="v1"><date>Mon, 31 May 2021 15:39:41 GMT</date><size>508kb</size><source_type>D</source_type></version><title>Telling Stories through Multi-User Dialogue by Modeling Character
  Relations</title><authors>Wai Man Si, Prithviraj Ammanabrolu, Mark O. Riedl</authors><categories>cs.CL cs.AI</categories><comments>In Proceedings of SIGDIAL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores character-driven story continuation, in which the story
emerges through characters' first- and second-person narration as well as
dialogue -- requiring models to select language that is consistent with a
character's persona and their relationships with other characters while
following and advancing the story. We hypothesize that a multi-task model that
trains on character dialogue plus character relationship information improves
transformer-based story continuation. To this end, we extend the Critical Role
Dungeons and Dragons Dataset (Rameshkumar and Bailey, 2020) -- consisting of
dialogue transcripts of people collaboratively telling a story while playing
the role-playing game Dungeons and Dragons -- with automatically extracted
relationships between each pair of interacting characters as well as their
personas. A series of ablations lend evidence to our hypothesis, showing that
our multi-task model using character relationships improves story continuation
accuracy over strong baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15056</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15056</id><submitter>Hugo Lhachemi</submitter><version version="v1"><date>Mon, 31 May 2021 15:42:54 GMT</date><size>1466kb</size><source_type>D</source_type></version><title>Boundary Output Feedback Stabilization of State Delayed
  Reaction-Diffusion PDEs</title><authors>Hugo Lhachemi and Robert Shorten</authors><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the boundary output feedback stabilization of general 1-D
reaction-diffusion PDEs in the presence of a state delay in the reaction term.
The control input applies through a Robin boundary condition while the system
output is selected as a either Dirichlet or Neumann boundary trace. The control
strategy takes the form of a finite-dimensional observer-based controller with
feedback and observer gains that are computed in order to dominate the state
delayed term. For any arbitrarily given value of the state delay, we show the
exponential stability of the resulting closed-loop system provided the order of
the observer is selected large enough.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15057</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15057</id><submitter>Zhixing Ye</submitter><version version="v1"><date>Mon, 31 May 2021 15:43:04 GMT</date><size>10876kb</size><source_type>D</source_type></version><title>Dominant Patterns: Critical Features Hidden in Deep Neural Networks</title><authors>Zhixing Ye, Shaofei Qin, Sizhe Chen, Xiaolin Huang</authors><categories>cs.LG cs.CR cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we find the existence of critical features hidden in Deep
NeuralNetworks (DNNs), which are imperceptible but can actually dominate the
outputof DNNs. We call these features dominant patterns. As the name suggests,
for a natural image, if we add the dominant pattern of a DNN to it, the output
of this DNN is determined by the dominant pattern instead of the original
image, i.e., DNN's prediction is the same with the dominant pattern's. We
design an algorithm to find such patterns by pursuing the insensitivity in the
feature space. A direct application of the dominant patterns is the Universal
Adversarial Perturbations(UAPs). Numerical experiments show that the found
dominant patterns defeat state-of-the-art UAP methods, especially in label-free
settings. In addition, dominant patterns are proved to have the potential to
attack downstream tasks in which DNNs share the same backbone. We claim that
DNN-specific dominant patterns reveal some essential properties of a DNN and
are of great importance for its feature analysis and robustness enhancement.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15061</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15061</id><submitter>Eduardo Sebasti\'an</submitter><version version="v1"><date>Mon, 31 May 2021 15:49:03 GMT</date><size>174kb</size><source_type>D</source_type></version><title>All-in-one: Certifiable Optimal Distributed Kalman Filter under Unknown
  Correlations</title><authors>Eduardo Sebasti\'an and Eduardo Montijano and Carlos Sag\&quot;u\'es</authors><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal fusion of estimates in a Distributed Kalman Filter (DKF) requires
tracking of the complete network error covariance, which is a problem in terms
of memory and communication bandwidth. A scalable alternative is to fuse
estimates under unknown correlations, updating the local estimates and error
covariance matrix as the solution of an optimisation problem. Unfortunately,
this problem is NP-hard, forcing relaxations that lose optimality guarantees
over the original problem. Motivated by this, we present the first Certifiable
Optimal DKF (CO-DKF). Using only information from one-hop neighbours, CO-DKF
solves the optimal fusion of estimates under unknown correlations by a tight
Semidefinite Programming (SDP) relaxation. This particular relaxation allows to
certify locally and in real time if the solution from the relaxed problem is
the optimum of the original. In that case, we prove that CO-DKF is optimal in
the Mean Square Error (MSE) sense. Additionally, we demonstrate that CO-DKF is
a globally asymptotically stable estimator. Simulations show that CO-DKF
outperforms other state-of-the-art DKF algorithms, specially in sparse, highly
noisy setups.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15064</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15064</id><submitter>William Blanzeisky</submitter><version version="v1"><date>Mon, 31 May 2021 15:51:43 GMT</date><size>1546kb</size><source_type>D</source_type></version><title>Using Pareto Simulated Annealing to Address Algorithmic Bias in Machine
  Learning</title><authors>William Blanzeisky, P\'adraig Cunningham</authors><categories>cs.LG cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Algorithmic Bias can be due to bias in the training data or issues with the
algorithm itself. These algorithmic issues typically relate to problems with
model capacity and regularisation. This underestimation bias may arise because
the model has been optimised for good generalisation accuracy without any
explicit consideration of bias or fairness. In a sense, we should not be
surprised that a model might be biased when it hasn't been &quot;asked&quot; not to be.
In this paper, we consider including bias (underestimation) as an additional
criterion in model training. We present a multi-objective optimisation strategy
using Pareto Simulated Annealing that optimise for both balanced accuracy and
underestimation. We demonstrate the effectiveness of this strategy on one
synthetic and two real-world datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15065</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15065</id><submitter>Amar Prakash Azad</submitter><version version="v1"><date>Mon, 31 May 2021 15:51:44 GMT</date><size>3476kb</size><source_type>D</source_type></version><title>Picking Pearl From Seabed: Extracting Artefacts from Noisy Issue
  Triaging Collaborative Conversations for Hybrid Cloud Services</title><authors>Amar Prakash Azad, Supriyo Ghosh, Ajay Gupta, Harshit Kumar and
  Prateeti Mohapatra</authors><categories>cs.AI cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Site Reliability Engineers (SREs) play a key role in issue identification and
resolution. After an issue is reported, SREs come together in a virtual room
(collaboration platform) to triage the issue. While doing so, they leave behind
a wealth of information which can be used later for triaging similar issues.
However, usability of the conversations offer challenges due to them being i)
noisy and ii) unlabelled. This paper presents a novel approach for issue
artefact extraction from the noisy conversations with minimal labelled data. We
propose a combination of unsupervised and supervised model with minimum human
intervention that leverages domain knowledge to predict artefacts for a small
amount of conversation data and use that for fine-tuning an already pretrained
language model for artefact prediction on a large amount of conversation data.
Experimental results on our dataset show that the proposed ensemble of
unsupervised and supervised model is better than using either one of them
individually.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15069</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15069</id><submitter>Alex Nowak-Vila</submitter><version version="v1"><date>Mon, 31 May 2021 15:55:52 GMT</date><size>266kb</size><source_type>D</source_type></version><title>Max-Margin is Dead, Long Live Max-Margin!</title><authors>Alex Nowak-Vila, Alessandro Rudi, Francis Bach</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The foundational concept of Max-Margin in machine learning is ill-posed for
output spaces with more than two labels such as in structured prediction. In
this paper, we show that the Max-Margin loss can only be consistent to the
classification task under highly restrictive assumptions on the discrete loss
measuring the error between outputs. These conditions are satisfied by
distances defined in tree graphs, for which we prove consistency, thus being
the first losses shown to be consistent for Max-Margin beyond the binary
setting. We finally address these limitations by correcting the concept of
Max-Margin and introducing the Restricted-Max-Margin, where the maximization of
the loss-augmented scores is maintained, but performed over a subset of the
original domain. The resulting loss is also a generalization of the binary
support vector machine and it is consistent under milder conditions on the
discrete loss.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15071</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15071</id><submitter>Wei-Jen Ko</submitter><version version="v1"><date>Mon, 31 May 2021 16:01:18 GMT</date><size>617kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 03:21:36 GMT</date><size>617kb</size><source_type>D</source_type></version><title>Adapting High-resource NMT Models to Translate Low-resource Related
  Languages without Parallel Data</title><authors>Wei-Jen Ko, Ahmed El-Kishky, Adithya Renduchintala, Vishrav Chaudhary,
  Naman Goyal, Francisco Guzm\'an, Pascale Fung, Philipp Koehn, Mona Diab</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The scarcity of parallel data is a major obstacle for training high-quality
machine translation systems for low-resource languages. Fortunately, some
low-resource languages are linguistically related or similar to high-resource
languages; these related languages may share many lexical or syntactic
structures. In this work, we exploit this linguistic overlap to facilitate
translating to and from a low-resource language with only monolingual data, in
addition to any parallel data in the related high-resource language. Our
method, NMT-Adapt, combines denoising autoencoding, back-translation and
adversarial objectives to utilize monolingual data for low-resource adaptation.
We experiment on 7 languages from three different language families and show
that our technique significantly improves translation into low-resource
language compared to other translation baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15074</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15074</id><submitter>Sergio Contreras</submitter><version version="v1"><date>Mon, 31 May 2021 16:02:01 GMT</date><size>275kb</size><source_type>D</source_type></version><title>Detecting Fetal Alcohol Spectrum Disorder in children using Artificial
  Neural Network</title><authors>Vannessa de J. Duarte, Paul Leger, Sergio Contreras and Hiroaki Fukuda</authors><categories>cs.LG cs.NE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fetal alcohol spectrum disorder (FASD) is a syndrome whose only difference
compared to other children's conditions is the mother's alcohol consumption
during pregnancy. An earlier diagnosis of FASD improving the quality of life of
children and adolescents. For this reason, this study focus on evaluating the
use of the artificial neural network (ANN) to classify children with FASD and
explore how accurate it is. ANN has been used to diagnose cancer, diabetes, and
other diseases in the medical area, being a tool that presents good results.
The data used is from a battery of tests from children for 5-18 years old
(include tests of psychometric, saccade eye movement, and diffusion tensor
imaging (DTI)). We study the different configurations of ANN with dense layers.
The first one predicts 75\% of the outcome correctly for psychometric data. The
others models include a feature layer, and we used it to predict FASD using
every test individually. The models accurately predict over 70\% of the cases,
and psychometric and memory guides predict over 88\% accuracy. The results
suggest that the ANN approach is a competitive and efficient methodology to
detect FASD. However, we could be careful in used as a diagnostic technique.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15075</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15075</id><submitter>Yulin Wang</submitter><version version="v1"><date>Mon, 31 May 2021 16:04:10 GMT</date><size>7904kb</size><source_type>D</source_type></version><title>Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with
  Adaptive Sequence Length</title><authors>Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, Gao Huang</authors><categories>cs.CV cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vision Transformers (ViT) have achieved remarkable success in large-scale
image recognition. They split every 2D image into a fixed number of patches,
each of which is treated as a token. Generally, representing an image with more
tokens would lead to higher prediction accuracy, while it also results in
drastically increased computational cost. To achieve a decent trade-off between
accuracy and speed, the number of tokens is empirically set to 16x16. In this
paper, we argue that every image has its own characteristics, and ideally the
token number should be conditioned on each individual input. In fact, we have
observed that there exist a considerable number of &quot;easy&quot; images which can be
accurately predicted with a mere number of 4x4 tokens, while only a small
fraction of &quot;hard&quot; ones need a finer representation. Inspired by this
phenomenon, we propose a Dynamic Transformer to automatically configure a
proper number of tokens for each input image. This is achieved by cascading
multiple Transformers with increasing numbers of tokens, which are sequentially
activated in an adaptive fashion at test time, i.e., the inference is
terminated once a sufficiently confident prediction is produced. We further
design efficient feature reuse and relationship reuse mechanisms across
different components of the Dynamic Transformer to reduce redundant
computations. Extensive empirical results on ImageNet, CIFAR-10, and CIFAR-100
demonstrate that our method significantly outperforms the competitive baselines
in terms of both theoretical computational efficiency and practical inference
speed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15076</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15076</id><submitter>Xiujun Shu</submitter><version version="v1"><date>Mon, 31 May 2021 16:05:51 GMT</date><size>7217kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 02:29:58 GMT</date><size>7218kb</size><source_type>D</source_type></version><title>Large-Scale Spatio-Temporal Person Re-identification: Algorithm and
  Benchmark</title><authors>Xiujun Shu, Xiao Wang, Shiliang Zhang, Xianghao Zhang, Yuanqi Chen, Ge
  Li, Qi Tian</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person re-identification (re-ID) in the scenario with large spatial and
temporal spans has not been fully explored. This is partially because that,
existing benchmark datasets were mainly collected with limited spatial and
temporal ranges, e.g., using videos recorded in a few days by cameras in a
specific region of the campus. Such limited spatial and temporal ranges make it
hard to simulate the difficulties of person re-ID in real scenarios. In this
work, we contribute a novel Large-scale Spatio-Temporal (LaST) person re-ID
dataset, including 10,860 identities with more than 224k images. Compared with
existing datasets, LaST presents more challenging and high-diversity reID
settings, and significantly larger spatial and temporal ranges. For instance,
each person can appear in different cities or countries, and in various time
slots from daytime to night, and in different seasons from spring to winter. To
our best knowledge, LaST is a novel person re-ID dataset with the largest
spatiotemporal ranges. Based on LaST, we verified its challenge by conducting a
comprehensive performance evaluation of 14 re-ID algorithms. We further propose
an easy-to-implement baseline that works well on such challenging re-ID
setting. We also verified that models pre-trained on LaST can generalize well
on existing datasets with short-term and cloth-changing scenarios. We expect
LaST to inspire future works toward more realistic and challenging re-ID tasks.
More information about the dataset is available at
https://github.com/shuxjweb/last.git.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15077</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15077</id><submitter>Fuxiang Tan</submitter><version version="v1"><date>Mon, 31 May 2021 16:06:02 GMT</date><size>2774kb</size><source_type>D</source_type></version><title>SDNet: mutil-branch for single image deraining using swin</title><authors>Fuxiang Tan, YuTing Kong, Yingying Fan, Feng Liu, Daxin Zhou, Hao
  zhang, Long Chen, Liang Gao and Yurong Qian</authors><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rain streaks degrade the image quality and seriously affect the performance
of subsequent computer vision tasks, such as autonomous driving, social
security, etc. Therefore, removing rain streaks from a given rainy images is of
great significance. Convolutional neural networks(CNN) have been widely used in
image deraining tasks, however, the local computational characteristics of
convolutional operations limit the development of image deraining tasks.
Recently, the popular transformer has global computational features that can
further facilitate the development of image deraining tasks. In this paper, we
introduce Swin-transformer into the field of image deraining for the first time
to study the performance and potential of Swin-transformer in the field of
image deraining. Specifically, we improve the basic module of Swin-transformer
and design a three-branch model to implement single-image rain removal. The
former implements the basic rain pattern feature extraction, while the latter
fuses different features to further extract and process the image features. In
addition, we employ a jump connection to fuse deep features and shallow
features. In terms of experiments, the existing public dataset suffers from
image duplication and relatively homogeneous background. So we propose a new
dataset Rain3000 to validate our model. Therefore, we propose a new dataset
Rain3000 for validating our model. Experimental results on the publicly
available datasets Rain100L, Rain100H and our dataset Rain3000 show that our
proposed method has performance and inference speed advantages over the current
mainstream single-image rain streaks removal models.The source code will be
available at https://github.com/H-tfx/SDNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15078</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15078</id><submitter>Meng-Hao Guo</submitter><version version="v1"><date>Mon, 31 May 2021 16:08:46 GMT</date><size>91kb</size><source_type>D</source_type></version><title>Can Attention Enable MLPs To Catch Up With CNNs?</title><authors>Meng-Hao Guo, Zheng-Ning Liu, Tai-Jiang Mu, Dun Liang, Ralph R. Martin
  and Shi-Min Hu</authors><categories>cs.CV cs.LG</categories><comments>Computational Visual Media, 2021, accepted. 4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first week of May, 2021, researchers from four different institutions:
Google, Tsinghua University, Oxford University and Facebook, shared their
latest work [16, 7, 12, 17] on arXiv.org almost at the same time, each
proposing new learning architectures, consisting mainly of linear layers,
claiming them to be comparable, or even superior to convolutional-based models.
This sparked immediate discussion and debate in both academic and industrial
communities as to whether MLPs are sufficient, many thinking that learning
architectures are returning to MLPs. Is this true? In this perspective, we give
a brief history of learning architectures, including multilayer perceptrons
(MLPs), convolutional neural networks (CNNs) and transformers. We then examine
what the four newly proposed architectures have in common. Finally, we give our
views on challenges and directions for new learning architectures, hoping to
inspire future research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15079</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15079</id><submitter>Luong Phan Luc</submitter><version version="v1"><date>Mon, 31 May 2021 16:09:26 GMT</date><size>2939kb</size><source_type>D</source_type></version><title>SA2SL: From Aspect-Based Sentiment Analysis to Social Listening System
  for Business Intelligence</title><authors>Luong Luc Phan, Phuc Huynh Pham, Kim Thi-Thanh Nguyen, Tham Thi
  Nguyen, Sieu Khai Huynh, Luan Thanh Nguyen, Tin Van Huynh, and Kiet Van
  Nguyen</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we present a process of building a social listening system
based on aspect-based sentiment analysis in Vietnamese from creating a dataset
to building a real application. Firstly, we create UIT-ViSFD, a Vietnamese
Smartphone Feedback Dataset as a new benchmark corpus built based on a strict
annotation schemes for evaluating aspect-based sentiment analysis, consisting
of 11,122 human-annotated comments for mobile e-commerce, which is freely
available for research purposes. We also present a proposed approach based on
the Bi-LSTM architecture with the fastText word embeddings for the Vietnamese
aspect based sentiment task. Our experiments show that our approach achieves
the best performances with the F1-score of 84.48% for the aspect task and
63.06% for the sentiment task, which performs several conventional machine
learning and deep learning systems. Last but not least, we build SA2SL, a
social listening system based on the best performance model on our dataset,
which will inspire more social listening systems in future.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15080</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15080</id><submitter>Geoffrey Messier</submitter><version version="v1"><date>Mon, 31 May 2021 16:09:43 GMT</date><size>28kb</size></version><title>Predicting Chronic Homelessness: The Importance of Comparing Algorithms
  using Client Histories</title><authors>Geoffrey G. Messier, Caleb John, Ayush Malik</authors><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper investigates how to best compare algorithms for predicting chronic
homelessness for the purpose of identifying good candidates for housing
programs. Predictive methods can rapidly refer potentially chronic shelter
users to housing but also sometimes incorrectly identify individuals who will
not become chronic (false positives). We use shelter access histories to
demonstrate that these false positives are often still good candidates for
housing. Using this approach, we compare a simple threshold method for
predicting chronic homelessness to the more complex logistic regression and
neural network algorithms. While traditional binary classification performance
metrics show that the machine learning algorithms perform better than the
threshold technique, an examination of the shelter access histories of the
cohorts identified by the three algorithms show that they select groups with
very similar characteristics. This has important implications for resource
constrained not-for-profit organizations since the threshold technique can be
implemented using much simpler information technology infrastructure than the
machine learning algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15081</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15081</id><submitter>Alexander Wein</submitter><version version="v1"><date>Mon, 31 May 2021 16:10:49 GMT</date><size>41kb</size></version><title>Optimal Spectral Recovery of a Planted Vector in a Subspace</title><authors>Cheng Mao, Alexander S. Wein</authors><categories>math.ST cs.DS stat.ML stat.TH</categories><comments>47 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering a planted vector $v$ in an $n$-dimensional random subspace of
$\mathbb{R}^N$ is a generic task related to many problems in machine learning
and statistics, such as dictionary learning, subspace recovery, and principal
component analysis. In this work, we study computationally efficient estimation
and detection of a planted vector $v$ whose $\ell_4$ norm differs from that of
a Gaussian vector with the same $\ell_2$ norm. For instance, in the special
case of an $N \rho$-sparse vector $v$ with Rademacher nonzero entries, our
results include the following:
  (1) We give an improved analysis of (a slight variant of) the spectral method
proposed by Hopkins, Schramm, Shi, and Steurer, showing that it approximately
recovers $v$ with high probability in the regime $n \rho \ll \sqrt{N}$. In
contrast, previous work required either $\rho \ll 1/\sqrt{n}$ or $n \sqrt{\rho}
\lesssim \sqrt{N}$ for polynomial-time recovery. Our result subsumes both of
these conditions (up to logarithmic factors) and also treats the dense case
$\rho = 1$ which was not previously considered.
  (2) Akin to $\ell_\infty$ bounds for eigenvector perturbation, we establish
an entrywise error bound for the spectral estimator via a leave-one-out
analysis, from which it follows that thresholding recovers $v$ exactly.
  (3) We study the associated detection problem and show that in the regime $n
\rho \gg \sqrt{N}$, any spectral method from a large class (and more generally,
any low-degree polynomial of the input) fails to detect the planted vector.
This establishes optimality of our upper bounds and offers evidence that no
polynomial-time algorithm can succeed when $n \rho \gg \sqrt{N}$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15082</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15082</id><submitter>An Yang</submitter><version version="v1"><date>Mon, 31 May 2021 16:12:44 GMT</date><size>990kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 15:28:15 GMT</date><size>2349kb</size><source_type>D</source_type></version><title>Exploring Sparse Expert Models and Beyond</title><authors>An Yang, Junyang Lin, Rui Men, Chang Zhou, Le Jiang, Xianyan Jia, Ang
  Wang, Jie Zhang, Jiamang Wang, Yong Li, Di Zhang, Wei Lin, Lin Qu, Jingren
  Zhou, Hongxia Yang</authors><categories>cs.LG cs.CL</categories><comments>11 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Mixture-of-Experts (MoE) models can achieve promising results with outrageous
large amount of parameters but constant computation cost, and thus it has
become a trend in model scaling. Still it is a mystery how MoE layers bring
quality gains by leveraging the parameters with sparse activation. In this
work, we investigate several key factors in sparse expert models. We observe
that load imbalance may not be a significant problem affecting model quality,
contrary to the perspectives of recent studies, while the number of sparsely
activated experts $k$ and expert capacity $C$ in top-$k$ routing can
significantly make a difference in this context. Furthermore, we take a step
forward to propose a simple method called expert prototyping that splits
experts into different prototypes and applies $k$ top-$1$ routing. This
strategy improves the model quality but maintains constant computational costs,
and our further exploration on extremely large-scale models reflects that it is
more effective in training larger models. We push the model scale to over $1$
trillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in
comparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model
achieves substantial speedup in convergence over the same-size baseline.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15086</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15086</id><submitter>Gianira N. Alfarano</submitter><version version="v1"><date>Mon, 31 May 2021 16:15:07 GMT</date><size>23kb</size></version><title>Sum-rank product codes and bounds on the minimum distance</title><authors>Gianira N. Alfarano, F.J. Lobillo, Alessandro Neri, Antonia
  Wachter-Zeh</authors><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tensor product of one code endowed with the Hamming metric and one
endowed with the rank metric is analyzed. This gives a code which naturally
inherits the sum-rank metric. Specializing to the product of a cyclic code and
a skew-cyclic code, the resulting code turns out to belong to the recently
introduced family of cyclic-skew-cyclic. A group theoretical description of
these codes is given, after investigating the semilinear isometries in the
sum-rank metric. Finally, a generalization of the Roos and the Hartmann-Tzeng
bounds for the sum rank-metric is established, as well as a new lower bound on
the minimum distance of one of the two codes constituting the product code.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15087</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15087</id><submitter>Eleftheria Briakou</submitter><version version="v1"><date>Mon, 31 May 2021 16:15:35 GMT</date><size>11043kb</size><source_type>D</source_type></version><title>Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences
  on Neural Machine Translation</title><authors>Eleftheria Briakou and Marine Carpuat</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While it has been shown that Neural Machine Translation (NMT) is highly
sensitive to noisy parallel training samples, prior work treats all types of
mismatches between source and target as noise. As a result, it remains unclear
how samples that are mostly equivalent but contain a small number of
semantically divergent tokens impact NMT training. To close this gap, we
analyze the impact of different types of fine-grained semantic divergences on
Transformer models. We show that models trained on synthetic divergences output
degenerated text more frequently and are less confident in their predictions.
Based on these findings, we introduce a divergent-aware NMT framework that uses
factors to help NMT recover from the degradation caused by naturally occurring
divergences, improving both translation quality and model calibration on EN-FR
tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15089</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15089</id><submitter>Jiangning Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 16:20:03 GMT</date><size>4125kb</size><source_type>D</source_type></version><title>Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model</title><authors>Jiangning Zhang, Chao Xu, Jian Li, Wenzhou Chen, Yabiao Wang, Ying
  Tai, Shuo Chen, Chengjie Wang, Feiyue Huang, Yong Liu</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by biological evolution, we explain the rationality of Vision
Transformer by analogy with the proven practical Evolutionary Algorithm (EA)
and derive that both of them have consistent mathematical representation.
Analogous to the dynamic local population in EA, we improve the existing
transformer structure and propose a more efficient EAT model, and design
task-related heads to deal with different tasks more flexibly. Moreover, we
introduce the spatial-filling curve into the current vision transformer to
sequence image data into a uniform sequential format. Thus we can design a
unified EAT framework to address multi-modal tasks, separating the network
architecture from the data format adaptation. Our approach achieves
state-of-the-art results on the ImageNet classification task compared with
recent vision transformer works while having smaller parameters and greater
throughput. We further conduct multi-model tasks to demonstrate the superiority
of the unified EAT, e.g., Text-Based Image Retrieval, and our approach improves
the rank-1 by +3.7 points over the baseline on the CSS dataset.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15093</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15093</id><submitter>Anuj Rai</submitter><version version="v1"><date>Mon, 31 May 2021 16:22:33 GMT</date><size>1500kb</size><source_type>D</source_type></version><title>Pho(SC)Net: An Approach Towards Zero-shot Word Image Recognition in
  Historical Documents</title><authors>Anuj Rai, Narayanan C. Krishnan, and Sukalpa Chanda</authors><categories>cs.CV</categories><comments>Published at 16th International Conference on Document Analysis and
  Recognition (ICDAR 2021)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Annotating words in a historical document image archive for word image
recognition purpose demands time and skilled human resource (like historians,
paleographers). In a real-life scenario, obtaining sample images for all
possible words is also not feasible. However, Zero-shot learning methods could
aptly be used to recognize unseen/out-of-lexicon words in such historical
document images. Based on previous state-of-the-art methods for word spotting
and recognition, we propose a hybrid representation that considers the
character's shape appearance to differentiate between two different words and
has shown to be more effective in recognizing unseen words. This representation
has been termed as Pyramidal Histogram of Shapes (PHOS), derived from PHOC,
which embeds information about the occurrence and position of characters in the
word. Later, the two representations are combined and experiments were
conducted to examine the effectiveness of an embedding that has properties of
both PHOS and PHOC. Encouraging results were obtained on two publicly available
historical document datasets and one synthetic handwritten dataset, which
justifies the efficacy of &quot;Phos&quot; and the combined &quot;Pho(SC)&quot; representation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15094</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15094</id><submitter>Michael Horry Mr</submitter><version version="v1"><date>Tue, 20 Apr 2021 03:49:48 GMT</date><size>707kb</size></version><title>Systematic investigation into generalization of COVID-19 CT deep
  learning models with Gabor ensemble for lung involvement scoring</title><authors>Michael J. Horry, Subrata Chakraborty, Biswajeet Pradhan, Maryam
  Fallahpoor, Chegeni Hossein, Manoranjan Paul</authors><categories>cs.CV cs.LG eess.IV</categories><comments>39 Pages, 8 figures, 14 tables comparing the generalization of
  COVID-19 CT Deep Learning Models</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The COVID-19 pandemic has inspired unprecedented data collection and computer
vision modelling efforts worldwide, focusing on diagnosis and stratification of
COVID-19 from medical images. Despite this large-scale research effort, these
models have found limited practical application due in part to unproven
generalization of these models beyond their source study. This study
investigates the generalizability of key published models using the publicly
available COVID-19 Computed Tomography data through cross dataset validation.
We then assess the predictive ability of these models for COVID-19 severity
using an independent new dataset that is stratified for COVID-19 lung
involvement. Each inter-dataset study is performed using histogram
equalization, and contrast limited adaptive histogram equalization with and
without a learning Gabor filter. The study shows high variability in the
generalization of models trained on these datasets due to varied sample image
provenances and acquisition processes amongst other factors. We show that under
certain conditions, an internally consistent dataset can generalize well to an
external dataset despite structural differences between these datasets with f1
scores up to 86%. Our best performing model shows high predictive accuracy for
lung involvement score for an independent dataset for which expertly labelled
lung involvement stratification is available. Creating an ensemble of our best
model for disease positive prediction with our best model for disease negative
prediction using a min-max function resulted in a superior model for lung
involvement prediction with average predictive accuracy of 75% for zero lung
involvement and 96% for 75-100% lung involvement with almost linear
relationship between these stratifications.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15096</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15096</id><submitter>Shu Sun Dr.</submitter><version version="v1"><date>Thu, 1 Apr 2021 17:42:56 GMT</date><size>1764kb</size></version><title>Small-Scale Spatial-Temporal Correlation Modeling for Reconfigurable
  Intelligent Surfaces</title><authors>Shu Sun, Hangsong Yan</authors><categories>cs.NI cs.ET eess.SP</categories><comments>14 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reconfigurable intelligent surface (RIS) is an emerging promising
candidate technology for the sixth-generation wireless networks, where the
element spacing is usually of sub-wavelength. Only limited knowledge, however,
has been gained about the spatial-temporal correlation behavior among the
elements in an RIS. In this paper, we investigate the joint spatial-temporal
correlation models for an RIS in a wireless communication system. Joint
small-scale spatial-temporal correlation functions are provided and analyzed
for both ideal isotropic scattering and more practical non-isotropic scattering
environments, where the latter is studied by employing an angular distribution
derived from real-world millimeter-wave measurements. Analytical and simulation
results demonstrate that the joint spatial-temporal correlation can be
represented by a four-dimensional sinc function under isotropic scattering,
while the correlation is generally stronger with more fluctuation for
non-isotropic scattering with various motion directions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15097</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15097</id><submitter>Yueyan Chu</submitter><version version="v1"><date>Thu, 1 Apr 2021 02:30:19 GMT</date><size>2812kb</size><source_type>D</source_type></version><title>Multiple Sources Localization with Sparse Recovery under Log-normal
  Shadow Fading</title><authors>Yueyan Chu, Kangyong You, Wenbin Guo</authors><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization based on received signal strength (RSS) has drawn great interest
in the wireless sensor network (WSN). In this paper, we investigate the
RSS-based multi-sources localization problem with unknown transmitted power
under shadow fading. The log-normal shadowing effect is approximated through
Fenton-Wilkinson (F-W) method and maximum likelihood estimation is adopted to
optimize the RSS-based multiple sources localization problem. Moreover, we
exploit a sparse recovery and weighted average of candidates (SR-WAC) based
method to set up an initiation, which can efficiently approach a superior local
optimal solution. It is shown from the simulation results that the proposed
method has a much higher localization accuracy and outperforms the other
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15098</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15098</id><submitter>Yongxin Liu</submitter><version version="v1"><date>Thu, 8 Apr 2021 03:31:50 GMT</date><size>6836kb</size><source_type>D</source_type></version><title>Zero-bias Deep Learning Enabled Quick and Reliable Abnormality Detection
  in IoT</title><authors>Yongxin Liu, Jian Wang, Jianqiang Li, Shuteng Niu, Houbing Song</authors><categories>cs.NI cs.LG cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abnormality detection is essential to the performance of safety-critical and
latency-constrained systems. However, as systems are becoming increasingly
complicated with a large quantity of heterogeneous data, conventional
statistical change point detection methods are becoming less effective and
efficient. Although Deep Learning (DL) and Deep Neural Networks (DNNs) are
increasingly employed to handle heterogeneous data, they still lack theoretic
assurable performance and explainability. This paper integrates zero-bias DNN
and Quickest Event Detection algorithms to provide a holistic framework for
quick and reliable detection of both abnormalities and time-dependent abnormal
events in the Internet of Things (IoT). We first use the zero-bias dense layer
to increase the explainability of DNN. We provide a solution to convert
zero-bias DNN classifiers into performance assured binary abnormality
detectors. Using the converted abnormality detector, we then present a
sequential quickest detection scheme that provides the theoretically assured
lowest abnormal event detection delay under false alarm constraints. Finally,
we demonstrate the effectiveness of the framework using both massive signal
records from real-world aviation communication systems and simulated data. Code
and data of our work is available at
\url{https://github.com/pcwhy/AbnormalityDetectionInZbDNN}
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15100</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15100</id><submitter>Suman Kumar</submitter><version version="v1"><date>Thu, 15 Apr 2021 20:32:54 GMT</date><size>2062kb</size><source_type>D</source_type></version><title>Skin-Health Monitoring system using a Wireless Body Area Network</title><authors>Suman Kumar, Kazi Amanul Islam Siddiqui, Mukesh Kumary</authors><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  A new class of sensing paradigm known as lab-onskin where stretchable and
flexible smart sensor devices are integrated into the skin, provides direct
monitoring and diagnostic interfaces to the body. Distributed lab-on-skin
wireless sensors have the ability to provide continuous long term assessment of
the skin health. This paper proposes a distributed skin health monitoring
system using a wireless body area network. The system is responsive to the
dynamic changes in the skin health, and remotely reports on the same. The
proposed algorithm detects the abnormal skin and creates an energy efficient
data aggregation tree covering the affected area while putting the unnecessary
sensors to sleep mode. The algorithm responds to the changing conditions of the
skin by dynamically adapting the size and shape of the monitoring trees to that
of the abnormal skin areas thus providing a comprehensive monitoring.
Simulation results demonstrate the application and utility of the proposed
algorithm for changing wound shapes and sizes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15101</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15101</id><submitter>Saeed Ghadiri</submitter><version version="v1"><date>Mon, 19 Apr 2021 10:05:33 GMT</date><size>623kb</size></version><title>Anchor Nodes Positioning for Self-localization in Wireless Sensor
  Networks using Belief Propagation and Evolutionary Algorithms</title><authors>Saeed Ghadiri</authors><categories>cs.NI cs.AI eess.SP</categories><comments>5 pages, 12 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Locating each node in a wireless sensor network is essential for starting the
monitoring job and sending information about the area. One method that has been
used in hard and inaccessible environments is randomly scattering each node in
the area. In order to reduce the cost of using GPS at each node, some nodes
should be equipped with GPS (anchors), Then using the belief propagation
algorithm, locate other nodes. The number of anchor nodes must be reduced since
they are expensive. Furthermore, the location of these nodes affects the
algorithm's performance. Using multi-objective optimization, an algorithm is
introduced in this paper that minimizes the estimated location error and the
number of anchor nodes. According to simulation results, This algorithm
proposes a set of solutions with less energy consumption and less error than
similar algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15102</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15102</id><submitter>Chathuranga M. Wijerathna Basnayaka</submitter><version version="v1"><date>Mon, 19 Apr 2021 10:48:38 GMT</date><size>322kb</size></version><title>Age of Information in an URLLC-enabled Decode-and-Forward Wireless
  Communication System</title><authors>Chathuranga M. Wijerathna Basnayaka, Dushantha Nalin K. Jayakody,
  Tharindu D. Ponnimbaduge Perera, Moises Vidal Ribeiro</authors><categories>cs.NI cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Age of Information (AoI) measures the freshness of data in mission critical
Internet-of-Things (IoT) applications i.e., industrial internet, intelligent
transportation systems etc. In this paper, a new system model is proposed to
estimate the average AoI (AAoI) in an ultra-reliable low latency communication
(URLLC) enabled wireless communication system with decodeand-forward relay
scheme over the quasi-static Rayleigh block fading channels. Short packet
communication scheme is used to meet both reliability and latency requirements
of the proposed wireless network. By resorting finite block length information
theory, queuing theory and stochastic processes, a closed-form expression for
AAoI is obtained. Finally, the impact of the system parameters, such as update
generation rate, block length and block length allocation factor on the AAoI
are investigated. All results are validated by the numerical results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15103</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15103</id><submitter>Krishna Sivalingam</submitter><version version="v1"><date>Wed, 21 Apr 2021 05:40:07 GMT</date><size>767kb</size><source_type>D</source_type></version><title>Applications of Artificial Intelligence, Machine Learning and related
  techniques for Computer Networking Systems</title><authors>Krishna M. Sivalingam</authors><categories>cs.NI cs.LG</categories><comments>38 pages</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This article presents a primer/overview of applications of Artificial
Intelligence and Machine Learning (AI/ML) techniques to address problems in the
domain of computer networking. In particular, the techniques have been used to
support efficient and accurate traffic prediction, traffic classification,
anomaly detection, network management, network security, network resource
allocation and optimization, network scheduling algorithms, fault diagnosis and
many more such applications. The article first summarizes some of the key
networking concepts and a few representative machine learning techniques and
algorithms. The article then presents details regarding the availability of
data sets for networking applications and machine learning software and
toolkits for processing these data sets. Highlights of some of the standards
activities, pursued by ITU-T and ETSI, which are related to AI/ML for
networking, are also presented. Finally, the article discusses a small set of
representative networking problems where AI/ML techniques have been
successfully applied.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15105</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15105</id><submitter>Davide Callegaro</submitter><version version="v1"><date>Thu, 22 Apr 2021 05:15:44 GMT</date><size>18335kb</size></version><title>SeReMAS: Self-Resilient Mobile AutonomousSystems Through Predictive Edge
  Computing</title><authors>Davide Callegaro and Marco Levorato and Francesco Restuccia</authors><categories>cs.NI cs.DC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edge computing enables Mobile Autonomous Systems (MASs) to execute continuous
streams of heavy-duty mission-critical processing tasks, such as real-time
obstacle detection and navigation. However, in practical applications, erratic
patterns in channel quality, network load, and edge server load can interrupt
the task flow execution, which necessarily leads to severe disruption of the
system's key operations. Existing work has mostly tackled the problem with
reactive approaches, which cannot guarantee task-level reliability. Conversely,
in this paper we focus on learning-based predictive edge computing to achieve
self-resilient task offloading. By conducting a preliminary experimental
evaluation, we show that there is no dominant feature that can predict the
edge-MAS system reliability, which calls for an ensemble and selection of
weaker features. To tackle the complexity of the problem, we propose SeReMAS, a
data-driven optimization framework. We first mathematically formulate a
Redundant Task Offloading Problem (RTOP), where a MAS may connect to multiple
edge servers for redundancy, and needs to select which server(s) to transmit
its computing tasks in order to maximize the probability of task execution
while minimizing channel and edge resource utilization. We then create a
predictor based on Deep Reinforcement Learning (DRL), which produces the
optimum task assignment based on application-, network- and telemetry-based
features. We prototype SeReMAS on a testbed composed by a drone, mounting a
PixHawk flight controller, a Jetson Nano board, and three 802.11n WiFi
interfaces. We extensively evaluate SeReMAS by considering an application where
one drone offloads high-resolution images for real-time analysis to three edge
servers on the ground. Experimental results show that SeReMAS improves task
execution probability by $17\%$ with respect to existing reactive-based
approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15106</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15106</id><submitter>Shuanghong Shen</submitter><version version="v1"><date>Thu, 6 May 2021 13:05:55 GMT</date><size>2136kb</size><source_type>D</source_type></version><version version="v2"><date>Tue, 1 Jun 2021 04:43:30 GMT</date><size>2136kb</size><source_type>D</source_type></version><title>A Survey of Knowledge Tracing</title><authors>Qi Liu, Shuanghong Shen, Zhenya Huang, Enhong Chen, and Yonghe Zheng</authors><categories>cs.CY cs.LG</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-quality education is one of the keys to achieving a more sustainable
world. The recent COVID-19 epidemic has triggered the outbreak of online
education, which has enabled both students and teachers to learn and teach at
home. Meanwhile, it is now possible to record and research a large amount of
learning data using online learning platforms in order to offer better
intelligent educational services. Knowledge Tracing (KT), which aims to monitor
students' evolving knowledge state, is a fundamental and crucial task to
support these intelligent services. Therefore, an increasing amount of research
attention has been paid to this emerging area and considerable progress has
been made. In this survey, we propose a new taxonomy of existing basic KT
models from a technical perspective and provide a comprehensive overview of
these models in a systematic manner. In addition, many variants of KT models
have been proposed to capture more complete learning process. We then review
these variants involved in three phases of the learning process: before,
during, and after the student learning, respectively. Moreover, we present
several typical applications of KT in different educational scenarios. Finally,
we provide some potential directions for future research in this fast-growing
field.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15108</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15108</id><submitter>Elena Kronberg A.</submitter><version version="v1"><date>Tue, 11 May 2021 10:33:25 GMT</date><size>655kb</size><source_type>D</source_type></version><title>Prediction of soft proton intensities in the near-Earth space using
  machine learning</title><authors>Elena A. Kronberg, Tanveer Hannan, Jens Huthmacher, Marcus M\&quot;unzer,
  Florian Peste, Ziyang Zhou, Max Berrendorf, Evgeniy Faerman, Fabio
  Gastaldello, Simona Ghizzardi, Philippe Escoubet, Stein Haaland, Artem
  Smirnov, Nithin Sivadas, Robert C. Allen, Andrea Tiengo, and Raluca Ilie</authors><categories>physics.space-ph astro-ph.EP astro-ph.SR cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The spatial distribution of energetic protons contributes towards the
understanding of magnetospheric dynamics. Based upon 17 years of the
Cluster/RAPID observations, we have derived machine learning-based models to
predict the proton intensities at energies from 28 to 1,885 keV in the 3D
terrestrial magnetosphere at radial distances between 6 and 22 RE. We used the
satellite location and indices for solar, solar wind and geomagnetic activity
as predictors. The results demonstrate that the neural network (multi-layer
perceptron regressor) outperforms baseline models based on the k-Nearest
Neighbors and historical binning on average by ~80% and ~33\%, respectively.
The average correlation between the observed and predicted data is about 56%,
which is reasonable in light of the complex dynamics of fast-moving energetic
protons in the magnetosphere. In addition to a quantitative analysis of the
prediction results, we also investigate parameter importance in our model. The
most decisive parameters for predicting proton intensities are related to the
location: ZGSE direction and the radial distance. Among the activity indices,
the solar wind dynamic pressure is the most important. The results have a
direct practical application, for instance, for assessing the contamination
particle background in the X-Ray telescopes for X-ray astronomy orbiting above
the radiation belts. To foster reproducible research and to enable the
community to build upon our work we publish our complete code, the data, as
well as weights of trained models. Further description can be found in the
GitHub project at https://github.com/Tanveer81/deep_horizon.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15110</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15110</id><submitter>Martin Gerlach</submitter><version version="v1"><date>Mon, 31 May 2021 16:29:42 GMT</date><size>1691kb</size><source_type>D</source_type></version><title>A Multilingual Entity Linking System for Wikipedia with a
  Machine-in-the-Loop Approach</title><authors>Martin Gerlach and Marshall Miller and Rita Ho and Kosta Harlan and
  Djellel Difallah</authors><categories>cs.CY cs.HC cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Hyperlinks constitute the backbone of the Web; they enable user navigation,
information discovery, content ranking, and many other crucial services on the
Internet. In particular, hyperlinks found within Wikipedia allow the readers to
navigate from one page to another to expand their knowledge on a given subject
of interest or to discover a new one. However, despite Wikipedia editors'
efforts to add and maintain its content, the distribution of links remains
sparse in many language editions. This paper introduces a machine-in-the-loop
entity linking system that can comply with community guidelines for adding a
link and aims at increasing link coverage in new pages and wiki-projects with
low-resources. To tackle these challenges, we build a context and language
agnostic entity linking model that combines data collected from millions of
anchors found across wiki-projects, as well as billions of users' reading
sessions. We develop an interactive recommendation interface that proposes
candidate links to editors who can confirm, reject, or adapt the recommendation
with the overall aim of providing a more accessible editing experience for
newcomers through structured tasks. Our system's design choices were made in
collaboration with members of several language communities. When the system is
implemented as part of Wikipedia, its usage by volunteer editors will help us
build a continuous evaluation dataset with active feedback. Our experimental
results show that our link recommender can achieve a precision above 80% while
ensuring a recall of at least 50% across 6 languages covering different sizes,
continents, and families.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15111</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15111</id><submitter>Peter Boncz</submitter><version version="v1"><date>Tue, 18 May 2021 12:36:32 GMT</date><size>54kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 12:39:38 GMT</date><size>54kb</size></version><title>An Epidemiological Model for contact tracing with the Dutch CoronaMelder
  App</title><authors>Peter Boncz</authors><categories>cs.CY physics.soc-ph</categories><comments>This is a first and preliminary draft. Future updates are expected</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present an epidemiological model for the effectiveness of CoronaMelder,
the Dutch digital contact tracing app developed on top of the Google/Apple
Exposure Notification framework. We compare the effectiveness of CoronaMelder
with manual contract tracing on a number of metrics. CoronaMelder turns out to
have a small but noticeable positive influence in slowing down the COVID-19
pandemic, an effect that will become more pronounced in an opened-up society
where adoption of CoronaMelder is increased.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15114</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15114</id><submitter>Spyridon Doukakis</submitter><version version="v1"><date>Fri, 21 May 2021 05:53:11 GMT</date><size>77kb</size></version><title>The use of e-portfolios in teaching and assessment</title><authors>Maria Chionidou-Moskofoglou, Spyridon Doukakis, Amalia Lappa</authors><categories>cs.CY</categories><comments>8 pages</comments><journal-ref>Proceedings of the 7th International Conference on Technology in
  Mathematics Teaching, pp. 224-232, 2005</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we will initially go through the results of assessment in
mathematics according to the international assessment programs PISA, TIMSS
(2003), with respect to students' portfolios. Furthermore, we will present the
forms and the ways of assessment and will focus on that assessment which refers
to the use of eportfolios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15115</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15115</id><submitter>Nasim Sadat Mosavi</submitter><version version="v1"><date>Sat, 22 May 2021 07:21:41 GMT</date><size>790kb</size></version><title>Adoption of Precision Medicine; Limitations and Considerations</title><authors>Nasim Sadat Mosavi, Manuel Filipe Santos</authors><categories>cs.CY</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research is ongoing all over the world for identifying the barriers and
finding effective solutions to accelerate the projection of Precision Medicine
(PM) in the healthcare industry. Yet there has not been a valid and practical
model to tackle the several challenges that have slowed down the widespread of
this clinical practice. This study aimed to highlight the major limitations and
considerations for implementing Precision Medicine. The two theories Diffusion
of Innovation and Socio-Technical are employed to discuss the success
indicators of PM adoption. Throughout the theoretical assessment, two key
theoretical gaps are identified and related findings are discussed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15119</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15119</id><submitter>Paulo Roberto de Oliveira da Costa</submitter><version version="v1"><date>Mon, 31 May 2021 16:35:15 GMT</date><size>186kb</size><source_type>D</source_type></version><title>Policies for the Dynamic Traveling Maintainer Problem with Alerts</title><authors>Paulo da Costa, Peter Verleijsdonk, Simon Voorberg, Alp Akcay, Stella
  Kapodistria, Willem van Jaarsveld and Yingqian Zhang</authors><categories>math.OC cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Companies require modern capital assets such as wind turbines, trains and
hospital equipment to experience minimal downtime. Ideally, assets are
maintained right before failure to ensure maximum availability at minimum
maintenance costs. To this end, two challenges arise: failure times of assets
are unknown a priori and assets can be part of a larger asset network.
Nowadays, it is common for assets to be equipped with real-time monitoring that
emits alerts, typically triggered by the first signs of degradation. Thus, it
becomes crucial to plan maintenance considering information received via
alerts, asset locations and maintenance costs. This problem is referred to as
the Dynamic Traveling Maintainer Problem with Alerts (DTMPA). We propose a
modeling framework for the DTMPA, where the alerts are early and imperfect
indicators of failures. The objective is to minimize discounted maintenance
costs accrued over an infinite time horizon. We propose three methods to solve
this problem, leveraging different information levels from the alert signals.
The proposed methods comprise various greedy heuristics that rank assets based
on proximity, urgency and economic risk; a Traveling Maintainer Heuristic
employing combinatorial optimization to optimize near-future costs; a Deep
Reinforcement Learning (DRL) method trained to minimize the long-term costs
using exclusively the history of alerts. In a simulated environment, all
methods can approximate optimal policies with access to perfect condition
information for small asset networks. For larger networks, where computing the
optimal policy is intractable, the proposed methods yield competitive
maintenance policies, with DRL consistently achieving the lowest costs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15121</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15121</id><submitter>Fatemeh Golpayegani</submitter><version version="v1"><date>Sun, 23 May 2021 20:11:02 GMT</date><size>58kb</size></version><title>Pregnancy loss and unethical algorithms: Ethical issues in targeted
  advertising</title><authors>Fatemeh Golpayegani</authors><categories>cs.CY</categories><comments>18th International Conference on the Ethical and Social Impacts of
  ICT Proceedings of the ETHICOMP 2020. Paradigm Shifts in ICT Ethics</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, the ethical issues and the importance of ethical algorithm
design for target ads were briefly discussed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15122</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15122</id><submitter>Michael Cook</submitter><version version="v1"><date>Sun, 23 May 2021 23:52:43 GMT</date><size>94kb</size></version><title>The Social Responsibility of Game AI</title><authors>Michael Cook</authors><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Over the last decade we have watched as artificial intelligence has been
transformed into one of the most important issues of our time, and games have
grown into the biggest entertainment industry. As a result, game AI research as
a field has enjoyed increased access to funding, exposure in the press, and
influence with governments and some of the largest technology firms in the
world. At this pivotal moment in the history of our field, this paper argues
that this privileged position brings with it an important set of
responsibilities which we have largely failed to meet. We show to whom we are
responsible, identify some of these responsibilities, and suggest actions we
can take as a community to leverage this power for good.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15124</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15124</id><submitter>Myung Suh Choi</submitter><version version="v1"><date>Mon, 24 May 2021 07:07:37 GMT</date><size>419kb</size></version><title>Screening of the Characteristics of Hate Crimes against Asian American
  and Comparison to African Americans in Bay Area</title><authors>Myung Suh Choi, Yuli Choi, Kevin Kang, Katherine Lee, Jacquelyn Ryu,
  Nayeon Yu, Sihyeon Yoon</authors><categories>cs.CY</categories><comments>10 pages, 3 tables</comments><doi>10.18034/abcjar.v10i1.556</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  COVID-19 has aided the spread of racism, as well as national insecurity,
distrust of immigrants, and general xenophobia, both of which may be linked to
the rise in anti-Asian hate crimes during the pandemic. Coronavirus Disease
2019(COVID19) is thought to have originated in late December 2019 in Wuhan,
China, and quickly spread across the world during the spring months of 2020.
Asian Americans recorded in increase in racially based hate crimes including
physical abuse and intimidation as COVID-19 spread throughout the United
States. This research study was conducted by high school students in the Bay
Area to compare the intention and characteristics of hate crimes against Asian
Americans to hate crimes against African Americans. According to studies of
both victim-related and most offender-related variables, hate crimes against
Asian Americans have been rapidly growing in the United States and vary from
those against African Americans. This leads to an investigation into the racial
disparity between Asian American offenders and those of other races. The nature
and characteristics of hate crimes against Asian Americans are compared to
those of hate crimes against African Americans in our research. According to
studies of all victim-related factors, hate crimes against Asian Americans are
similar to those against African Americans. Hate crimes against Asian
Americans, on the other hand, vary greatly from hate crimes against African
Americans in terms of the offender's ethnicity and all incident-related
variables.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15125</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15125</id><submitter>Radhika Kotecha Dr.</submitter><version version="v1"><date>Mon, 24 May 2021 10:22:39 GMT</date><size>445kb</size></version><title>Strengthening e-Education in India using Machine Learning</title><authors>Naheed Khan, Darshan Bhanushali, Shreya Patel, and Radhika Kotecha</authors><categories>cs.CY</categories><doi>10.2139/ssrn.3565255</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  e-Education has developed as one of the most encouraging territories. The
Indian Government is investing all amounts of energy to improve education among
the residents of the nation. School and graduate understudies are focused on,
however the stage is being created for all the residents seeking to learn.
Without a doubt, the objective is to build the quantity of literates with
advanced education. To accomplish the equivalent, propels in Data and
Correspondence innovation are being utilized in the education division, which
has cleared route for e-Training in India as well. To help educators in
concentrating more on more current viewpoints, their excess work can be
disposed of utilizing Machine Learning (ML). Difference to programming, ML
deals with information and answers to create rules. In the event that Machine
Learning is tackled effectively, it can setup the training division and
contribute essentially to the development of the country. Hence, the work
presented in this paper fortifies e-Education in India utilizing Machine
Learning. For the most part, three concerns are focused to be tended to:
Personalized recommendation of course and Customized teaching methodology. The
work proposes utilizing developmental methodology of hereditary calculations
for improving conventional procedures. Implementation and experiments presented
in the paper verify the viability of proposed calculations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15131</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15131</id><submitter>Gabriella Laatikainen</submitter><version version="v1"><date>Wed, 26 May 2021 08:56:22 GMT</date><size>775kb</size></version><version version="v2"><date>Wed, 2 Jun 2021 03:42:16 GMT</date><size>782kb</size></version><title>Towards a trustful digital world: exploring self-sovereign identity
  ecosystems</title><authors>Gabriella Laatikainen, Taija Kolehmainen, Mengcheng Li, Markus
  Hautala, Antti Kettunen and Pekka Abrahamsson</authors><categories>cs.CY</categories><comments>This is a preprint (the authors' version) of an article accepted for
  publication in Twenty-fifth Pacific Asia Conference on Information Systems,
  Dubai, UAE, 2021 (PACIS 2021) conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current global situation-burdened by, among others, a vast number of
people without formal identification, digital leap, the need for health
passports and contact tracking applications-providing private and secure
digital identity for individuals, organizations and other entities is crucial.
The emerging self-sovereign identity (SSI) solutions rely on distributed ledger
technologies and verifiable credentials and have the potential to enable
trustful digital interactions. In this human-centric paradigm, trust among
actors can be established in a decentralized manner while the identity holders
are able to own and control their confidential data. In this paper, we build on
observations gathered in a field study to identify the building blocks,
antecedents and possible outcomes of SSI ecosystems. We also showcase
opportunities for researchers and practitioners to investigate this phenomenon
from a wide range of domains and theories, such as the digital innovation
ecosystems, value co-creation, surveillance theory, or entrepreneurship
theories.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15133</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15133</id><submitter>Patrick Glauner</submitter><version version="v1"><date>Wed, 26 May 2021 20:32:01 GMT</date><size>166kb</size><source_type>D</source_type></version><title>An Assessment of the AI Regulation Proposed by the European Commission</title><authors>Patrick Glauner</authors><categories>cs.CY</categories><comments>To appear in the 2022 Springer book &quot;The Future Circle of Healthcare:
  AI, 3D Printing, Longevity, Ethics, and Uncertainty Mitigation&quot; edited by
  Sepehr Ehsani, Patrick Glauner, Philipp Plugmann and Florian M. Thieringer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In April 2021, the European Commission published a proposed regulation on AI.
It intends to create a uniform legal framework for AI within the European Union
(EU). In this chapter, we analyze and assess the proposal. We show that the
proposed regulation is actually not needed due to existing regulations. We also
argue that the proposal clearly poses the risk of overregulation. As a
consequence, this would make the use or development of AI applications in
safety-critical application areas, such as in healthcare, almost impossible in
the EU. This would also likely further strengthen Chinese and US corporations
in their technology leadership. Our assessment is based on the oral evidence we
gave in May 2021 to the joint session of the European Union affairs committees
of the German federal parliament and the French National Assembly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15134</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15134</id><submitter>Zixin Wen</submitter><version version="v1"><date>Mon, 31 May 2021 16:42:09 GMT</date><size>4424kb</size><source_type>D</source_type></version><title>Toward Understanding the Feature Learning Process of Self-supervised
  Contrastive Learning</title><authors>Zixin Wen, Yuanzhi Li</authors><categories>cs.LG cs.CV stat.ML</categories><comments>Accepted to ICML2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can neural networks trained by contrastive learning extract features from
the unlabeled data? Why does contrastive learning usually need much stronger
data augmentations than supervised learning to ensure good representations?
These questions involve both the optimization and statistical aspects of deep
learning, but can hardly be answered by analyzing supervised learning, where
the target functions are the highest pursuit. Indeed, in self-supervised
learning, it is inevitable to relate to the optimization/generalization of
neural networks to how they can encode the latent structures in the data, which
we refer to as the \textit{feature learning process}.
  In this work, we formally study how contrastive learning learns the feature
representations for neural networks by analyzing its feature learning process.
We consider the case where our data are comprised of two types of features: the
more semantically aligned sparse features which we want to learn from, and the
other dense features we want to avoid. Theoretically, we prove that contrastive
learning using \textbf{ReLU} networks provably learns the desired sparse
features if proper augmentations are adopted. We present an underlying
principle called \textbf{feature decoupling} to explain the effects of
augmentations, where we theoretically characterize how augmentations can reduce
the correlations of dense features between positive samples while keeping the
correlations of sparse features intact, thereby forcing the neural networks to
learn from the self-supervision of sparse features. Empirically, we verified
that the feature decoupling principle matches the underlying mechanism of
contrastive learning in practice.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15135</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15135</id><submitter>Sajib Mistry</submitter><version version="v1"><date>Thu, 27 May 2021 02:51:23 GMT</date><size>2811kb</size><source_type>D</source_type></version><title>Reputation Bootstrapping for Composite Services using CP-nets</title><authors>Sajib Mistry and Athman Bouguettaya</authors><categories>cs.AI</categories><comments>14 Pages, accepted and to appear in IEEE Transactions on Services
  Computing</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We propose a novel framework to bootstrap the reputation of on-demand service
compositions. On-demand compositions are usually context-aware and have little
or no direct consumer feedback. The reputation bootstrapping of single or
atomic services does not consider the topology of the composition and
relationships among reputation-related factors. We apply Conditional Preference
Networks (CP-nets) of reputation-related factors for component services in a
composition. The reputation of a composite service is bootstrapped by the
composition of CP-nets. We consider the history of invocation among component
services to determine reputation-interdependence in a composition. The
composition rules are constructed using the composition topology and four types
of reputation-influence among component services. A heuristic-based Q-learning
approach is proposed to select the optimal set of reputation-related CP-nets.
Experimental results prove the efficiency of the proposed approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15136</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15136</id><submitter>Youry Khmelevsky</submitter><version version="v1"><date>Thu, 27 May 2021 04:53:18 GMT</date><size>7kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 01:10:33 GMT</date><size>7kb</size></version><title>Students Programming Competitions as an Educational Tool and a
  Motivational Incentive to Students</title><authors>Youry Khmelevsky, Ken Chidlow</authors><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In this short paper we report on student programming competition results by
students from the Computer Science Department (COSC) of Okanagan College (OC)
and discuss the achieved results from an educational point of view. We found
that some freshmen and sophomore students in diploma and degree programs are
very capable and eager to be involved in applied research projects as early as
the second semester, and into local and international programming competitions
as well. Our observation is based on the last 2 educational years, beginning
2015 when we introduced programming competitions to COSC students. Students
reported that participation in competitions give them motivation to effectively
learn in their programming courses, inspire them to learn deeper and more
thoroughly, and help them achieve better results in their classes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15139</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15139</id><submitter>Henderik Alex Proper</submitter><version version="v1"><date>Thu, 27 May 2021 08:09:08 GMT</date><size>294kb</size></version><title>Towards an Integrated Conceptual Modelling Kernel for Business
  Transaction Workflows</title><authors>Alistair P. Barros, Arthur H.M. ter Hofstede and Henderik A. Proper</authors><categories>cs.CY cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The workflow concept, proliferated through the recently emergent computer
supported cooperative work (CSCW) systems and workflow systems, advances
information systems (IS) implementation models by incorporating aspects of
collaboration and coordination in business processes. Under traditional
implementation models, applications are partitioned into discrete units of
functionality, with (typically) operational procedures used to describe how
human and computerised actions of business processes combine to deliver
business services. In this paper, a number of essential modelling concepts and
features for business transaction workflows are developed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15145</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15145</id><submitter>Lukasz Matysiak</submitter><version version="v1"><date>Fri, 28 May 2021 09:08:07 GMT</date><size>15kb</size></version><title>A polynomial composites and monoid domains as algebraic structures and
  their applications</title><authors>Magdalena Jankowska, Lukasz Matysiak</authors><categories>math.AC cs.IT math.IT</categories><comments>22 pages. arXiv admin note: substantial text overlap with
  arXiv:2006.14948</comments><msc-class>13B25, 13B05, 11T71</msc-class><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper contains the results collected so far on polynomial composites in
terms of many basic algebraic properties. Since it is a polynomial structure,
results for monoid domains come in here and there. The second part of the paper
contains the results of the relationship between the theory of polynomial
composites, the Galois theory and the theory of nilpotents. The third part of
this paper shows us some cryptosystems. We find generalizations of known
ciphers taking into account the infinite alphabet and using simple algebraic
methods. We also find two cryptosystems in which the structure of Dedekind
rings resides, namely certain elements are equivalent to fractional ideals.
Finally, we find the use of polynomial composites and monoid domains in
cryptology.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15147</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15147</id><submitter>Mohammad Sina Kiarostami</submitter><version version="v1"><date>Fri, 28 May 2021 12:19:30 GMT</date><size>633kb</size></version><title>Comparing Two Different Approaches in Big Data and Business Analysis for
  Churn Prediction with the Focus on How Apache Spark Employed</title><authors>Mohammad Sina Kiarostami</authors><categories>cs.DC cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Due to the significant importance of Big Data analysis, especially in
business-related topics such as improving services, finding potential
customers, and selecting practical approaches to manage income and expenses,
many companies attempt to collaborate with scientists to find how, why, and
what they should analysis. In this work, we would like to compare and discuss
two different approaches that employed in business analysis topic in Big Data
with more consideration on how they utilized Spark. Both studies have
investigated Churn Prediction as their case study for their proposed approaches
since it is an essential topic in business analysis for companies to recognize
a customer intends to leave or stop using their services. Here, we focus on
Apache Spark since it has provided several solutions to handle a massive amount
of data in recent years efficiently. This feature in Spark makes it one of the
most robust candidate tools to upfront with a Big Data problem, particularly
time and resource are concerns.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15152</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15152</id><submitter>Sabah Al-Fedaghi Dr.</submitter><version version="v1"><date>Mon, 31 May 2021 16:48:56 GMT</date><size>830kb</size></version><title>UML Sequence Diagram: An Alternative Model</title><authors>Sabah Al-Fedaghi</authors><categories>cs.SE</categories><comments>11 pages, 11 figures</comments><journal-ref>(IJACSA) International Journal of Advanced Computer Science and
  Applications, Vol. 12, No. 5, 2021</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The general acceptance of sequence diagrams can be attributed to their
relatively intuitive nature and ability to describe partial behaviors (as
opposed to such diagrams as state charts). However, studies have shown that
over 80 percent of graduating students were unable to create a software design
or even a partial design, and many students had no idea how sequence diagrams
were constrained by other models. Many students exhibited difficulties in
identifying valid interacting objects and constructing messages with
appropriate arguments. Additionally, according to authorities, even though many
different semantics have been proposed for sequence diagrams (e.g.,
translations to state machines), there exists no suitable semantic basis
refinement of required sequence diagram behavior because direct style semantics
do not precisely capture required sequence diagram behaviors; translations to
other formalisms disregard essential features of sequence diagrams such as
guard conditions and critical regions. This paper proposes an alternative to
sequence diagrams, a generalized model that provides further understanding of
sequence diagrams to assimilate them into a new modeling language called
thinging machine (TM). The sequence diagram is extended horizontally by
removing the superficial vertical-only dimensional limitation of expansion to
preserve the logical chronology of events. TM diagramming is spread nonlinearly
in terms of actions. Events and their chronology are constructed on a second
plane of description that is superimposed on the initial static description.
The result is a more refined representation that would simplify the modeling
process. This is demonstrated through remodeling sequence diagram cases from
the literature.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15157</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15157</id><submitter>Kai Zhao</submitter><version version="v1"><date>Mon, 31 May 2021 17:01:05 GMT</date><size>1846kb</size><source_type>D</source_type></version><title>Adaptive Feature Alignment for Adversarial Training</title><authors>Tao Wang and Ruixin Zhang and Xingyu Chen and Kai Zhao and Xiaolin
  Huang and Yuge Huang and Shaoxin Li and Jilin Li and Feiyue Huang</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Recent studies reveal that Convolutional Neural Networks (CNNs) are typically
vulnerable to adversarial attacks, which pose a threat to security-sensitive
applications. Many adversarial defense methods improve robustness at the cost
of accuracy, raising the contradiction between standard and adversarial
accuracies. In this paper, we observe an interesting phenomenon that feature
statistics change monotonically and smoothly w.r.t the rising of attacking
strength. Based on this observation, we propose the adaptive feature alignment
(AFA) to generate features of arbitrary attacking strengths. Our method is
trained to automatically align features of arbitrary attacking strength. This
is done by predicting a fusing weight in a dual-BN architecture. Unlike
previous works that need to either retrain the model or manually tune a
hyper-parameters for different attacking strengths, our method can deal with
arbitrary attacking strengths with a single model without introducing any
hyper-parameter. Importantly, our method improves the model robustness against
adversarial samples without incurring much loss in standard accuracy.
Experiments on CIFAR-10, SVHN, and tiny-ImageNet datasets demonstrate that our
method outperforms the state-of-the-art under a wide range of attacking
strengths.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15158</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15158</id><submitter>Michael D. Multerer</submitter><version version="v1"><date>Mon, 31 May 2021 17:02:53 GMT</date><size>10553kb</size><source_type>D</source_type></version><title>Isogeometric shape optimization for scaffold structures</title><authors>Helmut Harbrecht and Michael Multerer and Remo von Rickenbach</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of materials with specific structural properties is of huge
practical interest, for example, for medical applications or for the
development of light weight structures in aeronautics. In this article, we
combine shape optimization and homogenization for the optimal design of the
microstructure in scaffolds. Given the current microstructure, we apply the
isogeometric boundary element method to compute the effective tensor and to
update the microstructure by using the shape gradient in order to match the
desired effective tensor. Extensive numerical studies are presented to
demonstrate the applicability and feasibility of the approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15159</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15159</id><submitter>Chenhao Wang</submitter><version version="v1"><date>Mon, 31 May 2021 17:03:16 GMT</date><size>78kb</size></version><title>On maximizing a monotone $k$-submodular function under a knapsack
  constraint</title><authors>Zhongzheng Tang, Chenhao Wang, Hau Chan</authors><categories>cs.DS cs.DM math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of maximizing a monotone $k$-submodular function $f$
under a knapsack constraint, where a $k$-submodular function is a natural
generalization of a submodular function to $k$ dimensions. We present a
deterministic $(\frac12-\frac{1}{2e})$-approximation algorithm that evaluates
$f$ $O(n^5k^4)$ times.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15161</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15161</id><submitter>Li You</submitter><version version="v1"><date>Mon, 31 May 2021 17:11:18 GMT</date><size>107kb</size></version><title>Energy Efficiency Optimization for Multi-cell Massive MIMO: Centralized
  and Distributed Power Allocation Algorithms</title><authors>Li You, Yufei Huang, Di Zhang, Zheng Chang, Wenjin Wang, Xiqi Gao</authors><categories>cs.IT eess.SP math.IT</categories><comments>to appear in IEEE Transactions on Communications</comments><doi>10.1109/TCOMM.2021.3081451</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper investigates the energy efficiency (EE) optimization in downlink
multi-cell massive multiple-input multiple-output (MIMO). In our research, the
statistical channel state information (CSI) is exploited to reduce the
signaling overhead. To maximize the minimum EE among the neighbouring cells, we
design the transmit covariance matrices for each base station (BS).
Specifically, optimization schemes for this max-min EE problem are developed,
in the centralized and distributed ways, respectively. To obtain the transmit
covariance matrices, we first find out the closed-form optimal transmit
eigenmatrices for the BS in each cell, and convert the original transmit
covariance matrices designing problem into a power allocation one. Then, to
lower the computational complexity, we utilize an asymptotic approximation
expression for the problem objective. Moreover, for the power allocation
design, we adopt the minorization maximization method to address the
non-convexity of the ergodic rate, and use Dinkelbach's transform to convert
the max-min fractional problem into a series of convex optimization
subproblems. To tackle the transformed subproblems, we propose a centralized
iterative water-filling scheme. For reducing the backhaul burden, we further
develop a distributed algorithm for the power allocation problem, which
requires limited inter-cell information sharing. Finally, the performance of
the proposed algorithms are demonstrated by extensive numerical results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15162</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15162</id><submitter>Aciel Eshky</submitter><version version="v1"><date>Mon, 31 May 2021 17:11:28 GMT</date><size>999kb</size><source_type>D</source_type></version><title>Automatic audiovisual synchronisation for ultrasound tongue imaging</title><authors>Aciel Eshky, Joanne Cleland, Manuel Sam Ribeiro, Eleanor Sugden, Korin
  Richmond, Steve Renals</authors><categories>eess.AS cs.CL cs.LG cs.SD eess.IV</categories><comments>18 pages, 10 figures. Manuscript accepted at Speech Communication</comments><doi>10.1016/j.specom.2021.05.008</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Ultrasound tongue imaging is used to visualise the intra-oral articulators
during speech production. It is utilised in a range of applications, including
speech and language therapy and phonetics research. Ultrasound and speech audio
are recorded simultaneously, and in order to correctly use this data, the two
modalities should be correctly synchronised. Synchronisation is achieved using
specialised hardware at recording time, but this approach can fail in practice
resulting in data of limited usability. In this paper, we address the problem
of automatically synchronising ultrasound and audio after data collection. We
first investigate the tolerance of expert ultrasound users to synchronisation
errors in order to find the thresholds for error detection. We use these
thresholds to define accuracy scoring boundaries for evaluating our system. We
then describe our approach for automatic synchronisation, which is driven by a
self-supervised neural network, exploiting the correlation between the two
signals to synchronise them. We train our model on data from multiple domains
with different speaker characteristics, different equipment, and different
recording environments, and achieve an accuracy &gt;92.4% on held-out in-domain
data. Finally, we introduce a novel resource, the Cleft dataset, which we
gathered with a new clinical subgroup and for which hardware synchronisation
proved unreliable. We apply our model to this out-of-domain data, and evaluate
its performance subjectively with expert users. Results show that users prefer
our model's output over the original hardware output 79.3% of the time. Our
results demonstrate the strength of our approach and its ability to generalise
to data from new domains.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15164</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15164</id><submitter>Asma Ghandeharioun</submitter><version version="v1"><date>Mon, 31 May 2021 17:11:56 GMT</date><size>22184kb</size><source_type>D</source_type></version><title>DISSECT: Disentangled Simultaneous Explanations via Concept Traversals</title><authors>Asma Ghandeharioun, Been Kim, Chun-Liang Li, Brendan Jou, Brian Eoff,
  Rosalind W. Picard</authors><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Explaining deep learning model inferences is a promising venue for scientific
understanding, improving safety, uncovering hidden biases, evaluating fairness,
and beyond, as argued by many scholars. One of the principal benefits of
counterfactual explanations is allowing users to explore &quot;what-if&quot; scenarios
through what does not and cannot exist in the data, a quality that many other
forms of explanation such as heatmaps and influence functions are inherently
incapable of doing. However, most previous work on generative explainability
cannot disentangle important concepts effectively, produces unrealistic
examples, or fails to retain relevant information. We propose a novel approach,
DISSECT, that jointly trains a generator, a discriminator, and a concept
disentangler to overcome such challenges using little supervision. DISSECT
generates Concept Traversals (CTs), defined as a sequence of generated examples
with increasing degrees of concepts that influence a classifier's decision. By
training a generative model from a classifier's signal, DISSECT offers a way to
discover a classifier's inherent &quot;notion&quot; of distinct concepts automatically
rather than rely on user-predefined concepts. We show that DISSECT produces CTs
that (1) disentangle several concepts, (2) are influential to a classifier's
decision and are coupled to its reasoning due to joint training (3), are
realistic, (4) preserve relevant information, and (5) are stable across similar
inputs. We validate DISSECT on several challenging synthetic and realistic
datasets where previous methods fall short of satisfying desirable criteria for
interpretability and show that it performs consistently well and better than
existing methods. Finally, we present experiments showing applications of
DISSECT for detecting potential biases of a classifier and identifying spurious
artifacts that impact predictions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15165</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15165</id><submitter>Armin Kirchknopf</submitter><version version="v1"><date>Mon, 31 May 2021 17:13:47 GMT</date><size>1153kb</size><source_type>D</source_type></version><title>Multimodal Detection of Information Disorder from Social Media</title><authors>Armin Kirchknopf, Djordje Slijepcevic, Matthias Zeppelzauer</authors><categories>cs.IR cs.SI</categories><comments>4 pages, 2 figures, 2 tables, PrePrint CBMI 2021</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Social media is accompanied by an increasing proportion of content that
provides fake information or misleading content, known as information disorder.
In this paper, we study the problem of multimodal fake news detection on a
largescale multimodal dataset. We propose a multimodal network architecture
that enables different levels and types of information fusion. In addition to
the textual and visual content of a posting, we further leverage secondary
information, i.e. user comments and metadata. We fuse information at multiple
levels to account for the specific intrinsic structure of the modalities. Our
results show that multimodal analysis is highly effective for the task and all
modalities contribute positively when fused properly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15168</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15168</id><submitter>Jiemin Fang</submitter><version version="v1"><date>Mon, 31 May 2021 17:16:42 GMT</date><size>293kb</size><source_type>D</source_type></version><title>MSG-Transformer: Exchanging Local Spatial Information by Manipulating
  Messenger Tokens</title><authors>Jiemin Fang, Lingxi Xie, Xinggang Wang, Xiaopeng Zhang, Wenyu Liu, Qi
  Tian</authors><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformers have offered a new methodology of designing neural networks for
visual recognition. Compared to convolutional networks, Transformers enjoy the
ability of referring to global features at each stage, yet the attention module
brings higher computational overhead that obstructs the application of
Transformers to process high-resolution visual data. This paper aims to
alleviate the conflict between efficiency and flexibility, for which we propose
a specialized token for each region that serves as a messenger (MSG). Hence, by
manipulating these MSG tokens, one can flexibly exchange visual information
across regions and the computational complexity is reduced. We then integrate
the MSG token into a multi-scale architecture named MSG-Transformer. In
standard image classification and object detection, MSG-Transformer achieves
competitive performance and the inference on both GPU and CPU is accelerated.
The code will be available at https://github.com/hustvl/MSG-Transformer.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15171</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15171</id><submitter>Wangchunshu Zhou</submitter><version version="v1"><date>Mon, 31 May 2021 17:28:37 GMT</date><size>1287kb</size><source_type>D</source_type></version><title>Learning from Perturbations: Diverse and Informative Dialogue Generation
  with Inverse Adversarial Training</title><authors>Wangchunshu Zhou, Qifei Li, Chenle Li</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose Inverse Adversarial Training (IAT) algorithm for
training neural dialogue systems to avoid generic responses and model dialogue
history better. In contrast to standard adversarial training algorithms, IAT
encourages the model to be sensitive to the perturbation in the dialogue
history and therefore learning from perturbations. By giving higher rewards for
responses whose output probability reduces more significantly when dialogue
history is perturbed, the model is encouraged to generate more diverse and
consistent responses. By penalizing the model when generating the same response
given perturbed dialogue history, the model is forced to better capture
dialogue history and generate more informative responses. Experimental results
on two benchmark datasets show that our approach can better model dialogue
history and generate more diverse and consistent responses. In addition, we
point out a problem of the widely used maximum mutual information (MMI) based
methods for improving the diversity of dialogue response generation models and
demonstrate it empirically.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15172</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15172</id><submitter>Pietro Gravino - SONY Gravino</submitter><version version="v1"><date>Mon, 31 May 2021 17:32:06 GMT</date><size>645kb</size><source_type>D</source_type></version><title>Assessing disinformation through the dynamics of supply and demand in
  the news ecosystem</title><authors>Pietro Gravino, Giulio Prevedello, Martina Galletti and Vittorio
  Loreto</authors><categories>physics.soc-ph cs.SI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Social dialogue, the foundation of our democracies, is currently threatened
by disinformation and partisanship, with their disrupting role on individual
and collective awareness and detrimental effects on decision-making processes.
Despite a great deal of attention to the news sphere itself, little is known
about the subtle interplay between the offer and the demand for information.
Still, a broader perspective on the news ecosystem, including both the
producers and the consumers of information, is needed to build new tools to
assess the health of the infosphere. Here, we combine in the same framework
news supply, as mirrored by a fairly complete Italian news database - partially
annotated for fake news, and news demand, as captured through the Google Trends
data for Italy. Our investigation focuses on the temporal and semantic
interplay of news, fake news, and searches in several domains, including the
virus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is
extremely reactive to people's interests and tends to thrive, especially when
there is a mismatch between what people are interested in and what news outlets
provide. Second, a suitably defined index can assess the level of
disinformation only based on the available volumes of news and searches.
Although our results mainly concern the Coronavirus subject, we provide hints
that the same findings can have more general applications. We contend these
results can be a powerful asset in informing campaigns against disinformation
and providing news outlets and institutions with potentially relevant
strategies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15173</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15173</id><submitter>Vitalii Kurbatov</submitter><version version="v1"><date>Mon, 31 May 2021 17:32:57 GMT</date><size>23kb</size></version><title>Calculating a function of a matrix with a real spectrum</title><authors>P. Kubel\'ik, V. G. Kurbatov, and I. V. Kurbatova</authors><categories>math.NA cs.NA math.SP</categories><comments>24 pages</comments><msc-class>65F60 (Primary), 97N50 (Secondary)</msc-class><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Let $T$ be a square matrix with a real spectrum, and let $f$ be an analytic
function. The problem of the approximate calculation of $f(T)$ is discussed.
Applying the Schur triangular decomposition and the reordering, one can assume
that $T$ is triangular and its diagonal entries $t_{ii}$ are arranged in
increasing order. To avoid calculations using the differences $t_{ii}-t_{jj}$
with close (including equal) $t_{ii}$ and $t_{jj}$, it is proposed to represent
$T$ in a block form and calculate the two main block diagonals using
interpolating polynomials. The rest of the $f(T)$ entries can be calculated
using the Parlett recurrence algorithm. It is also proposed to perform scalar
operations (such as the building of interpolating polynomials) with an enlarged
number of decimal digits.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15174</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15174</id><submitter>Li You</submitter><version version="v1"><date>Mon, 31 May 2021 17:33:08 GMT</date><size>137kb</size></version><title>Energy-Efficient Precoding in Electromagnetic Exposure-Constrained
  Uplink Multiuser MIMO</title><authors>Jiayuan Xiong, Li You, Derrick Wing Kwan Ng, Wenjin Wang, Xiqi Gao</authors><categories>cs.IT eess.SP math.IT</categories><comments>We investigate the SAR-aware uplink precoder design for the EE
  maximization in multiuser MIMO transmission exploiting statistical CSI</comments><doi>10.1109/TVT.2021.3085296</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  User electromagnetic (EM) exposure is continuously being exacerbated by the
evolution of multi-antenna portable devices. To mitigate the effects of EM
radiation, portable devices must satisfy tight regulations on user exposure
level, generally measured by specific absorption rate (SAR). To this end, we
investigate the SAR-aware uplink precoder design for the energy efficiency (EE)
maximization in multiuser multiple-input multiple-output transmission
exploiting statistical channel state information (CSI). As the objective
function of the design problem is computationally demanding in the absence of
closed form, we present an asymptotic approximation of the objective to
facilitate the precoder design. An iterative algorithm based on Dinkelbach's
method and sequential optimization is proposed to obtain an optimal solution of
the asymptotic EE optimization problem. Based on the transformed problem, an
iterative SAR-aware water-filing scheme is further conceived for the EE
optimization precoding design with statistical CSI. Numerical results
illustrate substantial performance improvements provided by our proposed
SAR-aware energy-efficient transmission scheme over the traditional baseline
schemes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15176</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15176</id><submitter>Tianyang Xu</submitter><version version="v1"><date>Mon, 31 May 2021 17:34:47 GMT</date><size>35kb</size></version><title>Reinforced Generative Adversarial Network for Abstractive Text
  Summarization</title><authors>Tianyang Xu, Chunyun Zhang</authors><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence models provide a viable new approach to generative
summarization, allowing models that are no longer limited to simply selecting
and recombining sentences from the original text. However, these models have
three drawbacks: their grasp of the details of the original text is often
inaccurate, and the text generated by such models often has repetitions, while
it is difficult to handle words that are beyond the word list. In this paper,
we propose a new architecture that combines reinforcement learning and
adversarial generative networks to enhance the sequence-to-sequence attention
model. First, we use a hybrid pointer-generator network that copies words
directly from the source text, contributing to accurate reproduction of
information without sacrificing the ability of generators to generate new
words. Second, we use both intra-temporal and intra-decoder attention to
penalize summarized content and thus discourage repetition. We apply our model
to our own proposed COVID-19 paper title summarization task and achieve close
approximations to the current model on ROUEG, while bringing better
readability.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15179</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15179</id><submitter>Nadir Durrani Dr</submitter><version version="v1"><date>Mon, 31 May 2021 17:43:57 GMT</date><size>893kb</size><source_type>D</source_type></version><title>How transfer learning impacts linguistic knowledge in deep NLP models?</title><authors>Nadir Durrani and Hassan Sajjad and Fahim Dalvi</authors><categories>cs.CL</categories><comments>Findings of the ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transfer learning from pre-trained neural language models towards downstream
tasks has been a predominant theme in NLP recently. Several researchers have
shown that deep NLP models learn non-trivial amount of linguistic knowledge,
captured at different layers of the model. We investigate how fine-tuning
towards downstream NLP tasks impacts the learned linguistic knowledge. We carry
out a study across popular pre-trained models BERT, RoBERTa and XLNet using
layer and neuron-level diagnostic classifiers. We found that for some GLUE
tasks, the network relies on the core linguistic information and preserve it
deeper in the network, while for others it forgets. Linguistic information is
distributed in the pre-trained language models but becomes localized to the
lower layers post fine-tuning, reserving higher layers for the task specific
knowledge. The pattern varies across architectures, with BERT retaining
linguistic information relatively deeper in the network compared to RoBERTa and
XLNet, where it is predominantly delegated to the lower layers.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15182</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15182</id><submitter>Peter Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 17:45:12 GMT</date><size>210kb</size></version><title>Model Mis-specification and Algorithmic Bias</title><authors>Runshan Fu, Yangfan Liang, Peter Zhang</authors><categories>cs.LG cs.CY math.OC</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Machine learning algorithms are increasingly used to inform critical
decisions. There is a growing concern about bias, that algorithms may produce
uneven outcomes for individuals in different demographic groups. In this work,
we measure bias as the difference between mean prediction errors across groups.
We show that even with unbiased input data, when a model is mis-specified: (1)
population-level mean prediction error can still be negligible, but group-level
mean prediction errors can be large; (2) such errors are not equal across
groups; and (3) the difference between errors, i.e., bias, can take the
worst-case realization. That is, when there are two groups of the same size,
mean prediction errors for these two groups have the same magnitude but
opposite signs. In closed form, we show such errors and bias are functions of
the first and second moments of the joint distribution of features (for linear
and probit regressions). We also conduct numerical experiments to show similar
results in more general settings. Our work provides a first step for decoupling
the impact of different causes of bias.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15183</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15183</id><submitter>Mathieu Blondel</submitter><version version="v1"><date>Mon, 31 May 2021 17:45:58 GMT</date><size>322kb</size><source_type>D</source_type></version><title>Efficient and Modular Implicit Differentiation</title><authors>Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan
  Hoyer, Felipe Llinares-L\'opez, Fabian Pedregosa, Jean-Philippe Vert</authors><categories>cs.LG cs.NA math.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic differentiation (autodiff) has revolutionized machine learning. It
allows expressing complex computations by composing elementary ones in creative
ways and removes the burden of computing their derivatives by hand. More
recently, differentiation of optimization problem solutions has attracted
widespread attention with applications such as optimization as a layer, and in
bi-level problems such as hyper-parameter optimization and meta-learning.
However, the formulas for these derivatives often involve case-by-case tedious
mathematical derivations. In this paper, we propose a unified, efficient and
modular approach for implicit differentiation of optimization problems. In our
approach, the user defines (in Python in the case of our implementation) a
function $F$ capturing the optimality conditions of the problem to be
differentiated. Once this is done, we leverage autodiff of $F$ and implicit
differentiation to automatically differentiate the optimization problem. Our
approach thus combines the benefits of implicit differentiation and autodiff.
It is efficient as it can be added on top of any state-of-the-art solver and
modular as the optimality condition specification is decoupled from the
implicit differentiation mechanism. We show that seemingly simple principles
allow to recover many recently proposed implicit differentiation methods and
create new ones easily. We demonstrate the ease of formulating and solving
bi-level optimization problems using our framework. We also showcase an
application to the sensitivity analysis of molecular dynamics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15186</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15186</id><submitter>Shicong Cen</submitter><version version="v1"><date>Mon, 31 May 2021 17:51:15 GMT</date><size>1057kb</size><source_type>D</source_type></version><title>Fast Policy Extragradient Methods for Competitive Games with Entropy
  Regularization</title><authors>Shicong Cen, Yuting Wei, Yuejie Chi</authors><categories>math.OC cs.GT cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of computing the equilibrium of
competitive games, which is often modeled as a constrained saddle-point
optimization problem with probability simplex constraints. Despite recent
efforts in understanding the last-iterate convergence of extragradient methods
in the unconstrained setting, the theoretical underpinnings of these methods in
the constrained settings, especially those using multiplicative updates, remain
highly inadequate, even when the objective function is bilinear. Motivated by
the algorithmic role of entropy regularization in single-agent reinforcement
learning and game theory, we develop provably efficient extragradient methods
to find the quantal response equilibrium (QRE) -- which are solutions to
zero-sum two-player matrix games with entropy regularization -- at a linear
rate. The proposed algorithms can be implemented in a decentralized manner,
where each player executes symmetric and multiplicative updates iteratively
using its own payoff without observing the opponent's actions directly. In
addition, by controlling the knob of entropy regularization, the proposed
algorithms can locate an approximate Nash equilibrium of the unregularized
matrix game at a sublinear rate without assuming the Nash equilibrium to be
unique. Our methods also lead to efficient policy extragradient algorithms for
solving entropy-regularized zero-sum Markov games at a linear rate. All of our
convergence rates are nearly dimension-free, which are independent of the size
of the state and action spaces up to logarithm factors, highlighting the
positive role of entropy regularization for accelerating convergence.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15187</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15187</id><submitter>Anupam Gupta</submitter><version version="v1"><date>Mon, 31 May 2021 17:51:25 GMT</date><size>150kb</size><source_type>D</source_type></version><title>A Quasipolynomial $(2+\varepsilon)$-Approximation for Planar Sparsest
  Cut</title><authors>Vincent Cohen-Addad and Anupam Gupta and Philip N. Klein and Jason Li</authors><categories>cs.DS</categories><comments>To appear at STOC 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The (non-uniform) sparsest cut problem is the following graph-partitioning
problem: given a &quot;supply&quot; graph, and demands on pairs of vertices, delete some
subset of supply edges to minimize the ratio of the supply edges cut to the
total demand of the pairs separated by this deletion. Despite much effort,
there are only a handful of nontrivial classes of supply graphs for which
constant-factor approximations are known.
  We consider the problem for planar graphs, and give a
$(2+\varepsilon)$-approximation algorithm that runs in quasipolynomial time.
Our approach defines a new structural decomposition of an optimal solution
using a &quot;patching&quot; primitive. We combine this decomposition with a
Sherali-Adams-style linear programming relaxation of the problem, which we then
round. This should be compared with the polynomial-time approximation algorithm
of Rao (1999), which uses the metric linear programming relaxation and
$\ell_1$-embeddings, and achieves an $O(\sqrt{\log n})$-approximation in
polynomial time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15189</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15189</id><submitter>Brady Moon</submitter><version version="v1"><date>Mon, 31 May 2021 17:51:55 GMT</date><size>4584kb</size><source_type>D</source_type></version><title>CVaR-based Flight Energy Risk Assessment for Multirotor UAVs using a
  Deep Energy Model</title><authors>Arnav Choudhry, Brady Moon, Jay Patrikar, Constantine Samaras,
  Sebastian Scherer</authors><categories>cs.LG cs.RO</categories><comments>7 pages, 8 figures, Submitted ICRA 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy management is a critical aspect of risk assessment for Uncrewed Aerial
Vehicle (UAV) flights, as a depleted battery during a flight brings almost
guaranteed vehicle damage and a high risk of human injuries or property damage.
Predicting the amount of energy a flight will consume is challenging as
routing, weather, obstacles, and other factors affect the overall consumption.
We develop a deep energy model for a UAV that uses Temporal Convolutional
Networks to capture the time varying features while incorporating static
contextual information. Our energy model is trained on a real world dataset and
does not require segregating flights into regimes. We illustrate an improvement
in power predictions by $29\%$ on test flights when compared to a
state-of-the-art analytical method. Using the energy model, we can predict the
energy usage for a given trajectory and evaluate the risk of running out of
battery during flight. We propose using Conditional Value-at-Risk (CVaR) as a
metric for quantifying this risk. We show that CVaR captures the risk
associated with worst-case energy consumption on a nominal path by transforming
the output distribution of Monte Carlo forward simulations into a risk space.
Computing the CVaR on the risk-space distribution provides a metric that can
evaluate the overall risk of a flight before take-off. Our energy model and
risk evaluation method can improve flight safety and evaluate the coverage area
from a proposed takeoff location.
  The video and codebase are available at https://youtu.be/PHXGigqilOA and
https://git.io/cvar-risk .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15191</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15191</id><submitter>Siddharth Divi</submitter><version version="v1"><date>Mon, 31 May 2021 17:54:29 GMT</date><size>2403kb</size><source_type>D</source_type></version><title>Unifying Distillation with Personalization in Federated Learning</title><authors>Siddharth Divi, Habiba Farrukh, Berkay Celik</authors><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Federated learning (FL) is a decentralized privacy-preserving learning
technique in which clients learn a joint collaborative model through a central
aggregator without sharing their data. In this setting, all clients learn a
single common predictor (FedAvg), which does not generalize well on each
client's local data due to the statistical data heterogeneity among clients. In
this paper, we address this problem with PersFL, a discrete two-stage
personalized learning algorithm. In the first stage, PersFL finds the optimal
teacher model of each client during the FL training phase. In the second stage,
PersFL distills the useful knowledge from optimal teachers into each user's
local model. The teacher model provides each client with some rich, high-level
representation that a client can easily adapt to its local model, which
overcomes the statistical heterogeneity present at different clients. We
evaluate PersFL on CIFAR-10 and MNIST datasets using three data-splitting
strategies to control the diversity between clients' data distributions. We
empirically show that PersFL outperforms FedAvg and three state-of-the-art
personalization methods, pFedMe, Per-FedAvg, and FedPer on majority data-splits
with minimal communication cost. Further, we study the performance of PersFL on
different distillation objectives, how this performance is affected by the
equitable notion of fairness among clients, and the number of required
communication rounds. PersFL code is available at https://tinyurl.com/hdh5zhxs
for public use and validation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15196</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15196</id><submitter>Tuan Hoang Manh</submitter><version version="v1"><date>Mon, 31 May 2021 17:56:39 GMT</date><size>13kb</size></version><version version="v2"><date>Tue, 1 Jun 2021 20:39:24 GMT</date><size>17kb</size></version><title>A novel second-order nonstandard finite difference method for solving
  one-dimensional autonomous dynamical systems</title><authors>Manh Tuan Hoang</authors><categories>math.NA cs.NA</categories><comments>20 pages, 2 figure</comments><msc-class>37M05, 37M15, 65L05, 65P99</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, a novel second-order nonstandard finite difference (NSFD)
method that preserves simultaneously the positivity and local asymptotic
stability of one-dimensional autonomous dynamical systems is introduced and
analyzed. This method is based on novel non-local approximations for right-hand
side functions of differential equations in combination with nonstandard
denominator functions. The obtained results not only resolve the contradiction
between the dynamic consistency and high-order accuracy of NSFD methods but
also improve and extend some well-known results that have been published
recently in [Applied Mathematics Letters 112(2021) 106775], [AIP Conference
Proceedings 2302(2020) 110003] and [Applied Mathematics Letters 50(2015)
78-82]. Furthermore, as a simple but important application, we apply the
constructed NSFD method for solving the logistic, sine, cubic, and Monod
equations; consequently, the NSFD schemes constructed in the earlier work
[Journal of Computational and Applied Mathematics 110(1999) 181-185] are
improved significantly. Finally, we report some numerical experiments to
support and illustrate the theoretical assertions as well as advantages of the
constructed NSFD method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15197</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15197</id><submitter>Rahul Singh</submitter><version version="v1"><date>Mon, 31 May 2021 17:57:02 GMT</date><size>93kb</size></version><title>A Simple and General Debiased Machine Learning Theorem with Finite
  Sample Guarantees</title><authors>Victor Chernozhukov, Whitney K. Newey, Rahul Singh</authors><categories>stat.ML cs.LG econ.EM math.ST stat.TH</categories><comments>25 pages. arXiv admin note: text overlap with arXiv:2102.11076</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Debiased machine learning is a meta algorithm based on bias correction and
sample splitting to calculate confidence intervals for functionals (i.e. scalar
summaries) of machine learning algorithms. For example, an analyst may desire
the confidence interval for a treatment effect estimated with a neural network.
We provide a nonasymptotic debiased machine learning theorem that encompasses
any global or local functional of any machine learning algorithm that satisfies
a few simple, interpretable conditions. Formally, we prove consistency,
Gaussian approximation, and semiparametric efficiency by finite sample
arguments. The rate of convergence is root-n for global functionals, and it
degrades gracefully for local functionals. Our results culminate in a simple
set of conditions that an analyst can use to translate modern learning theory
rates into traditional statistical inference. The conditions reveal a new
double robustness property for ill posed inverse problems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2105.15203</identifier>
 <datestamp>2021-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2105.15203</id><submitter>Enze Xie</submitter><version version="v1"><date>Mon, 31 May 2021 17:59:51 GMT</date><size>5279kb</size><source_type>D</source_type></version><title>SegFormer: Simple and Efficient Design for Semantic Segmentation with
  Transformers</title><authors>Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez,
  Ping Luo</authors><categories>cs.CV cs.LG</categories><comments>Tech Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present SegFormer, a simple, efficient yet powerful semantic segmentation
framework which unifies Transformers with lightweight multilayer perception
(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a
novel hierarchically structured Transformer encoder which outputs multiscale
features. It does not need positional encoding, thereby avoiding the
interpolation of positional codes which leads to decreased performance when the
testing resolution differs from training. 2) SegFormer avoids complex decoders.
The proposed MLP decoder aggregates information from different layers, and thus
combining both local attention and global attention to render powerful
representations. We show that this simple and lightweight design is the key to
efficient segmentation on Transformers. We scale our approach up to obtain a
series of models from SegFormer-B0 to SegFormer-B5, reaching significantly
better performance and efficiency than previous counterparts. For example,
SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x
smaller and 2.2% better than the previous best method. Our best model,
SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows
excellent zero-shot robustness on Cityscapes-C. Code will be released at:
github.com/NVlabs/SegFormer.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00001</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00001</id><submitter>Vikrant Singhal</submitter><version version="v1"><date>Fri, 28 May 2021 21:09:23 GMT</date><size>193kb</size><source_type>D</source_type></version><title>Privately Learning Subspaces</title><authors>Vikrant Singhal, Thomas Steinke</authors><categories>cs.CR cs.DS cs.LG stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Private data analysis suffers a costly curse of dimensionality. However, the
data often has an underlying low-dimensional structure. For example, when
optimizing via gradient descent, the gradients often lie in or near a
low-dimensional subspace. If that low-dimensional structure can be identified,
then we can avoid paying (in terms of privacy or accuracy) for the high ambient
dimension.
  We present differentially private algorithms that take input data sampled
from a low-dimensional linear subspace (possibly with a small amount of error)
and output that subspace (or an approximation to it). These algorithms can
serve as a pre-processing step for other procedures.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00002</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00002</id><submitter>Shixin Xu</submitter><version version="v1"><date>Sat, 29 May 2021 14:27:08 GMT</date><size>19715kb</size><source_type>D</source_type></version><title>Analysis and classification of main risk factors causing stroke in
  Shanxi Province</title><authors>Junjie Liu, Yiyang Sun, Jing Ma, Jiachen Tu, Yuhui Deng, Ping He,
  Huaxiong Huang, Xiaoshuang Zhou, Shixin Xu</authors><categories>cs.LG</categories><comments>13 pages, 9 figures</comments><msc-class>92C50</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In China, stroke is the first leading cause of death in recent years. It is a
major cause of long-term physical and cognitive impairment, which bring great
pressure on the National Public Health System. Evaluation of the risk of
getting stroke is important for the prevention and treatment of stroke in
China. A data set with 2000 hospitalized stroke patients in 2018 and 27583
residents during the year 2017 to 2020 is analyzed in this study. Due to data
incompleteness, inconsistency, and non-structured formats, missing values in
the raw data are filled with -1 as an abnormal class. With the cleaned
features, three models on risk levels of getting stroke are built by using
machine learning methods. The importance of &quot;8+2&quot; factors from China National
Stroke Prevention Project (CSPP) is evaluated via decision tree and random
forest models. Except for &quot;8+2&quot; factors the importance of features and SHAP1
values for lifestyle information, demographic information, and medical
measurement are evaluated and ranked via a random forest model. Furthermore, a
logistic regression model is applied to evaluate the probability of getting
stroke for different risk levels. Based on the census data in both communities
and hospitals from Shanxi Province, we investigate different risk factors of
getting stroke and their ranking with interpretable machine learning models.
The results show that Hypertension (Systolic blood pressure, Diastolic blood
pressure), Physical Inactivity (Lack of sports), and Overweight (BMI) are
ranked as the top three high-risk factors of getting stroke in Shanxi province.
The probability of getting stroke for a person can also be predicted via our
machine learning model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00003</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00003</id><submitter>Firas Hamze</submitter><version version="v1"><date>Sun, 30 May 2021 00:47:03 GMT</date><size>309kb</size><source_type>D</source_type></version><title>Parallelized Computation and Backpropagation Under Angle-Parametrized
  Orthogonal Matrices</title><authors>Firas Hamze</authors><categories>cs.LG cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a methodology for parallel acceleration of learning in the
presence of matrix orthogonality and unitarity constraints of interest in
several branches of machine learning. We show how an apparently sequential
elementary rotation parametrization can be restructured into blocks of
commutative operations using a well-known tool for coloring the edges of
complete graphs, in turn widely applied to schedule round-robin
(all-against-all) sports tournaments. The resulting decomposition admits an
algorithm to compute a fully-parametrized orthogonal matrix from its rotation
parameters in $O(n)$ sequential steps and one to compute the gradient of a
training loss with respect to its parameters in $O(n\log n)$ steps. We discuss
parametric restrictions of interest to generative modeling and present
promising performance results with a prototype GPU implementation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00005</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00005</id><submitter>Mahdi Chehimi</submitter><version version="v1"><date>Sun, 30 May 2021 12:19:27 GMT</date><size>198kb</size><source_type>D</source_type></version><title>Quantum Federated Learning with Quantum Data</title><authors>Mahdi Chehimi and Walid Saad</authors><categories>quant-ph cs.LG cs.NI</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum machine learning (QML) has emerged as a promising field that leans on
the developments in quantum computing to explore large complex machine learning
problems. Recently, some purely quantum machine learning models were proposed
such as the quantum convolutional neural networks (QCNN) to perform
classification on quantum data. However, all of the existing QML models rely on
centralized solutions that cannot scale well for large-scale and distributed
quantum networks. Hence, it is apropos to consider more practical quantum
federated learning (QFL) solutions tailored towards emerging quantum network
architectures. Indeed, developing QFL frameworks for quantum networks is
critical given the fragile nature of computing qubits and the difficulty of
transferring them. On top of its practical momentousness, QFL allows for
distributed quantum learning by leveraging existing wireless communication
infrastructure. This paper proposes the first fully quantum federated learning
framework that can operate over quantum data and, thus, share the learning of
quantum circuit parameters in a decentralized manner. First, given the lack of
existing quantum federated datasets in the literature, the proposed framework
begins by generating the first quantum federated dataset, with a hierarchical
data format, for distributed quantum networks. Then, clients sharing QCNN
models are fed with the quantum data to perform a classification task.
Subsequently, the server aggregates the learnable quantum circuit parameters
from clients and performs federated averaging. Extensive experiments are
conducted to evaluate and validate the effectiveness of the proposed QFL
solution. This work is the first to combine Google's TensorFlow Federated and
TensorFlow Quantum in a practical implementation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00007</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00007</id><submitter>Saurabh Gore</submitter><version version="v1"><date>Sun, 30 May 2021 23:35:13 GMT</date><size>868kb</size></version><title>DikpolaSat Mission: Improvement of Space Flight Performance and Optimal
  Control Using Trained Deep Neural Network -- Trajectory Controller for Space
  Objects Collision Avoidance</title><authors>Manuel Ntumba, Saurabh Gore, Jean Baptiste Awanyo</authors><categories>cs.RO cs.LG</categories><comments>7 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduced the space mission DikpolaSat Mission, how this research
fits into the mission, and the importance of having a trained DNN model instead
of the usual GN&amp;C functionality. This paper shows how the controller
demonstration is carried out by having the spacecraft follow a desired path,
specified in the referenced model. Increases can be made by examining the route
used to construct a DNN and understanding the effects of various activating
functions on system efficiency. The obstacle avoidance algorithm is built into
the control features to respond spontaneously using inputs from the neural
network for collision avoidance while optimizing the modified trajectory. The
action of a neural network to control the adaptive nature of the nonlinear
mechanisms in the controller will make the control system capable of handling
multiple nonlinear events and also uncertainties that have not been induced in
the control algorithm. Multiple algorithms for optimizing flight controls and
fuel consumption can be implemented using knowledge of flight dynamics in
trajectory and also in the event of obstacle avoidance. This paper also
explains how a DNN can learn to control the flight path and make the system
more reliable with each launch, thereby improving the chances of predicting
collisions of space objects. The data released from this research is used to
design more advanced DNN model capable of predicting other orbital events as
well.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00008</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00008</id><submitter>Dongxiao Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 02:11:59 GMT</date><size>1323kb</size></version><title>Robust discovery of partial differential equations in complex situations</title><authors>Hao Xu and Dongxiao Zhang</authors><categories>cs.LG cs.AI math.OC</categories><comments>20 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven discovery of partial differential equations (PDEs) has achieved
considerable development in recent years. Several aspects of problems have been
resolved by sparse regression-based and neural network-based methods. However,
the performances of existing methods lack stability when dealing with complex
situations, including sparse data with high noise, high-order derivatives and
shock waves, which bring obstacles to calculating derivatives accurately.
Therefore, a robust PDE discovery framework, called the robust deep
learning-genetic algorithm (R-DLGA), that incorporates the physics-informed
neural network (PINN), is proposed in this work. In the framework, a
preliminary result of potential terms provided by the deep learning-genetic
algorithm is added into the loss function of the PINN as physical constraints
to improve the accuracy of derivative calculation. It assists to optimize the
preliminary result and obtain the ultimately discovered PDE by eliminating the
error compensation terms. The stability and accuracy of the proposed R-DLGA in
several complex situations are examined for proof-and-concept, and the results
prove that the proposed framework is able to calculate derivatives accurately
with the optimization of PINN and possesses surprising robustness to complex
situations, including sparse data with high noise, high-order derivatives, and
shock waves.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00009</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00009</id><submitter>Dongxiao Zhang</submitter><version version="v1"><date>Mon, 31 May 2021 02:24:57 GMT</date><size>1518kb</size></version><title>Deep-Learning Discovers Macroscopic Governing Equations for Viscous
  Gravity Currents from Microscopic Simulation Data</title><authors>Junsheng Zeng, Hao Xu, Yuntian Chen, and Dongxiao Zhang</authors><categories>physics.comp-ph cs.AI cs.LG physics.data-an</categories><comments>10 pages, 2 figures,and SI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although deep-learning has been successfully applied in a variety of science
and engineering problems owing to its strong high-dimensional nonlinear mapping
capability, it is of limited use in scientific knowledge discovery. In this
work, we propose a deep-learning based framework to discover the macroscopic
governing equation of viscous gravity current based on high-resolution
microscopic simulation data without the need for prior knowledge of underlying
terms. For two typical scenarios with different viscosity ratios, the
deep-learning based equations exactly capture the same dominated terms as the
theoretically derived equations for describing long-term asymptotic behaviors,
which validates the proposed framework. Unknown macroscopic equations are then
obtained for describing short-term behaviors, and hidden mechanisms are
eventually discovered with deep-learned explainable compensation terms and
corresponding coefficients. Consequently, the presented deep-learning framework
shows considerable potential for discovering unrevealed intrinsic laws in
scientific semantic space from raw experimental or simulation results in data
space.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00010</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00010</id><submitter>Lu Ma</submitter><version version="v1"><date>Mon, 31 May 2021 06:30:59 GMT</date><size>412kb</size></version><title>Multi-Scale Attention Neural Network for Acoustic Echo Cancellation</title><authors>Lu Ma, Song Yang, Yaguang Gong, Zhongqin Wu</authors><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, 4 tables. arXiv admin note: substantial text
  overlap with arXiv:2105.14666</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic Echo Cancellation (AEC) plays a key role in speech interaction by
suppressing the echo received at microphone introduced by acoustic
reverberations from loudspeakers. Since the performance of linear adaptive
filter (AF) would degrade severely due to nonlinear distortions, background
noises, and microphone clipping in real scenarios, deep learning has been
employed for AEC for its good nonlinear modelling ability. In this paper, we
constructed an end-to-end multi-scale attention neural network for AEC.
Temporal convolution is first used to transform waveform into spectrogram. The
spectrograms of the far-end reference and the near-end mixture are
concatenated, and fed to a temporal convolution network (TCN) with stacked
dilated convolution layers. Attention mechanism is performed among these
representations from different layers to adaptively extract relevant features
by referring to the previous hidden state in the encoder long short-term memory
(LSTM) unit. The representations are weighted averaged and fed to the encoder
LSTM for the near-end speech estimation. Experiments show the superiority of
our method in terms of the echo return loss enhancement (ERLE) for single-talk
periods and the perceptual evaluation of speech quality (PESQ) score for
double-talk periods in background noise and nonlinear distortion scenarios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00011</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00011</id><submitter>Fahri Wisnu Murti</submitter><version version="v1"><date>Mon, 31 May 2021 07:57:27 GMT</date><size>3337kb</size><source_type>D</source_type></version><title>Constrained Deep Reinforcement Based Functional Split Optimization in
  Virtualized RANs</title><authors>Fahri Wisnu Murti, Samad Ali, and Matti Latva-aho</authors><categories>cs.NI eess.SP</categories><comments>Submitted to IEEE for possible publication. arXiv admin note: text
  overlap with arXiv:2105.14731</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtualized Radio Access Network (vRAN) brings agility to Next-Generation RAN
through functional split. It allows decomposing the base station (BS) functions
into virtualized components and hosts it either at the distributed-unit (DU) or
central-unit (CU). However, deciding which functions to deploy at DU or CU to
minimize the total network cost is challenging. In this paper, a constrained
deep reinforcement based functional split optimization (CDRS) is proposed to
optimize the locations of functions in vRAN. Our formulation results in a
combinatorial and NP-hard problem for which finding the exact solution is
computationally expensive. Hence, in our proposed approach, a policy gradient
method with Lagrangian relaxation is applied that uses a penalty signal to lead
the policy toward constraint satisfaction. It utilizes a neural network
architecture formed by an encoder-decoder sequence-to-sequence model based on
stacked Long Short-term Memory (LSTM) networks to approximate the policy.
Greedy decoding and temperature sampling methods are also leveraged for a
search strategy to infer the best solution among candidates from multiple
trained models that help to avoid a severe suboptimality. Simulations are
performed to evaluate the performance of the proposed solution in both
synthetic and real network datasets. Our findings reveal that CDRS successfully
learns the optimal decision, solves the problem with the accuracy of 0.05\%
optimality gap and becomes the most cost-effective compared to the available
RAN setups. Moreover, altering the routing cost and traffic load does not
significantly degrade the optimality. The results also show that all of our
CDRS settings have faster computational time than the optimal baseline solver.
Our proposed method fills the gap of optimizing the functional split offering a
near-optimal solution, faster computational time and minimal hand-engineering.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00012</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00012</id><submitter>Asier Guti\'errez-Fandi\~no</submitter><version version="v1"><date>Mon, 31 May 2021 09:17:31 GMT</date><size>12060kb</size><source_type>D</source_type></version><title>Persistent Homology Captures the Generalization of Neural Networks
  Without A Validation Set</title><authors>Asier Guti\'errez-Fandi\~no, David P\'erez-Fern\'andez, Jordi
  Armengol-Estap\'e, Marta Villegas</authors><categories>cs.LG cs.AI math.AT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The training of neural networks is usually monitored with a validation
(holdout) set to estimate the generalization of the model. This is done instead
of measuring intrinsic properties of the model to determine whether it is
learning appropriately. In this work, we suggest studying the training of
neural networks with Algebraic Topology, specifically Persistent Homology (PH).
Using simplicial complex representations of neural networks, we study the PH
diagram distance evolution on the neural network learning process with
different architectures and several datasets. Results show that the PH diagram
distance between consecutive neural network states correlates with the
validation accuracy, implying that the generalization error of a neural network
could be intrinsically estimated without any holdout set.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00014</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00014</id><submitter>Mircea Andrecut Dr</submitter><version version="v1"><date>Mon, 31 May 2021 16:27:50 GMT</date><size>348kb</size><source_type>D</source_type></version><title>Diffusion Self-Organizing Map on the Hypersphere</title><authors>M. Andrecut</authors><categories>cs.NE cs.LG</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a diffusion based implementation of the self-organizing map on the
unit hypersphere. We show that this approach can be efficiently implemented
using just linear algebra methods, we give a python numpy implementation, and
we illustrate the approach using the well known MNIST dataset.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00026</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00026</id><submitter>Max Tegmark</submitter><version version="v1"><date>Mon, 31 May 2021 18:00:10 GMT</date><size>1152kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 02:05:53 GMT</date><size>1155kb</size><source_type>D</source_type></version><title>Machine-Learning Non-Conservative Dynamics for New-Physics Detection</title><authors>Ziming Liu, Bohan Wang, Qi Meng, Wei Chen, Max Tegmark and Tie-Yan Liu</authors><categories>cs.LG astro-ph.IM gr-qc physics.comp-ph</categories><comments>17 pages, 7 figs, 2 tables; typo correction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy conservation is a basic physics principle, the breakdown of which
often implies new physics. This paper presents a method for data-driven &quot;new
physics&quot; discovery. Specifically, given a trajectory governed by unknown
forces, our Neural New-Physics Detector (NNPhD) aims to detect new physics by
decomposing the force field into conservative and non-conservative components,
which are represented by a Lagrangian Neural Network (LNN) and a universal
approximator network (UAN), respectively, trained to minimize the force
recovery error plus a constant $\lambda$ times the magnitude of the predicted
non-conservative force. We show that a phase transition occurs at $\lambda$=1,
universally for arbitrary forces. We demonstrate that NNPhD successfully
discovers new physics in toy numerical experiments, rediscovering friction
(1493) from a damped double pendulum, Neptune from Uranus' orbit (1846) and
gravitational waves (2017) from an inspiraling orbit. We also show how NNPhD
coupled with an integrator outperforms previous methods for predicting the
future of a damped double pendulum.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00038</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00038</id><submitter>Lei Jiang</submitter><version version="v1"><date>Mon, 31 May 2021 18:05:53 GMT</date><size>591kb</size><source_type>D</source_type></version><title>HEMET: A Homomorphic-Encryption-Friendly Privacy-Preserving Mobile
  Neural Network Architecture</title><authors>Qian Lou and Lei Jiang</authors><categories>cs.CR cs.AI</categories><journal-ref>The Thirty-eighth International Conference on Machine Learning
  2021</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently Homomorphic Encryption (HE) is used to implement Privacy-Preserving
Neural Networks (PPNNs) that perform inferences directly on encrypted data
without decryption. Prior PPNNs adopt mobile network architectures such as
SqueezeNet for smaller computing overhead, but we find na\&quot;ively using mobile
network architectures for a PPNN does not necessarily achieve shorter inference
latency. Despite having less parameters, a mobile network architecture
typically introduces more layers and increases the HE multiplicative depth of a
PPNN, thereby prolonging its inference latency. In this paper, we propose a
\textbf{HE}-friendly privacy-preserving \textbf{M}obile neural n\textbf{ET}work
architecture, \textbf{HEMET}. Experimental results show that, compared to
state-of-the-art (SOTA) PPNNs, HEMET reduces the inference latency by
$59.3\%\sim 61.2\%$, and improves the inference accuracy by $0.4 \% \sim
0.5\%$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00041</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00041</id><submitter>Milliam Maxime Zekeng Ndadji</submitter><version version="v1"><date>Mon, 31 May 2021 18:18:13 GMT</date><size>17718kb</size><source_type>D</source_type></version><title>A Grammatical Approach for Distributed Business Process Management using
  Structured and Cooperatively Edited Mobile Artifacts</title><authors>Milliam Maxime Zekeng Ndadji</authors><categories>cs.SE cs.FL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this thesis, we focus on the proposal of distributed workflow systems
dedicated to the automation of administrative business processes. We propose an
approach to build such systems by relying on the concepts of multiagent
systems, Peer to Peer (P2P) architecture, Service-Oriented Architecture (SOA)
and structured documents (artifacts) cooperative edition. Indeed, we develop
mathematical tools that allow any workflow systems designer, to express each
administrative process in the form of an attributed grammar whose symbols
represent tasks to be executed, productions specify a scheduling of these
tasks, and instances (the derivation trees that conform to it) represent the
different execution scenarios leading to business goal states. The obtained
grammatical model is then introduced into a proposed P2P system which is in
charge of carrying out the completely decentralised execution of the underlying
process's instances. The said system orchestrates a process's instance
execution as a choreography during which, various software agents driven by
human agents (actors), coordinate themselves through artifacts that they
collectively edit. The exchanged artifacts represent the system's memory: they
provide information on already executed tasks, on those ready to be executed
and on their executors. The software agents are autonomous and identical: they
execute the same unique protocol each time they receive an artifact. This
protocol allows them to identify the tasks they must immediately execute, to
execute them, to update the artifact and to disseminate it if necessary, for
the continuation of the execution. Moreover, actors potentially have only a
partial perception of processes in which they are involved. In practice, this
means that certain tasks can be carried out confidentially.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00042</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00042</id><submitter>Tudor Berariu</submitter><version version="v1"><date>Mon, 31 May 2021 18:21:06 GMT</date><size>447kb</size><source_type>D</source_type></version><title>A study on the plasticity of neural networks</title><authors>Tudor Berariu, Wojciech Czarnecki, Soham De, Jorg Bornschein, Samuel
  Smith, Razvan Pascanu and Claudia Clopath</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One aim shared by multiple settings, such as continual learning or transfer
learning, is to leverage previously acquired knowledge to converge faster on
the current task. Usually this is done through fine-tuning, where an implicit
assumption is that the network maintains its plasticity, meaning that the
performance it can reach on any given task is not affected negatively by
previously seen tasks. It has been observed recently that a pretrained model on
data from the same distribution as the one it is fine-tuned on might not reach
the same generalisation as a freshly initialised one. We build and extend this
observation, providing a hypothesis for the mechanics behind it. We discuss the
implication of losing plasticity for continual learning which heavily relies on
optimising pretrained models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00043</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00043</id><submitter>Matthew Baas</submitter><version version="v1"><date>Mon, 31 May 2021 18:21:28 GMT</date><size>501kb</size><source_type>D</source_type></version><title>StarGAN-ZSVC: Towards Zero-Shot Voice Conversion in Low-Resource
  Contexts</title><authors>Matthew Baas, Herman Kamper</authors><categories>eess.AS cs.CL cs.SD</categories><comments>16 pages, 3 figures. Published in Springer Communications in Computer
  and Information Science, Artificial Intelligence Research (SACAIR 2021), vol.
  1342, pp. 69-84, 2020</comments><journal-ref>In: Springer Communications in Computer and Information Science,
  Artificial Intelligence Research (SACAIR 2021), vol. 1342, pp. 69-84, 2020</journal-ref><doi>10.1007/978-3-030-66151-9_5</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Voice conversion is the task of converting a spoken utterance from a source
speaker so that it appears to be said by a different target speaker while
retaining the linguistic content of the utterance. Recent advances have led to
major improvements in the quality of voice conversion systems. However, to be
useful in a wider range of contexts, voice conversion systems would need to be
(i) trainable without access to parallel data, (ii) work in a zero-shot setting
where both the source and target speakers are unseen during training, and (iii)
run in real time or faster. Recent techniques fulfil one or two of these
requirements, but not all three. This paper extends recent voice conversion
models based on generative adversarial networks (GANs), to satisfy all three of
these conditions. We specifically extend the recent StarGAN-VC model by
conditioning it on a speaker embedding (from a potentially unseen speaker).
This allows the model to be used in a zero-shot setting, and we therefore call
it StarGAN-ZSVC. We compare StarGAN-ZSVC against other voice conversion
techniques in a low-resource setting using a small 9-minute training set.
Compared to AutoVC -- another recent neural zero-shot approach -- we observe
that StarGAN-ZSVC gives small improvements in the zero-shot setting, showing
that real-time zero-shot voice conversion is possible even for a model trained
on very little data. Further work is required to see whether scaling up
StarGAN-ZSVC will also improve zero-shot voice conversion quality in
high-resource contexts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00047</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00047</id><submitter>Abhishek Panigrahi</submitter><version version="v1"><date>Mon, 31 May 2021 18:27:51 GMT</date><size>2645kb</size><source_type>D</source_type></version><title>Learning and Generalization in RNNs</title><authors>Abhishek Panigrahi, Navin Goyal</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Simple recurrent neural networks (RNNs) and their more advanced cousins LSTMs
etc. have been very successful in sequence modeling. Their theoretical
understanding, however, is lacking and has not kept pace with the progress for
feedforward networks, where a reasonably complete understanding in the special
case of highly overparametrized one-hidden-layer networks has emerged. In this
paper, we make progress towards remedying this situation by proving that RNNs
can learn functions of sequences. In contrast to the previous work that could
only deal with functions of sequences that are sums of functions of individual
tokens in the sequence, we allow general functions. Conceptually and
technically, we introduce new ideas which enable us to extract information from
the hidden state of the RNN in our proofs -- addressing a crucial weakness in
previous work. We illustrate our results on some regular language recognition
problems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00050</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00050</id><submitter>Lukas Hedegaard</submitter><version version="v1"><date>Mon, 31 May 2021 18:30:52 GMT</date><size>938kb</size><source_type>D</source_type></version><title>Continual 3D Convolutional Neural Networks for Real-time Processing of
  Videos</title><authors>Lukas Hedegaard and Alexandros Iosifidis</authors><categories>cs.CV cs.LG</categories><comments>12 pages, 6 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces Continual 3D Convolutional Neural Networks (Co3D CNNs),
a new computational formulation of spatio-temporal 3D CNNs, in which videos are
processed frame-by-frame rather than by clip. In online processing tasks
demanding frame-wise predictions, Co3D CNNs dispense with the computational
redundancies of regular 3D CNNs, namely the repeated convolutions over frames,
which appear in multiple clips. While yielding an order of magnitude in
computational savings, Co3D CNNs have memory requirements comparable with that
of corresponding regular 3D CNNs and are less affected by changes in the size
of the temporal receptive field. We show that Continual 3D CNNs initialised on
the weights from preexisting state-of-the-art video recognition models reduce
the floating point operations for frame-wise computations by 10.0-12.4x while
improving accuracy on Kinetics-400 by 2.3-3.8. Moreover, we investigate the
transient start-up response of Co3D CNNs and perform an extensive benchmark of
online processing speed as well as accuracy for publicly available
state-of-the-art 3D CNNs on modern hardware.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00052</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00052</id><submitter>Nikolay Mikhaylovskiy</submitter><version version="v1"><date>Mon, 31 May 2021 18:35:27 GMT</date><size>1010kb</size></version><title>Low-Resource Spoken Language Identification Using Self-Attentive Pooling
  and Deep 1D Time-Channel Separable Convolutions</title><authors>Roman Bedyakin, Nikolay Mikhaylovskiy</authors><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted to Dialog2021. arXiv admin note: text overlap with
  arXiv:2104.11985</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This memo describes NTR/TSU winning submission for Low Resource ASR challenge
at Dialog2021 conference, language identification track.
  Spoken Language Identification (LID) is an important step in a multilingual
Automated Speech Recognition (ASR) system pipeline. Traditionally, the ASR task
requires large volumes of labeled data that are unattainable for most of the
world's languages, including most of the languages of Russia. In this memo, we
show that a convolutional neural network with a Self-Attentive Pooling layer
shows promising results in low-resource setting for the language identification
task and set up a SOTA for the Low Resource ASR challenge dataset.
  Additionally, we compare the structure of confusion matrices for this and
significantly more diverse VoxForge dataset and state and substantiate the
hypothesis that whenever the dataset is diverse enough so that the other
classification factors, like gender, age etc. are well-averaged, the confusion
matrix for LID system bears the language similarity measure.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00055</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00055</id><submitter>Thomas Bott</submitter><version version="v1"><date>Mon, 31 May 2021 18:41:39 GMT</date><size>304kb</size><source_type>D</source_type></version><title>More than just Frequency? Demasking Unsupervised Hypernymy Prediction
  Methods</title><authors>Thomas Bott, Dominik Schlechtweg and Sabine Schulte im Walde</authors><categories>cs.CL</categories><comments>ACL Findings, 5 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a comparison of unsupervised methods of hypernymy
prediction (i.e., to predict which word in a pair of words such as fish-cod is
the hypernym and which the hyponym). Most importantly, we demonstrate across
datasets for English and for German that the predictions of three methods
(WeedsPrec, invCL, SLQS Row) strongly overlap and are highly correlated with
frequency-based predictions. In contrast, the second-order method SLQS shows an
overall lower accuracy but makes correct predictions where the others go wrong.
Our study once more confirms the general need to check the frequency bias of a
computational method in order to identify frequency-(un)related effects.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00058</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00058</id><submitter>Bahareh Tolooshams</submitter><version version="v1"><date>Mon, 31 May 2021 18:49:58 GMT</date><size>1633kb</size><source_type>D</source_type></version><title>PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation</title><authors>Bahareh Tolooshams and Demba Ba</authors><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dictionary learning problem, representing data as a combination of few
atoms, has long stood as a popular method for learning representations in
statistics and signal processing. The most popular dictionary learning
algorithm alternates between sparse coding and dictionary update steps, and a
rich literature has studied its theoretical convergence. The growing popularity
of neurally plausible unfolded sparse coding networks has led to the empirical
finding that backpropagation through such networks performs dictionary
learning. This paper offers the first theoretical proof for these empirical
results through PUDLE, a Provable Unfolded Dictionary LEarning method. We
highlight the impact of loss, unfolding, and backpropagation on convergence. We
discover an implicit acceleration: as a function of unfolding, the
backpropagated gradient converges faster and is more accurate than the gradient
from alternating minimization. We complement our findings through synthetic and
image denoising experiments. The findings support the use of accelerated deep
learning optimizers and unfolded networks for dictionary learning.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00062</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00062</id><submitter>Haonan Wang</submitter><version version="v1"><date>Mon, 31 May 2021 19:07:17 GMT</date><size>5885kb</size><source_type>D</source_type></version><title>Controllable Gradient Item Retrieval</title><authors>Haonan Wang, Chang Zhou, Carl Yang, Hongxia Yang, Jingrui He</authors><categories>cs.IR</categories><comments>Accepted by The International World Wide Web Conference (WWW), 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we identify and study an important problem of gradient item
retrieval. We define the problem as retrieving a sequence of items with a
gradual change on a certain attribute, given a reference item and a
modification text. For example, after a customer saw a white dress, she/he
wants to buy a similar one but more floral on it. The extent of &quot;more floral&quot;
is subjective, thus prompting one floral dress is hard to satisfy the
customer's needs. A better way is to present a sequence of products with
increasingly floral attributes based on the white dress, and allow the customer
to select the most satisfactory one from the sequence. Existing item retrieval
methods mainly focus on whether the target items appear at the top of the
retrieved sequence, but ignore the demand for retrieving a sequence of products
with gradual change on a certain attribute. To deal with this problem, we
propose a weakly-supervised method that can learn a disentangled item
representation from user-item interaction data and ground the semantic meaning
of attributes to dimensions of the item representation. Our method takes a
reference item and a modification as a query. During inference, we start from
the reference item and &quot;walk&quot; along the direction of the modification in the
item representation space to retrieve a sequence of items in a gradient manner.
We demonstrate our proposed method can achieve disentanglement through weak
supervision. Besides, we empirically show that an item sequence retrieved by
our method is gradually changed on an indicated attribute and, in the item
retrieval task, our method outperforms existing approaches on three different
datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00063</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00063</id><submitter>Andrew Adamatzky</submitter><version version="v1"><date>Mon, 31 May 2021 19:12:20 GMT</date><size>11009kb</size><source_type>D</source_type></version><title>Living mycelium composites discern weights</title><authors>Andrew Adamatzky and Antoni Gandia</authors><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fungal construction materials -- substrates colonised by mycelium -- are
getting increased recognition as viable ecologically friendly alternatives to
conventional building materials. A functionality of the constructions made from
fungal materials would be enriched if blocks with living mycelium, known for
their ability to respond to chemical, optical and tactile stimuli, were
inserted. We investigate how large blocks of substrates colonised with mycelium
of \emph{Ganoderma resinaceum} respond to stimulation with heavy weights. We
analyse details of the electrical responses to the stimulation with weights and
show that ON and OFF stimuli can be discriminated by the living mycelium
composites and that a habituation to the stimulation occurs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00066</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00066</id><submitter>Sudeep Pasricha</submitter><version version="v1"><date>Mon, 31 May 2021 19:15:50 GMT</date><size>3608kb</size></version><title>Energy and Network Aware Workload Management for Geographically
  Distributed Data Centers</title><authors>Ninad Hogade, Sudeep Pasricha, Howard Jay Siegel</authors><categories>cs.DC cs.GT cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Cloud service providers are distributing data centers geographically to
minimize energy costs through intelligent workload distribution. With
increasing data volumes in emerging cloud workloads, it is critical to factor
in the network costs for transferring workloads across data centers. For
geo-distributed data centers, many researchers have been exploring strategies
for energy cost minimization and intelligent inter-data-center workload
distribution separately. However, prior work does not comprehensively and
simultaneously consider data center energy costs, data transfer costs, and data
center queueing delay. In this paper, we propose a novel game theory-based
workload management framework that takes a holistic approach to the cloud
operating cost minimization problem by making intelligent scheduling decisions
aware of data transfer costs and the data center queueing delay. Our framework
performs intelligent workload management that considers heterogeneity in data
center compute capability, cooling power, interference effects from task
co-location in servers, time-of-use electricity pricing, renewable energy, net
metering, peak demand pricing distribution, and network pricing. Our
simulations show that the proposed game-theoretic technique can minimize the
cloud operating cost more effectively than existing approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00072</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00072</id><submitter>Shixiang Zhu</submitter><version version="v1"><date>Mon, 31 May 2021 19:28:17 GMT</date><size>6105kb</size><source_type>D</source_type></version><title>Early Detection of COVID-19 Hotspots Using Spatio-Temporal Data</title><authors>Shixiang Zhu, Alexander Bukharin, Liyan Xie, Shihao Yang, Pinar
  Keskinocak, Yao Xie</authors><categories>stat.ML cs.LG stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the Centers for Disease Control and Prevention (CDC) has worked
with other federal agencies to identify counties with increasing coronavirus
disease 2019 (COVID-19) incidence (hotspots) and offers support to local health
departments to limit the spread of the disease. Understanding the
spatio-temporal dynamics of hotspot events is of great importance to support
policy decisions and prevent large-scale outbreaks. This paper presents a
spatio-temporal Bayesian framework for early detection of COVID-19 hotspots (at
the county level) in the United States. We assume both the observed number of
cases and hotspots depend on a class of latent random variables, which encode
the underlying spatio-temporal dynamics of the transmission of COVID-19. Such
latent variables follow a zero-mean Gaussian process, whose covariance is
specified by a non-stationary kernel function. The most salient feature of our
kernel function is that deep neural networks are introduced to enhance the
model's representative power while still enjoying the interpretability of the
kernel. We derive a sparse model and fit the model using a variational learning
strategy to circumvent the computational intractability for large data sets.
Our model demonstrates better interpretability and superior hotspot-detection
performance compared to other baseline methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00073</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00073</id><submitter>Tanujay Saha</submitter><version version="v1"><date>Mon, 31 May 2021 19:35:23 GMT</date><size>9965kb</size><source_type>D</source_type></version><title>GRAVITAS: Graphical Reticulated Attack Vectors for Internet-of-Things
  Aggregate Security</title><authors>Jacob Brown, Tanujay Saha, Niraj K. Jha</authors><categories>cs.CR cs.AI cs.LG cs.NI</categories><comments>This article has been published in IEEE Transactions on Emerging
  Topics in Computing, 2021</comments><doi>10.1109/TETC.2021.3082525</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Internet-of-Things (IoT) and cyber-physical systems (CPSs) may consist of
thousands of devices connected in a complex network topology. The diversity and
complexity of these components present an enormous attack surface, allowing an
adversary to exploit security vulnerabilities of different devices to execute a
potent attack. Though significant efforts have been made to improve the
security of individual devices in these systems, little attention has been paid
to security at the aggregate level. In this article, we describe a
comprehensive risk management system, called GRAVITAS, for IoT/CPS that can
identify undiscovered attack vectors and optimize the placement of defenses
within the system for optimal performance and cost. While existing risk
management systems consider only known attacks, our model employs a machine
learning approach to extrapolate undiscovered exploits, enabling us to identify
attacks overlooked by manual penetration testing (pen-testing). The model is
flexible enough to analyze practically any IoT/CPS and provide the system
administrator with a concrete list of suggested defenses that can reduce system
vulnerability at optimal cost. GRAVITAS can be employed by governments,
companies, and system administrators to design secure IoT/CPS at scale,
providing a quantitative measure of security and efficiency in a world where
IoT/CPS devices will soon be ubiquitous.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00075</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00075</id><submitter>Antonio Moretti</submitter><version version="v1"><date>Mon, 31 May 2021 19:44:24 GMT</date><size>1322kb</size><source_type>D</source_type></version><title>Variational Combinatorial Sequential Monte Carlo Methods for Bayesian
  Phylogenetic Inference</title><authors>Antonio Khalil Moretti, Liyi Zhang, Christian A. Naesseth, Hadiah
  Venner, David Blei, Itsik Pe'er</authors><categories>stat.ML cs.LG stat.CO</categories><comments>16 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bayesian phylogenetic inference is often conducted via local or sequential
search over topologies and branch lengths using algorithms such as random-walk
Markov chain Monte Carlo (MCMC) or Combinatorial Sequential Monte Carlo (CSMC).
However, when MCMC is used for evolutionary parameter learning, convergence
requires long runs with inefficient exploration of the state space. We
introduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a powerful
framework that establishes variational sequential search to learn distributions
over intricate combinatorial structures. We then develop nested CSMC, an
efficient proposal distribution for CSMC and prove that nested CSMC is an exact
approximation to the (intractable) locally optimal proposal. We use nested CSMC
to define a second objective, VNCSMC which yields tighter lower bounds than
VCSMC. We show that VCSMC and VNCSMC are computationally efficient and explore
higher probability spaces than existing methods on a range of tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00076</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00076</id><submitter>Sebastian Cygert</submitter><version version="v1"><date>Mon, 31 May 2021 19:50:43 GMT</date><size>12864kb</size><source_type>D</source_type></version><title>Closer Look at the Uncertainty Estimation in Semantic Segmentation under
  Distributional Shift</title><authors>Sebastian Cygert, Bart{\l}omiej Wr\'oblewski, Karol Wo\'zniak,
  Rados{\l}aw S{\l}owi\'nski, Andrzej Czy\.zewski</authors><categories>cs.CV</categories><comments>International Joint Conference on Neural Networks 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While recent computer vision algorithms achieve impressive performance on
many benchmarks, they lack robustness - presented with an image from a
different distribution, (e.g. weather or lighting conditions not considered
during training), they may produce an erroneous prediction. Therefore, it is
desired that such a model will be able to reliably predict its confidence
measure. In this work, uncertainty estimation for the task of semantic
segmentation is evaluated under a varying level of domain shift: in a
cross-dataset setting and when adapting a model trained on data from the
simulation. It was shown that simple color transformations already provide a
strong baseline, comparable to using more sophisticated style-transfer data
augmentation. Further, by constructing an ensemble consisting of models using
different backbones and/or augmentation methods, it was possible to improve
significantly model performance in terms of overall accuracy and uncertainty
estimation under the domain shift setting. The Expected Calibration Error (ECE)
on challenging GTA to Cityscapes adaptation was reduced from 4.05 to the
competitive value of 1.1. Further, an ensemble of models was utilized in the
self-training setting to improve the pseudo-labels generation, which resulted
in a significant gain in the final model accuracy, compared to the standard
fine-tuning (without ensemble).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00077</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00077</id><submitter>Nicolas Holliman Professor</submitter><version version="v1"><date>Mon, 31 May 2021 19:52:08 GMT</date><size>5097kb</size><source_type>D</source_type></version><title>Automating Visualization Quality Assessment: a Case Study in Higher
  Education</title><authors>Nicolas Steven Holliman</authors><categories>cs.HC cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a case study in the use of machine+human mixed intelligence for
visualization quality assessment, applying automated visualization quality
metrics to support the human assessment of data visualizations produced as
coursework by students taking higher education courses. A set of image
informatics algorithms including edge congestion, visual saliency and colour
analysis generate machine analysis of student visualizations. The insight from
the image informatics outputs has proved helpful for the marker in assessing
the work and is also provided to the students as part of a written report on
their work. Student and external reviewer comments suggest that the addition of
the image informatics outputs to the standard feedback document was a positive
step. We review the ethical challenges of working with assessment data and of
automating assessment processes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00083</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00083</id><submitter>Daniel Engel</submitter><version version="v1"><date>Mon, 31 May 2021 20:09:26 GMT</date><size>32kb</size></version><title>Composing Networks of Automated Market Makers</title><authors>Daniel Engel, Maurice Herlihy</authors><categories>cs.DC cs.MA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automated market makers (AMMs) are automata that trade electronic assets at
rates set by mathematical formulas. AMMs are usually implemented by smart
contracts on blockchains. In practice, AMMs are often composed: and outputs
from AMMs can be directed into other compatible AMMs. This paper proposes a
mathematical model for AMM composition. We define sequential and parallel
composition operators for AMMs in a way that ensures that AMMs are closed under
composition, in a way that works for &quot;higher-dimensional&quot; AMMs that manage more
than two asset classes, and so the composition of AMMs in &quot;stable&quot; states
remains stable.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00085</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00085</id><submitter>Clara Meister</submitter><version version="v1"><date>Mon, 31 May 2021 20:13:44 GMT</date><size>12053kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 03:41:11 GMT</date><size>12053kb</size><source_type>D</source_type></version><title>Language Model Evaluation Beyond Perplexity</title><authors>Clara Meister, Ryan Cotterell</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an alternate approach to quantifying how well language models
learn natural language: we ask how well they match the statistical tendencies
of natural language. To answer this question, we analyze whether text generated
from language models exhibits the statistical tendencies present in the
human-generated text on which they were trained. We provide a framework--paired
with significance tests--for evaluating the fit of language models to these
trends. We find that neural language models appear to learn only a subset of
the tendencies considered, but align much more closely with empirical trends
than proposed theoretical distributions (when present). Further, the fit to
different distributions is highly-dependent on both model architecture and
generation strategy. As concrete examples, text generated under the nucleus
sampling scheme adheres more closely to the type--token relationship of natural
language than text produced using standard ancestral sampling; text from LSTMs
reflects the natural language distributions over length, stopwords, and symbols
surprisingly well.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00089</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00089</id><submitter>Fernando Gama</submitter><version version="v1"><date>Mon, 31 May 2021 20:26:53 GMT</date><size>1663kb</size><source_type>D</source_type></version><title>Node-Variant Graph Filters in Graph Neural Networks</title><authors>Fernando Gama, Brendon G. Anderson, Somayeh Sojoudi</authors><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph neural networks (GNNs) have been successfully employed in a myriad of
applications involving graph-structured data. Theoretical findings establish
that GNNs use nonlinear activation functions to create low-eigenvalue frequency
content that can be processed in a stable manner by subsequent graph
convolutional filters. However, the exact shape of the frequency content
created by nonlinear functions is not known, and thus, it cannot be learned nor
controlled. In this work, node-variant graph filters (NVGFs) are shown to be
capable of creating frequency content and are thus used in lieu of nonlinear
activation functions. This results in a novel GNN architecture that, although
linear, is capable of creating frequency content as well. Furthermore, this new
frequency content can be either designed or learned from data. In this way, the
role of frequency creation is separated from the nonlinear nature of
traditional GNNs. Extensive simulations are carried out to differentiate the
contributions of frequency creation from those of the nonlinearity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00090</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00090</id><submitter>Yuanpeng Liu</submitter><version version="v1"><date>Mon, 31 May 2021 20:27:41 GMT</date><size>1332kb</size><source_type>D</source_type></version><title>Deep learning for prediction of hepatocellular carcinoma recurrence
  after resection or liver transplantation: a discovery and validation study</title><authors>Zhikun Liu, Yuanpeng Liu, Yuan Hong, Jinwen Meng, Jianguo Wang, Shusen
  Zheng and Xiao Xu</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This study aimed to develop a classifier of prognosis after resection or
liver transplantation (LT) for HCC by directly analysing the ubiquitously
available histological images using deep learning based neural networks.
Nucleus map set was used to train U-net to capture the nuclear architectural
information. Train set included the patients with HCC treated by resection and
has a distinct outcome. LT set contained patients with HCC treated by LT. Train
set and its nuclear architectural information extracted by U-net were used to
train MobileNet V2 based classifier (MobileNetV2_HCC_Class), purpose-built for
classifying supersized heterogeneous images. The MobileNetV2_HCC_Class
maintained relative higher discriminatory power than the other factors after
HCC resection or LT in the independent validation set. Pathological review
showed that the tumoral areas most predictive of recurrence were characterized
by presence of stroma, high degree of cytological atypia, nuclear
hyperchomasia, and a lack of immune infiltration. A clinically useful
prognostic classifier was developed using deep learning allied to histological
slides. The classifier has been extensively evaluated in independent patient
populations with different treatment, and gives consistent excellent results
across the classical clinical, biological and pathological features. The
classifier assists in refining the prognostic prediction of HCC patients and
identifying patients who would benefit from more intensive management.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00091</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00091</id><submitter>Kangning Wang</submitter><version version="v1"><date>Mon, 31 May 2021 20:28:59 GMT</date><size>376kb</size></version><title>Optimal Algorithms for Multiwinner Elections and the Chamberlin-Courant
  Rule</title><authors>Kamesh Munagala, Zeyu Shen and Kangning Wang</authors><categories>cs.GT cs.DS econ.TH</categories><comments>Accepted by the Twenty-Second ACM Conference on Economics and
  Computation (EC 2021)</comments><doi>10.1145/3465456.3467624</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the algorithmic question of choosing a subset of candidates of a
given size $k$ from a set of $m$ candidates, with knowledge of voters' ordinal
rankings over all candidates. We consider the well-known and classic scoring
rule for achieving diverse representation: the Chamberlin-Courant (CC) or
$1$-Borda rule, where the score of a committee is the average over the voters,
of the rank of the best candidate in the committee for that voter; and its
generalization to the average of the top $s$ best candidates, called the
$s$-Borda rule.
  Our first result is an improved analysis of the natural and well-studied
greedy heuristic. We show that greedy achieves a $\left(1 -
\frac{2}{k+1}\right)$-approximation to the maximization (or satisfaction)
version of CC rule, and a $\left(1 - \frac{2s}{k+1}\right)$-approximation to
the $s$-Borda score. Our result improves on the best known approximation
algorithm for this problem. We show that these bounds are almost tight.
  For the dissatisfaction (or minimization) version of the problem, we show
that the score of $\frac{m+1}{k+1}$ can be viewed as an optimal benchmark for
the CC rule, as it is essentially the best achievable score of any
polynomial-time algorithm even when the optimal score is a polynomial factor
smaller (under standard computational complexity assumptions). We show that
another well-studied algorithm for this problem, called the Banzhaf rule,
attains this benchmark.
  We finally show that for the $s$-Borda rule, when the optimal value is small,
these algorithms can be improved by a factor of $\tilde \Omega(\sqrt{s})$ via
LP rounding. Our upper and lower bounds are a significant improvement over
previous results, and taken together, not only enable us to perform a finer
comparison of greedy algorithms for these problems, but also provide analytic
justification for using such algorithms in practice.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00092</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00092</id><submitter>Kushal Chakrabarti</submitter><version version="v1"><date>Mon, 31 May 2021 20:30:25 GMT</date><size>581kb</size><source_type>D</source_type></version><title>Generalized AdaGrad (G-AdaGrad) and Adam: A State-Space Perspective</title><authors>Kushal Chakrabarti, Nikhil Chopra</authors><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accelerated gradient-based methods are being extensively used for solving
non-convex machine learning problems, especially when the data points are
abundant or the available data is distributed across several agents. Two of the
prominent accelerated gradient algorithms are AdaGrad and Adam. AdaGrad is the
simplest accelerated gradient method, which is particularly effective for
sparse data. Adam has been shown to perform favorably in deep learning problems
compared to other methods. In this paper, we propose a new fast optimizer,
Generalized AdaGrad (G-AdaGrad), for accelerating the solution of potentially
non-convex machine learning problems. Specifically, we adopt a state-space
perspective for analyzing the convergence of gradient acceleration algorithms,
namely G-AdaGrad and Adam, in machine learning. Our proposed state-space models
are governed by ordinary differential equations. We present simple convergence
proofs of these two algorithms in the deterministic settings with minimal
assumptions. Our analysis also provides intuition behind improving upon
AdaGrad's convergence rate. We provide empirical results on MNIST dataset to
reinforce our claims on the convergence and performance of G-AdaGrad and Adam.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00093</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00093</id><submitter>Yuval Filmus</submitter><version version="v1"><date>Mon, 31 May 2021 20:32:40 GMT</date><size>41kb</size></version><title>Approximate polymorphisms</title><authors>Gilad Chase and Yuval Filmus and Dor Minzer and Nitin Saurabh</authors><categories>cs.DM math.CO</categories><comments>43 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  For a function $g\colon\{0,1\}^m\to\{0,1\}$, a function $f\colon
\{0,1\}^n\to\{0,1\}$ is called a $g$-polymorphism if their actions commute:
$f(g(\mathsf{row}_1(Z)),\ldots,g(\mathsf{row}_n(Z))) =
g(f(\mathsf{col}_1(Z)),\ldots,f(\mathsf{col}_m(Z)))$ for all
$Z\in\{0,1\}^{n\times m}$. The function $f$ is called an approximate
polymorphism if this equality holds with probability close to $1$, when $Z$ is
sampled uniformly.
  We study the structure of exact polymorphisms as well as approximate
polymorphisms. Our results include:
  - We prove that an approximate polymorphism $f$ must be close to an exact
polymorphism;
  - We give a characterization of exact polymorphisms, showing that besides
trivial cases, only the functions $g = \mathsf{AND}, \mathsf{XOR}, \mathsf{OR},
\mathsf{NXOR}$ admit non-trivial exact polymorphisms.
  We also study the approximate polymorphism problem in the list-decoding
regime (i.e., when the probability equality holds is not close to $1$, but is
bounded away from some value) and obtain partial results.
  Our result generalize the classical linearity testing result of Blum, Luby
and Rubinfeld, that in this language showed that the approximate polymorphisms
of $g = \mathsf{XOR}$ are close to XOR's, as well as a recent result of Filmus,
Lifshitz, Minzer and Mossel, showing that the approximate polymorphisms of AND
can only be close to AND functions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00099</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00099</id><submitter>Harsh Satija</submitter><version version="v1"><date>Mon, 31 May 2021 21:04:21 GMT</date><size>3164kb</size><source_type>D</source_type></version><title>Multi-Objective SPIBB: Seldonian Offline Policy Improvement with Safety
  Constraints in Finite MDPs</title><authors>Harsh Satija, Philip S. Thomas, Joelle Pineau, Romain Laroche</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study the problem of Safe Policy Improvement (SPI) under constraints in
the offline Reinforcement Learning (RL) setting. We consider the scenario
where: (i) we have a dataset collected under a known baseline policy, (ii)
multiple reward signals are received from the environment inducing as many
objectives to optimize. We present an SPI formulation for this RL setting that
takes into account the preferences of the algorithm's user for handling the
trade-offs for different reward signals while ensuring that the new policy
performs at least as well as the baseline policy along each individual
objective. We build on traditional SPI algorithms and propose a novel method
based on Safe Policy Iteration with Baseline Bootstrapping (SPIBB, Laroche et
al., 2019) that provides high probability guarantees on the performance of the
agent in the true environment. We show the effectiveness of our method on a
synthetic grid-world safety task as well as in a real-world critical care
context to learn a policy for the administration of IV fluids and vasopressors
to treat sepsis.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00102</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00102</id><submitter>Michal Kompan</submitter><version version="v1"><date>Mon, 31 May 2021 21:09:23 GMT</date><size>830kb</size><source_type>D</source_type></version><title>The Cold-start Problem: Minimal Users' Activity Estimation</title><authors>Juraj Visnovsky, Ondrej Kassak, Michal Kompan, Maria Bielikova</authors><categories>cs.IR</categories><comments>1st Workshop on Recommender Systems for Television and online Video
  (RecSysTV) in conjunction with 8th ACM Conference on Recommender Systems,
  2014</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cold-start problem, which arises upon the new users arrival, is one of the
fundamental problems in today's recommender approaches. Moreover, in some
domains as TV or multime-dia-items take long time to experience by users, thus
users usually do not provide rich preference information. In this paper we
analyze the minimal amount of ratings needs to be done by a user over a set of
items, in order to solve or reduce the cold-start problem. In our analysis we
applied clustering data mining technique in order to identify minimal amount of
item's ratings required from recommender system's users, in order to be
assigned to a correct cluster. In this context, cluster quality is being
monitored and in case of reaching certain cluster quality threshold, the
rec-ommender system could start to generate recommendations for given user, as
in this point cold-start problem is considered as resolved. Our proposed
approach is applicable to any domain in which user preferences are received
based on explicit items rating. Our experiments are performed within the movie
and jokes recommendation domain using the MovieLens and Jester dataset.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00103</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00103</id><submitter>Rushikesh Kamalapurkar</submitter><version version="v1"><date>Mon, 31 May 2021 21:14:30 GMT</date><size>250kb</size><source_type>D</source_type></version><title>Control Occupation Kernel Regression for Nonlinear Control-Affine
  Systems</title><authors>Moad Abudia, Tejasvi Channagiri, Joel A. Rosenfeld, Rushikesh
  Kamalapurkar</authors><categories>math.OC cs.LG cs.SY eess.SY math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript presents an algorithm for obtaining an approximation of
nonlinear high order control affine dynamical systems, that leverages the
controlled trajectories as the central unit of information. As the fundamental
basis elements leveraged in approximation, higher order control occupation
kernels represent iterated integration after multiplication by a given
controller in a vector valued reproducing kernel Hilbert space. In a
regularized regression setting, the unique optimizer for a particular
optimization problem is expressed as a linear combination of these occupation
kernels, which converts an infinite dimensional optimization problem to a
finite dimensional optimization problem through the representer theorem.
Interestingly, the vector valued structure of the Hilbert space allows for
simultaneous approximation of the drift and control effectiveness components of
the control affine system. Several experiments are performed to demonstrate the
effectiveness of the approach.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00104</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00104</id><submitter>Yumo Xu</submitter><version version="v1"><date>Mon, 31 May 2021 21:14:58 GMT</date><size>85kb</size><source_type>D</source_type></version><title>Text Summarization with Latent Queries</title><authors>Yumo Xu and Mirella Lapata</authors><categories>cs.CL cs.LG</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability of large-scale datasets has driven the development of neural
models that create summaries from single documents, for generic purposes. When
using a summarization system, users often have specific intents with various
language realizations, which, depending on the information need, can range from
a single keyword to a long narrative composed of multiple questions. Existing
summarization systems, however, often either fail to support or act robustly on
this query focused summarization task. We introduce LaQSum, the first unified
text summarization system that learns Latent Queries from documents for
abstractive summarization with any existing query forms. Under a deep
generative framework, our system jointly optimizes a latent query model and a
conditional language model, allowing users to plug-and-play queries of any type
at test time. Despite learning from only generic summarization data and
requiring no further optimization for downstream summarization tasks, our
system robustly outperforms strong comparison systems across summarization
benchmarks with different query types, document settings, and target domains.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00106</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00106</id><submitter>Rushikesh Kamalapurkar</submitter><version version="v1"><date>Mon, 31 May 2021 21:20:01 GMT</date><size>1797kb</size><source_type>D</source_type></version><title>Anti-Koopmanism</title><authors>Efrain Gonzalez, Moad Abudia, Michael Jury, Rushikesh Kamalapurkar,
  Joel A. Rosenfeld</authors><categories>math.FA cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article addresses several longstanding misconceptions concerning Koopman
operators, including the existence of lattices of eigenfunctions, common
eigenfunctions between Koopman operators, and boundedness and compactness of
Koopman operators, among others. Counterexamples are provided for each
misconception. This manuscript also proves that the Gaussian RBF's native space
only supports bounded Koopman operator corresponding to affine dynamics, which
shows that the assumption of boundedness is very limiting. A framework for DMD
is presented that requires only densely defined Koopman operators over
reproducing kernel Hilbert spaces, and the effectiveness of this approach is
demonstrated through reconstruction examples.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00107</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00107</id><submitter>Terence Lines</submitter><version version="v1"><date>Mon, 31 May 2021 21:24:35 GMT</date><size>8821kb</size><source_type>D</source_type></version><title>3D map creation using crowdsourced GNSS data</title><authors>Terence Lines (1) and Ana Basiri (1) ((1) School of Geographical and
  Earth Sciences, University of Glasgow)</authors><categories>cs.RO cs.CV eess.SP</categories><comments>25 pages with 11 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  3D maps are increasingly useful for many applications such as drone
navigation, emergency services, and urban planning. However, creating 3D maps
and keeping them up-to-date using existing technologies, such as laser
scanners, is expensive. This paper proposes and implements a novel approach to
generate 2.5D (otherwise known as 3D level-of-detail (LOD) 1) maps for free
using Global Navigation Satellite Systems (GNSS) signals, which are globally
available and are blocked only by obstacles between the satellites and the
receivers. This enables us to find the patterns of GNSS signal availability and
create 3D maps. The paper applies algorithms to GNSS signal strength patterns
based on a boot-strapped technique that iteratively trains the signal
classifiers while generating the map. Results of the proposed technique
demonstrate the ability to create 3D maps using automatically processed GNSS
data. The results show that the third dimension, i.e. height of the buildings,
can be estimated with below 5 metre accuracy, which is the benchmark
recommended by the CityGML standard.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00109</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00109</id><submitter>Jong Gwang Kim</submitter><version version="v1"><date>Mon, 31 May 2021 21:31:06 GMT</date><size>124kb</size></version><title>Equilibrium Computation of Generalized Nash Games: A New
  Lagrangian-Based Approach</title><authors>Jong Gwang Kim</authors><categories>cs.GT math.OC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a new primal-dual method for computing an equilibrium of
generalized (continuous) Nash game (referred to as generalized Nash equilibrium
problem (GNEP)) where each player's feasible strategy set depends on the other
players' strategies. The method is based on a new form of Lagrangian function
with a quadratic approximation. First, we reformulate a GNEP as a saddle point
computation using the new Lagrangian and establish equivalence between a saddle
point of the Lagrangian and an equilibrium of the GNEP. We then propose a
simple algorithm that is convergent to the saddle point. Furthermore, we
establish global convergence by assuming that the Lagrangian function satisfies
the Kurdyka-{\L}ojasiewicz property. A distinctive feature of our analysis is
to make use of the new Lagrangian as a potential function to guide the iterate
convergence, which is based on the idea of turning a descent method into a
multiplier method. Our method has two novel features over existing approaches:
(i) it requires neither boundedness assumptions on the strategy set and the set
of multipliers of each player, nor any boundedness assumptions on the iterates
generated by the algorithm; (ii) it leads to a Jacobi-type decomposition
scheme, which, to the best of our knowledge, is the first development of a
distributed algorithm to solve a general class of GNEPs. Numerical experiments
are performed on benchmark test problems and the results demonstrate the
effectiveness of the proposed method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00110</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00110</id><submitter>Anna Yanchenko</submitter><version version="v1"><date>Mon, 31 May 2021 21:31:27 GMT</date><size>11909kb</size><source_type>D</source_type></version><title>Towards Explainable Convolutional Features for Music Audio Modeling</title><authors>Anna K. Yanchenko, Mohammadreza Soltani, Robert J. Ravier, Sayan
  Mukherjee and Vahid Tarokh</authors><categories>cs.SD cs.LG eess.AS</categories><comments>Code available at
  https://github.com/aky4wn/convolutions-for-music-audio</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio signals are often represented as spectrograms and treated as 2D images.
In this light, deep convolutional architectures are widely used for music audio
tasks even though these two data types have very different structures. In this
work, we attempt to &quot;open the black-box&quot; on deep convolutional models to inform
future architectures for music audio tasks, and explain the excellent
performance of deep convolutions that model spectrograms as 2D images. To this
end, we expand recent explainability discussions in deep learning for natural
image data to music audio data through systematic experiments using the deep
features learned by various convolutional architectures. We demonstrate that
deep convolutional features perform well across various target tasks, whether
or not they are extracted from deep architectures originally trained on that
task. Additionally, deep features exhibit high similarity to hand-crafted
wavelet features, whether the deep features are extracted from a trained or
untrained model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00115</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00115</id><submitter>Waleed Mustafa</submitter><version version="v1"><date>Mon, 31 May 2021 21:44:14 GMT</date><size>59kb</size></version><title>Fine-grained Generalization Analysis of Structured Output Prediction</title><authors>Waleed Mustafa, Yunwen Lei, Antoine Ledent, Marius Kloft</authors><categories>cs.LG stat.ML</categories><comments>To appearn in IJCAI 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In machine learning we often encounter structured output prediction problems
(SOPPs), i.e. problems where the output space admits a rich internal structure.
Application domains where SOPPs naturally occur include natural language
processing, speech recognition, and computer vision. Typical SOPPs have an
extremely large label set, which grows exponentially as a function of the size
of the output. Existing generalization analysis implies generalization bounds
with at least a square-root dependency on the cardinality $d$ of the label set,
which can be vacuous in practice. In this paper, we significantly improve the
state of the art by developing novel high-probability bounds with a logarithmic
dependency on $d$. Moreover, we leverage the lens of algorithmic stability to
develop generalization bounds in expectation without any dependency on $d$. Our
results therefore build a solid theoretical foundation for learning in
large-scale SOPPs. Furthermore, we extend our results to learning with weakly
dependent data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00116</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00116</id><submitter>Jenia Jitsev</submitter><version version="v1"><date>Mon, 31 May 2021 21:55:56 GMT</date><size>137kb</size><source_type>D</source_type></version><title>Effect of large-scale pre-training on full and few-shot transfer
  learning for natural and medical images</title><authors>Mehdi Cherti and Jenia Jitsev</authors><categories>cs.LG cs.AI cs.CV</categories><comments>Preprint. Under review</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transfer learning aims to exploit pre-trained models for more efficient
follow-up training on wide range of downstream tasks and datasets, enabling
successful training also on small data. Recent line of work posits strong
benefits for model generalization and transfer when model size, data size, and
compute budget are increased for the pre-training. It remains however still
largely unclear whether the observed transfer improvement due to increase in
scale also holds when source and target data distributions are far apart from
each other. In this work we conduct large-scale pre-training on large source
datasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and
compare full and few-shot transfer using different target datasets from both
natural and medical imaging domains. Our observations provide evidence that
while pre-training and transfer on closely related datasets do show clear
benefit of increasing model and data size during pre-training, such benefits
are not clearly visible when source and target datasets are further apart.
These observations hold across both full and few-shot transfer and indicate
that scaling laws hinting improvement of generalization and transfer with
increasing model and data size are incomplete and should also take into account
the degree of how distinct the source and target data distributions are, to
correctly predict effect of model size and data size variation during
pre-training on transfer. (Repository for reproducing the experiments will be
made available.)
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00120</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00120</id><submitter>Daniel T Chang</submitter><version version="v1"><date>Mon, 31 May 2021 22:13:21 GMT</date><size>947kb</size></version><version version="v2"><date>Wed, 2 Jun 2021 00:45:23 GMT</date><size>947kb</size></version><title>Probabilistic Deep Learning with Probabilistic Neural Networks and Deep
  Probabilistic Models</title><authors>Daniel T. Chang</authors><categories>cs.LG stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:1811.06622</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic deep learning is deep learning that accounts for uncertainty,
both model uncertainty and data uncertainty. It is based on the use of
probabilistic models and deep neural networks. We distinguish two approaches to
probabilistic deep learning: probabilistic neural networks and deep
probabilistic models. The former employs deep neural networks that utilize
probabilistic layers which can represent and process uncertainty; the latter
uses probabilistic models that incorporate deep neural network components which
capture complex non-linear stochastic relationships between the random
variables. We discuss some major examples of each approach including Bayesian
neural networks and mixture density networks (for probabilistic neural
networks), and variational autoencoders, deep Gaussian processes and deep mixed
effects models (for deep probabilistic models). TensorFlow Probability is a
library for probabilistic modeling and inference which can be used for both
approaches of probabilistic deep learning. We include its code examples for
illustration.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00122</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00122</id><submitter>Sebin Gracy</submitter><version version="v1"><date>Mon, 31 May 2021 22:25:17 GMT</date><size>91kb</size></version><title>Suppressing the endemic equilibrium in SIS epidemics: A state dependent
  approach</title><authors>Yuan Wang, Sebin Gracy, Hideaki Ishii, Karl Henrik Johansson</authors><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the susceptible-infected-susceptible (SIS) epidemic
model with an underlying network structure among subpopulations and focuses on
the effect of social distancing to regulate the epidemic level. We demonstrate
that if each subpopulation is informed of its infection rate and reduces
interactions accordingly, the fraction of the subpopulation infected can remain
below half for all time instants. To this end, we first modify the basic SIS
model by introducing a state dependent parameter representing the frequency of
interactions between subpopulations. Thereafter, we show that for this modified
SIS model, the spectral radius of a suitably-defined matrix being not greater
than one causes all the agents, regardless of their initial sickness levels, to
converge to the healthy state; assuming non-trivial disease spread, the
spectral radius being greater than one leads to the existence of a unique
endemic equilibrium, which is also asymptotically stable. Finally, by
leveraging the aforementioned results, we show that the fraction of
(sub)populations infected never exceeds half.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00123</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00123</id><submitter>Tidor-Vlad Pricope</submitter><version version="v1"><date>Mon, 31 May 2021 22:26:43 GMT</date><size>1450kb</size><source_type>D</source_type></version><title>Deep Reinforcement Learning in Quantitative Algorithmic Trading: A
  Review</title><authors>Tidor-Vlad Pricope</authors><categories>cs.LG q-fin.TR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Algorithmic stock trading has become a staple in today's financial market,
the majority of trades being now fully automated. Deep Reinforcement Learning
(DRL) agents proved to be to a force to be reckon with in many complex games
like Chess and Go. We can look at the stock market historical price series and
movements as a complex imperfect information environment in which we try to
maximize return - profit and minimize risk. This paper reviews the progress
made so far with deep reinforcement learning in the subdomain of AI in finance,
more precisely, automated low-frequency quantitative stock trading. Many of the
reviewed studies had only proof-of-concept ideals with experiments conducted in
unrealistic settings and no real-time trading applications. For the majority of
the works, despite all showing statistically significant improvements in
performance compared to established baseline strategies, no decent
profitability level was obtained. Furthermore, there is a lack of experimental
testing in real-time, online trading platforms and a lack of meaningful
comparisons between agents built on different types of DRL or human traders. We
conclude that DRL in stock trading has showed huge applicability potential
rivalling professional traders under strong assumptions, but the research is
still in the very early stages of development.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00124</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00124</id><submitter>Helen Xu</submitter><version version="v1"><date>Mon, 31 May 2021 22:39:50 GMT</date><size>2250kb</size><source_type>D</source_type></version><title>Multidimensional Included and Excluded Sums</title><authors>Helen Xu, Sean Fraser, Charles E. Leiserson</authors><categories>cs.DS</categories><comments>18 pages, short version to appear in ACDA 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents algorithms for the included-sums and excluded-sums
problems used by scientific computing applications such as the fast multipole
method. These problems are defined in terms of a $d$-dimensional array of $N$
elements and a binary associative operator~$\oplus$ on the elements. The
included-sum problem requires that the elements within overlapping boxes
cornered at each element within the array be reduced using $\oplus$. The
excluded-sum problem reduces the elements outside each box. The weak versions
of these problems assume that the operator $\oplus$ has an inverse $\ominus$,
whereas the strong versions do not require this assumption. In addition to
studying existing algorithms to solve these problems, we introduce three new
algorithms.
  The bidirectional box-sum (BDBS) algorithm solves the strong included-sums
problem in $\Theta(d N)$ time, asymptotically beating the classical summed-area
table (SAT) algorithm, which runs in $\Theta(2^d N)$ and which only solves the
weak version of the problem. Empirically, the BDBS algorithm outperforms the
SAT algorithm in higher dimensions by up to $17.1\times$.
  The \defn{box-complement} algorithm can solve the strong excluded-sums
problem in $\Theta(d N)$ time, asymptotically beating the state-of-the-art
corners algorithm by Demaine et al., which runs in $\Omega(2^d N)$ time. In 3
dimensions the box-complement algorithm empirically outperforms the corners
algorithm by about $1.4\times$ given similar amounts of space.
  The weak excluded-sums problem can be solved in $\Theta(d N)$ time by the
bidirectional box-sum complement (BDBSC) algorithm, which is a trivial
extension of the BDBS algorithm. Given an operator inverse $\ominus$, BDBSC can
beat box-complement by up to a factor of $4$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00127</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00127</id><submitter>Guo Qingyu</submitter><version version="v1"><date>Fri, 28 May 2021 09:28:12 GMT</date><size>261kb</size><source_type>D</source_type></version><title>Integer-Only Neural Network Quantization Scheme Based on
  Shift-Batch-Normalization</title><authors>Qingyu Guo, Yuan Wang, Xiaoxin Cui</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Neural networks are very popular in many areas, but great computing
complexity makes it hard to run neural networks on devices with limited
resources. To address this problem, quantization methods are used to reduce
model size and computation cost, making it possible to use neural networks on
embedded platforms or mobile devices.
  In this paper, an integer-only-quantization scheme is introduced. This scheme
uses one layer that combines shift-based batch normalization and uniform
quantization to implement 4-bit integer-only inference. Without big integer
multiplication(which is used in previous integer-only-quantization methods),
this scheme can achieve good power and latency efficiency, and is especially
suitable to be deployed on co-designed hardware platforms. Tests have proved
that this scheme works very well for easy tasks. And for tough tasks,
performance loss can be tolerated for its inference efficiency. Our work is
available on github: https://github.com/hguq/IntegerNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00130</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00130</id><submitter>Rui Meng</submitter><version version="v1"><date>Mon, 31 May 2021 22:58:38 GMT</date><size>13357kb</size><source_type>D</source_type></version><title>Bringing Structure into Summaries: a Faceted Summarization Dataset for
  Long Scientific Documents</title><authors>Rui Meng, Khushboo Thaker, Lei Zhang, Yue Dong, Xingdi Yuan, Tong
  Wang, Daqing He</authors><categories>cs.CL</categories><comments>Accepted at ACL2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Faceted summarization provides briefings of a document from different
perspectives. Readers can quickly comprehend the main points of a long document
with the help of a structured outline. However, little research has been
conducted on this subject, partially due to the lack of large-scale faceted
summarization datasets. In this study, we present FacetSum, a faceted
summarization benchmark built on Emerald journal articles, covering a diverse
range of domains. Different from traditional document-summary pairs, FacetSum
provides multiple summaries, each targeted at specific sections of a long
document, including the purpose, method, findings, and value. Analyses and
empirical results on our dataset reveal the importance of bringing structure
into summaries. We believe FacetSum will spur further advances in summarization
research and foster the development of NLP systems that can leverage the
structured information in both long texts and summaries.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00131</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00131</id><submitter>Yaling Tao Dr.</submitter><version version="v1"><date>Mon, 31 May 2021 22:59:31 GMT</date><size>10915kb</size><source_type>D</source_type></version><title>Clustering-friendly Representation Learning via Instance Discrimination
  and Feature Decorrelation</title><authors>Yaling Tao, Kentaro Takagi, Kouta Nakata</authors><categories>cs.LG cs.CV</categories><comments>15 pages, ICLR2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is one of the most fundamental tasks in machine learning.
Recently, deep clustering has become a major trend in clustering techniques.
Representation learning often plays an important role in the effectiveness of
deep clustering, and thus can be a principal cause of performance degradation.
In this paper, we propose a clustering-friendly representation learning method
using instance discrimination and feature decorrelation. Our
deep-learning-based representation learning method is motivated by the
properties of classical spectral clustering. Instance discrimination learns
similarities among data and feature decorrelation removes redundant correlation
among features. We utilize an instance discrimination method in which learning
individual instance classes leads to learning similarity among instances.
Through detailed experiments and examination, we show that the approach can be
adapted to learning a latent space for clustering. We design novel
softmax-formulated decorrelation constraints for learning. In evaluations of
image clustering using CIFAR-10 and ImageNet-10, our method achieves accuracy
of 81.5% and 95.4%, respectively. We also show that the softmax-formulated
constraints are compatible with various neural networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00132</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00132</id><submitter>Zhifeng Kong</submitter><version version="v1"><date>Mon, 31 May 2021 23:00:54 GMT</date><size>4565kb</size><source_type>D</source_type></version><title>On Fast Sampling of Diffusion Probabilistic Models</title><authors>Zhifeng Kong, Wei Ping</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose FastDPM, a unified framework for fast sampling in
diffusion probabilistic models. FastDPM generalizes previous methods and gives
rise to new algorithms with improved sample quality. We systematically
investigate the fast sampling methods under this framework across different
domains, on different datasets, and with different amount of conditional
information provided for generation. We find the performance of a particular
method depends on data domains (e.g., image or audio), the trade-off between
sampling speed and sample quality, and the amount of conditional information.
We further provide insights and recipes on the choice of methods for
practitioners.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00133</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00133</id><submitter>Maayan Shvo</submitter><version version="v1"><date>Mon, 31 May 2021 23:02:38 GMT</date><size>19206kb</size><source_type>D</source_type></version><title>AppBuddy: Learning to Accomplish Tasks in Mobile Apps via Reinforcement
  Learning</title><authors>Maayan Shvo, Zhiming Hu, Rodrigo Toro Icarte, Iqbal Mohomed, Allan
  Jepson, Sheila A. McIlraith</authors><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human beings, even small children, quickly become adept at figuring out how
to use applications on their mobile devices. Learning to use a new app is often
achieved via trial-and-error, accelerated by transfer of knowledge from past
experiences with like apps. The prospect of building a smarter smartphone - one
that can learn how to achieve tasks using mobile apps - is tantalizing. In this
paper we explore the use of Reinforcement Learning (RL) with the goal of
advancing this aspiration. We introduce an RL-based framework for learning to
accomplish tasks in mobile apps. RL agents are provided with states derived
from the underlying representation of on-screen elements, and rewards that are
based on progress made in the task. Agents can interact with screen elements by
tapping or typing. Our experimental results, over a number of mobile apps, show
that RL agents can learn to accomplish multi-step tasks, as well as achieve
modest generalization across different apps. More generally, we develop a
platform which addresses several engineering challenges to enable an effective
RL training environment. Our AppBuddy platform is compatible with OpenAI Gym
and includes a suite of mobile apps and benchmark tasks that supports a
diversity of RL research in the mobile app setting.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00134</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00134</id><submitter>Tianlong Chen</submitter><version version="v1"><date>Mon, 31 May 2021 23:03:00 GMT</date><size>7731kb</size><source_type>D</source_type></version><title>GANs Can Play Lottery Tickets Too</title><authors>Xuxi Chen, Zhenyu Zhang, Yongduo Sui, Tianlong Chen</authors><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep generative adversarial networks (GANs) have gained growing popularity in
numerous scenarios, while usually suffer from high parameter complexities for
resource-constrained real-world applications. However, the compression of GANs
has less been explored. A few works show that heuristically applying
compression techniques normally leads to unsatisfactory results, due to the
notorious training instability of GANs. In parallel, the lottery ticket
hypothesis shows prevailing success on discriminative models, in locating
sparse matching subnetworks capable of training in isolation to full model
performance. In this work, we for the first time study the existence of such
trainable matching subnetworks in deep GANs. For a range of GANs, we certainly
find matching subnetworks at 67%-74% sparsity. We observe that with or without
pruning discriminator has a minor effect on the existence and quality of
matching subnetworks, while the initialization weights used in the
discriminator play a significant role. We then show the powerful
transferability of these subnetworks to unseen tasks. Furthermore, extensive
experimental results demonstrate that our found subnetworks substantially
outperform previous state-of-the-art GAN compression approaches in both image
generation (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN).
Codes available at https://github.com/VITA-Group/GAN-LTH.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00135</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00135</id><submitter>Mohannad Alkhraijah</submitter><version version="v1"><date>Mon, 31 May 2021 23:04:31 GMT</date><size>5678kb</size><source_type>D</source_type></version><title>Evaluating the Performance of Distributed Optimal Power Flow Algorithms
  with Nonideal Communication</title><authors>Mohannad Alkhraijah, Carlos Menendez, and Daniel K. Molzahn</authors><categories>eess.SY cs.SY</categories><comments>10 pages with 16 figures, the paper is submitted to IEEE Transactions
  on Smart Grid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power system operators are increasingly looking toward distributed
optimization to address various challenges facing electric power systems. To
assess their capabilities in environments with nonideal communications, this
paper investigates the impacts of data quality on the performance of
distributed optimization algorithms. Specifically, this paper compares the
performance of the Alternating Direction Method of Multipliers (ADMM), Analytic
Target Cascading (ATC), and Auxiliary Principal Problem (APP) algorithms in the
context of DC Optimal Power Flow (DC OPF) problems. Using several test cases,
this paper characterizes the performance of these algorithms in terms of their
convergence rates and solution quality under three data quality nonidealities:
(1) additive Gaussian noise, (2) false data, and (3) intermittent communication
failure.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00136</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00136</id><submitter>Anuj Mahajan</submitter><version version="v1"><date>Mon, 31 May 2021 23:08:05 GMT</date><size>2776kb</size><source_type>D</source_type></version><title>Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning</title><authors>Anuj Mahajan, Mikayel Samvelyan, Lei Mao, Viktor Makoviychuk, Animesh
  Garg, Jean Kossaifi, Shimon Whiteson, Yuke Zhu, Animashree Anandkumar</authors><categories>cs.LG</categories><comments>38th International Conference on Machine Learning, PMLR 139, 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Reinforcement Learning in large action spaces is a challenging problem.
Cooperative multi-agent reinforcement learning (MARL) exacerbates matters by
imposing various constraints on communication and observability. In this work,
we consider the fundamental hurdle affecting both value-based and
policy-gradient approaches: an exponential blowup of the action space with the
number of agents. For value-based methods, it poses challenges in accurately
representing the optimal value function. For policy gradient methods, it makes
training the critic difficult and exacerbates the problem of the lagging
critic. We show that from a learning theory perspective, both problems can be
addressed by accurately representing the associated action-value function with
a low-complexity hypothesis class. This requires accurately modelling the agent
interactions in a sample efficient way. To this end, we propose a novel
tensorised formulation of the Bellman equation. This gives rise to our method
Tesseract, which views the Q-function as a tensor whose modes correspond to the
action spaces of different agents. Algorithms derived from Tesseract decompose
the Q-tensor across agents and utilise low-rank tensor approximations to model
agent interactions relevant to the task. We provide PAC analysis for
Tesseract-based algorithms and highlight their relevance to the class of rich
observation MDPs. Empirical results in different domains confirm Tesseract's
gains in sample efficiency predicted by the theory.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00139</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00139</id><submitter>Jiaming Shen</submitter><version version="v1"><date>Mon, 31 May 2021 23:19:00 GMT</date><size>559kb</size><source_type>D</source_type></version><title>Training ELECTRA Augmented with Multi-word Selection</title><authors>Jiaming Shen, Jialu Liu, Tianqi Liu, Cong Yu, Jiawei Han</authors><categories>cs.CL</categories><comments>Accepted in Findings of ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pre-trained text encoders such as BERT and its variants have recently
achieved state-of-the-art performances on many NLP tasks. While being
effective, these pre-training methods typically demand massive computation
resources. To accelerate pre-training, ELECTRA trains a discriminator that
predicts whether each input token is replaced by a generator. However, this new
task, as a binary classification, is less semantically informative. In this
study, we present a new text encoder pre-training method that improves ELECTRA
based on multi-task learning. Specifically, we train the discriminator to
simultaneously detect replaced tokens and select original tokens from candidate
sets. We further develop two techniques to effectively combine all pre-training
tasks: (1) using attention-based networks for task-specific heads, and (2)
sharing bottom layers of the generator and the discriminator. Extensive
experiments on GLUE and SQuAD datasets demonstrate both the effectiveness and
the efficiency of our proposed method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00141</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00141</id><submitter>Tyler Kaczmarek</submitter><version version="v1"><date>Mon, 31 May 2021 23:20:54 GMT</date><size>8225kb</size><source_type>D</source_type></version><title>Proactive Provenance Policies for Automatic Cryptographic Data Centric
  Security</title><authors>Shamaria Engram, Tyler Kaczmarek, Alice Lee, and David Bigelow</authors><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Data provenance analysis has been used as an assistive measure for ensuring
system integrity. However, such techniques are typically reactive approaches to
identify the root cause of an attack in its aftermath. This is in part due to
fact that the collection of provenance metadata often results in a deluge of
information that cannot easily be queried and analyzed in real time. This paper
presents an approach for proactively reasoning about provenance metadata within
the Automatic Cryptographic Data Centric (ACDC) security architecture, a new
security infrastructure in which all data interactions are considered at a
coarse granularity, similar to the Function as a Service model. At this scale,
we have found that data interactions are manageable for the proactive
specification and evaluation of provenance policies -- constraints placed on
provenance metadata to prevent the consumption of untrusted data. This paper
provides a model for proactively evaluating provenance metadata in the ACDC
paradigm as well as a case study of an electronic voting scheme to demonstrate
the applicability of ACDC and the provenance policies needed to ensure data
integrity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00142</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00142</id><submitter>Ujun Jeong</submitter><version version="v1"><date>Mon, 31 May 2021 23:20:58 GMT</date><size>304kb</size><source_type>D</source_type></version><title>FBAdTracker: An Interactive Data Collection and Analysis Tool for
  Facebook Advertisements</title><authors>Ujun Jeong, Kaize Ding, Huan Liu</authors><categories>cs.IR</categories><comments>3 pages, 1 figure, 2021 International Conference on Social Computing,
  Behavioral-Cultural Modeling, &amp; Prediction and Behavior Representation in
  Modeling and Simulation, demo track</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The growing use of social media has led to drastic changes in our
decision-making. Especially, Facebook offers marketing API which promotes
business to target potential groups who are likely to consume their items.
However, this service can be abused by malicious advertisers who attempt to
deceive people by disinformation such as propaganda and divisive opinion. To
counter this problem, we introduce a new application named FBAdTracker. The
purpose of this application is to provide an integrated data collection and
analysis system for current research on fact-checking related to Facebook
advertisements. Our system is capable of monitoring up-to-date Facebook ads and
analyzing ads retrieved from Facebook Ads Library.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00143</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00143</id><submitter>Tharindu Ranasinghe Mr</submitter><version version="v1"><date>Mon, 31 May 2021 23:21:10 GMT</date><size>5711kb</size><source_type>D</source_type></version><title>An Exploratory Analysis of Multilingual Word-Level Quality Estimation
  with Cross-Lingual Transformers</title><authors>Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov</authors><categories>cs.CL cs.AI cs.LG</categories><comments>Accepted to appear at the ACL-IJCNLP 2021 Main conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Most studies on word-level Quality Estimation (QE) of machine translation
focus on language-specific models. The obvious disadvantages of these
approaches are the need for labelled data for each language pair and the high
cost required to maintain several language-specific models. To overcome these
problems, we explore different approaches to multilingual, word-level QE. We
show that these QE models perform on par with the current language-specific
models. In the cases of zero-shot and few-shot QE, we demonstrate that it is
possible to accurately predict word-level quality for any given new language
pair from models trained on other language pairs. Our findings suggest that the
word-level QE models based on powerful pre-trained transformers that we propose
in this paper generalise well across languages, making them more useful in
real-world scenarios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00144</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00144</id><submitter>Robert Mieth</submitter><version version="v1"><date>Mon, 31 May 2021 23:23:53 GMT</date><size>2069kb</size><source_type>D</source_type></version><title>Risk-Aware Dimensioning and Procurement of Contingency Reserve</title><authors>Robert Mieth, Yury Dvorkin, Miguel A. Ortega-Vazquez</authors><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current contingency reserve criteria ignore the likelihood of individual
contingencies and, thus, their impact on system reliability and risk. This
paper develops an iterative approach, inspired by the current
security-constrained unit commitment (SCUC) practice, enabling system operators
to determine risk-cognizant contingency reserve requirements and their
allocation with minimal alterations to the current SCUC practice. The proposed
approach uses generator and transmission system reliability models, including
failure-to synchronize and adverse conditions, to compute contingency
probabilities, which inform a risk-based system reliability assessment, and
ensures reserve deliverability by learning the response of generators to
post-contingency states within the SCUC. The effectiveness of the proposed
approach is demonstrated using the Grid Modernization Lab Consortium update of
the Reliability Test System.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00145</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00145</id><submitter>Tedo Vrbanec</submitter><version version="v1"><date>Mon, 31 May 2021 23:29:24 GMT</date><size>1450kb</size></version><title>Corpus-Based Paraphrase Detection Experiments and Review</title><authors>Tedo Vrbanec and Ana Mestrovic</authors><categories>cs.CL cs.LG</categories><comments>25 pages, 7 figures, 4 tables</comments><journal-ref>In Information (Switzerland) (Vol. 11, Issue 5, p. 241). 2020,
  MDPI AG</journal-ref><doi>10.3390/INFO11050241</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Paraphrase detection is important for a number of applications, including
plagiarism detection, authorship attribution, question answering, text
summarization, text mining in general, etc. In this paper, we give a
performance overview of various types of corpus-based models, especially deep
learning (DL) models, with the task of paraphrase detection. We report the
results of eight models (LSI, TF-IDF, Word2Vec, Doc2Vec, GloVe, FastText, ELMO,
and USE) evaluated on three different public available corpora: Microsoft
Research Paraphrase Corpus, Clough and Stevenson and Webis Crowd Paraphrase
Corpus 2011. Through a great number of experiments, we decided on the most
appropriate approaches for text pre-processing: hyper-parameters, sub-model
selection-where they exist (e.g., Skipgram vs. CBOW), distance measures, and
semantic similarity/paraphrase detection threshold. Our findings and those of
other researchers who have used deep learning models show that DL models are
very competitive with traditional state-of-the-art approaches and have
potential that should be further developed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00149</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00149</id><submitter>Jiaao Chen</submitter><version version="v1"><date>Mon, 31 May 2021 23:57:43 GMT</date><size>742kb</size><source_type>D</source_type></version><title>HiddenCut: Simple Data Augmentation for Natural Language Understanding
  with Better Generalization</title><authors>Jiaao Chen, Dinghan Shen, Weizhu Chen, Diyi Yang</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Fine-tuning large pre-trained models with task-specific data has achieved
great success in NLP. However, it has been demonstrated that the majority of
information within the self-attention networks is redundant and not utilized
effectively during the fine-tuning stage. This leads to inferior results when
generalizing the obtained models to out-of-domain distributions. To this end,
we propose a simple yet effective data augmentation technique, HiddenCut, to
better regularize the model and encourage it to learn more generalizable
features. Specifically, contiguous spans within the hidden space are
dynamically and strategically dropped during training. Experiments show that
our HiddenCut method outperforms the state-of-the-art augmentation methods on
the GLUE benchmark, and consistently exhibits superior generalization
performances on out-of-distribution and challenging counterexamples. We have
publicly released our code at https://github.com/GT-SALT/HiddenCut.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00150</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00150</id><submitter>Daniel Rakita</submitter><version version="v1"><date>Mon, 31 May 2021 23:58:55 GMT</date><size>21159kb</size><source_type>D</source_type></version><title>Single-query Path Planning Using Sample-efficient Probability Informed
  Trees</title><authors>Daniel Rakita, Bilge Mutlu, Michael Gleicher</authors><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a novel sampling-based path planning method, called
SPRINT. The method finds solutions for high dimensional path planning problems
quickly and robustly. Its efficiency comes from minimizing the number of
collision check samples. This reduction in sampling relies on heuristics that
predict the likelihood that samples will be useful in the search process.
Specifically, heuristics (1) prioritize more promising search regions; (2) cull
samples from local minima regions; and (3) steer the search away from
previously observed collision states. Empirical evaluations show that our
method finds shorter or comparable-length solution paths in significantly less
time than commonly used methods. We demonstrate that these performance gains
can be largely attributed to our approach to achieve sample efficiency.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00152</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00152</id><submitter>Bei Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:09:06 GMT</date><size>5295kb</size><source_type>D</source_type></version><title>Visualization in Astrophysics: Developing New Methods, Discovering Our
  Universe, and Educating the Earth</title><authors>Fangfei Lan, Michael Young, Lauren Anderson, Anders Ynnerman,
  Alexander Bock, Michelle A. Borkin, Angus G. Forbes, Juna A. Kollmeier, Bei
  Wang</authors><categories>astro-ph.IM cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a state-of-the-art report on visualization in astrophysics. We
survey representative papers from both astrophysics and visualization and
provide a taxonomy of existing approaches based on data analysis tasks. The
approaches are classified based on five categories: data wrangling, data
exploration, feature identification, object reconstruction, as well as
education and outreach. Our unique contribution is to combine the diverse
viewpoints from both astronomers and visualization experts to identify
challenges and opportunities for visualization in astrophysics. The main goal
is to provide a reference point to bring modern data analysis and visualization
techniques to the rich datasets in astrophysics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00153</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00153</id><submitter>Daniel Rakita</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:13:18 GMT</date><size>13641kb</size><source_type>D</source_type></version><title>Strobe: An Acceleration Meta-algorithm for Optimizing Robot Paths using
  Concurrent Interleaved Sub-Epoch Pods</title><authors>Daniel Rakita, Bilge Mutlu, Michael Gleicher</authors><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a meta-algorithm intended to accelerate many
existing path optimization algorithms. The central idea of our work is to
strategically break up a waypoint path into consecutive groupings called
&quot;pods,&quot; then optimize over various pods concurrently using parallel processing.
Each pod is assigned a color, either blue or red, and the path is divided in
such a way that adjacent pods of the same color have an appropriate buffer of
the opposite color between them, reducing the risk of interference between
concurrent computations. We present a path splitting algorithm to create blue
and red pod groupings and detail steps for a meta-algorithm that optimizes over
these pods in parallel. We assessed how our method works on a testbed of
simulated path optimization scenarios using various optimization tasks and
characterize how it scales with additional threads. We also compared our
meta-algorithm on these tasks to other parallelization schemes. Our results
show that our method more effectively utilizes concurrency compared to the
alternatives, both in terms of speed and optimization quality.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00154</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00154</id><submitter>Joao Marques-Silva</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:14:12 GMT</date><size>116kb</size></version><title>Explanations for Monotonic Classifiers</title><authors>Joao Marques-Silva, Thomas Gerspacher, Martin Cooper, Alexey Ignatiev,
  Nina Narodytska</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In many classification tasks there is a requirement of monotonicity.
Concretely, if all else remains constant, increasing (resp. decreasing) the
value of one or more features must not decrease (resp. increase) the value of
the prediction. Despite comprehensive efforts on learning monotonic
classifiers, dedicated approaches for explaining monotonic classifiers are
scarce and classifier-specific. This paper describes novel algorithms for the
computation of one formal explanation of a (black-box) monotonic classifier.
These novel algorithms are polynomial in the run time complexity of the
classifier and the number of features. Furthermore, the paper presents a
practically efficient model-agnostic algorithm for enumerating formal
explanations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00156</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00156</id><submitter>Eryk Lipka</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:22:11 GMT</date><size>12kb</size></version><title>Detecting a single fault in a deterministic finite automaton</title><authors>Artur Pola\'nski and Eryk Lipka</authors><categories>cs.FL cs.DM</categories><comments>13 pages</comments><msc-class>68Q45, 68M15</msc-class><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a deterministic finite automaton and its implementation with at most
one single fault, that we can test on a set of inputs, we provide an algorithm
to find a test set that guarantees finding whether the fault exists.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00157</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00157</id><submitter>Bei Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:34:18 GMT</date><size>12781kb</size><source_type>D</source_type></version><title>Scalar Field Comparison with Topological Descriptors: Properties and
  Applications for Scientific Visualization</title><authors>Lin Yan, Talha Bin Masood, Raghavendra Sridharamurthy, Farhan Rasheed,
  Vijay Natarajan, Ingrid Hotz, Bei Wang</authors><categories>cs.HC cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In topological data analysis and visualization, topological descriptors such
as persistence diagrams, merge trees, contour trees, Reeb graphs, and
Morse-Smale complexes play an essential role in capturing the shape of scalar
field data. We present a state-of-the-art report on scalar field comparison
using topological descriptors. We provide a taxonomy of existing approaches
based on visualization tasks associated with three categories of data: single
fields, time-varying fields, and ensembles. These tasks include symmetry
detection, periodicity detection, key event/feature detection, feature
tracking, clustering, and structure statistics. Our main contributions include
the formulation of a set of desirable mathematical and computational properties
of comparative measures, and the classification of visualization tasks and
applications that are enabled by these measures.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00158</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00158</id><submitter>David Paulius</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:43:04 GMT</date><size>3822kb</size><source_type>D</source_type></version><title>A Road-map to Robot Task Execution with the Functional Object-Oriented
  Network</title><authors>David Paulius, Alejandro Agostini, Yu Sun and Dongheui Lee</authors><categories>cs.RO cs.AI</categories><comments>Ubiquitous Robots 2021 Submission -- 4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following work on joint object-action representations, the functional
object-oriented network (FOON) was introduced as a knowledge graph
representation for robots. Taking the form of a bipartite graph, a FOON
contains symbolic or high-level information that would be pertinent to a
robot's understanding of its environment and tasks in a way that mirrors human
understanding of actions. In this work, we outline a road-map for future
development of FOON and its application in robotic systems for task planning as
well as knowledge acquisition from demonstration. We propose preliminary ideas
to show how a FOON can be created in a real-world scenario with a robot and
human teacher in a way that can jointly augment existing knowledge in a FOON
and teach a robot the skills it needs to replicate the demonstrated actions and
solve a given manipulation problem.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00161</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00161</id><submitter>Travis Munyer</submitter><version version="v1"><date>Tue, 1 Jun 2021 00:45:32 GMT</date><size>1400kb</size></version><title>Integrative Use of Computer Vision and Unmanned Aircraft Technologies in
  Public Inspection: Foreign Object Debris Image Collection</title><authors>Travis J. E. Munyer, Daniel Brinkman, Chenyu Huang, Xin Zhong</authors><categories>cs.CV</categories><comments>This paper has been accepted for publication by the 22nd Annual
  International Conference on Digital Government Research. 7 pages, 1 figure, 1
  table</comments><doi>10.1145/3463677.3463743</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Unmanned Aircraft Systems (UAS) have become an important resource for public
service providers and smart cities. The purpose of this study is to expand this
research area by integrating computer vision and UAS technology to automate
public inspection. As an initial case study for this work, a dataset of common
foreign object debris (FOD) is developed to assess the potential of
light-weight automated detection. This paper presents the rationale and
creation of this dataset. Future iterations of our work will include further
technical details analyzing experimental implementation. At a local airport,
UAS and portable cameras are used to collect the data contained in the initial
version of this dataset. After collecting these videos of FOD, they were split
into individual frames and stored as several thousand images. These frames are
then annotated following standard computer vision format and stored in a
folder-structure that reflects our creation method. The dataset annotations are
validated using a custom tool that could be abstracted to fit future
applications. Initial detection models were successfully created using the
famous You Only Look Once algorithm, which indicates the practicality of the
proposed data. Finally, several potential scenarios that could utilize either
this dataset or similar methods for other public service are presented.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00162</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00162</id><submitter>Weixin Liang</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:09:55 GMT</date><size>1093kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 06:15:17 GMT</date><size>1093kb</size><source_type>D</source_type></version><title>HERALD: An Annotation Efficient Method to Detect User Disengagement in
  Social Conversations</title><authors>Weixin Liang, Kai-Hui Liang, Zhou Yu</authors><categories>cs.CL</categories><comments>ACL 2021. Code &amp; data available at
  https://github.com/Weixin-Liang/HERALD/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open-domain dialog systems have a user-centric goal: to provide humans with
an engaging conversation experience. User engagement is one of the most
important metrics for evaluating open-domain dialog systems, and could also be
used as real-time feedback to benefit dialog policy learning. Existing work on
detecting user disengagement typically requires hand-labeling many dialog
samples. We propose HERALD, an efficient annotation framework that reframes the
training data annotation process as a denoising problem. Specifically, instead
of manually labeling training samples, we first use a set of labeling
heuristics to label training samples automatically. We then denoise the weakly
labeled data using the Shapley algorithm. Finally, we use the denoised data to
train a user engagement detector. Our experiments show that HERALD improves
annotation efficiency significantly and achieves 86% user disengagement
detection accuracy in two dialog corpora.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00163</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00163</id><submitter>Filipo Sharevski</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:12:44 GMT</date><size>433kb</size><source_type>D</source_type></version><title>Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform</title><authors>Emma Pieroni, Peter Jachim, Nathaniel Jachim, Filipo Sharevski</authors><categories>cs.SI cs.HC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper evaluates Parler, the controversial social media platform, from
two seemingly orthogonal perspectives: UX design perspective and data science.
UX design researchers explore how users react to the interface/content of their
social media feeds; Data science researchers analyze the misinformation flow in
these feeds to detect alternative narratives and state-sponsored disinformation
campaigns. We took a critical look into the intersection of these approaches to
understand how Parler's interface itself is conductive to the flow of
misinformation and the perception of &quot;free speech&quot; among its audience. Parler
drew widespread attention leading up to and after the 2020 U.S. elections as
the &quot;alternative&quot; place for free speech, as a reaction to other mainstream
social media platform which actively engaged in labeling misinformation with
content warnings. Because platforms like Parler are disruptive to the social
media landscape, we believe the evaluation uniquely uncovers the platform's
conductivity to the spread of misinformation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00168</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00168</id><submitter>Hengduo Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:32:03 GMT</date><size>1756kb</size><source_type>D</source_type></version><title>Rethinking Pseudo Labels for Semi-Supervised Object Detection</title><authors>Hengduo Li, Zuxuan Wu, Abhinav Shrivastava, Larry S. Davis</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in semi-supervised object detection (SSOD) are largely driven
by consistency-based pseudo-labeling methods for image classification tasks,
producing pseudo labels as supervisory signals. However, when using pseudo
labels, there is a lack of consideration in localization precision and
amplified class imbalance, both of which are critical for detection tasks. In
this paper, we introduce certainty-aware pseudo labels tailored for object
detection, which can effectively estimate the classification and localization
quality of derived pseudo labels. This is achieved by converting conventional
localization as a classification task followed by refinement. Conditioned on
classification and localization quality scores, we dynamically adjust the
thresholds used to generate pseudo labels and reweight loss functions for each
category to alleviate the class imbalance problem. Extensive experiments
demonstrate that our method improves state-of-the-art SSOD performance by 1-2%
and 4-6% AP on COCO and PASCAL VOC, respectively. In the limited-annotation
regime, our approach improves supervised baselines by up to 10% AP using only
1-10% labeled data from COCO.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00169</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00169</id><submitter>Adithya Renduchintala</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:32:08 GMT</date><size>5396kb</size><source_type>D</source_type></version><title>Gender Bias Amplification During Speed-Quality Optimization in Neural
  Machine Translation</title><authors>Adithya Renduchintala, Denise Diaz, Kenneth Heafield, Xian Li, Mona
  Diab</authors><categories>cs.CL</categories><comments>Accepted at ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is bias amplified when neural machine translation (NMT) models are optimized
for speed and evaluated on generic test sets using BLEU? We investigate
architectures and techniques commonly used to speed up decoding in
Transformer-based models, such as greedy search, quantization, average
attention networks (AANs) and shallow decoder models and show their effect on
gendered noun translation. We construct a new gender bias test set, SimpleGEN,
based on gendered noun phrases in which there is a single, unambiguous, correct
answer. While we find minimal overall BLEU degradation as we apply speed
optimizations, we observe that gendered noun translation performance degrades
at a much faster rate.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00173</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00173</id><submitter>Brandon Victor</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:43:19 GMT</date><size>120kb</size></version><title>Enhancing Trajectory Prediction using Sparse Outputs: Application to
  Team Sports</title><authors>Brandon Victor, Aiden Nibali, Zhen He, David L. Carey</authors><categories>cs.LG stat.ML</categories><comments>10 pages (not including references), 7 figures. Published in Neural
  Computing and Applications on 20 March 2021</comments><acm-class>I.2.6</acm-class><doi>10.1007/s00521-021-05888-w</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Sophisticated trajectory prediction models that effectively mimic team
dynamics have many potential uses for sports coaches, broadcasters and
spectators. However, through experiments on soccer data we found that it can be
surprisingly challenging to train a deep learning model for player trajectory
prediction which outperforms linear extrapolation on average distance between
predicted and true future trajectories. We propose and test a novel method for
improving training by predicting a sparse trajectory and interpolating using
constant acceleration, which improves performance for several models. This
interpolation can also be used on models that aren't trained with sparse
outputs, and we find that this consistently improves performance for all tested
models. Additionally, we find that the accuracy of predicted trajectories for a
subset of players can be improved by conditioning on the full trajectories of
the other players, and that this is further improved when combined with sparse
predictions. We also propose a novel architecture using graph networks and
multi-head attention (GraN-MA) which achieves better performance than other
tested state-of-the-art models on our dataset and is trivially adapted for both
sparse trajectories and full-trajectory conditioned trajectory prediction.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00175</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00175</id><submitter>Kumail Abbas</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:48:22 GMT</date><size>156kb</size></version><title>Duckworth-Lewis-Stern Method Comparison with Machine Learning Approach</title><authors>Kumail Abbas and Sajjad Haider</authors><categories>cs.LG stat.ML</categories><comments>The paper has been published in the conference of Frontiers of
  Information Technology 2019</comments><journal-ref>2019 International Conference on Frontiers of Information
  Technology (FIT), 2019, pp. 197-1975</journal-ref><doi>10.1109/FIT47737.2019.00045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents an analysis of the Duckworth-Lewis-Stern (DLS) method for
One Day International (ODI) cricket matches. The accuracy of the DLS method is
compared against various supervised learning algorithms for result prediction.
The result of a cricket match is predicted during the second inning. The paper
also optimized DLS resource table which is used in the Duckworth-Lewis (D/L)
formula to increase its predictive power. Finally, an Unpredictability Index is
developed that ranks different cricket playing nations according to how
unpredictable they are while playing an ODI match.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00178</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00178</id><submitter>Tsu-Jui Fu</submitter><version version="v1"><date>Tue, 1 Jun 2021 01:58:50 GMT</date><size>38151kb</size><source_type>D</source_type></version><title>Language-Driven Image Style Transfer</title><authors>Tsu-Jui Fu, Xin Eric Wang, William Yang Wang</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite having promising results, style transfer, which requires preparing
style images in advance, may result in lack of creativity and accessibility.
Following human instruction, on the other hand, is the most natural way to
perform artistic style transfer that can significantly improve controllability
for visual effect applications. We introduce a new task -- language-driven
image style transfer (\texttt{LDIST}) -- to manipulate the style of a content
image, guided by a text. We propose contrastive language visual artist (CLVA)
that learns to extract visual semantics from style instructions and accomplish
\texttt{LDIST} by the patch-wise style discriminator. The discriminator
considers the correlation between language and patches of style images or
transferred results to jointly embed style instructions. CLVA further compares
contrastive pairs of content image and style instruction to improve the mutual
relativeness between transfer results. The transferred results from the same
content image can preserve consistent content structures. Besides, they should
present analogous style patterns from style instructions that contain similar
visual semantics. The experiments show that our CLVA is effective and achieves
superb transferred results on \texttt{LDIST}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00180</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00180</id><submitter>Tokuhiro Nishikawa</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:02:52 GMT</date><size>11534kb</size><source_type>D</source_type></version><title>Dual Normalization Multitasking for Audio-Visual Sounding Object
  Localization</title><authors>Tokuhiro Nishikawa, Daiki Shimada, Jerry Jun Yokono</authors><categories>cs.CV cs.SD eess.AS</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although several research works have been reported on audio-visual sound
source localization in unconstrained videos, no datasets and metrics have been
proposed in the literature to quantitatively evaluate its performance. Defining
the ground truth for sound source localization is difficult, because the
location where the sound is produced is not limited to the range of the source
object, but the vibrations propagate and spread through the surrounding
objects. Therefore we propose a new concept, Sounding Object, to reduce the
ambiguity of the visual location of sound, making it possible to annotate the
location of the wide range of sound sources. With newly proposed metrics for
quantitative evaluation, we formulate the problem of Audio-Visual Sounding
Object Localization (AVSOL). We also created the evaluation dataset (AVSOL-E
dataset) by manually annotating the test set of well-known Audio-Visual Event
(AVE) dataset. To tackle this new AVSOL problem, we propose a novel multitask
training strategy and architecture called Dual Normalization Multitasking
(DNM), which aggregates the Audio-Visual Correspondence (AVC) task and the
classification task for video events into a single audio-visual similarity map.
By efficiently utilize both supervisions by DNM, our proposed architecture
significantly outperforms the baseline methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00181</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00181</id><submitter>Ziyang Luo</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:12:45 GMT</date><size>838kb</size><source_type>D</source_type></version><title>Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese
  Adjectives</title><authors>Meichun Jiao, Ziyang Luo</authors><categories>cs.CL</categories><comments>Accepted at the 3rd Workshop on Gender Bias in Natural Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gender bias in word embeddings gradually becomes a vivid research field in
recent years. Most studies in this field aim at measurement and debiasing
methods with English as the target language. This paper investigates gender
bias in static word embeddings from a unique perspective, Chinese adjectives.
By training word representations with different models, the gender bias behind
the vectors of adjectives is assessed. Through a comparison between the
produced results and a human-scored data set, we demonstrate how gender bias
encoded in word embeddings differentiates from people's attitudes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00182</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00182</id><submitter>Wang Zhou</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:15:20 GMT</date><size>18731kb</size><source_type>D</source_type></version><title>Quantification of Carbon Sequestration in Urban Forests</title><authors>Levente Klein, Wang Zhou, Conrad Albrecht</authors><categories>cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Vegetation, trees in particular, sequester carbon by absorbing carbon dioxide
from the atmosphere, however, the lack of efficient quantification methods of
carbon stored in trees renders it difficult to track the process. Here we
present an approach to estimate the carbon storage in trees based on fusing
multispectral aerial imagery and LiDAR data to identify tree coverage,
geometric shape, and tree species, which are crucial attributes in carbon
storage quantification. We demonstrate that tree species information and their
three-dimensional geometric shapes can be estimated from remote imagery in
order to calculate the tree's biomass. Specifically, for Manhattan, New York
City, we estimate a total of $52,000$ tons of carbon sequestered in trees.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00184</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00184</id><submitter>Jack White</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:17:36 GMT</date><size>1407kb</size><source_type>D</source_type></version><title>Anti-aliasing Semantic Reconstruction for Few-Shot Semantic Segmentation</title><authors>Binghao Liu and Yao Ding and Jianbin Jiao and Xiangyang Ji and Qixiang
  Ye</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Encouraging progress in few-shot semantic segmentation has been made by
leveraging features learned upon base classes with sufficient training data to
represent novel classes with few-shot examples. However, this feature sharing
mechanism inevitably causes semantic aliasing between novel classes when they
have similar compositions of semantic concepts. In this paper, we reformulate
few-shot segmentation as a semantic reconstruction problem, and convert base
class features into a series of basis vectors which span a class-level semantic
space for novel class reconstruction. By introducing contrastive loss, we
maximize the orthogonality of basis vectors while minimizing semantic aliasing
between classes. Within the reconstructed representation space, we further
suppress interference from other classes by projecting query features to the
support vector for precise semantic activation. Our proposed approach, referred
to as anti-aliasing semantic reconstruction (ASR), provides a systematic yet
interpretable solution for few-shot learning problems. Extensive experiments on
PASCAL VOC and MS COCO datasets show that ASR achieves strong results compared
with the prior works.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00185</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00185</id><submitter>Tzu-Chi Yen</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:21:44 GMT</date><size>1939kb</size><source_type>D</source_type></version><title>Construction of Simplicial Complexes with Prescribed Degree-Size
  Sequences</title><authors>Tzu-Chi Yen</authors><categories>cs.SI cs.DS math.AT math.CO physics.soc-ph</categories><comments>6 pages, 4 figures. Code implementing our methods is available at
  https://github.com/junipertcy/simplicial-test (Python, pip installable). Read
  the Docs at https://docs.netscied.tw/simplicial-test/index.html</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We study the realizability of simplicial complexes with a given pair of
integer sequences, representing the node degree distribution and facet size
distribution, respectively. While the $s$-uniform variant of the problem is
$\mathsf{NP}$-complete when $s \geq 3$, we identify two populations of input
sequences, most of which can be solved in polynomial time using a recursive
algorithm that we contribute. Combining with a sampler for the simplicial
configuration model [Young $\textit{et al.}$, Phys. Rev. E $\textbf{96}$,
032312 (2017)], we facilitate efficient sampling of simplicial ensembles from
arbitrary degree and size distributions. We find that, contrary to expectations
based on dyadic networks, increasing nodes' degrees reduces the number of loops
in simplicial complexes. Our work unveils a fundamental constraint on the
degree-size sequences and sheds light on further analysis of higher-order
phenomena based on local structures.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00186</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00186</id><submitter>ByungSoo Ko</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:28:08 GMT</date><size>6291kb</size><source_type>D</source_type></version><title>Towards Real-time and Light-weight Line Segment Detection</title><authors>Geonmo Gu, Byungsoo Ko, SeoungHyun Go, Sung-Hyun Lee, Jingeun Lee,
  Minchul Shin</authors><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous deep learning-based line segment detection (LSD) suffer from the
immense model size and high computational cost for line prediction. This
constrains them from real-time inference on computationally restricted
environments. In this paper, we propose a real-time and light-weight line
segment detector for resource-constrained environments named Mobile LSD
(M-LSD). We design an extremely efficient LSD architecture by minimizing the
backbone network and removing the typical multi-module process for line
prediction in previous methods. To maintain competitive performance with such a
light-weight network, we present novel training schemes: Segments of Line
segment (SoL) augmentation and geometric learning scheme. SoL augmentation
splits a line segment into multiple subparts, which are used to provide
auxiliary line data during the training process. Moreover, the geometric
learning scheme allows a model to capture additional geometry cues from
matching loss, junction and line segmentation, length and degree regression.
Compared with TP-LSD-Lite, previously the best real-time LSD method, our model
(M-LSD-tiny) achieves competitive performance with 2.5% of model size and an
increase of 130.5% in inference speed on GPU when evaluated with Wireframe and
YorkUrban datasets. Furthermore, our model runs at 56.8 FPS and 48.6 FPS on
Android and iPhone mobile devices, respectively. To the best of our knowledge,
this is the first real-time deep LSD method available on mobile devices.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00188</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00188</id><submitter>Rowan Zellers</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:32:12 GMT</date><size>4379kb</size><source_type>D</source_type></version><title>PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D
  World</title><authors>Rowan Zellers, Ari Holtzman, Matthew Peters, Roozbeh Mottaghi,
  Aniruddha Kembhavi, Ali Farhadi, Yejin Choi</authors><categories>cs.CL cs.AI</categories><comments>ACL 2021 camera ready, project page at
  https://rowanzellers.com/piglet/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose PIGLeT: a model that learns physical commonsense knowledge through
interaction, and then uses this knowledge to ground language. We factorize
PIGLeT into a physical dynamics model, and a separate language model. Our
dynamics model learns not just what objects are but also what they do: glass
cups break when thrown, plastic ones don't. We then use it as the interface to
our language model, giving us a unified model of linguistic form and grounded
meaning. PIGLeT can read a sentence, simulate neurally what might happen next,
and then communicate that result through a literal symbolic representation, or
natural language.
  Experimental results show that our model effectively learns world dynamics,
along with how to communicate them. It is able to correctly forecast &quot;what
happens next&quot; given an English sentence over 80% of the time, outperforming a
100x larger, text-to-text approach by over 10%. Likewise, its natural language
summaries of physical interactions are also judged by humans as more accurate
than LM alternatives. We present comprehensive analysis showing room for future
work.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00192</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00192</id><submitter>Sundong Kim</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:40:49 GMT</date><size>1991kb</size><source_type>D</source_type></version><title>Responses to COVID-19 with Probabilistic Programming</title><authors>Assem Zhunis and Tung-Duong Mai and Sundong Kim</authors><categories>cs.CE</categories><comments>25 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The COVID-19 pandemic left its unique mark on the 21st century as one of the
most significant disasters in history, triggering governments all over the
world to respond with a wide range of interventions. However, these
restrictions come with a substantial price tag. It is crucial for governments
to form anti-virus strategies that balance the trade-off between protecting
public health and minimizing the economic cost. This work proposes a
probabilistic programming method to quantify the efficiency of major
non-pharmaceutical interventions. We present a generative simulation model that
accounts for the economic and human capital cost of adopting such strategies,
and provide an end-to-end pipeline to simulate the virus spread and the
incurred loss of various policy combinations. By investigating the national
response in 10 countries covering four continents, we found that social
distancing coupled with contact tracing is the most successful policy, reducing
the virus transmission rate by 96\% along with a 98\% reduction in economic and
human capital loss. Together with experimental results, we open-sourced a
framework to test the efficacy of each policy combination.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00196</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00196</id><submitter>Misun Min Dr</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:49:50 GMT</date><size>18088kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 14:55:57 GMT</date><size>18088kb</size><source_type>D</source_type></version><title>All-Hex Meshing Strategies For Densely Packed Spheres</title><authors>Yu-Hsiang Lan, Paul Fischer, Elia Merzari, Misun Min</authors><categories>cs.CE</categories><comments>13 pages, 10 figures</comments><msc-class>76-10</msc-class><acm-class>D.0; F.2; I.6; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an all-hex meshing strategy for the interstitial space in beds of
densely packed spheres that is tailored to turbulent flow simulations based on
the spectral element method (SEM). The SEM achieves resolution through elevated
polynomial order N and requires two to three orders of magnitude fewer elements
than standard finite element approaches do. These reduced element counts place
stringent requirements on mesh quality and conformity. Our meshing algorithm is
based on a Voronoi decomposition of the sphere centers. Facets of the Voronoi
cells are tessellated into quads that are swept to the sphere surface to
generate a high-quality base mesh. Refinements to the algorithm include edge
collapse to remove slivers, node insertion to balance resolution, localized
refinement in the radial direction about each sphere, and mesh optimization. We
demonstrate geometries with 10^2-10^5 spheres using approximately 300 elements
per sphere (for three radial layers), along with mesh quality metrics, timings,
flow simulations, and solver performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00197</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00197</id><submitter>Xingshan Zeng</submitter><version version="v1"><date>Tue, 1 Jun 2021 02:50:49 GMT</date><size>220kb</size><source_type>D</source_type></version><title>Multilingual Speech Translation with Unified Transformer: Huawei Noah's
  Ark Lab at IWSLT 2021</title><authors>Xingshan Zeng, Liangyou Li and Qun Liu</authors><categories>cs.CL cs.SD eess.AS</categories><comments>IWSLT 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the system submitted to the IWSLT 2021 Multilingual
Speech Translation (MultiST) task from Huawei Noah's Ark Lab. We use a unified
transformer architecture for our MultiST model, so that the data from different
modalities (i.e., speech and text) and different tasks (i.e., Speech
Recognition, Machine Translation, and Speech Translation) can be exploited to
enhance the model's ability. Specifically, speech and text inputs are firstly
fed to different feature extractors to extract acoustic and textual features,
respectively. Then, these features are processed by a shared encoder--decoder
architecture. We apply several training techniques to improve the performance,
including multi-task learning, task-level curriculum learning, data
augmentation, etc. Our final system achieves significantly better results than
bilingual baselines on supervised language pairs and yields reasonable results
on zero-shot language pairs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00198</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00198</id><submitter>Runyu Zhang Ms.</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:03:45 GMT</date><size>135kb</size><source_type>D</source_type></version><title>Gradient Play in Multi-Agent Markov Stochastic Games: Stationary Points
  and Convergence</title><authors>Runyu Zhang, Zhaolin Ren, Na Li</authors><categories>cs.LG cs.GT cs.MA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of the gradient play algorithm for multi-agent
tabular Markov decision processes (MDPs), which are also known as stochastic
games (SGs), where each agent tries to maximize its own total discounted reward
by making decisions independently based on current state information which is
shared between agents. Policies are directly parameterized by the probability
of choosing a certain action at a given state. We show that Nash equilibria
(NEs) and first order stationary policies are equivalent in this setting, and
give a non-asymptotic global convergence rate analysis to an $\epsilon$-NE for
a subclass of multi-agent MDPs called Markov potential games, which includes
the cooperative setting with identical rewards among agents as an important
special case. Our result shows that the number of iterations to reach an
$\epsilon$-NE scales linearly, instead of exponentially, with the number of
agents. Local geometry and local stability are also considered. For Markov
potential games, we prove that strict NEs are local maxima of the total
potential function and fully-mixed NEs are saddle points. We also give a local
convergence rate around strict NEs for more general settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00199</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00199</id><submitter>Andr\'e C. R. Martins</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:10:31 GMT</date><size>18kb</size></version><title>Agent mental models and Bayesian rules as a tool to create opinion
  dynamics models</title><authors>Andre C. R. Martins</authors><categories>physics.soc-ph cs.MA nlin.AO</categories><comments>17 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Traditional opinion dynamics models are simple and yet, enough to explore the
consequences in basic scenarios. But, to better describe problems such as
polarization and extremism, we might need to include details about human biases
and other cognitive characteristics. In this paper, I explain how we can
describe and use mental models and assumptions of the agents using
Bayesian-inspired model building. The relationship between human rationality
and Bayesian methods will be explored, and we will see that Bayesian ideas can
indeed be used to explain how humans reason. We will see how to use
Bayesian-inspired rules using the simplest version of the Continuous Opinions
and Discrete Actions (CODA) model. From that, we will explore how we can obtain
update rules that include human behavioral characteristics such as confirmation
bias, motivated reasoning, or our tendency to change opinions much less than we
should.
  Keywords: Opinion dynamics, Bayesian methods, Cognition, CODA, Agent-based
models
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00200</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00200</id><submitter>Haitian Sun</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:13:35 GMT</date><size>418kb</size><source_type>D</source_type></version><title>End-to-End Multihop Retrieval for Compositional Question Answering over
  Long Documents</title><authors>Haitian Sun, William W. Cohen, Ruslan Salakhutdinov</authors><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Answering complex questions from long documents requires aggregating multiple
pieces of evidence and then predicting the answers. In this paper, we propose a
multi-hop retrieval method, DocHopper, to answer compositional questions over
long documents. At each step, DocHopper retrieves a paragraph or sentence
embedding from the document, mixes the retrieved result with the query, and
updates the query for the next step. In contrast to many other retrieval-based
methods (e.g., RAG or REALM) the query is not augmented with a token sequence:
instead, it is augmented by &quot;numerically&quot; combining it with another neural
representation. This means that model is end-to-end differentiable. We
demonstrate that utilizing document structure in this was can largely improve
question-answering and retrieval performance on long documents. We experimented
with DocHopper on three different QA tasks that require reading long documents
to answer compositional questions: discourse entailment reasoning, factual QA
with table and text, and information seeking QA from academic papers. DocHopper
outperforms all baseline models and achieves state-of-the-art results on all
datasets. Additionally, DocHopper is efficient at inference time, being 3~10
times faster than the baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00202</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00202</id><submitter>Julius Fergy Rabago</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:19:42 GMT</date><size>1100kb</size></version><title>Comoving mesh method for certain classes of moving boundary problems</title><authors>Yosuke Sunayama, Masato Kimura, and Julius Fergy Rabago</authors><categories>math.NA cs.NA</categories><comments>28 pages, 37 figures</comments><msc-class>35R37, 76D27, 35R35, 65Nxx</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A Lagrangian-type numerical scheme called the &quot;comoving mesh method&quot; or CMM
is developed for numerically solving certain classes of moving boundary
problems which include, for example, the classical Hele-Shaw flow problem and
the well-known mean curvature flow problem. This finite element scheme exploits
the idea that the normal velocity field of the moving boundary can be extended
throughout the entire domain of definition of the problem using, for instance,
the Laplace operator. Then, the boundary as well as the finite element mesh of
the domain are easily updated at every time step by moving the nodal points
along this velocity field. The feasibility of the method, highlighting its
practicality, is illustrated through various numerical experiments. Also, in
order to examine the accuracy of the proposed scheme, the experimental order of
convergences between the numerical and manufactured solutions for these
examples are also calculated.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00203</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00203</id><submitter>Hoda Shajari</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:21:47 GMT</date><size>1366kb</size><source_type>D</source_type></version><title>Hybrid Generative Models for Two-Dimensional Datasets</title><authors>Hoda Shajari, Jaemoon Lee, Sanjay Ranka, Anand Rangarajan</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Two-dimensional array-based datasets are pervasive in a variety of domains.
Current approaches for generative modeling have typically been limited to
conventional image datasets and performed in the pixel domain which do not
explicitly capture the correlation between pixels. Additionally, these
approaches do not extend to scientific and other applications where each
element value is continuous and is not limited to a fixed range. In this paper,
we propose a novel approach for generating two-dimensional datasets by moving
the computations to the space of representation bases and show its usefulness
for two different datasets, one from imaging and another from scientific
computing. The proposed approach is general and can be applied to any dataset,
representation basis, or generative model. We provide a comprehensive
performance comparison of various combinations of generative models and
representation basis spaces. We also propose a new evaluation metric which
captures the deficiency of generating images in pixel space.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00209</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00209</id><submitter>Ju He</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:58:18 GMT</date><size>494kb</size><source_type>D</source_type></version><title>Rethinking Re-Sampling in Imbalanced Semi-Supervised Learning</title><authors>Ju He, Adam Kortylewski, Shaokang Yang, Shuai Liu, Cheng Yang, Changhu
  Wang, Alan Yuille</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-Supervised Learning (SSL) has shown its strong ability in utilizing
unlabeled data when labeled data is scarce. However, most SSL algorithms work
under the assumption that the class distributions are balanced in both training
and test sets. In this work, we consider the problem of SSL on class-imbalanced
data, which better reflects real-world situations but has only received limited
attention so far. In particular, we decouple the training of the representation
and the classifier, and systematically investigate the effects of different
data re-sampling techniques when training the whole network including a
classifier as well as fine-tuning the feature extractor only. We find that data
re-sampling is of critical importance to learn a good classifier as it
increases the accuracy of the pseudo-labels, in particular for the minority
classes in the unlabeled data. Interestingly, we find that accurate
pseudo-labels do not help when training the feature extractor, rather
contrariwise, data re-sampling harms the training of the feature extractor.
This finding is against the general intuition that wrong pseudo-labels always
harm the model performance in SSL. Based on these findings, we suggest to
re-think the current paradigm of having a single data re-sampling strategy and
develop a simple yet highly effective Bi-Sampling (BiS) strategy for SSL on
class-imbalanced data. BiS implements two different re-sampling strategies for
training the feature extractor and the classifier and integrates this decoupled
training into an end-to-end framework... Code will be released at
https://github.com/TACJu/Bi-Sampling.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00210</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00210</id><submitter>Zonghai Yao</submitter><version version="v1"><date>Tue, 1 Jun 2021 03:59:07 GMT</date><size>5334kb</size><source_type>D</source_type></version><title>Improving Formality Style Transfer with Context-Aware Rule Injection</title><authors>Zonghai Yao and Hong Yu</authors><categories>cs.CL</categories><comments>ACL2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models pre-trained on large-scale regular text corpora often do not work well
for user-generated data where the language styles differ significantly from the
mainstream text. Here we present Context-Aware Rule Injection (CARI), an
innovative method for formality style transfer (FST). CARI injects multiple
rules into an end-to-end BERT-based encoder and decoder model. It learns to
select optimal rules based on context. The intrinsic evaluation showed that
CARI achieved the new highest performance on the FST benchmark dataset. Our
extrinsic evaluation showed that CARI can greatly improve the regular
pre-trained models' performance on several tweet sentiment analysis tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00214</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00214</id><submitter>Yunhan Huang</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:05:27 GMT</date><size>834kb</size><source_type>D</source_type></version><title>Game-Theoretic Frameworks for Epidemic Spreading and Human Decision
  Making: A Review</title><authors>Yunhan Huang and Quanyan Zhu</authors><categories>eess.SY cs.GT cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This review presents and reviews various solved and open problems in
developing, analyzing, and mitigating epidemic spreading processes under human
decision-making. We provide a review of a range of epidemic models and explain
the pros and cons of different epidemic models. We exhibit the art of coupling
epidemic models and decision models in the existing literature. More
specifically, fundamental questions in human decision-making amid epidemics
such as what interventions are taken to combat the disease, who are
decision-makers, when interventions are taken, and how interventions are
modeled. Among many decision models, game-theoretic models have become
increasingly crucial in modeling human responses/behavior amid epidemics in the
last decade.
  In this review, we motivate the game-theoretic approach to human
decision-making amid epidemics. This review provides an overview of the
existing literature by developing a multi-dimensional taxonomy, which
categorizes existing works based on multiple dimensions, including 1) types of
games, such as differential games, stochastic games, evolutionary games, and
static games; 2) types of interventions, such as social distancing,
vaccination, quarantine, taking antidotes, etc.; 3) the types of
decision-makers, such as individuals, adversaries, and central authorities at
different hierarchical levels. A fine-grained dynamic game framework is
proposed to capture the essence of game-theoretic decision-making amid
epidemics. From a vast body of works, we showcase three representative works
with unique ways of integrating game-theoretic decision-making into the
epidemic models. The uniqueness of each of these three works distinguishes
themselves from each other regarding their models, analytical approaches, and
results. In the end, we identify several main open problems and research gaps
left to be addressed and filled.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00215</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00215</id><submitter>Matthew Kvalheim</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:06:18 GMT</date><size>447kb</size><source_type>D</source_type></version><title>Necessary conditions for feedback stabilization and safety</title><authors>Matthew D. Kvalheim and Daniel E. Koditschek</authors><categories>math.OC cs.RO math-ph math.DS math.MP</categories><comments>28 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brockett's necessary condition yields a test to determine whether a system
can be made to stabilize about some operating point via continuous, purely
state-dependent feedback. For many real-world systems, however, one wants to
stabilize sets which are more general than a single point. One also wants to
control such systems to operate safely by making obstacles and other
&quot;dangerous&quot; sets repelling.
  We generalize Brockett's necessary condition to the case of stabilizing
general compact subsets having a nonzero Euler characteristic. Using this
generalization, we also formulate a necessary condition for the existence of
&quot;safe&quot; control laws. We illustrate the theory in concrete examples and for some
general classes of systems including a broad class of nonholonomically
constrained Lagrangian systems. We also show that, for the special case of
stabilizing a point, the specialization of our general stabilizability test is
stronger than Brockett's.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00216</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00216</id><submitter>Yongjian Deng</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:07:03 GMT</date><size>1910kb</size><source_type>D</source_type></version><title>EV-VGCNN: A Voxel Graph CNN for Event-based Object Classification</title><authors>Yongjian Deng, Hao Chen, Huiying Chen, Youfu Li</authors><categories>cs.CV</categories><comments>10 pages, 5 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event cameras report sparse intensity changes and hold noticeable advantages
of low power consumption, high dynamic range, and high response speed for
visual perception and understanding on portable devices. Event-based learning
methods have recently achieved massive success on object recognition by
integrating events into dense frame-based representations to apply traditional
2D learning algorithms. However, these approaches introduce much redundant
information during the sparse-to-dense conversion and necessitate models with
heavy-weight and large capacities, limiting the potential of event cameras on
real-life applications. To address the core problem of balancing accuracy and
model complexity for event-based classification models, we (1) construct graph
representations for event data to utilize their sparsity nature better and
design a lightweight end-to-end graph neural network (EV-VGCNN) for
classification; (2) use voxel-wise vertices rather than traditional point-wise
methods to incorporate the information from more points; (3) introduce a
multi-scale feature relational layer (MFRL) to extract semantic and motion cues
from each vertex adaptively concerning its distances to neighbors.
Comprehensive experiments show that our approach advances state-of-the-art
classification accuracy while achieving nearly 20 times parameter reduction
(merely 0.84M parameters).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00217</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00217</id><submitter>Chinmay Garg</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:10:46 GMT</date><size>816kb</size><source_type>D</source_type></version><title>Toward a Secure Crowdsourced Location Tracking System</title><authors>Chinmay Garg, Aravind Machiry, Andrea Continella, Christopher Kruegel,
  Giovanni Vigna</authors><categories>cs.CR</categories><comments>10 pages - ACM WiSec 2021 - Preprint</comments><acm-class>C.2.1; C.2.3; C.5.m</acm-class><doi>10.1145/3448300.3467821</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Low-energy Bluetooth devices have become ubiquitous and widely used for
different applications. Among these, Bluetooth trackers are becoming popular as
they allow users to track the location of their physical objects. To do so,
Bluetooth trackers are often built-in within other commercial products
connected to a larger crowdsourced tracking system. Such a system, however, can
pose a threat to the security and privacy of the users, for instance, by
revealing the location of a user's valuable object. In this paper, we introduce
a set of security properties and investigate the state of commercial
crowdsourced tracking systems, which present common design flaws that make them
insecure. Leveraging the results of our investigation, we propose a new design
for a secure crowdsourced tracking system (SECrow), which allows devices to
leverage the benefits of the crowdsourced model without sacrificing security
and privacy. Our preliminary evaluation shows that SECrow is a practical,
secure, and effective crowdsourced tracking solution
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00218</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00218</id><submitter>Yucheng Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:13:39 GMT</date><size>681kb</size><source_type>D</source_type></version><title>Discontinuous Named Entity Recognition as Maximal Clique Discovery</title><authors>Yucheng Wang, Bowen Yu, Hongsong Zhu, Tingwen Liu, Nan Yu and Limin
  Sun</authors><categories>cs.CL</categories><comments>ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Named entity recognition (NER) remains challenging when entity mentions can
be discontinuous. Existing methods break the recognition process into several
sequential steps. In training, they predict conditioned on the golden
intermediate results, while at inference relying on the model output of the
previous steps, which introduces exposure bias. To solve this problem, we first
construct a segment graph for each sentence, in which each node denotes a
segment (a continuous entity on its own, or a part of discontinuous entities),
and an edge links two nodes that belong to the same entity. The nodes and edges
can be generated respectively in one stage with a grid tagging scheme and
learned jointly using a novel architecture named Mac. Then discontinuous NER
can be reformulated as a non-parametric process of discovering maximal cliques
in the graph and concatenating the spans in each clique. Experiments on three
benchmarks show that our method outperforms the state-of-the-art (SOTA)
results, with up to 3.5 percentage points improvement on F1, and achieves 5x
speedup over the SOTA model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00219</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00219</id><submitter>Shweta Yadav</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:21:31 GMT</date><size>59kb</size></version><title>Question-aware Transformer Models for Consumer Health Question
  Summarization</title><authors>Shweta Yadav, Deepak Gupta, Asma Ben Abacha and Dina Demner-Fushman</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Searching for health information online is becoming customary for more and
more consumers every day, which makes the need for efficient and reliable
question answering systems more pressing. An important contributor to the
success rates of these systems is their ability to fully understand the
consumers' questions. However, these questions are frequently longer than
needed and mention peripheral information that is not useful in finding
relevant answers. Question summarization is one of the potential solutions to
simplifying long and complex consumer questions before attempting to find an
answer. In this paper, we study the task of abstractive summarization for
real-world consumer health questions. We develop an abstractive question
summarization model that leverages the semantic interpretation of a question
via recognition of medical entities, which enables the generation of
informative summaries. Towards this, we propose multiple Cloze tasks (i.e. the
task of filing missing words in a given context) to identify the key medical
entities that enforce the model to have better coverage in question-focus
recognition. Additionally, we infuse the decoder inputs with question-type
information to generate question-type driven summaries. When evaluated on the
MeQSum benchmark corpus, our framework outperformed the state-of-the-art method
by 10.2 ROUGE-L points. We also conducted a manual evaluation to assess the
correctness of the generated summaries.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00220</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00220</id><submitter>Nicholas Sharp</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:23:04 GMT</date><size>23842kb</size><source_type>D</source_type></version><title>Integer Coordinates for Intrinsic Geometry Processing</title><authors>Mark Gillespie, Nicholas Sharp, Keenan Crane</authors><categories>cs.GR cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a general, efficient, and provably robust
representation for intrinsic triangulations. These triangulations have emerged
as a powerful tool for robust geometry processing of surface meshes, taking a
low-quality mesh and retriangulating it with high-quality intrinsic triangles.
However, existing representations either support only edge flips, or do not
offer a robust procedure to recover the common subdivision, that is, how the
intrinsic triangulation sits along the original surface. To build a
general-purpose robust structure, we extend the framework of normal
coordinates, which have been deeply studied in topology, as well as the more
recent idea of roundabouts from geometry processing, to support a variety of
mesh processing operations like vertex insertions, edge splits, etc. The basic
idea is to store an integer per mesh edge counting the number of times a curve
crosses that edge. We show that this paradigm offers a highly effective
representation for intrinsic triangulations with strong robustness guarantees.
The resulting data structure is general and efficient, while offering a
guarantee of always encoding a valid subdivision. Among other things, this
allows us to generate a high-quality intrinsic Delaunay refinement of all
manifold meshes in the challenging Thingi10k dataset for the first time. This
enables a broad class of existing surface geometry algorithms to be applied
out-of-the-box to low-quality triangulations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00221</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00221</id><submitter>Yong Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:26:02 GMT</date><size>952kb</size><source_type>D</source_type></version><title>Concurrent Adversarial Learning for Large-Batch Training</title><authors>Yong Liu, Xiangning Chen, Minhao Cheng, Cho-Jui Hsieh, Yang You</authors><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-batch training has become a commonly used technique when training
neural networks with a large number of GPU/TPU processors. As batch size
increases, stochastic optimizers tend to converge to sharp local minima,
leading to degraded test performance. Current methods usually use extensive
data augmentation to increase the batch size, but we found the performance gain
with data augmentation decreases as batch size increases, and data augmentation
will become insufficient after certain point. In this paper, we propose to use
adversarial learning to increase the batch size in large-batch training.
Despite being a natural choice for smoothing the decision surface and biasing
towards a flat region, adversarial learning has not been successfully applied
in large-batch training since it requires at least two sequential gradient
computations at each step, which will at least double the running time compared
with vanilla training even with a large number of processors. To overcome this
issue, we propose a novel Concurrent Adversarial Learning (ConAdv) method that
decouple the sequential gradient computations in adversarial learning by
utilizing staled parameters. Experimental results demonstrate that ConAdv can
successfully increase the batch size on both ResNet-50 and EfficientNet
training on ImageNet while maintaining high accuracy. In particular, we show
ConAdv along can achieve 75.3\% top-1 accuracy on ImageNet ResNet-50 training
with 96K batch size, and the accuracy can be further improved to 76.2\% when
combining ConAdv with data augmentation. This is the first work successfully
scales ResNet-50 training batch size to 96K.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00225</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00225</id><submitter>Zhen Lin</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:39:56 GMT</date><size>142kb</size><source_type>D</source_type></version><title>Locally Valid and Discriminative Confidence Intervals for Deep Learning
  Models</title><authors>Zhen Lin, Shubhendu Trivedi, Jimeng Sun</authors><categories>cs.LG stat.ME stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Crucial for building trust in deep learning models for critical real-world
applications is efficient and theoretically sound uncertainty quantification, a
task that continues to be challenging. Useful uncertainty information is
expected to have two key properties: It should be valid (guaranteeing coverage)
and discriminative (more uncertain when the expected risk is high). Moreover,
when combined with deep learning (DL) methods, it should be scalable and affect
the DL model performance minimally. Most existing Bayesian methods lack
frequentist coverage guarantees and usually affect model performance. The few
available frequentist methods are rarely discriminative and/or violate coverage
guarantees due to unrealistic assumptions. Moreover, many methods are expensive
or require substantial modifications to the base neural network. Building upon
recent advances in conformal prediction and leveraging the classical idea of
kernel regression, we propose Locally Valid and Discriminative confidence
intervals (LVD), a simple, efficient and lightweight method to construct
discriminative confidence intervals (CIs) for almost any DL model. With no
assumptions on the data distribution, such CIs also offer finite-sample local
coverage guarantees (contrasted to the simpler marginal coverage). Using a
diverse set of datasets, we empirically verify that besides being the only
locally valid method, LVD also exceeds or matches the performance (including
coverage rate and prediction accuracy) of existing uncertainty quantification
methods, while offering additional benefits in scalability and flexibility.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00226</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00226</id><submitter>Vincent Fontaine</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:43:59 GMT</date><size>2393kb</size><source_type>D</source_type></version><title>Families of hybridizable interior penalty discontinuous Galerkin methods
  for degenerate advection-diffusion-reaction problems</title><authors>G. Etangsale and M. Fahs and V. Fontaine and A.R. Isa-Abadi</authors><categories>math.NA cs.NA math.AP</categories><comments>22 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze families of primal high-order hybridizable discontinuous Galerkin
(HDG) methods for solving degenerate (second-order) elliptic problems. One
major trouble regarding this class of PDEs concerns its mathematical nature,
which may be nonuniform over the domain. Due to the local degeneracy of the
diffusion term, it can be purely hyperbolic in a subregion and elliptic in the
rest. This problem is thus quite delicate to solve since the exact solution is
discontinuous at interfaces separating both elliptic and hyperbolic parts. The
proposed HDG method is developed in a unified and compact fashion. It can
efficiently handle pure diffusive or advective regimes and intermediate regimes
that combine the above mechanisms for a wide range of P\'eclet numbers,
including the delicate situation of local evanescent diffusion. To this end, an
adaptive stabilization strategy based on the addition of jump-penalty terms is
then considered. A $\theta$-upwind-based scheme is favored for the hyperbolic
region, and an inspired Scharfetter--Gummel-based technique is preferred for
the elliptic region. The well-posedness of the HDG method is also discussed by
analyzing the consistency and discrete coercivity properties. Extensive
numerical experiments are finally considered to verify the model's robustness
for all the abovementioned regimes.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00227</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00227</id><submitter>Fanyi Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 04:49:25 GMT</date><size>10152kb</size><source_type>D</source_type></version><title>VA-GCN: A Vector Attention Graph Convolution Network for learning on
  Point Clouds</title><authors>Haotian Hu, Fanyi Wang, Huixiao Le</authors><categories>cs.CV</categories><comments>12 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Owing to the development of research on local aggregation operators, dramatic
breakthrough has been made in point cloud analysis models. However, existing
local aggregation operators in the current literature fail to attach decent
importance to the local information of the point cloud, which limits the power
of the models. To fit this gap, we propose an efficient Vector Attention
Convolution module (VAConv), which utilizes K-Nearest Neighbor (KNN) to extract
the neighbor points of each input point, and then uses the elevation and
azimuth relationship of the vectors between the center point and its neighbors
to construct an attention weight matrix for edge features. Afterwards, the
VAConv adopts a dual-channel structure to fuse weighted edge features and
global features. To verify the efficiency of the VAConv, we connect the VAConvs
with different receptive fields in parallel to obtain a Multi-scale graph
convolutional network, VA-GCN. The proposed VA-GCN achieves state-of-the-art
performance on standard benchmarks including ModelNet40, S3DIS and ShapeNet.
Remarkably, on the ModelNet40 dataset for 3D classification, VA-GCN increased
by 2.4% compared to the baseline.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00232</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00232</id><submitter>Jiajian Liang</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:14:09 GMT</date><size>1702kb</size><source_type>D</source_type></version><title>Multimodal Transportation with Ridesharing of Personal Vehicles</title><authors>Qian-Ping Gu, Jiajian Leo Liang</authors><categories>cs.DS</categories><comments>31 pages, 11 figures</comments><msc-class>68W25, 68Q25</msc-class><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current public transportation system is unable to keep up with the
growing passenger demand as the population grows in urban areas. The slow or
lack of improvements for public transportation pushes people to use private
transportation modes, such as carpooling and ridesharing. However, the
occupancy rate of personal vehicles has been dropping in many cities. In this
paper, we propose a centralized transit system that integrates public transit
and ridesharing, which is capable of matching drivers and public transit riders
such that the riders would result in shorter travel time. The optimization goal
of the system is to assign as many riders to drivers as possible for
ridesharing. We describe an exact approach and approximation algorithms to
achieve the optimization goal. We conduct an extensive computational study to
show the effectiveness of the transit system for different approximation
algorithms. Our experiments are based on the real-world traffic data in Chicago
City; the data sets include both public transit and ridesharing trip
information. The experiment results show that our system is able to assign more
than 60% of riders to drivers, leading to a substantial increase in occupancy
rate of personal vehicles and reducing riders' travel time.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00236</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00236</id><submitter>Patrick Kelley</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:27:51 GMT</date><size>611kb</size><source_type>AD</source_type></version><title>&quot;Why wouldn't someone think of democracy as a target?&quot;: Security
  practices &amp; challenges of people involved with U.S. political campaigns</title><authors>Sunny Consolvo, Patrick Gage Kelley, Tara Matthews, Kurt Thomas, Lee
  Dunn, Elie Bursztein</authors><categories>cs.CY</categories><comments>18 pages, 2 tables, one ancillary file with 4 appendices</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  People who are involved with political campaigns face increased digital
security threats from well-funded, sophisticated attackers, especially
nation-states. Improving political campaign security is a vital part of
protecting democracy. To identify campaign security issues, we conducted
qualitative research with 28 participants across the U.S. political spectrum to
understand the digital security practices, challenges, and perceptions of
people involved in campaigns. A main, overarching finding is that a unique
combination of threats, constraints, and work culture lead people involved with
political campaigns to use technologies from across platforms and domains in
ways that leave them--and democracy--vulnerable to security attacks. Sensitive
data was kept in a plethora of personal and work accounts, with ad hoc adoption
of strong passwords, two-factor authentication, encryption, and access
controls. No individual company, committee, organization, campaign, or academic
institution can solve the identified problems on their own. To this end, we
provide an initial understanding of this complex problem space and
recommendations for how a diverse group of experts can begin working together
to improve security for political campaigns.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00237</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00237</id><submitter>Nicolas Zampieri</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:30:29 GMT</date><size>271kb</size><source_type>D</source_type></version><title>Improving Automatic Hate Speech Detection with Multiword Expression
  Features</title><authors>Nicolas Zampieri, Irina Illina and Dominique Fohr</authors><categories>cs.CL</categories><comments>In Proceedings of NLDB 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of automatically detecting hate speech in social media is gaining
more and more attention. Given the enormous volume of content posted daily,
human monitoring of hate speech is unfeasible. In this work, we propose new
word-level features for automatic hate speech detection (HSD): multiword
expressions (MWEs). MWEs are lexical units greater than a word that have
idiomatic and compositional meanings. We propose to integrate MWE features in a
deep neural network-based HSD framework. Our baseline HSD system relies on
Universal Sentence Encoder (USE). To incorporate MWE features, we create a
three-branch deep neural network: one branch for USE, one for MWE categories,
and one for MWE embeddings. We conduct experiments on two hate speech tweet
corpora with different MWE categories and with two types of MWE embeddings,
word2vec and BERT. Our experiments demonstrate that the proposed HSD system
with MWE features significantly outperforms the baseline system in terms of
macro-F1.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00239</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00239</id><submitter>Sergio Guti\'errez</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:37:12 GMT</date><size>558kb</size><source_type>D</source_type></version><title>Watching Smartly from the Bottom: Intrusion Detection revamped through
  Programmable Networks and Artificial Intelligence</title><authors>Sergio Armando Guti\'errez, John Willian Branch, Luciano Paschoal
  Gaspary, Juan Felipe Botero</authors><categories>cs.NI</categories><comments>7 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The advent of Programmable Data Planes represents an outstanding evolution
and complete revolution of the Software- Defined Networking paradigm. The
capacity to define the entire behavior of forwarding devices by controlling the
packet parsing procedures and executing custom operations enables offloading
functionalities traditionally performed at the control plane. A recent research
line has explored the possibility of even offloading to the data plane part of
Artificial Intelligence algorithms, and more specifically, Machine Learning
ones, to increase their accuracy and responsiveness (by having more detailed
visibility of the traffic). This introduces a significant opportunity for
evolution in the critical field of Intrusion Detection. However, offloading
functionalities to the data plane is not a straightforward task. In this paper,
we discuss how Programmable Data Planes might complement different stages of an
Intrusion Detection System based on Machine Learning. We present two use cases
that make evident the feasibility of this approach and highlight aspects that
must be considered when addressing the challenge of deploying solutions
leveraging data-plane functionalities.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00240</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00240</id><submitter>Kshitij Gupta</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:41:03 GMT</date><size>8493kb</size><source_type>D</source_type></version><title>Volta at SemEval-2021 Task 6: Towards Detecting Persuasive Texts and
  Images using Textual and Multimodal Ensemble</title><authors>Kshitij Gupta, Devansh Gautam, Radhika Mamidi</authors><categories>cs.CL cs.CV</categories><comments>7 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memes are one of the most popular types of content used to spread information
online. They can influence a large number of people through rhetorical and
psychological techniques. The task, Detection of Persuasion Techniques in Texts
and Images, is to detect these persuasive techniques in memes. It consists of
three subtasks: (A) Multi-label classification using textual content, (B)
Multi-label classification and span identification using textual content, and
(C) Multi-label classification using visual and textual content. In this paper,
we propose a transfer learning approach to fine-tune BERT-based models in
different modalities. We also explore the effectiveness of ensembles of models
trained in different modalities. We achieve an F1-score of 57.0, 48.2, and 52.1
in the corresponding subtasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00241</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00241</id><submitter>Shining Liang</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:46:22 GMT</date><size>1606kb</size><source_type>D</source_type></version><title>Reinforced Iterative Knowledge Distillation for Cross-Lingual Named
  Entity Recognition</title><authors>Shining Liang, Ming Gong, Jian Pei, Linjun Shou, Wanli Zuo, Xianglin
  Zuo, Daxin Jiang</authors><categories>cs.CL cs.AI</categories><comments>KDD 2021</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Named entity recognition (NER) is a fundamental component in many
applications, such as Web Search and Voice Assistants. Although deep neural
networks greatly improve the performance of NER, due to the requirement of
large amounts of training data, deep neural networks can hardly scale out to
many languages in an industry setting. To tackle this challenge, cross-lingual
NER transfers knowledge from a rich-resource language to languages with low
resources through pre-trained multilingual language models. Instead of using
training data in target languages, cross-lingual NER has to rely on only
training data in source languages, and optionally adds the translated training
data derived from source languages. However, the existing cross-lingual NER
methods do not make good use of rich unlabeled data in target languages, which
is relatively easy to collect in industry applications. To address the
opportunities and challenges, in this paper we describe our novel practice in
Microsoft to leverage such large amounts of unlabeled data in target languages
in real production settings. To effectively extract weak supervision signals
from the unlabeled data, we develop a novel approach based on the ideas of
semi-supervised learning and reinforcement learning. The empirical study on
three benchmark data sets verifies that our approach establishes the new
state-of-the-art performance with clear edges. Now, the NER techniques reported
in this paper are on their way to become a fundamental component for Web
ranking, Entity Pane, Answers Triggering, and Question Answering in the
Microsoft Bing search engine. Moreover, our techniques will also serve as part
of the Spoken Language Understanding module for a commercial voice assistant.
We plan to open source the code of the prototype framework after deployment.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00243</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00243</id><submitter>Hamza Anwar</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:54:02 GMT</date><size>3351kb</size></version><version version="v2"><date>Wed, 2 Jun 2021 17:59:08 GMT</date><size>3346kb</size></version><title>Comprehensive Energy Footprint Benchmarking of Strong Parallel
  Electrified Powertrain</title><authors>Aashrith Vishwanath, Hamza Anwar, Apurva Chunodkar, Qadeer Ahmed</authors><categories>eess.SY cs.SY</categories><comments>Updated title, fixed typos</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we present a benchmark solution with higher number of
continuous and discrete states and control levers using validated powertrain
component models, where DP fails due to exponential rise in the computation
time. The problem involves 13 states and 4 control levers, with complex
interactions between multiple subsystems. Some of these variables are discrete
while some are continuous. Some have slow dynamics while some have fast
dynamics. A novel three step PS3 algorithm which is presented in our prequel
paper is used to obtain a near-optimal solution. PS3 algorithm makes use of
pseudo spectral method for accurate state estimations. We present three
scenarios where only fuel is minimized, only emissions are minimized and,
lastly a combination of both fuel and emissions are minimized. All three cases
are analyzed for their performance and computation time. The optimal compromise
between fuel consumption and emissions are analyzed using a Pareto-front study.
This large-scale powertrain optimization problem is solved for a P2 parallel
hybrid architecture on a class 6 pick-up &amp; delivery truck.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00245</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00245</id><submitter>Linjie Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 05:54:41 GMT</date><size>15704kb</size><source_type>D</source_type></version><title>Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA
  Models</title><authors>Linjie Li, Jie Lei, Zhe Gan, Jingjing Liu</authors><categories>cs.CV cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  With large-scale pre-training, the past two years have witnessed significant
performance boost on the Visual Question Answering (VQA) task. Though rapid
progresses have been made, it remains unclear whether these state-of-the-art
(SOTA) VQA models are robust when encountering test examples in the wild. To
study this, we introduce Adversarial VQA, a new large-scale VQA benchmark,
collected iteratively via an adversarial human-and-model-in-the-loop procedure.
Through this new benchmark, we present several interesting findings. (i)
Surprisingly, during dataset collection, we find that non-expert annotators can
successfully attack SOTA VQA models with relative ease. (ii) We test a variety
of SOTA VQA models on our new dataset to highlight their fragility, and find
that both large-scale pre-trained models and adversarial training methods can
only achieve far lower performance than what they can achieve on the standard
VQA v2 dataset. (iii) When considered as data augmentation, our dataset can be
used to improve the performance on other robust VQA benchmarks. (iv) We present
a detailed analysis of the dataset, providing valuable insights on the
challenges it brings to the community. We hope Adversarial VQA can serve as a
valuable benchmark that will be used by future work to test the robustness of
its developed VQA models. Our dataset is publicly available at
https://adversarialvqa. github.io/.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00247</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00247</id><submitter>Marc Zeller</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:01:08 GMT</date><size>709kb</size><source_type>D</source_type></version><title>Combination of component fault trees and Markov chains to analyze
  complex, software-controlled systems</title><authors>Marc Zeller, Francesco Montrone</authors><categories>cs.SE</categories><journal-ref>2018 3rd International Conference on System Reliability and Safety
  (ICSRS)</journal-ref><doi>10.1109/ICSRS.2018.8688854</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fault Tree analysis is a widely used failure analysis methodology to assess a
system in terms of safety or reliability in many industrial application
domains. However, with Fault Tree methodology there is no possibility to
express a temporal sequence of events or state-dependent behavior of
software-controlled systems. In contrast to this, Markov Chains are a
state-based analysis technique based on a stochastic model. But the use of
Markov Chains for failure analysis of complex safety-critical systems is
limited due to exponential explosion of the size of the model. In this paper,
we present a concept to integrate Markov Chains in Component Fault Tree models.
Based on a component concept for Markov Chains, which enables the association
of Markov Chains to system development elements such as components, complex or
software-controlled systems can be analyzed w.r.t. safety or reliability in a
modular and compositional way. We illustrate this approach using a case study
from the automotive domain.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00248</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00248</id><submitter>Devansh Gautam</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:06:29 GMT</date><size>5386kb</size><source_type>D</source_type></version><title>Volta at SemEval-2021 Task 9: Statement Verification and Evidence
  Finding with Tables using TAPAS and Transfer Learning</title><authors>Devansh Gautam, Kshitij Gupta, Manish Shrivastava</authors><categories>cs.CL</categories><comments>9 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tables are widely used in various kinds of documents to present information
concisely. Understanding tables is a challenging problem that requires an
understanding of language and table structure, along with numerical and logical
reasoning. In this paper, we present our systems to solve Task 9 of
SemEval-2021: Statement Verification and Evidence Finding with Tables
(SEM-TAB-FACTS). The task consists of two subtasks: (A) Given a table and a
statement, predicting whether the table supports the statement and (B)
Predicting which cells in the table provide evidence for/against the statement.
We fine-tune TAPAS (a model which extends BERT's architecture to capture
tabular structure) for both the subtasks as it has shown state-of-the-art
performance in various table understanding tasks. In subtask A, we evaluate how
transfer learning and standardizing tables to have a single header row improves
TAPAS' performance. In subtask B, we evaluate how different fine-tuning
strategies can improve TAPAS' performance. Our systems achieve an F1 score of
67.34 in subtask A three-way classification, 72.89 in subtask A two-way
classification, and 62.95 in subtask B.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00250</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00250</id><submitter>Kshitij Gupta</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:19:29 GMT</date><size>5754kb</size><source_type>D</source_type></version><title>ViTA: Visual-Linguistic Translation by Aligning Object Tags</title><authors>Kshitij Gupta, Devansh Gautam, Radhika Mamidi</authors><categories>cs.CL cs.CV</categories><comments>7 pages, accepted at WAT-2021 co-located with ACL-IJCNLP 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal Machine Translation (MMT) enriches the source text with visual
information for translation. It has gained popularity in recent years, and
several pipelines have been proposed in the same direction. Yet, the task lacks
quality datasets to illustrate the contribution of visual modality in the
translation systems. In this paper, we propose our system for the Multimodal
Translation Task of WAT 2021 from English to Hindi. We propose to use mBART, a
pretrained multilingual sequence-to-sequence model, for the textual-only
translations. Further, we bring the visual information to a textual domain by
extracting object tags from the image and enhance the input for the multimodal
task. We also explore the robustness of our system by systematically degrading
the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test
set and challenge set of the task.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00252</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00252</id><submitter>Sharu Theresa Jose</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:23:12 GMT</date><size>1956kb</size><source_type>D</source_type></version><title>Information-Theoretic Analysis of Epistemic Uncertainty in Bayesian
  Meta-learning</title><authors>Sharu Theresa Jose, Sangwoo Park, Osvaldo Simeone</authors><categories>cs.LG cs.IT eess.SP math.IT</categories><comments>Under review, 21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The overall predictive uncertainty of a trained predictor can be decomposed
into separate contributions due to epistemic and aleatoric uncertainty. Under a
Bayesian formulation, assuming a well-specified model, the two contributions
can be exactly expressed (for the log-loss) or bounded (for more general
losses) in terms of information-theoretic quantities (Xu and Raginsky, 2020).
This paper addresses the study of epistemic uncertainty within an
information-theoretic framework in the broader setting of Bayesian
meta-learning. A general hierarchical Bayesian model is assumed in which
hyperparameters determine the per-task priors of the model parameters. Exact
characterizations (for the log-loss) and bounds (for more general losses) are
derived for the epistemic uncertainty - quantified by the minimum excess
meta-risk (MEMR)- of optimal meta-learning rules. This characterization is
leveraged to bring insights into the dependence of the epistemic uncertainty on
the number of tasks and on the amount of per-task training data. Experiments
are presented that compare the proposed information-theoretic bounds, evaluated
via neural mutual information estimators, with the performance of a novel
approximate fully Bayesian meta-learning strategy termed Langevin-Stein
Bayesian Meta-Learning (LS-BML).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00253</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00253</id><submitter>Hamed Haggi</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:25:07 GMT</date><size>456kb</size><source_type>D</source_type></version><title>Proactive Scheduling of Hydrogen Systems for Resilience Enhancement of
  Distribution Networks</title><authors>Hamed Haggi, Wei Sun, James M. Fenton, and Paul Brooker</authors><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in smart grid technologies bring opportunities to better
control the modern and complex power grids with renewable integration. The
operation of power systems, especially distribution network (DN), is facing
with preeminent challenges from cyber-physical-human (CPH) threats and natural
disasters. In order to provide better response against threats and improve the
resilience of power grid, proactive plans and operational schemes are required
by system operators to minimize the damages caused by CPH threats. To that end,
this paper proposes a proactive plan for DN operation by using hydrogen (H2)
systems to enhance the resilience through cost-effective long-term energy
storage. Unlike batteries, H2 energy can be stored in the storage tanks days
before the extreme event, and transformed into power by fuel cell units in the
post-event time to reduce load curtailment caused by CPH threats. The proposed
framework is validated by testing on 33-node test feeder. Simulation results
demonstrate that H2 systems can improve the resilience of DN during $N-m$
outages lasting for more than 10 hours.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00254</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00254</id><submitter>Min Fu</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:27:03 GMT</date><size>1063kb</size><source_type>D</source_type></version><title>UAV Aided Over-the-Air Computation</title><authors>Min Fu, Yong Zhou, Yuanming Shi, Wei Chen, and Rui Zhang</authors><categories>eess.SP cs.SY eess.SY</categories><comments>30 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Over-the-air computation (AirComp) seamlessly integrates communication and
computation by exploiting the waveform superposition property of
multiple-access channels. Different from the existing works that focus on
transceiver design of AirComp over static networks, this paper considers an
unmanned aerial vehicle (UAV) aided AirComp system, where the UAV as a flying
base station aggregates data from mobile sensors. The trajectory design of the
UAV provides an additional degree of freedom to improve the performance of
AirComp. Our goal is to minimize the time-averaged mean-squared error (MSE) of
AirComp by jointly optimizing the UAV trajectory, receive normalizing factors,
and sensors' transmit power. To this end, we first propose a novel and
equivalent problem transformation by introducing intermediate variables. This
reformulation leads to a convex subproblem when fixing any other two blocks of
variables, thereby enabling efficient algorithm design based on the principle
of block coordinate descent and alternating direction method of multipliers
(ADMM) techniques. In particular, we derive the optimal closed-form solutions
for normalizing factors and intermediate variables optimization subproblems. We
also recast the convex trajectory design subproblem into an ADMM form and
obtain the closed-form expressions for each variable updating. Simulation
results show that the proposed algorithm achieves a smaller time-averaged MSE
while reducing the simulation time by orders of magnitude compared to
state-of-the-art algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00256</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00256</id><submitter>Hao Cheng</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:33:24 GMT</date><size>1951kb</size><source_type>D</source_type></version><title>Reconciliation of Statistical and Spatial Sparsity For Robust Image and
  Image-Set Classification</title><authors>Hao Cheng, Kim-Hui Yap, and Bihan Wen</authors><categories>cs.CV</categories><comments>Submitted to IEEE Transactions on Multimedia</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent image classification algorithms, by learning deep features from
large-scale datasets, have achieved significantly better results comparing to
the classic feature-based approaches. However, there are still various
challenges of image classifications in practice, such as classifying noisy
image or image-set queries and training deep image classification models over
the limited-scale dataset. Instead of applying generic deep features, the
model-based approaches can be more effective and data-efficient for robust
image and image-set classification tasks, as various image priors are exploited
for modeling the inter- and intra-set data variations while preventing
over-fitting. In this work, we propose a novel Joint Statistical and Spatial
Sparse representation, dubbed \textit{J3S}, to model the image or image-set
data for classification, by reconciling both their local patch structures and
global Gaussian distribution mapped into Riemannian manifold. To the best of
our knowledge, no work to date utilized both global statistics and local patch
structures jointly via joint sparse representation. We propose to solve the
joint sparse coding problem based on the J3S model, by coupling the local and
global image representations using joint sparsity. The learned J3S models are
used for robust image and image-set classification. Experiments show that the
proposed J3S-based image classification scheme outperforms the popular or
state-of-the-art competing methods over FMD, UIUC, ETH-80 and YTC databases.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00257</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00257</id><submitter>Yu Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:41:48 GMT</date><size>1341kb</size><source_type>D</source_type></version><title>A Coarse to Fine Question Answering System based on Reinforcement
  Learning</title><authors>Yu Wang, Hongxia Jin</authors><categories>cs.CL cs.AI</categories><comments>9 pages, original work published in AAAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a coarse to fine question answering (CFQA) system
based on reinforcement learning which can efficiently processes documents with
different lengths by choosing appropriate actions. The system is designed using
an actor-critic based deep reinforcement learning model to achieve multi-step
question answering. Compared to previous QA models targeting on datasets mainly
containing either short or long documents, our multi-step coarse to fine model
takes the merits from multiple system modules, which can handle both short and
long documents. The system hence obtains a much better accuracy and faster
trainings speed compared to the current state-of-the-art models. We test our
model on four QA datasets, WIKEREADING, WIKIREADING LONG, CNN and SQuAD, and
demonstrate 1.3$\%$-1.7$\%$ accuracy improvements with 1.5x-3.4x training
speed-ups in comparison to the baselines using state-of-the-art models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00258</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00258</id><submitter>Qianyu Feng</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:45:56 GMT</date><size>6943kb</size><source_type>D</source_type></version><title>Divide and Rule: Recurrent Partitioned Network for Dynamic Processes</title><authors>Qianyu Feng, Bang Zhang, Yi Yang</authors><categories>cs.AI</categories><comments>arXiv admin note: text overlap with arXiv:2007.15240,
  arXiv:2007.00631 by other authors</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In general, many dynamic processes are involved with interacting variables,
from physical systems to sociological analysis. The interplay of components in
the system can give rise to confounding dynamic behavior. Many approaches model
temporal sequences holistically ignoring the internal interaction which are
impotent in capturing the protogenic actuation. Differently, our goal is to
represent a system with a part-whole hierarchy and discover the implied
dependencies among intra-system variables: inferring the interactions that
possess causal effects on the sub-system behavior with REcurrent partItioned
Network (REIN). The proposed architecture consists of (i) a perceptive module
that extracts a hierarchical and temporally consistent representation of the
observation at multiple levels, (ii) a deductive module for determining the
relational connection between neurons at each level, and (iii) a statistical
module that can predict the future by conditioning on the temporal
distributional estimation. Our model is demonstrated to be effective in
identifying the componential interactions with limited observation and stable
in long-term future predictions experimented with diverse physical systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00259</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00259</id><submitter>Qiufu Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:46:50 GMT</date><size>12837kb</size><source_type>D</source_type></version><title>3D WaveUNet: 3D Wavelet Integrated Encoder-Decoder Network for Neuron
  Segmentation</title><authors>Qiufu Li and Linlin Shen</authors><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  3D neuron segmentation is a key step for the neuron digital reconstruction,
which is essential for exploring brain circuits and understanding brain
functions. However, the fine line-shaped nerve fibers of neuron could spread in
a large region, which brings great computational cost to the segmentation in 3D
neuronal images. Meanwhile, the strong noises and disconnected nerve fibers in
the image bring great challenges to the task. In this paper, we propose a 3D
wavelet and deep learning based 3D neuron segmentation method. The neuronal
image is first partitioned into neuronal cubes to simplify the segmentation
task. Then, we design 3D WaveUNet, the first 3D wavelet integrated
encoder-decoder network, to segment the nerve fibers in the cubes; the wavelets
could assist the deep networks in suppressing data noise and connecting the
broken fibers. We also produce a Neuronal Cube Dataset (NeuCuDa) using the
biggest available annotated neuronal image dataset, BigNeuron, to train 3D
WaveUNet. Finally, the nerve fibers segmented in cubes are assembled to
generate the complete neuron, which is digitally reconstructed using an
available automatic tracing algorithm. The experimental results show that our
neuron segmentation method could completely extract the target neuron in noisy
neuronal images. The integrated 3D wavelets can efficiently improve the
performance of 3D neuron segmentation and reconstruction. The code and
pre-trained models for this work will be available at
https://github.com/LiQiufu/3D-WaveUNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00260</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00260</id><submitter>Qi Tang</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:49:54 GMT</date><size>43442kb</size><source_type>D</source_type></version><title>An adaptive scalable fully implicit algorithm based on stabilized finite
  element for reduced visco-resistive MHD</title><authors>Qi Tang and Luis Chacon and Tzanio V. Kolev and John N. Shadid and
  Xian-Zhu Tang</authors><categories>physics.comp-ph cs.NA math.NA</categories><comments>41 pages, 21 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The magnetohydrodynamics (MHD) equations are continuum models used in the
study of a wide range of plasma physics systems, including the evolution of
complex plasma dynamics in tokamak disruptions. However, efficient numerical
solution methods for MHD are extremely challenging due to disparate time and
length scales, strong hyperbolic phenomena, and nonlinearity. Therefore the
development of scalable, implicit MHD algorithms and high-resolution adaptive
mesh refinement strategies is of considerable importance. In this work, we
develop a high-order stabilized finite-element algorithm for the reduced
visco-resistive MHD equations based on the MFEM finite element library
(mfem.org). The scheme is fully implicit, solved with the Jacobian-free
Newton-Krylov (JFNK) method with a physics-based preconditioning strategy. Our
preconditioning strategy is a generalization of the physics-based
preconditioning methods in [Chacon, et al, JCP 2002] to adaptive, stabilized
finite elements. Algebraic multigrid methods are used to invert sub-block
operators to achieve scalability. A parallel adaptive mesh refinement scheme
with dynamic load-balancing is implemented to efficiently resolve the
multi-scale spatial features of the system. Our implementation uses the MFEM
framework, which provides arbitrary-order polynomials and flexible adaptive
conforming and non-conforming meshes capabilities. Results demonstrate the
accuracy, efficiency, and scalability of the implicit scheme in the presence of
large scale disparity. The potential of the AMR approach is demonstrated on an
island coalescence problem in the high Lundquist-number regime ($\ge 10^7$)
with the successful resolution of plasmoid instabilities and thin current
sheets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00261</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00261</id><submitter>Jiang Hui</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:52:41 GMT</date><size>1337kb</size><source_type>D</source_type></version><title>Exploring Dynamic Selection of Branch Expansion Orders for Code
  Generation</title><authors>Hui Jiang, Chulun Zhou, Fandong Meng, Biao Zhang, Jie Zhou, Degen
  Huang, Qingqiang Wu, Jinsong Su</authors><categories>cs.CL</categories><comments>Accepted by ACL 2021 main conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Due to the great potential in facilitating software development, code
generation has attracted increasing attention recently. Generally, dominant
models are Seq2Tree models, which convert the input natural language
description into a sequence of tree-construction actions corresponding to the
pre-order traversal of an Abstract Syntax Tree (AST). However, such a traversal
order may not be suitable for handling all multi-branch nodes. In this paper,
we propose to equip the Seq2Tree model with a context-based Branch Selector,
which is able to dynamically determine optimal expansion orders of branches for
multi-branch nodes. Particularly, since the selection of expansion orders is a
non-differentiable multi-step operation, we optimize the selector through
reinforcement learning, and formulate the reward function as the difference of
model losses obtained through different expansion orders. Experimental results
and in-depth analysis on several commonly-used datasets demonstrate the
effectiveness and generality of our approach. We have released our code at
https://github.com/DeepLearnXMU/CG-RL.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00263</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00263</id><submitter>Mengfan Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:53:17 GMT</date><size>466kb</size><source_type>D</source_type></version><title>Graph-based Exercise- and Knowledge-Aware Learning Network for Student
  Performance Prediction</title><authors>Mengfan Liu, Pengyang Shao, Kun Zhang</authors><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting student performance is a fundamental task in Intelligent Tutoring
Systems (ITSs), by which we can learn about students' knowledge level and
provide personalized teaching strategies for them. Researchers have made plenty
of efforts on this task. They either leverage educational psychology methods to
predict students' scores according to the learned knowledge proficiency, or
make full use of Collaborative Filtering (CF) models to represent latent
factors of students and exercises. However, most of these methods either
neglect the exercise-specific characteristics (e.g., exercise materials), or
cannot fully explore the high-order interactions between students, exercises,
as well as knowledge concepts. To this end, we propose a Graph-based Exercise-
and Knowledge-Aware Learning Network for accurate student score prediction.
Specifically, we learn students' mastery of exercises and knowledge concepts
respectively to model the two-fold effects of exercises and knowledge concepts.
Then, to model the high-order interactions, we apply graph convolution
techniques in the prediction process. Extensive experiments on two real-world
datasets prove the effectiveness of our proposed Graph-EKLN.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00264</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00264</id><submitter>Bo Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:55:19 GMT</date><size>1715kb</size><source_type>D</source_type></version><title>Hardness Sampling for Self-Training Based Transductive Zero-Shot
  Learning</title><authors>Liu Bo, Qiulei Dong, Zhanyi Hu</authors><categories>cs.CV</categories><comments>11 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Transductive zero-shot learning (T-ZSL) which could alleviate the domain
shift problem in existing ZSL works, has received much attention recently.
However, an open problem in T-ZSL: how to effectively make use of unseen-class
samples for training, still remains. Addressing this problem, we first
empirically analyze the roles of unseen-class samples with different degrees of
hardness in the training process based on the uneven prediction phenomenon
found in many ZSL methods, resulting in three observations. Then, we propose
two hardness sampling approaches for selecting a subset of diverse and hard
samples from a given unseen-class dataset according to these observations. The
first one identifies the samples based on the class-level frequency of the
model predictions while the second enhances the former by normalizing the class
frequency via an approximate class prior estimated by an explored prior
estimation algorithm. Finally, we design a new Self-Training framework with
Hardness Sampling for T-ZSL, called STHS, where an arbitrary inductive ZSL
method could be seamlessly embedded and it is iteratively trained with
unseen-class samples selected by the hardness sampling approach. We introduce
two typical ZSL methods into the STHS framework and extensive experiments
demonstrate that the derived T-ZSL methods outperform many state-of-the-art
methods on three public benchmarks. Besides, we note that the unseen-class
dataset is separately used for training in some existing transductive
generalized ZSL (T-GZSL) methods, which is not strict for a GZSL task. Hence,
we suggest a more strict T-GZSL data setting and establish a competitive
baseline on this setting by introducing the proposed STHS framework to T-GZSL.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00265</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00265</id><submitter>Sharu Theresa Jose</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:55:37 GMT</date><size>181kb</size></version><title>A unified PAC-Bayesian framework for machine unlearning via information
  risk minimization</title><authors>Sharu Theresa Jose, Osvaldo Simeone</authors><categories>cs.LG cs.IT eess.SP math.IT</categories><comments>Under Review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine unlearning refers to mechanisms that can remove the influence of a
subset of training data upon request from a trained model without incurring the
cost of re-training from scratch. This paper develops a unified PAC-Bayesian
framework for machine unlearning that recovers the two recent design principles
- variational unlearning (Nguyen et.al., 2020) and forgetting Lagrangian
(Golatkar et.al., 2020) - as information risk minimization problems
(Zhang,2006). Accordingly, both criteria can be interpreted as PAC-Bayesian
upper bounds on the test loss of the unlearned model that take the form of free
energy metrics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00266</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00266</id><submitter>Oriol Corcoll</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:58:31 GMT</date><size>1731kb</size><source_type>D</source_type></version><title>Did I do that? Blame as a means to identify controlled effects in
  reinforcement learning</title><authors>Oriol Corcoll, Raul Vicente</authors><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Modeling controllable aspects of the environment enable better prioritization
of interventions and has become a popular exploration strategy in reinforcement
learning methods. Despite repeatedly achieving State-of-the-Art results, this
approach has only been studied as a proxy to a reward-based task and has not
yet been evaluated on its own. We show that solutions relying on action
prediction fail to model important events. Humans, on the other hand, assign
blame to their actions to decide what they controlled. Here we propose
Controlled Effect Network (CEN), an unsupervised method based on counterfactual
measures of blame. CEN is evaluated in a wide range of environments showing
that it can identify controlled effects better than popular models based on
action prediction.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00267</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00267</id><submitter>Sabah Al-Fedaghi Dr.</submitter><version version="v1"><date>Tue, 1 Jun 2021 06:58:48 GMT</date><size>1190kb</size></version><title>Classes in Object-Oriented Modeling (UML): Further Understanding and
  Abstraction</title><authors>Sabah Al-Fedaghi</authors><categories>cs.SE</categories><comments>12 pages, 22 figures</comments><journal-ref>IJCSNS International Journal of Computer Science and Network
  Security, Vol. 21, No. 5, pp. 139-150, May, 2021</journal-ref><doi>10.22937/IJCSNS.2021.21.5.21</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Object orientation has become the predominant paradigm for conceptual
modeling (e.g., UML), where the notions of class and object form the primitive
building blocks of thought. Classes act as templates for objects that have
attributes and methods (actions). The modeled systems are not even necessarily
software systems: They can be human and artificial systems of many different
kinds (e.g., teaching and learning systems). The UML class diagram is described
as a central component of model-driven software development. It is the most
common diagram in object-oriented models and used to model the static design
view of a system. Objects both carry data and execute actions. According to
some authorities in modeling, a certain degree of difficulty exists in
understanding the semantics of these notions in UML class diagrams. Some
researchers claim class diagrams have limited use for conceptual analysis and
that they are best used for logical design. Performing conceptual analysis
should not concern the ways facts are grouped into structures. Whether a fact
will end up in the design as an attribute is not a conceptual issue. UML leads
to drilling down into physical design details (e.g., private/public attributes,
encapsulated operations, and navigating direction of an association). This
paper is a venture to further the understanding of object-orientated concepts
as exemplified in UML with the aim of developing a broad comprehension of
conceptual modeling fundamentals. Thinging machine (TM) modeling is a new
modeling language employed in such an undertaking. TM modeling interlaces
structure (components) and actionality where actions infiltrate the attributes
as much as the classes. Although space limitations affect some aspects of the
class diagram, the concluding assessment of this study reveals the class
description is a kind of shorthand for a richer sematic TM construct.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00273</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00273</id><submitter>Haibin Wu</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:10:54 GMT</date><size>4980kb</size><source_type>D</source_type></version><title>Adversarial Defense for Automatic Speaker Verification by
  Self-Supervised Learning</title><authors>Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-yi Lee</authors><categories>cs.SD cs.LG eess.AS</categories><comments>Submitted to TASLP on 03 May 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Previous works have shown that automatic speaker verification (ASV) is
seriously vulnerable to malicious spoofing attacks, such as replay, synthetic
speech, and recently emerged adversarial attacks. Great efforts have been
dedicated to defending ASV against replay and synthetic speech; however, only a
few approaches have been explored to deal with adversarial attacks. All the
existing approaches to tackle adversarial attacks for ASV require the knowledge
for adversarial samples generation, but it is impractical for defenders to know
the exact attack algorithms that are applied by the in-the-wild attackers. This
work is among the first to perform adversarial defense for ASV without knowing
the specific attack algorithms. Inspired by self-supervised learning models
(SSLMs) that possess the merits of alleviating the superficial noise in the
inputs and reconstructing clean samples from the interrupted ones, this work
regards adversarial perturbations as one kind of noise and conducts adversarial
defense for ASV by SSLMs. Specifically, we propose to perform adversarial
defense from two perspectives: 1) adversarial perturbation purification and 2)
adversarial perturbation detection. Experimental results show that our
detection module effectively shields the ASV by detecting adversarial samples
with an accuracy of around 80%. Moreover, since there is no common metric for
evaluating the adversarial defense performance for ASV, this work also
formalizes evaluation metrics for adversarial defense considering both
purification and detection based approaches into account. We sincerely
encourage future works to benchmark their approaches based on the proposed
evaluation framework.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00274</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00274</id><submitter>Alex D\'iaz Santos</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:14:51 GMT</date><size>3548kb</size><source_type>D</source_type></version><title>Analysis of classifiers robust to noisy labels</title><authors>Alex D\'iaz and Damian Steele</authors><categories>cs.LG cs.AI cs.CV cs.DS</categories><comments>12 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We explore contemporary robust classification algorithms for overcoming
class-dependant labelling noise: Forward, Importance Re-weighting and
T-revision. The classifiers are trained and evaluated on class-conditional
random label noise data while the final test data is clean. We demonstrate
methods for estimating the transition matrix in order to obtain better
classifier performance when working with noisy data. We apply deep learning to
three data-sets and derive an end-to-end analysis with unknown noise on the
CIFAR data-set from scratch. The effectiveness and robustness of the
classifiers are analysed, and we compare and contrast the results of each
experiment are using top-1 accuracy as our criterion.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00275</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00275</id><submitter>He Yang</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:15:31 GMT</date><size>731kb</size><source_type>D</source_type></version><title>H-FL: A Hierarchical Communication-Efficient and Privacy-Protected
  Architecture for Federated Learning</title><authors>He Yang</authors><categories>cs.LG cs.CR cs.DC</categories><comments>Accepted by IJCAI 2021, 7pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The longstanding goals of federated learning (FL) require rigorous privacy
guarantees and low communication overhead while holding a relatively high model
accuracy. However, simultaneously achieving all the goals is extremely
challenging. In this paper, we propose a novel framework called hierarchical
federated learning (H-FL) to tackle this challenge. Considering the degradation
of the model performance due to the statistic heterogeneity of the training
data, we devise a runtime distribution reconstruction strategy, which
reallocates the clients appropriately and utilizes mediators to rearrange the
local training of the clients. In addition, we design a compression-correction
mechanism incorporated into H-FL to reduce the communication overhead while not
sacrificing the model performance. To further provide privacy guarantees, we
introduce differential privacy while performing local training, which injects
moderate amount of noise into only part of the complete model. Experimental
results show that our H-FL framework achieves the state-of-art performance on
different datasets for the real-world image recognition tasks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00278</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00278</id><submitter>Alexandru Popa Dr.</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:19:09 GMT</date><size>7254kb</size><source_type>D</source_type></version><title>Approximate and exact results for the harmonious chromatic number</title><authors>Ruxandra Marinescu-Ghemeci, Camelia Obreja and Alexandru Popa</authors><categories>cs.DM math.CO</categories><comments>15 pages, 27 figures, under submission</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Graph colorings is a fundamental topic in graph theory that require an
assignment of labels (or colors) to vertices or edges subject to various
constraints. We focus on the harmonious coloring of a graph, which is a proper
vertex coloring such that for every two distinct colors i, j at most one pair
of adjacent vertices are colored with i and j. This type of coloring is
edge-distinguishing and has potential applications in transportation network,
computer network, airway network system.
  The results presented in this paper fall into two categories: in the first
part of the paper we are concerned with the computational aspects of finding a
minimum harmonious coloring and in the second part we determine the exact value
of the harmonious chromatic number for some particular graphs and classes of
graphs. More precisely, in the first part we show that finding a minimum
harmonious coloring for arbitrary graphs is APX-hard, the natural greedy
algorithm is a $\Omega(\sqrt{n})$-approximation, and, moreover, we show a
relationship between the vertex cover and the harmonious chromatic number. In
the second part we determine the exact value of the harmonious chromatic number
for all 3-regular planar graphs of diameter 3, some non-planar regular graphs
and cycle-related graphs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00279</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00279</id><submitter>Quentin Stout</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:19:17 GMT</date><size>186kb</size></version><title>$L_0$ Isotonic Regression With Secondary Objectives</title><authors>Quentin F. Stout</authors><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We provide algorithms for isotonic regression minimizing $L_0$ error (Hamming
distance). This is also known as monotonic relabeling, and is applicable when
labels have a linear ordering but not necessarily a metric. There may be
exponentially many optimal relabelings, so we look at secondary criteria to
determine which are best. For arbitrary ordinal labels the criterion is
maximizing the number of labels which are only changed to an adjacent label
(and recursively apply this). For real-valued labels we minimize the $L_p$
error. For linearly ordered sets we also give algorithms which minimize the sum
of the $L_p$ and weighted $L_0$ errors, a form of penalized (regularized)
regression. We also examine $L_0$ isotonic regression on multidimensional
coordinate-wise orderings. Previous algorithms took $\Theta(n^3)$ time, but we
reduce this to $o(n^{3/2})$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00280</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00280</id><submitter>Martin Genzel</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:20:33 GMT</date><size>1139kb</size><source_type>D</source_type></version><title>AAPM DL-Sparse-View CT Challenge Submission Report: Designing an
  Iterative Network for Fanbeam-CT with Unknown Geometry</title><authors>Martin Genzel, Jan Macdonald, Maximilian M\&quot;arz</authors><categories>cs.LG cs.NA eess.IV math.NA physics.med-ph</categories><comments>This is a technical report of a method participating in a not yet
  finished challenge. Therefore, it does not contain any final results. In
  particular, the reported reconstruction errors are only with respect to our
  own validation split of the provided training data. Once the official
  challenge report is released, these values will be updated with the results
  from the actual test set</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This report is dedicated to a short motivation and description of our
contribution to the AAPM DL-Sparse-View CT Challenge (team name:
&quot;robust-and-stable&quot;). The task is to recover breast model phantom images from
limited view fanbeam measurements using data-driven reconstruction techniques.
The challenge is distinctive in the sense that participants are provided with a
collection of ground truth images and their noiseless, subsampled sinograms (as
well as the associated limited view filtered backprojection images), but not
with the actual forward model. Therefore, our approach first estimates the
fanbeam geometry in a data-driven geometric calibration step. In a subsequent
two-step procedure, we design an iterative end-to-end network that enables the
computation of near-exact solutions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00282</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00282</id><submitter>Zhang Chao</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:28:52 GMT</date><size>6331kb</size><source_type>D</source_type></version><title>Diffuse interface relaxation model for two-phase compressible flows with
  diffusion processes</title><authors>Chao Zhang and Igor Menshov and Lifeng Wang and Zhijun Shen</authors><categories>math.NA cs.NA math.AP</categories><comments>37 pages, 16 figures</comments><acm-class>G.1.8; J.2</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The paper addresses a two-temperature model for simulating compressible
two-phase flow taking into account diffusion processes related to the heat
conduction and viscosity of the phases. This model is reduced from the
two-phase Baer-Nunziato model in the limit of complete velocity relaxation and
consists of the phase mass and energy balance equations, the mixture momentum
equation, and a transport equation for the volume fraction.Terms describing
effects of mechanical relaxation, temperature relaxation, and thermal
conduction on volume fraction evolution are derived and demonstrated to be
significant for heat conduction problems. The thermal conduction leads to
instantaneous thermal relaxation so that the temperature equilibrium is always
maintained in the interface region with meeting the entropy relations. A
numerical method is developed to solve the model governing equations that
ensures the pressure-velocity-temperature (PVT) equilibrium condition in its
high-order extension. We solve the hyperbolic part of the governing equations
with the Godunov method with the HLLC approximate Riemann solver. The
non-linear parabolic part is solved with an efficient Chebyshev explicit
iterative method without dealing with large sparse matrices. To verify the
model and numerical methods proposed,we demonstrate numerical results of
several numerical tests such as the multiphase shock tube problem, the
multiphase impact problem, and the planar ablative Rayleigh-Taylor instability
problem.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00284</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00284</id><submitter>Kensuke Aihara</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:36:44 GMT</date><size>333kb</size></version><title>Cross-interactive residual smoothing for global and block Lanczos-type
  solvers for linear systems with multiple right-hand sides</title><authors>Kensuke Aihara, Akira Imakura, Keiichi Morikuni</authors><categories>math.NA cs.NA</categories><comments>20 pages, 5 figures</comments><msc-class>65F10, 65F45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global and block Krylov subspace methods are efficient iterative solvers for
large sparse linear systems with multiple right-hand sides. However, global or
block Lanczos-type solvers often exhibit large oscillations in the residual
norms and may have a large residual gap relating to the loss of attainable
accuracy of the approximations. Conventional residual smoothing schemes
suppress the oscillations but do not aid in improving the attainable accuracy,
whereas a novel residual smoothing scheme enables the attainable accuracy for
single right-hand side Lanczos-type solvers to be improved. The underlying
concept of this scheme is that the primary and smoothed sequences of the
approximations and residuals influence one another, thereby avoiding the severe
propagation of rounding errors. In the present study, we extend this
cross-interactive residual smoothing to the case of solving linear systems with
multiple right-hand sides. The resulting smoothed methods can reduce the
residual gap with few additional costs compared to their original counterparts.
We demonstrate the effectiveness of the proposed approach through rounding
error analysis and numerical experiments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00285</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00285</id><submitter>Jiahui Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:38:34 GMT</date><size>501kb</size><source_type>D</source_type></version><title>Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning</title><authors>Jiahui Li, Kun Kuang, Baoxiang Wang, Furui Liu, Long Chen, Fei Wu and
  Jun Xiao</authors><categories>cs.AI cs.MA</categories><doi>10.1145/3447548.3467420</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Centralized Training with Decentralized Execution (CTDE) has been a popular
paradigm in cooperative Multi-Agent Reinforcement Learning (MARL) settings and
is widely used in many real applications. One of the major challenges in the
training process is credit assignment, which aims to deduce the contributions
of each agent according to the global rewards. Existing credit assignment
methods focus on either decomposing the joint value function into individual
value functions or measuring the impact of local observations and actions on
the global value function. These approaches lack a thorough consideration of
the complicated interactions among multiple agents, leading to an unsuitable
assignment of credit and subsequently mediocre results on MARL. We propose
Shapley Counterfactual Credit Assignment, a novel method for explicit credit
assignment which accounts for the coalition of agents. Specifically, Shapley
Value and its desired properties are leveraged in deep MARL to credit any
combinations of agents, which grants us the capability to estimate the
individual credit for each agent. Despite this capability, the main technical
difficulty lies in the computational complexity of Shapley Value who grows
factorially as the number of agents. We instead utilize an approximation method
via Monte Carlo sampling, which reduces the sample complexity while maintaining
its effectiveness. We evaluate our method on StarCraft II benchmarks across
different scenarios. Our method outperforms existing cooperative MARL
algorithms significantly and achieves the state-of-the-art, with especially
large margins on tasks with more severe difficulties.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00286</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00286</id><submitter>Andi Han</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:39:19 GMT</date><size>1411kb</size><source_type>D</source_type></version><title>On Riemannian Optimization over Positive Definite Matrices with the
  Bures-Wasserstein Geometry</title><authors>Andi Han, Bamdev Mishra, Pratik Jawanpuria, Junbin Gao</authors><categories>math.OC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we comparatively analyze the Bures-Wasserstein (BW) geometry
with the popular Affine-Invariant (AI) geometry for Riemannian optimization on
the symmetric positive definite (SPD) matrix manifold. Our study begins with an
observation that the BW metric has a linear dependence on SPD matrices in
contrast to the quadratic dependence of the AI metric. We build on this to show
that the BW metric is a more suitable and robust choice for several Riemannian
optimization problems over ill-conditioned SPD matrices. We show that the BW
geometry has a non-negative curvature, which further improves convergence rates
of algorithms over the non-positively curved AI geometry. Finally, we verify
that several popular cost functions, which are known to be geodesic convex
under the AI geometry, are also geodesic convex under the BW geometry.
Extensive experiments on various applications support our findings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00287</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00287</id><submitter>Michael Whitmeyer</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:39:26 GMT</date><size>54kb</size></version><title>Junta Distance Approximation with Sub-Exponential Queries</title><authors>Vishnu Iyer, Avishay Tal, Michael Whitmeyer</authors><categories>cs.DS cs.CC</categories><comments>To appear in CCC 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two
different results pertaining to the \emph{tolerant testing} of juntas. Given
black-box access to a Boolean function $f:\{\pm1\}^{n} \to \{\pm1\}$, we give a
$poly(k, \frac{1}{\varepsilon})$ query algorithm that distinguishes between
functions that are $\gamma$-close to $k$-juntas and $(\gamma+\varepsilon)$-far
from $k'$-juntas, where $k' = O(\frac{k}{\varepsilon^2})$.
  In the non-relaxed setting, we extend our ideas to give a
$2^{\tilde{O}(\sqrt{k/\varepsilon})}$ (adaptive) query algorithm that
distinguishes between functions that are $\gamma$-close to $k$-juntas and
$(\gamma+\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this
is the first subexponential-in-$k$ query algorithm for approximating the
distance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,
Levi, and Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required
exponentially many queries in $k$).
  Our techniques are Fourier analytical and make use of the notion of
&quot;normalized influences&quot; that was introduced by Talagrand [AoP, 1994].
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00289</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00289</id><submitter>Pranay Mathur</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:44:25 GMT</date><size>4335kb</size><source_type>D</source_type></version><title>Resource-aware Online Parameter Adaptation for
  Computationally-constrained Visual-Inertial Navigation Systems</title><authors>Pranay Mathur, Nikhil Khedekar, Kostas Alexis</authors><categories>cs.RO</categories><comments>6+1 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a computational resources-aware parameter adaptation method
for visual-inertial navigation systems is proposed with the goal of enabling
the improved deployment of such algorithms on computationally constrained
systems. Such a capacity can prove critical when employed on ultra-lightweight
systems or alongside mission critical computationally expensive processes. To
achieve this objective, the algorithm proposes selected changes in the vision
front-end and optimization back-end of visual-inertial odometry algorithms,
both prior to execution and in real-time based on an online profiling of
available resources. The method also utilizes information from the motion
dynamics experienced by the system to manipulate parameters online. The general
policy is demonstrated on three established algorithms, namely S-MSCKF,
VINS-Mono and OKVIS and has been verified experimentally on the EuRoC dataset.
The proposed approach achieved comparable performance at a fraction of the
original computational cost.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00291</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00291</id><submitter>Yinpei Dai</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:52:35 GMT</date><size>5795kb</size><source_type>D</source_type></version><title>Preview, Attend and Review: Schema-Aware Curriculum Learning for
  Multi-Domain Dialog State Tracking</title><authors>Yinpei Dai, Hangyu Li, Yongbin Li, Jian Sun, Fei Huang, Luo Si,
  Xiaodan Zhu</authors><categories>cs.CL</categories><comments>7 pages, 2 figures, accepted to ACL21</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Existing dialog state tracking (DST) models are trained with dialog data in a
random order, neglecting rich structural information in a dataset. In this
paper, we propose to use curriculum learning (CL) to better leverage both the
curriculum structure and schema structure for task-oriented dialogs.
Specifically, we propose a model-agnostic framework called Schema-aware
Curriculum Learning for Dialog State Tracking (SaCLog), which consists of a
preview module that pre-trains a DST model with schema information, a
curriculum module that optimizes the model with CL, and a review module that
augments mispredicted data to reinforce the CL training. We show that our
proposed approach improves DST performance over both a transformer-based and
RNN-based DST model (TripPy and TRADE) and achieves new state-of-the-art
results on WOZ2.0 and MultiWOZ2.1.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00293</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00293</id><submitter>Antonios Varvitsiotis</submitter><version version="v1"><date>Tue, 1 Jun 2021 07:55:09 GMT</date><size>1006kb</size><source_type>D</source_type></version><title>A Non-commutative Extension of Lee-Seung's Algorithm for Positive
  Semidefinite Factorizations</title><authors>Yong Sheng Soh, Antonios Varvitsiotis</authors><categories>math.OC cs.LG eess.SP stat.ML</categories><comments>Comments welcome</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Given a matrix $X\in \mathbb{R}_+^{m\times n}$ with nonnegative entries, a
Positive Semidefinite (PSD) factorization of $X$ is a collection of $r \times
r$-dimensional PSD matrices $\{A_i\}$ and $\{B_j\}$ satisfying $X_{ij}=
\mathrm{tr}(A_i B_j)$ for all $\ i\in [m],\ j\in [n]$. PSD factorizations are
fundamentally linked to understanding the expressiveness of semidefinite
programs as well as the power and limitations of quantum resources in
information theory. The PSD factorization task generalizes the Non-negative
Matrix Factorization (NMF) problem where we seek a collection of
$r$-dimensional nonnegative vectors $\{a_i\}$ and $\{b_j\}$ satisfying $X_{ij}=
a_i^\top b_j$, for all $i\in [m],\ j\in [n]$ -- one can recover the latter
problem by choosing matrices in the PSD factorization to be diagonal. The most
widely used algorithm for computing NMFs of a matrix is the Multiplicative
Update algorithm developed by Lee and Seung, in which nonnegativity of the
updates is preserved by scaling with positive diagonal matrices. In this paper,
we describe a non-commutative extension of Lee-Seung's algorithm, which we call
the Matrix Multiplicative Update (MMU) algorithm, for computing PSD
factorizations. The MMU algorithm ensures that updates remain PSD by congruence
scaling with the matrix geometric mean of appropriate PSD matrices, and it
retains the simplicity of implementation that Lee-Seung's algorithm enjoys.
Building on the Majorization-Minimization framework, we show that under our
update scheme the squared loss objective is non-increasing and fixed points
correspond to critical points. The analysis relies on Lieb's Concavity Theorem.
Beyond PSD factorizations, we use the MMU algorithm as a primitive to calculate
block-diagonal PSD factorizations and tensor PSD factorizations. We demonstrate
the utility of our method with experiments on real and synthetic data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00297</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00297</id><submitter>Guoming Tang</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:06:33 GMT</date><size>3944kb</size><source_type>D</source_type></version><title>More Behind Your Electricity Bill: a Dual-DNN Approach to Non-Intrusive
  Load Monitoring</title><authors>Yu Zhang, Guoming Tang, Qianyi Huang, Yi Wang, Hong Xu</authors><categories>cs.LG cs.AI</categories><comments>9 pages, 6 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Non-intrusive load monitoring (NILM) is a well-known single-channel blind
source separation problem that aims to decompose the household energy
consumption into itemised energy usage of individual appliances. In this way,
considerable energy savings could be achieved by enhancing household's
awareness of energy usage. Recent investigations have shown that deep neural
networks (DNNs) based approaches are promising for the NILM task. Nevertheless,
they normally ignore the inherent properties of appliance operations in the
network design, potentially leading to implausible results. We are thus
motivated to develop the dual Deep Neural Networks (dual-DNN), which aims to i)
take advantage of DNNs' learning capability of latent features and ii) empower
the DNN architecture with identification ability of universal properties.
Specifically in the design of dual-DNN, we adopt one subnetwork to measure
power ratings of different appliances' operation states, and the other
subnetwork to identify the running states of target appliances. The final
result is then obtained by multiplying these two network outputs and meanwhile
considering the multi-state property of household appliances. To enforce the
sparsity property in appliance's state operating, we employ median filtering
and hard gating mechanisms to the subnetwork for state identification. Compared
with the state-of-the-art NILM methods, our dual-DNN approach demonstrates a
21.67% performance improvement in average on two public benchmark datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00300</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00300</id><submitter>Ming-Chun Lee</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:13:39 GMT</date><size>174kb</size></version><title>Throughput-Outage Scaling Behaviors for Wireless Single-Hop D2D Caching
  Networks with Physical Model -- Analysis and Derivations</title><authors>Ming-Chun Lee and Andreas F. Molisch and Mingyue Ji</authors><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Throughput-Outage scaling laws for single-hop cache-aided device-to-device
(D2D) communications have been extensively investigated under the assumption of
the protocol model. However, the corresponding performance under physical
models has not been explored; in particular it remains unclear whether
link-level power control and scheduling can improve the asymptotic performance.
This paper thus investigates the throughput-outage scaling laws of cache-aided
single-hop D2D networks considering a general physical channel model. By
considering the networks with and without the equal-throughput assumption, we
analyze the corresponding outer bounds and provide the achievable performance
analysis. Results show that when the equal-throughput assumption is considered,
using link-level power control and scheduling cannot improve the scaling laws.
On the other hand, when the equal-throughput assumption is not considered, we
show that the proposed double time-slot framework with appropriate link-level
power control and scheduling can significantly improve the throughput-outage
scaling laws, where the fundamental concept is to first distinguish links
according to their communication distances, and then enhance the throughput for
links with small communication distances.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00302</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00302</id><submitter>Anastasios Nentidis</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:17:13 GMT</date><size>889kb</size><source_type>D</source_type></version><title>Harvesting the Public MeSH Note field</title><authors>Anastasios Nentidis, Anastasia Krithara, Grigorios Tsoumakas, Georgios
  Paliouras</authors><categories>cs.DL cs.IR</categories><comments>3 pages, 1 figure, 1 table. Technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this document, we report an analysis of the Public MeSH Note field of the
new descriptors introduced in the MeSH thesaurus between 2006 and 2020. The aim
of this analysis was to extract information about the previous status of these
new descriptors as Supplementary Concept Records. The Public MeSH Note field
contains information in semi-structured text, meant to be read by humans.
Therefore, we adopted a semi-automated approach, based on regular expressions,
to extract information from it. In the large majority of cases, we managed to
minimize the required manual effort for extracting the previous state of a new
descriptor as a Supplementary Concept Record. The source code for this analysis
is openly available on GitHub.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00305</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00305</id><submitter>Frank Ruis</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:24:09 GMT</date><size>313kb</size><source_type>D</source_type></version><title>Independent Prototype Propagation for Zero-Shot Compositionality</title><authors>Frank Ruis, Gertjan Burghours, Doina Bucur</authors><categories>cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Humans are good at compositional zero-shot reasoning; someone who has never
seen a zebra before could nevertheless recognize one when we tell them it looks
like a horse with black and white stripes. Machine learning systems, on the
other hand, usually leverage spurious correlations in the training data, and
while such correlations can help recognize objects in context, they hurt
generalization. To be able to deal with underspecified datasets while still
leveraging contextual clues during classification, we propose ProtoProp, a
novel prototype propagation graph method. First we learn prototypical
representations of objects (e.g., zebra) that are conditionally independent
w.r.t. their attribute labels (e.g., stripes) and vice versa. Next we propagate
the independent prototypes through a compositional graph, to learn
compositional prototypes of novel attribute-object combinations that reflect
the dependencies of the target distribution. The method does not rely on any
external data, such as class hierarchy graphs or pretrained word embeddings. We
evaluate our approach on AO-Clever, a synthetic and strongly visual dataset
with clean labels, and UT-Zappos, a noisy real-world dataset of fine-grained
shoe types. We show that in the generalized compositional zero-shot setting we
outperform state-of-the-art results, and through ablations we show the
importance of each part of the method and their contribution to the final
results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00306</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00306</id><submitter>Vasiliki Voukelatou</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:24:57 GMT</date><size>1016kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 14:17:03 GMT</date><size>1664kb</size><source_type>D</source_type></version><title>Understanding peacefulness through the world news</title><authors>Vasiliki Voukelatou, Ioanna Miliou, Fosca Giannotti, Luca Pappalardo</authors><categories>cs.AI</categories><comments>19 pages, 19 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Peacefulness is a principal dimension of well-being for all humankind and is
the way out of inequity and every single form of violence. Thus, its
measurement has lately drawn the attention of researchers and policy-makers.
During the last years, novel digital data streams have drastically changed the
research in this field. In the current study, we exploit information extracted
from Global Data on Events, Location, and Tone (GDELT) digital news database,
to capture peacefulness through the Global Peace Index (GPI). Applying
predictive machine learning models, we demonstrate that news media attention
from GDELT can be used as a proxy for measuring GPI at a monthly level.
Additionally, we use the SHAP methodology to obtain the most important
variables that drive the predictions. This analysis highlights each country's
profile and provides explanations for the predictions overall, and particularly
for the errors and the events that drive these errors. We believe that digital
data exploited by Social Good researchers, policy-makers, and peace-builders,
with data science tools as powerful as machine learning, could contribute to
maximize the societal benefits and minimize the risks to peacefulness.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00308</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00308</id><submitter>Jonathan Scarlett</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:30:53 GMT</date><size>255kb</size><source_type>D</source_type></version><title>Fast Splitting Algorithms for Sparsity-Constrained and Noisy Group
  Testing</title><authors>Eric Price and Jonathan Scarlett and Nelvin Tan</authors><categories>cs.IT cs.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In group testing, the goal is to identify a subset of defective items within
a larger set of items based on tests whose outcomes indicate whether at least
one defective item is present. This problem is relevant in areas such as
medical testing, DNA sequencing, communication protocols, and many more. In
this paper, we study (i) a sparsity-constrained version of the problem, in
which the testing procedure is subjected to one of the following two
constraints: items are finitely divisible and thus may participate in at most
$\gamma$ tests; or tests are size-constrained to pool no more than $\rho$ items
per test; and (ii) a noisy version of the problem, where each test outcome is
independently flipped with some constant probability. Under each of these
settings, considering the for-each recovery guarantee with asymptotically
vanishing error probability, we introduce a fast splitting algorithm and
establish its near-optimality not only in terms of the number of tests, but
also in terms of the decoding time. While the most basic formulations of our
algorithms require $\Omega(n)$ storage for each algorithm, we also provide
low-storage variants based on hashing, with similar recovery guarantees.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00309</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00309</id><submitter>Rasmus Ulfsnes</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:32:12 GMT</date><size>342kb</size></version><title>Innovation in Large-scale agile -- Benefits and Challenges of Hackathons
  when Hacking from Home</title><authors>Rasmus Ulfsnes, Viktoria Stray, Nils Brede Moe, Darja \v{S}mite</authors><categories>cs.SE</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Hackathons are events in which diverse teams work together to explore, and
develop solutions, software or even ideas. Hackathons have been recognized not
only as public events for hacking, but also as a corporate mechanism for
innovation. Hackathons are a way for established companies to achieve increased
employee wellbeing as well as being a curator for innovation and developing new
products. Sudden transition to the work-from-home mode caused by the COVID-19
pandemic first put many corporate events requiring collocation, such as
hackathons, temporarily on hold and then motivated companies to find ways to
hold these events virtually. In this paper, we report our findings from
investigating hackathons in the context of a large agile company by first
exploring the general benefits and challenges of hackathons and then trying to
understand how they were affected by the virtual setup. We conducted nine
interviews, surveyed 23 employees and analyzed a hackathon demo. We found that
hackathons provide both individual and organizational benefits of innovation,
personal interests, and acquiring new skills and competences. Several
challenges such as added stress due to stopping the regular work, employees
fearing not having enough contribution to deliver and potential mismatch
between individual and organizational goals were also found. With respect to
the virtual setup, we found that virtual hackathons are not diminishing the
innovation benefits, however, some negative effect surfaced on the social and
networking side.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00311</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00311</id><submitter>Marine Le Morvan</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:40:30 GMT</date><size>922kb</size><source_type>D</source_type></version><title>What's a good imputation to predict with missing values?</title><authors>Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CRISAM), Erwan
  Scornet (CMAP), Ga\&quot;el Varoquaux (PARIETAL)</authors><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How to learn a good predictor on data with missing values? Most efforts focus
on first imputing as well as possible and second learning on the completed data
to predict the outcome. Yet, this widespread practice has no theoretical
grounding. Here we show that for almost all imputation functions, an
impute-then-regress procedure with a powerful learner is Bayes optimal. This
result holds for all missing-values mechanisms, in contrast with the classic
statistical results that require missing-at-random settings to use imputation
in probabilistic modeling. Moreover, it implies that perfect conditional
imputation may not be needed for good prediction asymptotically. In fact, we
show that on perfectly imputed data the best regression function will generally
be discontinuous, which makes it hard to learn. Crafting instead the imputation
so as to leave the regression function unchanged simply shifts the problem to
learning discontinuous imputations. Rather, we suggest that it is easier to
learn imputation and regression jointly. We propose such a procedure, adapting
NeuMiss, a neural network capturing the conditional links across observed and
unobserved variables whatever the missing-value pattern. Experiments confirm
that joint imputation and regression through NeuMiss is better than various two
step procedures in our experiments with finite number of samples.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00313</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00313</id><submitter>Julien Dular</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:43:25 GMT</date><size>1060kb</size><source_type>D</source_type></version><title>On the Stability of Mixed Finite-Element Formulations for
  High-Temperature Superconductors</title><authors>Julien Dular, Mane Harutyunyan, Lorenzo Bortot, Sebastian Schoeps,
  Benoit Vanderheyden and Christophe Geuzaine</authors><categories>math.NA cs.CE cs.NA physics.acc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present and analyze the numerical stability of two coupled
finite element formulations. The first one is the h-a-formulation and is well
suited for modeling systems with superconductors and ferromagnetic materials.
The second one, the so-called t-a-formulation with thin-shell approximation,
applies for systems with thin superconducting domains. Both formulations
involve two coupled unknown fields and are mixed on the coupling interfaces.
Function spaces in mixed formulations must satisfy compatibility conditions to
ensure stability of the problem and reliability of the numerical solution. We
propose stable choices of function spaces using hierarchical basis functions
and demonstrate the effectiveness of the approach on simple 2D examples.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00314</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00314</id><submitter>Wei Guo</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:43:31 GMT</date><size>151kb</size><source_type>D</source_type></version><title>Dual Graph enhanced Embedding Neural Network for CTRPrediction</title><authors>Wei Guo, Rong Su, Renhao Tan, Huifeng Guo, Yingxue Zhang, Zhirong Liu,
  Ruiming Tang, Xiuqiang He</authors><categories>cs.IR</categories><comments>KDD 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  CTR prediction, which aims to estimate the probability that a user will click
an item, plays a crucial role in online advertising and recommender system.
Feature interaction modeling based and user interest mining based methods are
the two kinds of most popular techniques that have been extensively explored
for many years and have made great progress for CTR prediction. However, (1)
feature interaction based methods which rely heavily on the co-occurrence of
different features, may suffer from the feature sparsity problem (i.e., many
features appear few times); (2) user interest mining based methods which need
rich user behaviors to obtain user's diverse interests, are easy to encounter
the behavior sparsity problem (i.e., many users have very short behavior
sequences). To solve these problems, we propose a novel module named Dual Graph
enhanced Embedding, which is compatible with various CTR prediction models to
alleviate these two problems. We further propose a Dual Graph enhanced
Embedding Neural Network (DG-ENN) for CTR prediction. Dual Graph enhanced
Embedding exploits the strengths of graph representation with two carefully
designed learning strategies (divide-and-conquer, curriculum-learning-inspired
organized learning) to refine the embedding. We conduct comprehensive
experiments on three real-world industrial datasets. The experimental results
show that our proposed DG-ENN significantly outperforms state-of-the-art CTR
prediction models. Moreover, when applying to state-of-the-art CTR prediction
models, Dual graph enhanced embedding always obtains better performance.
Further case studies prove that our proposed dual graph enhanced embedding
could alleviate the feature sparsity and behavior sparsity problems. Our
framework will be open-source based on MindSpore in the near future.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00315</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00315</id><submitter>Davide Martincigh</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:43:53 GMT</date><size>45kb</size></version><version version="v2"><date>Thu, 3 Jun 2021 13:53:56 GMT</date><size>45kb</size></version><title>Ordering regular languages: a danger zone</title><authors>Giovanna D'Agostino and Davide Martincigh and Alberto Policriti</authors><categories>cs.FL</categories><comments>23 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Ordering the collection of states of a given automaton starting from an order
of the underlying alphabet is a natural move towards a computational treatment
of the language accepted by the automaton. Along this path, Wheeler
\emph{graphs} have been recently introduced as an extension/adaptation of the
Burrows-Wheeler Transform (the now famous BWT, originally defined on strings)
to graphs. These graphs constitute an important data-structure for languages,
since they allow a very efficient storage mechanism for the transition function
of an automaton, while providing a fast support to all sorts of substring
queries. This is possible as a consequence of a property -- the so-called
\emph{path coherence} -- valid on Wheeler graphs and consisting in an ordering
on nodes that &quot;propagates&quot; to (collections of) strings. By looking at a Wheeler
graph as an automaton, the ordering on strings corresponds to the
co-lexicographic order of the words entering each state. This leads naturally
to consider the class of regular languages accepted by Wheeler automata, i.e.
the Wheeler languages.
  It has been shown that, as opposed to the general case, the classic
determinization by powerset construction is polynomial on Wheeler languages. As
a consequence, most of the classical problems turn out to be &quot;easy&quot; -- that is,
solvable in polynomial time -- on Wheeler languages. Moreover, deciding whether
a DFA is Wheeler and deciding whether a DFA accepts a Wheeler language is
polynomial.
  Our contribution here is to put an upper bound to easy problems. For
instance, whenever we generalize by switching to general NFAs or by not fixing
an order of the underlying alphabet, the above mentioned problems become &quot;hard&quot;
-- that is NP-complete or even PSPACE-complete.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00316</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00316</id><submitter>Zhenghao Wu</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:45:41 GMT</date><size>1739kb</size><source_type>D</source_type></version><title>LenAtten: An Effective Length Controlling Unit For Text Summarization</title><authors>Zhongyi Yu, Zhenghao Wu, Hao Zheng, Zhe XuanYuan, Jefferson Fong,
  Weifeng Su</authors><categories>cs.CL</categories><comments>8 pages, accepted at Findings of ACL 2021 (short)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fixed length summarization aims at generating summaries with a preset number
of words or characters. Most recent researches incorporate length information
with word embeddings as the input to the recurrent decoding unit, causing a
compromise between length controllability and summary quality. In this work, we
present an effective length controlling unit Length Attention (LenAtten) to
break this trade-off. Experimental results show that LenAtten not only brings
improvements in length controllability and ROGUE scores but also has great
generalization ability. In the task of generating a summary with the target
length, our model is 732 times better than the best-performing length
controllable summarizer in length controllability on the CNN/Daily Mail
dataset.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00317</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00317</id><submitter>Anna Willmann</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:46:04 GMT</date><size>4110kb</size><source_type>D</source_type></version><title>Data-Driven Shadowgraph Simulation of a 3D Object</title><authors>Anna Willmann, Patrick Stiller, Alexander Debus, Arie Irman, Richard
  Pausch, Yen-Yu Chang, Michael Bussmann, Nico Hoffmann</authors><categories>cs.LG</categories><comments>9 pages, 9 figures. Published as a workshop paper at ICLR 2021 SimDL
  Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose a deep neural network based surrogate model for a
plasma shadowgraph - a technique for visualization of perturbations in a
transparent medium. We are substituting the numerical code by a computationally
cheaper projection based surrogate model that is able to approximate the
electric fields at a given time without computing all preceding electric fields
as required by numerical methods. This means that the projection based
surrogate model allows to recover the solution of the governing 3D partial
differential equation, 3D wave equation, at any point of a given compute domain
and configuration without the need to run a full simulation. This model has
shown a good quality of reconstruction in a problem of interpolation of data
within a narrow range of simulation parameters and can be used for input data
of large size.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00318</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00318</id><submitter>Julia Guerrero-Viu</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:48:38 GMT</date><size>2605kb</size><source_type>D</source_type></version><title>Semi-Supervised Disparity Estimation with Deep Feature Reconstruction</title><authors>Julia Guerrero-Viu, Sergio Izquierdo, Philipp Schr\&quot;oppel and Thomas
  Brox</authors><categories>cs.CV</categories><comments>Women in Computer Vision workshop CVPR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the success of deep learning in disparity estimation, the domain
generalization gap remains an issue. We propose a semi-supervised pipeline that
successfully adapts DispNet to a real-world domain by joint supervised training
on labeled synthetic data and self-supervised training on unlabeled real data.
Furthermore, accounting for the limitations of the widely-used photometric
loss, we analyze the impact of deep feature reconstruction as a promising
supervisory signal for disparity estimation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00319</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00319</id><submitter>Matteo Castiglioni</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:49:02 GMT</date><size>35kb</size></version><title>Bayesian Agency: Linear versus Tractable Contracts</title><authors>Matteo Castiglioni, Alberto Marchesi, Nicola Gatti</authors><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study principal-agent problems in which a principal commits to an
outcome-dependent payment scheme (a.k.a. contract) so as to induce an agent to
take a costly, unobservable action. We relax the assumption that the principal
perfectly knows the agent by considering a Bayesian setting where the agent's
type is unknown and randomly selected according to a given probability
distribution, which is known to the principal. Each agent's type is
characterized by her own action costs and action-outcome distributions. In the
literature on non-Bayesian principal-agent problems, considerable attention has
been devoted to linear contracts, which are simple, pure-commission payment
schemes that still provide nice approximation guarantees with respect to
principal-optimal (possibly non-linear) contracts. While in non-Bayesian
settings an optimal contract can be computed efficiently, this is no longer the
case for our Bayesian principal-agent problems. This further motivates our
focus on linear contracts, which can be optimized efficiently given their
single-parameter nature. Our goal is to analyze the properties of linear
contracts in Bayesian settings, in terms of approximation guarantees with
respect to optimal contracts and general tractable contracts (i.e.,
efficiently-computable ones). First, we study the approximation guarantees of
linear contracts with respect to optimal ones, showing that the former suffer
from a multiplicative loss linear in the number of agent's types. Nevertheless,
we prove that linear contracts can still provide a constant multiplicative
approximation $\rho$ of the optimal principal's expected utility, though at the
expense of an exponentially-small additive loss $2^{-\Omega(\rho)}$. Then, we
switch to tractable contracts, showing that, surprisingly, linear contracts
perform well among them.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00320</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00320</id><submitter>Yongfeng Huang</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:49:32 GMT</date><size>255kb</size><source_type>D</source_type></version><title>Distribution Matching for Rationalization</title><authors>Yongfeng Huang, Yujun Chen, Yulun Du, Zhilin Yang</authors><categories>cs.CL</categories><comments>Accepted by AAAI2021</comments><journal-ref>AAAI 2021</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of rationalization aims to extract pieces of input text as
rationales to justify neural network predictions on text classification tasks.
By definition, rationales represent key text pieces used for prediction and
thus should have similar classification feature distribution compared to the
original input text. However, previous methods mainly focused on maximizing the
mutual information between rationales and labels while neglecting the
relationship between rationales and input text. To address this issue, we
propose a novel rationalization method that matches the distributions of
rationales and input text in both the feature space and output space.
Empirically, the proposed distribution matching approach consistently
outperforms previous methods by a large margin. Our data and code are
available.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00321</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00321</id><submitter>Felix Thiel</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:50:46 GMT</date><size>66kb</size></version><title>A Way to a Universal VR Accessibility Toolkit</title><authors>Felix J. Thiel, Anthony Steed</authors><categories>cs.CY</categories><comments>This work was presented at the ACM CHI 2021 Workshop on Design and
  Creation of Inclusive User Interactions Through Immersive Media.
  https://sites.google.com/view/acm-chi-iicw21/home</comments><acm-class>K.4.2; H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual Reality (VR) has become more and more popular with dropping prices
for systems and a growing number of users. However, the issue of accessibility
in VR has been hardly addressed so far and no uniform approach or standard
exists at this time. In this position paper, we propose a customisable toolkit
implemented at the system-level and discuss the potential benefits of this
approach and challenges that will need to be overcome for a successful
implementation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00322</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00322</id><submitter>Bahar Taskesen</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:51:55 GMT</date><size>1041kb</size><source_type>D</source_type></version><title>Sequential Domain Adaptation by Synthesizing Distributionally Robust
  Experts</title><authors>Bahar Taskesen, Man-Chung Yue, Jose Blanchet, Daniel Kuhn, Viet Anh
  Nguyen</authors><categories>cs.LG math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Least squares estimators, when trained on a few target domain samples, may
predict poorly. Supervised domain adaptation aims to improve the predictive
accuracy by exploiting additional labeled training samples from a source
distribution that is close to the target distribution. Given available data, we
investigate novel strategies to synthesize a family of least squares estimator
experts that are robust with regard to moment conditions. When these moment
conditions are specified using Kullback-Leibler or Wasserstein-type
divergences, we can find the robust estimators efficiently using convex
optimization. We use the Bernstein online aggregation algorithm on the proposed
family of robust experts to generate predictions for the sequential stream of
target test samples. Numerical experiments on real data show that the robust
strategies may outperform non-robust interpolations of the empirical least
squares estimators.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00323</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00323</id><submitter>Chundong Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 08:53:08 GMT</date><size>2219kb</size><source_type>D</source_type></version><title>Boosting the Search Performance of B+-tree for Non-volatile Memory with
  Sentinels</title><authors>Chongnan Ye and Chundong Wang</authors><categories>cs.DS</categories><comments>Accepted and Presented at MSC 2020 (@ESWeek 2020)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The next-generation non-volatile memory (NVM) is striding into computer
systems as a new tier as it incorporates both DRAM's byte-addressability and
disk's persistency. Researchers and practitioners have considered building
persistent memory by placing NVM on the memory bus for CPU to directly load and
store data. As a result, cache-friendly data structures have been developed for
NVM. One of them is the prevalent B+-tree. State-of-the-art in-NVM B+-trees
mainly focus on the optimization of write operations (insertion and deletion).
However, search is of vital importance for B+-tree. Not only search-intensive
workloads benefit from an optimized search, but insertion and deletion also
rely on a preceding search operation to proceed. In this paper, we attentively
study a sorted B+-tree node that spans over contiguous cache lines. Such cache
lines exhibit a monotonically increasing trend and searching a target key
across them can be accelerated by estimating a range the key falls into. To do
so, we construct a probing Sentinel Array in which a sentinel stands for each
cache line of B+-tree node. Checking the Sentinel Array avoids scanning
unnecessary cache lines and hence significantly reduces cache misses for a
search. A quantitative evaluation shows that using Sentinel Arrays boosts the
search performance of state-of-the-art in-NVM B+-trees by up to 48.4% while the
cost of maintaining of Sentinel Array is low.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00326</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00326</id><submitter>Kimon Kieslich</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:01:14 GMT</date><size>304kb</size><source_type>D</source_type></version><title>AI-Ethics by Design. Evaluating Public Perception on the Importance of
  Ethical Design Principles of AI</title><authors>Kimon Kieslich, Birte Keller, Christopher Starke</authors><categories>cs.CY cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the immense societal importance of ethically designing artificial
intelligence (AI), little research on the public perceptions of ethical AI
principles exists. This becomes even more striking when considering that
ethical AI development has the aim to be human-centric and of benefit for the
whole society. In this study, we investigate how ethical principles
(explainability, fairness, security, accountability, accuracy, privacy, machine
autonomy) are weighted in comparison to each other. This is especially
important, since simultaneously considering ethical principles is not only
costly, but sometimes even impossible, as developers must make specific
trade-off decisions. In this paper, we give first answers on the relative
importance of ethical principles given a specific use case - the use of AI in
tax fraud detection. The results of a large conjoint survey (n=1099) suggest
that, by and large, German respondents found the ethical principles equally
important. However, subsequent cluster analysis shows that different preference
models for ethically designed systems exist among the German population. These
clusters substantially differ not only in the preferred attributes, but also in
the importance level of the attributes themselves. We further describe how
these groups are constituted in terms of sociodemographics as well as opinions
on AI. Societal implications as well as design challenges are discussed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00327</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00327</id><submitter>Zixuan Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:01:22 GMT</date><size>744kb</size><source_type>D</source_type></version><title>Search from History and Reason for Future: Two-stage Reasoning on
  Temporal Knowledge Graphs</title><authors>Zixuan Li, Xiaolong Jin, Saiping Guan, Wei Li, Jiafeng Guo, Yuanzhuo
  Wang and Xueqi Cheng</authors><categories>cs.AI</categories><comments>ACL 2021 long paper (main conference)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal Knowledge Graphs (TKGs) have been developed and used in many
different areas. Reasoning on TKGs that predicts potential facts (events) in
the future brings great challenges to existing models. When facing a prediction
task, human beings usually search useful historical information (i.e., clues)
in their memories and then reason for future meticulously. Inspired by this
mechanism, we propose CluSTeR to predict future facts in a two-stage manner,
Clue Searching and Temporal Reasoning, accordingly. Specifically, at the clue
searching stage, CluSTeR learns a beam search policy via reinforcement learning
(RL) to induce multiple clues from historical facts. At the temporal reasoning
stage, it adopts a graph convolution network based sequence method to deduce
answers from clues. Experiments on four datasets demonstrate the substantial
advantages of CluSTeR compared with the state-of-the-art methods. Moreover, the
clues found by CluSTeR further provide interpretability for the results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00328</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00328</id><submitter>Yuichi Ikeda</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:02:03 GMT</date><size>3350kb</size><source_type>D</source_type></version><title>Optimizing travel routes using temporal networks constructed from GPS
  data</title><authors>Tatsuro Mukai, Yuichi Ikeda</authors><categories>cs.SI physics.soc-ph</categories><comments>10 pages, 7 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because of the complexity of urban transportation networks and the temporal
changes in traffic conditions, it is difficult to assess real-time traffic
situations. However, the development of information terminals has made it
easier to obtain personal mobility information. In this study, we propose
methods for evaluating the mobility of people in a city using global
positioning system data. There are two main methods for evaluating movement.
One is to create a temporal network from real data and check the change in
travel time according to time zones or seasons. Temporal networks are difficult
to evaluate because of their time complexity, and in this study, we proposed an
evaluation method using the probability density function of travel time. The
other method is to define a time-dependent traveling salesman problem and find
an efficient traveling route by finding the shortest path. By creating a
time-dependent traveling salesman problem in an existing city and solving it, a
traveler can choose an efficient route by considering traffic conditions at
different times of the day. We used 2 months of data from Kyoto City to conduct
a traffic evaluation as a case study.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00329</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00329</id><submitter>Zihao Yan</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:03:21 GMT</date><size>41843kb</size><source_type>D</source_type></version><title>Consistent Two-Flow Network for Tele-Registration of Point Clouds</title><authors>Zihao Yan, Zimu Yi, Ruizhen Hu, Niloy J. Mitra, Daniel Cohen-Or, Hui
  Huang</authors><categories>cs.CV</categories><comments>Accepted to TVCG 2021, project page at
  https://vcc.tech/research/2021/CTFNet</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rigid registration of partial observations is a fundamental problem in
various applied fields. In computer graphics, special attention has been given
to the registration between two partial point clouds generated by scanning
devices. State-of-the-art registration techniques still struggle when the
overlap region between the two point clouds is small, and completely fail if
there is no overlap between the scan pairs. In this paper, we present a
learning-based technique that alleviates this problem, and allows registration
between point clouds, presented in arbitrary poses, and having little or even
no overlap, a setting that has been referred to as tele-registration. Our
technique is based on a novel neural network design that learns a prior of a
class of shapes and can complete a partial shape. The key idea is combining the
registration and completion tasks in a way that reinforces each other. In
particular, we simultaneously train the registration network and completion
network using two coupled flows, one that register-and-complete, and one that
complete-and-register, and encourage the two flows to produce a consistent
result. We show that, compared with each separate flow, this two-flow training
leads to robust and reliable tele-registration, and hence to a better point
cloud prediction that completes the registered scans. It is also worth
mentioning that each of the components in our neural network outperforms
state-of-the-art methods in both completion and registration. We further
analyze our network with several ablation studies and demonstrate its
performance on a large number of partial point clouds, both synthetic and
real-world, that have only small or no overlap.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00334</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00334</id><submitter>Chen Gong</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:09:51 GMT</date><size>5523kb</size></version><title>An In-depth Study on Internal Structure of Chinese Words</title><authors>Chen Gong, Saihao Huang, Houquan Zhou, Zhenghua Li, Min Zhang, Zhefeng
  Wang, Baoxing Huai, Nicholas Jing Yuan</authors><categories>cs.CL</categories><comments>Accepted by ACL-IJCNLP 2021 (long paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike English letters, Chinese characters have rich and specific meanings.
Usually, the meaning of a word can be derived from its constituent characters
in some way. Several previous works on syntactic parsing propose to annotate
shallow word-internal structures for better utilizing character-level
information. This work proposes to model the deep internal structures of
Chinese words as dependency trees with 11 labels for distinguishing syntactic
relationships. First, based on newly compiled annotation guidelines, we
manually annotate a word-internal structure treebank (WIST) consisting of over
30K multi-char words from Chinese Penn Treebank. To guarantee quality, each
word is independently annotated by two annotators and inconsistencies are
handled by a third senior annotator. Second, we present detailed and
interesting analysis on WIST to reveal insights on Chinese word formation.
Third, we propose word-internal structure parsing as a new task, and conduct
benchmark experiments using a competitive dependency parser. Finally, we
present two simple ways to encode word-internal structures, leading to
promising gains on the sentence-level syntactic parsing task.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00339</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00339</id><submitter>Zhenhao Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:19:43 GMT</date><size>2162kb</size><source_type>D</source_type></version><title>Studying Duplicate Logging Statements and Their Relationships with Code
  Clones</title><authors>Zhenhao Li, Tse-Hsun (Peter) Chen, Jinqiu Yang, Weiyi Shang</authors><categories>cs.SE</categories><comments>Accepted at IEEE Transactions on Software Engineering</comments><doi>10.1109/TSE.2021.3060918</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on studying duplicate logging statements, which are
logging statements that have the same static text message. We manually studied
over 4K duplicate logging statements and their surrounding code in five
large-scale open source systems. We uncovered five patterns of duplicate
logging code smells. For each instance of the duplicate logging code smell, we
further manually identify the potentially problematic and justifiable cases.
Then, we contact developers to verify our manual study result. We integrated
our manual study result and the feedback of developers into our automated
static analysis tool, DLFinder, which automatically detects problematic
duplicate logging code smells. We evaluated DLFinder on the five manually
studied systems and three additional systems. In total, combining the results
of DLFinder and our manual analysis, we reported 91 problematic duplicate
logging code smell instances to developers and all of them have been fixed. We
further study the relationship between duplicate logging statements, including
the problematic instances of duplicate logging code smells, and code clones. We
find that 83% of the duplicate logging code smell instances reside in cloned
code, but 17% of them reside in micro-clones that are difficult to detect using
automated clone detection tools. We also find that more than half of the
duplicate logging statements reside in cloned code snippets, and a large
portion of them reside in very short code blocks which may not be effectively
detected by existing code clone detection tools. Our study shows that, in
addition to general source code that implements the business logic, code clones
may also result in bad logging practices that could increase maintenance
difficulties.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00343</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00343</id><submitter>Rick Fritschek</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:30:15 GMT</date><size>65kb</size><source_type>D</source_type></version><title>Reinforce Security: A Model-Free Approach Towards Secure Wiretap Coding</title><authors>Rick Fritschek, Rafael F. Schaefer, Gerhard Wunder</authors><categories>cs.IT cs.LG math.IT</categories><comments>Accepted for ICC 2021, 6 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The use of deep learning-based techniques for approximating secure encoding
functions has attracted considerable interest in wireless communications due to
impressive results obtained for general coding and decoding tasks for wireless
communication systems. Of particular importance is the development of
model-free techniques that work without knowledge about the underlying channel.
Such techniques utilize for example generative adversarial networks to estimate
and model the conditional channel distribution, mutual information estimation
as a reward function, or reinforcement learning. In this paper, the approach of
reinforcement learning is studied and, in particular, the policy gradient
method for a model-free approach of neural network-based secure encoding is
investigated. Previously developed techniques for enforcing a certain co-set
structure on the encoding process can be combined with recent reinforcement
learning approaches. This new approach is evaluated by extensive simulations,
and it is demonstrated that the resulting decoding performance of an
eavesdropper is capped at a certain error level.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00344</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00344</id><submitter>Manuel Bravo</submitter><version version="v1"><date>Tue, 1 Jun 2021 09:30:23 GMT</date><size>141kb</size><source_type>D</source_type></version><title>UniStore: A fault-tolerant marriage of causal and strong consistency
  (extended version)</title><authors>Manuel Bravo, Alexey Gotsman, Borja de R\'egil, Hengfeng Wei</authors><categories>cs.DC</categories><comments>Extended version of a paper from USENIX ATC'21: Annual Technical
  Conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Modern online services rely on data stores that replicate their data across
geographically distributed data centers. Providing strong consistency in such
data stores results in high latencies and makes the system vulnerable to
network partitions. The alternative of relaxing consistency violates crucial
correctness properties. A compromise is to allow multiple consistency levels to
coexist in the data store. In this paper we present UniStore, the first
fault-tolerant and scalable data store that combines causal and strong
consistency. The key challenge we address in UniStore is to maintain liveness
despite data center failures: this could be compromised if a strong transaction
takes a dependency on a causal transaction that is later lost because of a
failure. UniStore ensures that such situations do not arise while paying the
cost of durability for causal transactions only when necessary. We evaluate
UniStore on Amazon EC2 using both microbenchmarks and a sample application. Our
results show that UniStore effectively and scalably combines causal and strong
consistency.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00352</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00352</id><submitter>Mark Anderson</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:00:46 GMT</date><size>1073kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 07:18:18 GMT</date><size>1073kb</size><source_type>D</source_type></version><title>Replicating and Extending &quot;Because Their Treebanks Leak&quot;: Graph
  Isomorphism, Covariants, and Parser Performance</title><authors>Mark Anderson and Anders S{\o}gaard and Carlos G\'omez Rodr\'iguez</authors><categories>cs.CL cs.AI</categories><comments>To appear in the Proceedings of the 59th Annual Meeting of the
  Association for Computational Linguistics</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  S{\o}gaard (2020) obtained results suggesting the fraction of trees occurring
in the test data isomorphic to trees in the training set accounts for a
non-trivial variation in parser performance. Similar to other statistical
analyses in NLP, the results were based on evaluating linear regressions.
However, the study had methodological issues and was undertaken using a small
sample size leading to unreliable results. We present a replication study in
which we also bin sentences by length and find that only a small subset of
sentences vary in performance with respect to graph isomorphism. Further, the
correlation observed between parser performance and graph isomorphism in the
wild disappears when controlling for covariants. However, in a controlled
experiment, where covariants are kept fixed, we do observe a strong
correlation. We suggest that conclusions drawn from statistical analyses like
this need to be tempered and that controlled experiments can complement them by
more readily teasing factors apart.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00354</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00354</id><submitter>Manuel Aprile</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:02:02 GMT</date><size>33kb</size></version><title>Binary extended formulations and sequential convexification</title><authors>Manuel Aprile, Michele Conforti, Marco Di Summa</authors><categories>math.OC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binarization of a bounded variable $x$ is a linear formulation with
variables $x$ and additional binary variables $y_1,\dots, y_k$, so that
integrality of $x$ is implied by the integrality of $y_1,\dots, y_k$. A binary
extended formulation of a polyhedron $P$ is obtained by adding to the original
description of $P$ binarizations of some of its variables. In the context of
mixed-integer programming, imposing integrality on 0/1 variables rather than on
general integer variables has interesting convergence properties and has been
studied both from the theoretical and from the practical point of view.
  We propose a notion of \emph{natural} binarizations and binary extended
formulations, encompassing all the ones studied in the literature. We give a
simple characterization of the vertices of such formulations, which allows us
to study their behavior with respect to sequential convexification. %0/1
disjunctions. In particular, given a binary extended formulation and % a
binarization $B$ of one of its variables $x$, we study a parameter that
measures the progress made towards ensuring the integrality of $x$ via
application of sequential convexification. We formulate this parameter, which
we call rank, as the solution of a set covering problem and express it exactly
for the classical binarizations from the literature.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00355</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00355</id><submitter>Justin Jacob</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:03:59 GMT</date><size>491kb</size><source_type>D</source_type></version><title>Refined Transformation Approach for Stabilization of MIMO System by Pole
  Placement</title><authors>Justin Jacob, Sreya Das and Navin Khaneja</authors><categories>eess.SY cs.SY</categories><comments>12 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The paper presents a distinctive and straightforward technique for
stabilization of multi-variable systems. The idea is to decouple the system
state matrix depending on different inputs and outputs. Refined special
canonical transformations are described for the design of controller and
observer for a single-input and single-output (SISO) case and are extended to
multi-input multi-output (MIMO) systems. These transformations help in the
stabilization of the error dynamics of the observer and in placing the closed
loop poles of the system. The idea is not only in the transformations taken but
also how the gain matrices are selected which simplifies the computation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00356</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00356</id><submitter>Joel Persson</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:05:02 GMT</date><size>5851kb</size><source_type>D</source_type></version><title>Predicting COVID-19 Spread from Large-Scale Mobility Data</title><authors>Amray Schwabe, Joel Persson and Stefan Feuerriegel</authors><categories>stat.AP cs.CY</categories><comments>9 pages, 3 figures. Accepted for publication in KDD '21: 27th ACM
  SIGKDD Conference on Knowledge Discovery and Data Mining</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To manage the COVID-19 epidemic effectively, decision-makers in public health
need accurate forecasts of case numbers. A potential near real-time predictor
of future case numbers is human mobility; however, research on the predictive
power of mobility is lacking. To fill this gap, we introduce a novel model for
epidemic forecasting based on mobility data, called mobility marked Hawkes
model. The proposed model consists of three components: (1) A Hawkes process
captures the transmission dynamics of infectious diseases. (2) A mark modulates
the rate of infections, thus accounting for how the reproduction number R
varies across space and time. The mark is modeled using a regularized Poisson
regression based on mobility covariates. (3) A correction procedure
incorporates new cases seeded by people traveling between regions. Our model
was evaluated on the COVID-19 epidemic in Switzerland. Specifically, we used
mobility data from February through April 2020, amounting to approximately 1.5
billion trips. Trip counts were derived from large-scale telecommunication
data, i.e., cell phone pings from the Swisscom network, the largest
telecommunication provider in Switzerland. We compared our model against
various state-of-the-art baselines in terms of out-of-sample root mean squared
error. We found that our model outperformed the baselines by 15.52%. The
improvement was consistently achieved across different forecast horizons
between 5 and 21 days. In addition, we assessed the predictive power of
conventional point of interest data, confirming that telecommunication data is
superior. To the best of our knowledge, our work is the first to predict the
spread of COVID-19 from telecommunication data. Altogether, our work
contributes to previous research by developing a scalable early warning system
for decision-makers in public health tasked with controlling the spread of
infectious diseases.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00357</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00357</id><submitter>Markus Sinnl</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:06:31 GMT</date><size>105kb</size><source_type>D</source_type></version><title>Experiments with graph convolutional networks for solving the vertex
  $p$-center problem</title><authors>Elisabeth Gaar and Markus Sinnl</authors><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the last few years, graph convolutional networks (GCN) have become a
popular research direction in the machine learning community to tackle NP-hard
combinatorial optimization problems (COPs) defined on graphs. While the
obtained results are usually still not competitive with problem-specific
solution approaches from the operations research community, GCNs often lead to
improvements compared to previous machine learning approaches for classical
COPs such as the traveling salesperson problem (TSP).
  In this work we present a preliminary study on using GCNs for solving the
vertex p-center problem (PCP), which is another classic COP on graphs. In
particular, we investigate whether a successful model based on end-to-end
training for the TSP can be adapted to a PCP, which is defined on a similar 2D
Euclidean graph input as the usually used version of the TSP. However, the
objective of the PCP has a min-max structure which could lead to many symmetric
optimal, i.e., ground-truth solutions and other potential difficulties for
learning. Our obtained preliminary results show that indeed a direct transfer
of network architecture ideas does not seem to work too well. Thus we think
that the PCP could be an interesting benchmark problem for new ideas and
developments in the area of GCNs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00358</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00358</id><submitter>Nicola Messina</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:11:46 GMT</date><size>598kb</size><source_type>D</source_type></version><title>Towards Efficient Cross-Modal Visual Textual Retrieval using
  Transformer-Encoder Deep Features</title><authors>Nicola Messina, Giuseppe Amato, Fabrizio Falchi, Claudio Gennaro,
  St\'ephane Marchand-Maillet</authors><categories>cs.CV</categories><comments>Accepted at CBMI 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-modal retrieval is an important functionality in modern search engines,
as it increases the user experience by allowing queries and retrieved objects
to pertain to different modalities. In this paper, we focus on the
image-sentence retrieval task, where the objective is to efficiently find
relevant images for a given sentence (image-retrieval) or the relevant
sentences for a given image (sentence-retrieval). Computer vision literature
reports the best results on the image-sentence matching task using deep neural
networks equipped with attention and self-attention mechanisms. They evaluate
the matching performance on the retrieval task by performing sequential scans
of the whole dataset. This method does not scale well with an increasing amount
of images or captions. In this work, we explore different preprocessing
techniques to produce sparsified deep multi-modal features extracting them from
state-of-the-art deep-learning architectures for image-text matching. Our main
objective is to lay down the paths for efficient indexing of complex
multi-modal descriptions. We use the recently introduced TERN architecture as
an image-sentence features extractor. It is designed for producing fixed-size
1024-d vectors describing whole images and sentences, as well as
variable-length sets of 1024-d vectors describing the various building
components of the two modalities (image regions and sentence words
respectively). All these vectors are enforced by the TERN design to lie into
the same common space. Our experiments show interesting preliminary results on
the explored methods and suggest further experimentation in this important
research direction.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00359</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00359</id><submitter>Adri\`a Arbu\'es-Sang\&quot;uesa</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:12:32 GMT</date><size>3350kb</size><source_type>D</source_type></version><title>Learning Football Body-Orientation as a Matter of Classification</title><authors>Adri\`a Arbu\'es-Sang\&quot;uesa, Adri\'an Mart\'in, Paulino Granero,
  Coloma Ballester, Gloria Haro</authors><categories>cs.LG cs.CV eess.IV</categories><comments>Accepted in the AI for Sports Analytics Workshop at ICJAI 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Orientation is a crucial skill for football players that becomes a
differential factor in a large set of events, especially the ones involving
passes. However, existing orientation estimation methods, which are based on
computer-vision techniques, still have a lot of room for improvement. To the
best of our knowledge, this article presents the first deep learning model for
estimating orientation directly from video footage. By approaching this
challenge as a classification problem where classes correspond to orientation
bins, and by introducing a cyclic loss function, a well-known convolutional
network is refined to provide player orientation data. The model is trained by
using ground-truth orientation data obtained from wearable EPTS devices, which
are individually compensated with respect to the perceived orientation in the
current frame. The obtained results outperform previous methods; in particular,
the absolute median error is less than 12 degrees per player. An ablation study
is included in order to show the potential generalization to any kind of
football video footage.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00365</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00365</id><submitter>Verity Allan</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:17:37 GMT</date><size>1356kb</size><source_type>D</source_type></version><title>Scientific Computing in the Cavendish Laboratory and the pioneering
  women Computors</title><authors>Verity Allan, Caitriona Leedham</authors><categories>cs.CY astro-ph.IM</categories><comments>11 pages, 8 figures, submitted to IEEE Annals in the History of
  Computing, (C) IEEE 2021</comments><acm-class>K.2.2; K.4.2</acm-class><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The use of computers and the role of women in radio astronomy and X-ray
crystallography research at the Cavendish Laboratory between 1949 and 1975 have
been investigated. We recorded examples of when computers were used, what they
were used for and who used them from hundreds of papers published during these
years. The use of the EDSAC, EDSAC 2 and TITAN computers was found to increase
considerably over this time-scale and they were used for a diverse range of
applications. The majority of references to computer operators and programmers
referred to women, 57% for astronomy and 62% for crystallography, in contrast
to a very small proportion, 4% and 13% respectively, of female authors of
papers.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00368</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00368</id><submitter>Michael Rotman</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:18:30 GMT</date><size>146kb</size><source_type>D</source_type></version><title>Natural Statistics of Network Activations and Implications for Knowledge
  Distillation</title><authors>Michael Rotman and Lior Wolf</authors><categories>cs.CV</categories><comments>Accepted to ICIP 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a matter that is analog to the study of natural image statistics, we study
the natural statistics of the deep neural network activations at various
layers. As we show, these statistics, similar to image statistics, follow a
power law. We also show, both analytically and empirically, that with depth the
exponent of this power law increases at a linear rate.
  As a direct implication of our discoveries, we present a method for
performing Knowledge Distillation (KD). While classical KD methods consider the
logits of the teacher network, more recent methods obtain a leap in performance
by considering the activation maps. This, however, uses metrics that are
suitable for comparing images. We propose to employ two additional loss terms
that are based on the spectral properties of the intermediate activation maps.
The proposed method obtains state of the art results on multiple image
recognition KD benchmarks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00369</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00369</id><submitter>Robert-Jeron Reifert</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:18:38 GMT</date><size>379kb</size><source_type>D</source_type></version><title>Rate-Splitting Multiple Access in Cache-Aided Cloud-Radio Access
  Networks</title><authors>Robert-Jeron Reifert, Alaa Alameer Ahmad, Yijie Mao, Aydin Sezgin and
  Bruno Clerckx</authors><categories>cs.IT math.IT</categories><comments>38 pages, 9 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rate-splitting multiple access (RSMA) has been recognized as a promising
physical layer strategy for 6G. Motivated by ever increasing popularity of
cache-enabled content delivery in wireless communications, this paper proposes
an innovative multigroup multicast transmission scheme based on RSMA for
cache-aided cloud-radio access networks (C-RAN). Our proposed scheme not only
exploits the properties of content-centric communications and local caching at
the base stations (BSs), but also incorporates RSMA to better manage
interference in multigroup multicast transmission with statistical channel
state information (CSI) known at the central processor (CP) and the BSs. At the
RSMA-enabled cloud CP, the message of each multicast group is split into a
private and a common part with the former private part being decoded by all
users in the respective group and the latter common part being decoded by
multiple users from other multicast groups. Common message decoding is done for
the purpose of mitigating the interference. In this work, we jointly optimize
the clustering of BSs and the precoding with the aim of maximizing the minimum
rate among all multicast groups to guarantee fairness serving all groups. The
problem is a mixed-integer non-linear stochastic program (MINLSP), which is
solved by a practical algorithm we proposed including a heuristic clustering
algorithm for assigning a set of BSs to serve each user followed by an
efficient iterative algorithm that combines the sample average approximation
(SAA) and weighted minimum mean square error (WMMSE) to solve the stochastic
non-convex sub-problem of precoder design. Numerical results show the explicit
max-min rate gain of our proposed transmission scheme compared to the
state-of-the-art trivial interference processing methods. Therefore, we
conclude that RSMA is a promising technique for cache-aided C-RAN.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00371</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00371</id><submitter>Oscar Mendez</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:28:49 GMT</date><size>543kb</size><source_type>D</source_type></version><title>Markov Localisation using Heatmap Regression and Deep Convolutional
  Odometry</title><authors>Oscar Mendez, Simon Hadfield, Richard Bowden</authors><categories>cs.RO cs.CV cs.LG</categories><comments>IEEE International Conference on Robotics and Automation (ICRA) 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of self-driving vehicles there is strong competition between
approaches based on visual localisation and LiDAR. While LiDAR provides
important depth information, it is sparse in resolution and expensive. On the
other hand, cameras are low-cost and recent developments in deep learning mean
they can provide high localisation performance. However, several fundamental
problems remain, particularly in the domain of uncertainty, where learning
based approaches can be notoriously over-confident.
  Markov, or grid-based, localisation was an early solution to the localisation
problem but fell out of favour due to its computational complexity.
Representing the likelihood field as a grid (or volume) means there is a trade
off between accuracy and memory size. Furthermore, it is necessary to perform
expensive convolutions across the entire likelihood volume. Despite the benefit
of simultaneously maintaining a likelihood for all possible locations, grid
based approaches were superseded by more efficient particle filters and Monte
Carlo Localisation (MCL). However, MCL introduces its own problems e.g.
particle deprivation.
  Recent advances in deep learning hardware allow large likelihood volumes to
be stored directly on the GPU, along with the hardware necessary to efficiently
perform GPU-bound 3D convolutions and this obviates many of the disadvantages
of grid based methods. In this work, we present a novel CNN-based localisation
approach that can leverage modern deep learning hardware. By implementing a
grid-based Markov localisation approach directly on the GPU, we create a hybrid
CNN that can perform image-based localisation and odometry-based likelihood
propagation within a single neural network. The resulting approach is capable
of outperforming direct pose regression methods as well as state-of-the-art
localisation systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00373</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00373</id><submitter>Vincent Vousten</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:31:47 GMT</date><size>614kb</size><source_type>D</source_type></version><title>Hybrid Deep Neural Network for Brachial Plexus Nerve Segmentation in
  Ultrasound Images</title><authors>Juul P.A. van Boxtel, Vincent R.J. Vousten, Josien Pluim, Nastaran
  Mohammadian Rad</authors><categories>eess.IV cs.CV</categories><comments>The first two authors contributed equally</comments><acm-class>I.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound-guided regional anesthesia (UGRA) can replace general anesthesia
(GA), improving pain control and recovery time. This method can be applied on
the brachial plexus (BP) after clavicular surgeries. However, identification of
the BP from ultrasound (US) images is difficult, even for trained
professionals. To address this problem, convolutional neural networks (CNNs)
and more advanced deep neural networks (DNNs) can be used for identification
and segmentation of the BP nerve region. In this paper, we propose a hybrid
model consisting of a classification model followed by a segmentation model to
segment BP nerve regions in ultrasound images. A CNN model is employed as a
classifier to precisely select the images with the BP region. Then, a U-net or
M-net model is used for the segmentation. Our experimental results indicate
that the proposed hybrid model significantly improves the segmentation
performance over a single segmentation model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00374</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00374</id><submitter>Michal Dory</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:36:30 GMT</date><size>1069kb</size><source_type>D</source_type></version><title>Fault-Tolerant Labeling and Compact Routing Schemes</title><authors>Michal Dory, Merav Parter</authors><categories>cs.DS cs.DC</categories><comments>PODC 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The paper presents fault-tolerant (FT) labeling schemes for general graphs,
as well as, improved FT routing schemes. For a given $n$-vertex graph $G$ and a
bound $f$ on the number of faults, an $f$-FT connectivity labeling scheme is a
distributed data structure that assigns each of the graph edges and vertices a
short label, such that given the labels of the vertices $s$ and $t$, and at
most $f$ failing edges $F$, one can determine if $s$ and $t$ are connected in
$G \setminus F$. The primary complexity measure is the length of the individual
labels. Since their introduction by [Courcelle, Twigg, STACS '07], compact FT
labeling schemes have been devised only for a limited collection of graph
families. In this work, we fill in this gap by proposing two (independent) FT
connectivity labeling schemes for general graphs, with a nearly optimal label
length. This serves the basis for providing also FT approximate distance
labeling schemes, and ultimately also routing schemes. Our main results for an
$n$-vertex graph and a fault bound $f$ are:
  -- There is a randomized FT connectivity labeling scheme with a label length
of $O(f+\log n)$ bits, hence optimal for $f=O(\log n)$. This scheme is based on
the notion of cycle space sampling [Pritchard, Thurimella, TALG '11].
  -- There is a randomized FT connectivity labeling scheme with a label length
of $O(\log^3 n)$ bits (independent of the number of faults $f$). This scheme is
based on the notion of linear sketches of [Ahn et al., SODA '12].
  -- For $k\geq 1$, there is a randomized routing scheme that routes a message
from $s$ to $t$ in the presence of a set $F$ of faulty edges, with stretch
$O(|F|^2 k)$ and routing tables of size $\tilde{O}(f^3 n^{1/k})$.
  This significantly improves over the state-of-the-art bounds by [Chechik,
ICALP '11], providing the first scheme with sub-linear FT labeling and routing
schemes for general graphs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00376</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00376</id><submitter>Yanfei Su</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:39:11 GMT</date><size>5478kb</size><source_type>D</source_type></version><title>DLA-Net: Learning Dual Local Attention Features for Semantic
  Segmentation of Large-Scale Building Facade Point Clouds</title><authors>Yanfei Su, Weiquan Liu, Zhimin Yuan, Ming Cheng, Zhihong Zhang, Xuelun
  Shen, Cheng Wang</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic segmentation of building facade is significant in various
applications, such as urban building reconstruction and damage assessment. As
there is a lack of 3D point clouds datasets related to the fine-grained
building facade, we construct the first large-scale building facade point
clouds benchmark dataset for semantic segmentation. The existing methods of
semantic segmentation cannot fully mine the local neighborhood information of
point clouds. Addressing this problem, we propose a learnable attention module
that learns Dual Local Attention features, called DLA in this paper. The
proposed DLA module consists of two blocks, including the self-attention block
and attentive pooling block, which both embed an enhanced position encoding
block. The DLA module could be easily embedded into various network
architectures for point cloud segmentation, naturally resulting in a new 3D
semantic segmentation network with an encoder-decoder architecture, called
DLA-Net in this work. Extensive experimental results on our constructed
building facade dataset demonstrate that the proposed DLA-Net achieves better
performance than the state-of-the-art methods for semantic segmentation.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00379</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00379</id><submitter>Luca Capezzuto</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:41:49 GMT</date><size>282kb</size></version><title>Large-scale, Dynamic and Distributed Coalition Formation with Spatial
  and Temporal Constraints</title><authors>Luca Capezzuto, Danesh Tarapore, and Sarvapali D. Ramchurn</authors><categories>cs.MA cs.AI</categories><comments>18 pages, 3 figures, accepted at EUMAS 2021</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)
is a multi-agent task allocation problem in which few agents have to perform
many tasks, each with its deadline and workload. To maximize the number of
completed tasks, the agents need to cooperate by forming, disbanding and
reforming coalitions. The original mathematical programming formulation of the
CFSTP is difficult to implement, since it is lengthy and based on the
problematic Big-M method. In this paper, we propose a compact and
easy-to-implement formulation. Moreover, we design D-CTS, a distributed version
of the state-of-the-art CFSTP algorithm. Using public London Fire Brigade
records, we create a dataset with $347588$ tasks and a test framework that
simulates the mobilization of firefighters in dynamic environments. In problems
with up to $150$ agents and $3000$ tasks, compared to DSA-SDP, a
state-of-the-art distributed algorithm, D-CTS completes $3.79\% \pm [42.22\%,
1.96\%]$ more tasks, and is one order of magnitude more efficient in terms of
communication overhead and time complexity. D-CTS sets the first large-scale,
dynamic and distributed CFSTP benchmark.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00387</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00387</id><submitter>Egor Dudyrev</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:45:35 GMT</date><size>51kb</size></version><title>Decision Concept Lattice vs. Decision Trees and Random Forests</title><authors>Egor Dudyrev, Sergei O. Kuznetsov</authors><categories>cs.LG</categories><comments>8 pages, 2 figures. The final authenticated version is going to be
  published in Braud, A., Buzmakov, A., Hanika, T., Le Ber, F. (eds.) ICFCA
  2021. LNCS (LNAI), vol. 12733, pp. 1-9. Springer, Heidelberg (2021).
  https://doi.org/10.1007/978-3-030-77867-5_16</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Decision trees and their ensembles are very popular models of supervised
machine learning. In this paper we merge the ideas underlying decision trees,
their ensembles and FCA by proposing a new supervised machine learning model
which can be constructed in polynomial time and is applicable for both
classification and regression problems. Specifically, we first propose a
polynomial-time algorithm for constructing a part of the concept lattice that
is based on a decision tree. Second, we describe a prediction scheme based on a
concept lattice for solving both classification and regression tasks with
prediction quality comparable to that of state-of-the-art models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00388</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00388</id><submitter>Felix Mannhardt</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:51:11 GMT</date><size>658kb</size></version><title>Privacy and Confidentiality in Process Mining -- Threats and Research
  Challenges</title><authors>Gamal Elkoumy, Stephan A. Fahrenkrog-Petersen, Mohammadreza Fani Sani,
  Agnes Koschmider, Felix Mannhardt, Saskia Nu\~nez von Voigt, Majid Rafiei,
  Leopold von Waldthausen</authors><categories>cs.CR cs.DB</categories><comments>Accepted for publication in ACM Transactions on Management
  Information Systems</comments><doi>10.1145/3468877</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy and confidentiality are very important prerequisites for applying
process mining in order to comply with regulations and keep company secrets.
This paper provides a foundation for future research on privacy-preserving and
confidential process mining techniques. Main threats are identified and related
to an motivation application scenario in a hospital context as well as to the
current body of work on privacy and confidentiality in process mining. A newly
developed conceptual model structures the discussion that existing techniques
leave room for improvement. This results in a number of important research
challenges that should be addressed by future process mining research.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00389</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00389</id><submitter>Nantheera Anantrasirichai</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:52:41 GMT</date><size>6065kb</size><source_type>D</source_type></version><title>Analysis of Vision-based Abnormal Red Blood Cell Classification</title><authors>Annika Wong and Nantheera Anantrasirichai and Thanarat H.
  Chalidabhongse and Duangdao Palasuwan and Attakorn Palasuwan and David Bull</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Identification of abnormalities in red blood cells (RBC) is key to diagnosing
a range of medical conditions from anaemia to liver disease. Currently this is
done manually, a time-consuming and subjective process. This paper presents an
automated process utilising the advantages of machine learning to increase
capacity and standardisation of cell abnormality detection, and its performance
is analysed. Three different machine learning technologies were used: a Support
Vector Machine (SVM), a classical machine learning technology; TabNet, a deep
learning architecture for tabular data; U-Net, a semantic segmentation network
designed for medical image segmentation. A critical issue was the highly
imbalanced nature of the dataset which impacts the efficacy of machine
learning. To address this, synthesising minority class samples in feature space
was investigated via Synthetic Minority Over-sampling Technique (SMOTE) and
cost-sensitive learning. A combination of these two methods is investigated to
improve the overall performance. These strategies were found to increase
sensitivity to minority classes. The impact of unknown cells on semantic
segmentation is demonstrated, with some evidence of the model applying learning
of labelled cells to these anonymous cells. These findings indicate both
classical models and new deep learning networks as promising methods in
automating RBC abnormality detection.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00390</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00390</id><submitter>Laura Giordano</submitter><version version="v1"><date>Tue, 1 Jun 2021 10:57:46 GMT</date><size>60kb</size></version><title>On the KLM properties of a fuzzy DL with Typicality</title><authors>Laura Giordano</authors><categories>cs.AI</categories><comments>15 pages</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates the properties of a fuzzy logic of typicality. The
extension of fuzzy logic with a typicality operator was proposed in recent work
to define a fuzzy multipreference semantics for Multilayer Perceptrons, by
regarding the deep neural network as a conditional knowledge base. In this
paper, we study its properties. First, a monotonic extension of a fuzzy ALC
with typicality is considered (called ALCFT) and a reformulation the KLM
properties of a preferential consequence relation for this logic is devised.
Most of the properties are satisfied, depending on the reformulation and on the
fuzzy combination functions considered. We then strengthen ALCFT with a closure
construction by introducing a notion of faithful model of a weighted knowledge
base, which generalizes the notion of coherent model of a conditional knowledge
base previously introduced, and we study its properties.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00391</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00391</id><submitter>Jonathan Kelly</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:00:45 GMT</date><size>784kb</size><source_type>D</source_type></version><title>A Question of Time: Revisiting the Use of Recursive Filtering for
  Temporal Calibration of Multisensor Systems</title><authors>Jonathan Kelly, Christopher Grebe, Matthew Giamou</authors><categories>eess.SY cs.RO cs.SY</categories><comments>Submitted to the 2021 IEEE International Conference on Multisensor
  Fusion and Integration (MFI 2021)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the problem of time delay estimation, or temporal calibration, in
the context of multisensor data fusion. Differences in processing intervals and
other factors typically lead to a relative delay between measurement from two
disparate sensors. Correct (optimal) data fusion demands that the relative
delay must either be known in advance or identified online. There have been
several recent proposals in the literature to determine the delay parameter
using recursive, causal filters such as the extended Kalman filter (EKF). We
carefully review this formulation and show that there are fundamental issues
with the structure of the EKF (and related algorithms) when the delay is
included in the filter state vector as a value to be estimated. These
structural issues, in turn, leave recursive filters prone to bias and
inconsistency. Our theoretical analysis is supported by simulation studies that
demonstrate the implications in terms of filter performance; although tuning of
the filter noise variances may reduce the chance of inconsistency or
divergence, the underlying structural concerns remain. We offer brief
suggestions for ways to maintain the computational efficiency of recursive
filtering for temporal calibration while avoiding the drawbacks of the standard
algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00393</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00393</id><submitter>Francesco Giannini</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:02:22 GMT</date><size>68kb</size><source_type>D</source_type></version><title>Learning Representations for Sub-Symbolic Reasoning</title><authors>Giuseppe Marra, Michelangelo Diligenti, Francesco Giannini and Marco
  Maggini</authors><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuro-symbolic methods integrate neural architectures, knowledge
representation and reasoning. However, they have been struggling at both
dealing with the intrinsic uncertainty of the observations and scaling to real
world applications. This paper presents Relational Reasoning Networks (R2N), a
novel end-to-end model that performs relational reasoning in the latent space
of a deep learner architecture, where the representations of constants, ground
atoms and their manipulations are learned in an integrated fashion. Unlike flat
architectures like Knowledge Graph Embedders, which can only represent
relations between entities, R2Ns define an additional computational structure,
accounting for higher-level relations among the ground atoms. The considered
relations can be explicitly known, like the ones defined by logic formulas, or
defined as unconstrained correlations among groups of ground atoms. R2Ns can be
applied to purely symbolic tasks or as a neuro-symbolic platform to integrate
learning and reasoning in heterogeneous problems with both symbolic and
feature-based represented entities. The proposed model bridges the gap between
previous neuro-symbolic methods that have been either limited in terms of
scalability or expressivity. The proposed methodology is shown to achieve
state-of-the-art results in different experimental settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00394</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00394</id><submitter>Shai Feldman</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:02:29 GMT</date><size>624kb</size><source_type>D</source_type></version><title>Improving Conditional Coverage via Orthogonal Quantile Regression</title><authors>Shai Feldman, Stephen Bates, Yaniv Romano</authors><categories>cs.LG</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a method to generate prediction intervals that have a
user-specified coverage level across all regions of feature-space, a property
called conditional coverage. A typical approach to this task is to estimate the
conditional quantiles with quantile regression -- it is well-known that this
leads to correct coverage in the large-sample limit, although it may not be
accurate in finite samples. We find in experiments that traditional quantile
regression can have poor conditional coverage. To remedy this, we modify the
loss function to promote independence between the size of the intervals and the
indicator of a miscoverage event. For the true conditional quantiles, these two
quantities are independent (orthogonal), so the modified loss function
continues to be valid. Moreover, we empirically show that the modified loss
function leads to improved conditional coverage, as evaluated by several
metrics. We also introduce two new metrics that check conditional coverage by
looking at the strength of the dependence between the interval size and the
indicator of miscoverage.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00396</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00396</id><submitter>Sinan Gezici</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:12:11 GMT</date><size>251kb</size></version><title>Distance and Position Estimation in Visible Light Systems with RGB LEDs</title><authors>Ilker Demirel and Sinan Gezici</authors><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, 9 figures, partially presented at IEEE PIMRC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript, distance and position estimation problems are
investigated for visible light positioning (VLP) systems with red-green-blue
(RGB) light emitting diodes (LEDs). The accuracy limits on distance and
position estimation are calculated in terms of the Cramer-Rao lower bound
(CRLB) for three different scenarios. Scenario~1 and Scenario~2 correspond to
synchronous and asynchronous systems, respectively, with known channel
attenuation formulas at the receiver. In Scenario~3, a synchronous system is
considered but channel attenuation formulas are not known at the receiver. The
derived CRLB expressions reveal the relations among distance/position
estimation accuracies in the considered scenarios and lead to intuitive
explanations for the benefits of using RGB LEDs. In addition, maximum
likelihood (ML) estimators are derived in all scenarios, and it is shown that
they can achieve close performance to the CRLBs in some cases for sufficiently
high source optical powers.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00397</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00397</id><submitter>Samuel Herrmann</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:13:04 GMT</date><size>435kb</size><source_type>D</source_type></version><title>Strong approximation of Bessel processes</title><authors>Madalina Deaconu and Samuel Herrmann</authors><categories>math.PR cs.NA math.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider the path approximation of Bessel processes and develop a new and
efficient algorithm. This study is based on a recent work by the authors, on
the path approximation of the Brownian motion, and on the construction of
specific own techniques. It is part of the family of the so-called
$\varepsilon$-strong approximations. More precisely, our approach constructs
jointly the sequences of exit times and corresponding exit positions of some
well-chosen domains, the construction of these domains being an important step.
Based on this procedure, we emphasize an algorithm which is easy to implement.
Moreover, we can develop the method for any dimension. We treat separately the
integer dimension case and the non integer framework, each situation requiring
appropriate techniques. In particular, for both situations, we show the
convergence of the scheme and provide the control of the efficiency with
respect to the small parameter $\varepsilon$. We expand the theoretical part by
a series of numerical developments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00399</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00399</id><submitter>Matthias Naaf</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:18:18 GMT</date><size>28kb</size><source_type>D</source_type></version><title>Computing Least and Greatest Fixed Points in Absorptive Semirings</title><authors>Matthias Naaf</authors><categories>cs.LO cs.CC</categories><comments>submitted to RAMiCS, full version</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present two methods to algorithmically compute both least and greatest
solutions of polynomial equation systems over absorptive semirings (with
certain completeness and continuity assumptions), such as the tropical
semiring. Both methods require a polynomial number of semiring operations,
including semiring addition, multiplication and an infinitary power operation.
  Our main result is a closed-form solution for least and greatest fixed points
based on the fixed-point iteration. The proof builds on the notion of (possibly
infinite) derivation trees; a careful analysis of the shape of these trees
allows us to collapse the fixed-point iteration to a linear number of steps.
  The second method is an iterative symbolic computation in the semiring of
absorptive polynomials, largely based on results on Kleene algebras.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00400</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00400</id><submitter>Chenglei Si</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:20:02 GMT</date><size>49kb</size><source_type>D</source_type></version><title>SHUOWEN-JIEZI: Linguistically Informed Tokenizers For Chinese Language
  Model Pretraining</title><authors>Chenglei Si, Zhengyan Zhang, Yingfa Chen, Fanchao Qi, Xiaozhi Wang,
  Zhiyuan Liu, Maosong Sun</authors><categories>cs.CL</categories><comments>Work in progress. Feedback is welcome</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Conventional tokenization methods for Chinese pretrained language models
(PLMs) treat each character as an indivisible token (Devlin et al., 2019),
which ignores the characteristics of the Chinese writing system. In this work,
we comprehensively study the influences of three main factors on the Chinese
tokenization for PLM: pronunciation, glyph (i.e., shape), and word boundary.
Correspondingly, we propose three kinds of tokenizers: 1) SHUOWEN (meaning Talk
Word), the pronunciation-based tokenizers; 2) JIEZI (meaning Solve Character),
the glyph-based tokenizers; 3) Word segmented tokenizers, the tokenizers with
Chinese word segmentation. To empirically compare the effectiveness of studied
tokenizers, we pretrain BERT-style language models with them and evaluate the
models on various downstream NLU tasks. We find that SHUOWEN and JIEZI
tokenizers can generally outperform conventional single-character tokenizers,
while Chinese word segmentation shows no benefit as a preprocessing step.
Moreover, the proposed SHUOWEN and JIEZI tokenizers exhibit significantly
better robustness in handling noisy texts. The code and pretrained models will
be publicly released to facilitate linguistically informed Chinese NLP.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00402</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00402</id><submitter>Christos Pelekis</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:28:13 GMT</date><size>9kb</size></version><title>A note on the network coloring game</title><authors>Nikolaos Fryganiotis, Symeon Papavassiliou, Christos Pelekis</authors><categories>cs.DM cs.GT</categories><comments>7 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The network coloring game has been proposed in the literature of social
sciences as a model for conflict-resolution circumstances. The players of the
game are the vertices of a graph with $n$ vertices and maximum degree $\Delta$.
The game is played over rounds, and in each round all players simultaneously
choose a color from a set of available colors. Players have local information
of the graph: they only observe the colors chosen by their neighbors and do not
communicate or cooperate with one another. A player is happy when she has
chosen a color that is different from the colors chosen by her neighbors,
otherwise she is unhappy, and a configuration of colors for which all players
are happy is a proper coloring of the graph. It has been shown in the
literature that, when the players adopt a particular greedy randomized
strategy, the game reaches a proper coloring of the graph within $O(\log(n))$
rounds, with high probability, provided the number of colors available to each
player is at least $\Delta+2$. In this note we show that a modification of the
aforementioned greedy strategy yields likewise a proper coloring of the graph,
provided the number of colors available to each player is at least $\Delta+1$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00407</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00407</id><submitter>Karen Aplin</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:32:39 GMT</date><size>480kb</size></version><title>Electric field measurements made on a robotic platform</title><authors>Karen Aplin and Zihao Xiong</authors><categories>cs.RO physics.ins-det</categories><comments>Proc. Electrostatics Society of America, 14-16 June 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This presentation reports the first known data from a field mill mounted on a
ground-based robotic platform. The robot's motor and electrostatic charging of
its wheels do not perturb the field mill data, and electric field varies
smoothly whilst the robot is moving. Test measurements under a charged
polystyrene plate are reduced in variability by a factor of 2 compared to a
hand-held field mill. This technology has potential for autonomous measurements
in inaccessible or hazardous environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00410</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00410</id><submitter>Genta Indra Winata</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:42:07 GMT</date><size>13460kb</size><source_type>D</source_type></version><title>Nora: The Well-Being Coach</title><authors>Genta Indra Winata, Holy Lovenia, Etsuko Ishii, Farhad Bin Siddique,
  Yongsheng Yang, Pascale Fung</authors><categories>cs.CL cs.HC cs.SD eess.AS</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current pandemic has forced people globally to remain in isolation and
practice social distancing, which creates the need for a system to combat the
resulting loneliness and negative emotions. In this paper we propose Nora, a
virtual coaching platform designed to utilize natural language understanding in
its dialogue system and suggest other recommendations based on user
interactions. It is intended to provide assistance and companionship to people
undergoing self-quarantine or work-from-home routines. Nora helps users gauge
their well-being by detecting and recording the user's emotion, sentiment, and
stress. Nora also recommends various workout, meditation, or yoga exercises to
users in support of developing a healthy daily routine. In addition, we provide
a social community inside Nora, where users can connect and share their
experiences with others undergoing a similar isolation procedure. Nora can be
accessed from anywhere via a web link and has support for both English and
Mandarin.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00411</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00411</id><submitter>D\'avid Lupt\'ak</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:49:37 GMT</date><size>505kb</size><source_type>D</source_type></version><title>WebMIaS on Docker: Deploying Math-Aware Search in a Single Line of Code</title><authors>D\'avid Lupt\'ak, V\'it Novotn\'y, Michal \v{S}tef\'anik, and Petr
  Sojka</authors><categories>cs.DL cs.IR</categories><comments>Accepted to be published in: Intelligent Computer Mathematics 14th
  International Conference, CICM 2021, Timisoara, Romania, July 26--31, 2021,
  Proceedings, Fairouz Kamareddine and Claudio Sacerdotti-Coen (eds.), Lecture
  Notes in Artificial Intelligence, Springer, Cham, 2021</comments><acm-class>H.3.3; H.3.4; H.3.5; H.3.6; H.3.7</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Math informational retrieval (MIR) search engines are absent in the
wide-spread production use, even though documents in the STEM fields contain
many mathematical formulae, which are sometimes more important than text for
understanding. We have developed and open-sourced the WebMIaS MIR search engine
that has been successfully deployed in the European Digital Mathematics Library
(EuDML). However, its deployment is difficult to automate due to the complexity
of this task. Moreover, the solutions developed so far to tackle this challenge
are imperfect in terms of speed, maintenance, and robustness. In this paper, we
will describe the virtualization of WebMIaS using Docker that solves all three
problems and allows anyone to deploy containerized WebMIaS in a single line of
code. The publicly available Docker image will also help the community push the
development of math-aware search engines in the ARQMath workshop series.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00412</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00412</id><submitter>Vashti Galpin</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:52:59 GMT</date><size>509kb</size><source_type>D</source_type></version><title>Curating Covid-19 data in Links</title><authors>Vashti Galpin, James Cheney</authors><categories>cs.DB cs.DL cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Curated scientific databases play an important role in the scientific
endeavour and support is needed for the significant effort that goes into their
creation and maintenance. This demonstration and case study illustrate how
curation support has been developed in the Links cross-tier programming
language, a functional, strongly typed language with language-integrated query
and support for temporal databases. The chosen case study uses weekly released
Covid-19 fatality figures from the Scottish government which exhibit updates to
previously released data. This data allows the capture and query of update
provenance in our prototype. This demonstration will highlight the potential
for language-integrated support for curation to simplify and streamline
prototyping of web-applications in support of scientific databases
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00415</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00415</id><submitter>Pedro Maia De Sant Ana</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:54:09 GMT</date><size>529kb</size><source_type>D</source_type></version><title>Age of Loop for Wireless Networked Control Systems Optimization</title><authors>Pedro M. de Sant Ana, Nikolaj Marchenko, Petar Popovski and Beatriz
  Soret</authors><categories>eess.SY cs.SY</categories><comments>7 pages, 7 Figures, Conference paper submitted to IEEE PIMRC 2021</comments><journal-ref>2021 IEEE International Symposium on Personal, Indoor and Mobile
  Radio Communications (IEEE PIMRC 2021)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Joint design of control and communication in Wireless Networked Control
Systems (WNCS) is a promising approach for future wireless industrial
applications. In this context, Age of Information (AoI) has been increasingly
utilized as a metric that is more representative than latency in the context of
systems with a sense-compute-actuate cycle. Nevertheless, AoI is commonly
defined for a single communication direction, Downlink or Uplink, which does
not capture the closed-loop dynamics. In this paper, we extend the concept of
AoI by defining a new metric, Age of Loop (AoL), relevant for WNCS closed-loop
systems. The AoL is defined as the time elapsed since the piece of information
causing the latest action or state (depending on the selected time origin) was
generated. We then use the proposed metric to learn the WNCS latency and
freshness bounds and we apply such learning methodology to minimize the long
term WNCS cost with the least amount of bandwidth. We show that, using the AoL,
we can learn the control system requirement and use this information to
optimize network resources.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00417</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00417</id><submitter>Yabin Zhang</submitter><version version="v1"><date>Tue, 1 Jun 2021 11:59:48 GMT</date><size>383kb</size><source_type>D</source_type></version><title>Semi-supervised Models are Strong Unsupervised Domain Adaptation
  Learners</title><authors>Yabin Zhang, Haojian Zhang, Bin Deng, Shuai Li, Kui Jia, Lei Zhang</authors><categories>cs.LG</categories><comments>Codes are available at https://github.com/YBZh</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Unsupervised domain adaptation (UDA) and semi-supervised learning (SSL) are
two typical strategies to reduce expensive manual annotations in machine
learning. In order to learn effective models for a target task, UDA utilizes
the available labeled source data, which may have different distributions from
unlabeled samples in the target domain, while SSL employs few manually
annotated target samples. Although UDA and SSL are seemingly very different
strategies, we find that they are closely related in terms of task objectives
and solutions, and SSL is a special case of UDA problems. Based on this
finding, we further investigate whether SSL methods work on UDA tasks. By
adapting eight representative SSL algorithms on UDA benchmarks, we show that
SSL methods are strong UDA learners. Especially, state-of-the-art SSL methods
significantly outperform existing UDA methods on the challenging UDA benchmark
of DomainNet, and state-of-the-art UDA methods could be further enhanced with
SSL techniques. We thus promote that SSL methods should be employed as
baselines in future UDA studies and expect that the revealed relationship
between UDA and SSL could shed light on future UDA development. Codes are
available at \url{https://github.com/YBZh}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00418</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00418</id><submitter>Aur\'elien Bibaut</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:01:51 GMT</date><size>2627kb</size><source_type>D</source_type></version><title>Post-Contextual-Bandit Inference</title><authors>Aur\'elien Bibaut and Antoine Chambaz and Maria Dimakopoulou and
  Nathan Kallus and Mark van der Laan</authors><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contextual bandit algorithms are increasingly replacing non-adaptive A/B
tests in e-commerce, healthcare, and policymaking because they can both improve
outcomes for study participants and increase the chance of identifying good or
even best policies. To support credible inference on novel interventions at the
end of the study, nonetheless, we still want to construct valid confidence
intervals on average treatment effects, subgroup effects, or value of new
policies. The adaptive nature of the data collected by contextual bandit
algorithms, however, makes this difficult: standard estimators are no longer
asymptotically normally distributed and classic confidence intervals fail to
provide correct coverage. While this has been addressed in non-contextual
settings by using stabilized estimators, the contextual setting poses unique
challenges that we tackle for the first time in this paper. We propose the
Contextual Adaptive Doubly Robust (CADR) estimator, the first estimator for
policy value that is asymptotically normal under contextual adaptive data
collection. The main technical challenge in constructing CADR is designing
adaptive and consistent conditional standard deviation estimators for
stabilization. Extensive numerical experiments using 57 OpenML datasets
demonstrate that confidence intervals based on CADR uniquely provide correct
coverage.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00420</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00420</id><submitter>Yi Xu</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:02:46 GMT</date><size>206kb</size></version><title>Dialogue-oriented Pre-training</title><authors>Yi Xu, Hai Zhao</authors><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pre-trained language models (PrLM) has been shown powerful in enhancing a
broad range of downstream tasks including various dialogue related ones.
However, PrLMs are usually trained on general plain text with common language
model (LM) training objectives, which cannot sufficiently capture dialogue
exclusive features due to the limitation of such training setting, so that
there is an immediate need to fill the gap between a specific dialogue task and
the LM task. As it is unlikely to collect huge dialogue data for
dialogue-oriented pre-training, in this paper, we propose three strategies to
simulate the conversation features on general plain text. Our proposed method
differs from existing post-training methods that it may yield a general-purpose
PrLM and does not individualize to any detailed task while keeping the
capability of learning dialogue related features including speaker awareness,
continuity and consistency. The resulted Dialog-PrLM is fine-tuned on three
public multi-turn dialogue datasets and helps achieve significant and
consistent improvement over the plain PrLMs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00421</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00421</id><submitter>Yang Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:02:50 GMT</date><size>10406kb</size><source_type>D</source_type></version><title>OpenBox: A Generalized Black-box Optimization Service</title><authors>Yang Li, Yu Shen, Wentao Zhang, Yuanwei Chen, Huaijun Jiang, Mingchao
  Liu, Jiawei Jiang, Jinyang Gao, Wentao Wu, Zhi Yang, Ce Zhang, Bin Cui</authors><categories>cs.LG cs.AI</categories><journal-ref>Proceedings of the 27th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD-2021)</journal-ref><doi>10.1145/3447548.3467061</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Black-box optimization (BBO) has a broad range of applications, including
automatic machine learning, engineering, physics, and experimental design.
However, it remains a challenge for users to apply BBO methods to their
problems at hand with existing software packages, in terms of applicability,
performance, and efficiency. In this paper, we build OpenBox, an open-source
and general-purpose BBO service with improved usability. The modular design
behind OpenBox also facilitates flexible abstraction and optimization of basic
BBO components that are common in other existing systems. OpenBox is
distributed, fault-tolerant, and scalable. To improve efficiency, OpenBox
further utilizes &quot;algorithm agnostic&quot; parallelization and transfer learning.
Our experimental results demonstrate the effectiveness and efficiency of
OpenBox compared to existing systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00424</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00424</id><submitter>Zhenting Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:07:35 GMT</date><size>1014kb</size><source_type>D</source_type></version><title>Assembly Planning by Recognizing a Graphical Instruction Manual</title><authors>Issei Sera, Natsuki Yamanobe, Ixchel G. Ramirez-Alpizar, Zhenting
  Wang, Weiwei Wan, and Kensuke Harada</authors><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a robot assembly planning method by automatically reading
the graphical instruction manuals design for humans. Essentially, the method
generates an Assembly Task Sequence Graph (ATSG) by recognizing a graphical
instruction manual. An ATSG is a graph describing the assembly task procedure
by detecting types of parts included in the instruction images, completing the
missing information automatically, and correcting the detection errors
automatically. To build an ATSG, the proposed method first extracts the
information of the parts contained in each image of the graphical instruction
manual. Then, by using the extracted part information, it estimates the proper
work motions and tools for the assembly task. After that, the method builds an
ATSG by considering the relationship between the previous and following images,
which makes it possible to estimate the undetected parts caused by occlusion
using the information of the entire image series. Finally, by collating the
total number of each part with the generated ATSG, the excess or deficiency of
parts are investigated, and task procedures are removed or added according to
those parts. In the experiment section, we build an ATSG using the proposed
method to a graphical instruction manual for a chair and demonstrate the action
sequences found in the ATSG can be performed by a dual-arm robot execution. The
results show the proposed method is effective and simplifies robot teaching in
automatic assembly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00432</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00432</id><submitter>Friedrich Bethke</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:26:10 GMT</date><size>1127kb</size><source_type>D</source_type></version><title>Invertible Surrogate Models: Joint surrogate modelling and
  reconstruction of Laser-Wakefield Acceleration by invertible neural networks</title><authors>Friedrich Bethke, Richard Pausch, Patrick Stiller, Alexander Debus,
  Michael Bussmann, Nico Hoffmann</authors><categories>physics.plasm-ph cs.LG physics.acc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Invertible neural networks are a recent technique in machine learning
promising neural network architectures that can be run in forward and reverse
mode. In this paper, we will be introducing invertible surrogate models that
approximate complex forward simulation of the physics involved in laser plasma
accelerators: iLWFA. The bijective design of the surrogate model also provides
all means for reconstruction of experimentally acquired diagnostics. The
quality of our invertible laser wakefield acceleration network will be verified
on a large set of numerical LWFA simulations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00433</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00433</id><submitter>Sungyeal Park</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:26:32 GMT</date><size>611kb</size><source_type>D</source_type></version><title>Low-Complexity Symbol-Level Precoding for MU-MISO Downlink Systems with
  QAM Signals</title><authors>Sungyeal Park, Yunseong Cho, Songnam Hong</authors><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 6 figures, Globecom 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes the construction of a transmit signal for large-scale
antenna systems with cost-effective 1-bit digital-to-analog converters in the
downlink. Under quadrature-amplitude-modulation constellations, it is still an
open problem to overcome a severe error floor problem caused by its nature
property. To this end, we first present a feasibility condition which
guarantees that each user's noiseless signal is placed in the desired decision
region. For robustness to additive noise, we formulate an optimization problem,
we then transform the feasibility conditions to cascaded matrix form. We
propose a low-complexity algorithm to generate a 1-bit transmit signal based on
the proposed optimization problem formulated as a well-defined
mixed-integer-linear-programming. Numerical results validate the superiority of
the proposed method in terms of detection performance and computational
complexity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00434</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00434</id><submitter>Hugh Kennedy Dr.</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:28:44 GMT</date><size>4163kb</size></version><title>Noise will be noise: Or phase optimized recursive filters for
  interference suppression, signal differentiation and state estimation
  (extended version)</title><authors>Hugh L. Kennedy</authors><categories>eess.SY cs.SY eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The increased temporal and spectral resolution of oversampled systems allows
many sensor-signal analysis tasks to be performed (e.g. detection,
classification and tracking) using a filterbank of low-pass digital
differentiators. Such filters are readily designed via flatness constraints on
the derivatives of the complex frequency response at dc, pi and at the centre
frequencies of narrowband interferers, i.e. using maximally-flat (MaxFlat)
designs. Infinite-impulse-response (IIR) filters are ideal in embedded online
systems with high data-rates because computational complexity is independent of
their (fading) memory. A novel procedure for the design of MaxFlat IIR
filterbanks with improved passband phase linearity is presented in this paper,
as a possible alternative to Kalman and Wiener filters in a class of
derivative-state estimation problems with uncertain signal models. Butterworth
poles are used for configurable bandwidth and guaranteed stability. Flatness
constraints of arbitrary order are derived for temporal derivatives of
arbitrary order and a prescribed group delay. As longer lags (in samples) are
readily accommodated in oversampled systems, an expression for the optimal
group delay that minimizes the white-noise gain (i.e. the error variance of the
derivative estimate at steady state) is derived. Filter zeros are optimally
placed for the required passband phase response and the cancellation of
narrowband interferers in the stopband, by solving a linear system of
equations. Low complexity filterbank realizations are discussed then their
behaviour is analysed in a Teager-Kaiser operator to detect pulsed signals and
in a state observer to track manoeuvring targets in simulated scenarios.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00436</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00436</id><submitter>Muhammad E. H. Chowdhury</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:33:08 GMT</date><size>1842kb</size></version><title>COV-ECGNET: COVID-19 detection using ECG trace images with deep
  convolutional neural network</title><authors>Tawsifur Rahman, Alex Akinbi, Muhammad E. H. Chowdhury, Tarik A.
  Rashid, Abdulkadir \c{S}eng\&quot;ur, Amith Khandakar, Khandaker Reajul Islam,
  Aras M. Ismael</authors><categories>eess.IV cs.CV cs.LG</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reliable and rapid identification of the COVID-19 has become crucial to
prevent the rapid spread of the disease, ease lockdown restrictions and reduce
pressure on public health infrastructures. Recently, several methods and
techniques have been proposed to detect the SARS-CoV-2 virus using different
images and data. However, this is the first study that will explore the
possibility of using deep convolutional neural network (CNN) models to detect
COVID-19 from electrocardiogram (ECG) trace images. In this work, COVID-19 and
other cardiovascular diseases (CVDs) were detected using deep-learning
techniques. A public dataset of ECG images consists of 1937 images from five
distinct categories, such as Normal, COVID-19, myocardial infarction (MI),
abnormal heartbeat (AHB), and recovered myocardial infarction (RMI) were used
in this study. Six different deep CNN models (ResNet18, ResNet50, ResNet101,
InceptionV3, DenseNet201, and MobileNetv2) were used to investigate three
different classification schemes: two-class classification (Normal vs
COVID-19); three-class classification (Normal, COVID-19, and Other CVDs), and
finally, five-class classification (Normal, COVID-19, MI, AHB, and RMI). For
two-class and three-class classification, Densenet201 outperforms other
networks with an accuracy of 99.1%, and 97.36%, respectively; while for the
five-class classification, InceptionV3 outperforms others with an accuracy of
97.83%. ScoreCAM visualization confirms that the networks are learning from the
relevant area of the trace images. Since the proposed method uses ECG trace
images which can be captured by smartphones and are readily available
facilities in low-resources countries, this study will help in faster
computer-aided diagnosis of COVID-19 and other cardiac abnormalities.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00444</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00444</id><submitter>Tor Lattimore</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:51:48 GMT</date><size>143kb</size><source_type>D</source_type></version><title>Minimax Regret for Bandit Convex Optimisation of Ridge Functions</title><authors>Tor Lattimore</authors><categories>cs.LG math.OC</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse adversarial bandit convex optimisation with an adversary that is
restricted to playing functions of the form $f(x) = g(\langle x,
\theta\rangle)$ for convex $g : \mathbb R \to \mathbb R$ and $\theta \in
\mathbb R^d$. We provide a short information-theoretic proof that the minimax
regret is at most $O(d\sqrt{n} \log(\operatorname{diam}\mathcal K))$ where $n$
is the number of interactions, $d$ the dimension and
$\operatorname{diam}(\mathcal K)$ is the diameter of the constraint set. Hence,
this class of functions is at most logarithmically harder than the linear case.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00445</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00445</id><submitter>Tongliang Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:53:53 GMT</date><size>411kb</size><source_type>D</source_type></version><title>Sample Selection with Uncertainty of Losses for Learning with Noisy
  Labels</title><authors>Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu,
  Masashi Sugiyama</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In learning with noisy labels, the sample selection approach is very popular,
which regards small-loss data as correctly labeled during training. However,
losses are generated on-the-fly based on the model being trained with noisy
labels, and thus large-loss data are likely but not certainly to be incorrect.
There are actually two possibilities of a large-loss data point: (a) it is
mislabeled, and then its loss decreases slower than other data, since deep
neural networks &quot;learn patterns first&quot;; (b) it belongs to an underrepresented
group of data and has not been selected yet. In this paper, we incorporate the
uncertainty of losses by adopting interval estimation instead of point
estimation of losses, where lower bounds of the confidence intervals of losses
derived from distribution-free concentration inequalities, but not losses
themselves, are used for sample selection. In this way, we also give large-loss
but less selected data a try; then, we can better distinguish between the cases
(a) and (b) by seeing if the losses effectively decrease with the uncertainty
after the try. As a result, we can better explore underrepresented data that
are correctly labeled but seem to be mislabeled at first glance. Experiments
demonstrate that the proposed method is superior to baselines and robust to a
broad range of label noise types.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00446</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00446</id><submitter>Vasileios Gkitsas</submitter><version version="v1"><date>Tue, 1 Jun 2021 12:56:53 GMT</date><size>9556kb</size><source_type>D</source_type></version><title>PanoDR: Spherical Panorama Diminished Reality for Indoor Scenes</title><authors>V. Gkitsas, V. Sterzentsenko, N. Zioulis, G. Albanis, D. Zarpalas</authors><categories>cs.CV</categories><comments>Accepted at CVPR, OmniCV Workshop. Code and models are available at
  https://vcl3d.github.io/PanoDR/</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The rising availability of commercial $360^\circ$ cameras that democratize
indoor scanning, has increased the interest for novel applications, such as
interior space re-design. Diminished Reality (DR) fulfills the requirement of
such applications, to remove existing objects in the scene, essentially
translating this to a counterfactual inpainting task. While recent advances in
data-driven inpainting have shown significant progress in generating realistic
samples, they are not constrained to produce results with reality mapped
structures. To preserve the `reality' in indoor (re-)planning applications, the
scene's structure preservation is crucial. To ensure structure-aware
counterfactual inpainting, we propose a model that initially predicts the
structure of an indoor scene and then uses it to guide the reconstruction of an
empty -- background only -- representation of the same scene. We train and
compare against other state-of-the-art methods on a version of the Structured3D
dataset modified for DR, showing superior results in both quantitative metrics
and qualitative results, but more interestingly, our approach exhibits a much
faster convergence rate. Code and models are available at
https://vcl3d.github.io/PanoDR/ .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00451</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00451</id><submitter>Fan Huang</submitter><version version="v1"><date>Fri, 28 May 2021 08:39:19 GMT</date><size>195kb</size></version><title>Highlight Timestamp Detection Model for Comedy Videos via Multimodal
  Sentiment Analysis</title><authors>Fan Huang</authors><categories>cs.CV cs.AI cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the videos on the Internet are prevailing. The precise and in-depth
understanding of the videos is a difficult but valuable problem for both
platforms and researchers. The existing video understand models do well in
object recognition tasks but currently still cannot understand the abstract and
contextual features like highlight humor frames in comedy videos. The current
industrial works are also mainly focused on the basic category classification
task based on the appearances of objects. The feature detection methods for the
abstract category remains blank. A data structure that includes the information
of video frames, audio spectrum and texts provide a new direction to explore.
The multimodal models are proposed to make this in-depth video understanding
mission possible. In this paper, we analyze the difficulties in abstract
understanding of videos and propose a multimodal structure to obtain
state-of-the-art performance in this field. Then we select several benchmarks
for multimodal video understanding and apply the most suitable model to find
the best performance. At last, we evaluate the overall spotlights and drawbacks
of the models and methods in this paper and point out the possible directions
for further improvements.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00455</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00455</id><submitter>Tongliang Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:05:55 GMT</date><size>1856kb</size><source_type>D</source_type></version><title>Instance Correction for Learning with Open-set Noisy Labels</title><authors>Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu,
  Masashi Sugiyama</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of open-set noisy labels denotes that part of training data have
a different label space that does not contain the true class. Lots of
approaches, e.g., loss correction and label correction, cannot handle such
open-set noisy labels well, since they need training data and test data to
share the same label space, which does not hold for learning with open-set
noisy labels. The state-of-the-art methods thus employ the sample selection
approach to handle open-set noisy labels, which tries to select clean data from
noisy data for network parameters updates. The discarded data are seen to be
mislabeled and do not participate in training. Such an approach is intuitive
and reasonable at first glance. However, a natural question could be raised
&quot;can such data only be discarded during training?&quot;. In this paper, we show that
the answer is no. Specifically, we discuss that the instances of discarded data
could consist of some meaningful information for generalization. For this
reason, we do not abandon such data, but use instance correction to modify the
instances of the discarded data, which makes the predictions for the discarded
data consistent with given labels. Instance correction are performed by
targeted adversarial attacks. The corrected data are then exploited for
training to help generalization. In addition to the analytical results, a
series of empirical evidences are provided to justify our claims.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00456</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00456</id><submitter>Thanh Vinh Vo</submitter><version version="v1"><date>Mon, 31 May 2021 08:06:00 GMT</date><size>766kb</size><source_type>D</source_type></version><title>Federated Estimation of Causal Effects from Observational Data</title><authors>Thanh Vinh Vo, Trong Nghia Hoang, Young Lee, Tze-Yun Leong</authors><categories>stat.ME cs.AI cs.CR cs.LG</categories><comments>Preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many modern applications collect data that comes in federated spirit, with
data kept locally and undisclosed. Till date, most insight into the causal
inference requires data to be stored in a central repository. We present a
novel framework for causal inference with federated data sources. We assess and
integrate local causal effects from different private data sources without
centralizing them. Then, the treatment effects on subjects from observational
data using a non-parametric reformulation of the classical potential outcomes
framework is estimated. We model the potential outcomes as a random function
distributed by Gaussian processes, whose defining parameters can be efficiently
learned from multiple data sources, respecting privacy constraints. We
demonstrate the promise and efficiency of the proposed approach through a set
of simulated and real-world benchmark examples.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00459</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00459</id><submitter>Kuldeep Singh</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:12:24 GMT</date><size>476kb</size><source_type>D</source_type></version><title>KGPool: Dynamic Knowledge Graph Context Selection for Relation
  Extraction</title><authors>Abhishek Nadgeri, Anson Bastos, Kuldeep Singh, Isaiah Onando Mulang',
  Johannes Hoffart, Saeedeh Shekarpour, Vijay Saraswat</authors><categories>cs.CL cs.AI</categories><comments>ACL 2021 (findings)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a novel method for relation extraction (RE) from a single
sentence, mapping the sentence and two given entities to a canonical fact in a
knowledge graph (KG). Especially in this presumed sentential RE setting, the
context of a single sentence is often sparse. This paper introduces the KGPool
method to address this sparsity, dynamically expanding the context with
additional facts from the KG. It learns the representation of these facts
(entity alias, entity descriptions, etc.) using neural methods, supplementing
the sentential context. Unlike existing methods that statically use all
expanded facts, KGPool conditions this expansion on the sentence. We study the
efficacy of KGPool by evaluating it with different neural models and KGs
(Wikidata and NYT Freebase). Our experimental evaluation on standard datasets
shows that by feeding the KGPool representation into a Graph Neural Network,
the overall method is significantly more accurate than state-of-the-art
methods.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00461</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00461</id><submitter>Paolo Bajardi</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:14:12 GMT</date><size>2172kb</size><source_type>D</source_type></version><title>To trust or not to trust an explanation: using LEAF to evaluate local
  linear XAI methods</title><authors>Elvio G. Amparore and Alan Perotti and Paolo Bajardi</authors><categories>cs.AI cs.CY cs.LG</categories><comments>16 pages, 8 figures</comments><journal-ref>PeerJ Computer Science 7:e479 (2021)</journal-ref><doi>10.7717/peerj-cs.479</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  The main objective of eXplainable Artificial Intelligence (XAI) is to provide
effective explanations for black-box classifiers. The existing literature lists
many desirable properties for explanations to be useful, but there is no
consensus on how to quantitatively evaluate explanations in practice. Moreover,
explanations are typically used only to inspect black-box models, and the
proactive use of explanations as a decision support is generally overlooked.
Among the many approaches to XAI, a widely adopted paradigm is Local Linear
Explanations - with LIME and SHAP emerging as state-of-the-art methods. We show
that these methods are plagued by many defects including unstable explanations,
divergence of actual implementations from the promised theoretical properties,
and explanations for the wrong label. This highlights the need to have standard
and unbiased evaluation procedures for Local Linear Explanations in the XAI
field. In this paper we address the problem of identifying a clear and
unambiguous set of metrics for the evaluation of Local Linear Explanations.
This set includes both existing and novel metrics defined specifically for this
class of explanations. All metrics have been included in an open Python
framework, named LEAF. The purpose of LEAF is to provide a reference for end
users to evaluate explanations in a standardised and unbiased way, and to guide
researchers towards developing improved explainable techniques.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00463</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00463</id><submitter>Ziyue Huang</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:15:50 GMT</date><size>266kb</size><source_type>D</source_type></version><title>Instance-optimal Mean Estimation Under Differential Privacy</title><authors>Ziyue Huang, Yuting Liang, Ke Yi</authors><categories>cs.CR cs.DS stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean estimation under differential privacy is a fundamental problem, but
worst-case optimal mechanisms do not offer meaningful utility guarantees in
practice when the global sensitivity is very large. Instead, various heuristics
have been proposed to reduce the error on real-world data that do not resemble
the worst-case instance. This paper takes a principled approach, yielding a
mechanism that is instance-optimal in a strong sense. In addition to its
theoretical optimality, the mechanism is also simple and practical, and adapts
to a variety of data characteristics without the need of parameter tuning. It
easily extends to the local and shuffle model as well.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00467</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00467</id><submitter>Daniele Regoli</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:19:30 GMT</date><size>182kb</size><source_type>D</source_type></version><title>The zoo of Fairness metrics in Machine Learning</title><authors>Alessandro Castelnovo, Riccardo Crupi, Greta Greco, Daniele Regoli</authors><categories>cs.LG cs.CY stat.ML</categories><comments>17 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the recent years, the problem of addressing fairness in Machine Learning
(ML) and automatic decision-making has attracted a lot of attention in the
scientific communities dealing with Artificial Intelligence. A plethora of
different definitions of fairness in ML have been proposed, that consider
different notions of what is a &quot;fair decision&quot; in situations impacting
individuals in the population. The precise differences, implications and
&quot;orthogonality&quot; between these notions have not yet been fully analyzed in the
literature. In this work, we try to make some order out of this zoo of
definitions.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00471</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00471</id><submitter>Jiali Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:21:38 GMT</date><size>6148kb</size></version><title>A Bayesian-network-based cybersecurity adversarial risk analysis
  framework with numerical examples</title><authors>Jiali Wang and Martin Neil</authors><categories>cs.GT</categories><comments>10 pages, 40 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cybersecurity risk analysis plays an essential role in supporting
organizations make effective decision about how to manage and control
cybersecurity risk. Cybersecurity risk is a function of the interplay between
the defender, i.e., the organisation, and the attacker: decisions and actions
made by the defender second guess the decisions and actions taken by the
attacker and vice versa. Insight into this game between these two agents
provides a means for the defender to identify and make optimal decisions. To
date, the adversarial risk analysis framework has provided a
decision-analytical approach to solve such game problems in the presence of
uncertainty and uses Monte Carlo simulation to calculate and identify optimal
decisions. We propose an alternative framework to construct and solve a serial
of sequential Defend-Attack models, that incorporates the adversarial risk
analysis approach, but uses a new class of influence diagrams algorithm, called
hybrid Bayesian network inference, to identify optimal decision strategies.
Compared to Monte Carlo simulation the proposed hybrid Bayesian network
inference is more versatile because it provides an automated way to compute
hybrid Defend-Attack models and extends their use to involve mixtures of
continuous and discrete variables, of any kind. More importantly, the hybrid
Bayesian network approach is novel in that it supports dynamic decision making
whereby new real-time observations can update the Defend-Attack model in
practice. We also extend the Defend-Attack model to support cases involving
extra variables and longer decision sequence. Examples are presented,
illustrating how the proposed framework can be adjusted for more complicated
scenarios, including dynamic decision making.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00472</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00472</id><submitter>Dario Fontanel</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:22:33 GMT</date><size>9491kb</size><source_type>D</source_type></version><title>Detecting Anomalies in Semantic Segmentation with Prototypes</title><authors>Dario Fontanel, Fabio Cermelli, Massimiliano Mancini, Barbara Caputo</authors><categories>cs.CV</categories><comments>SAIAD CVPR21 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional semantic segmentation methods can recognize at test time only the
classes that are present in the training set. This is a significant limitation,
especially for semantic segmentation algorithms mounted on intelligent
autonomous systems, deployed in realistic settings. Regardless of how many
classes the system has seen at training time, it is inevitable that unexpected,
unknown objects will appear at test time. The failure in identifying such
anomalies may lead to incorrect, even dangerous behaviors of the autonomous
agent equipped with such segmentation model when deployed in the real world.
Current state of the art of anomaly segmentation uses generative models,
exploiting their incapability to reconstruct patterns unseen during training.
However, training these models is expensive, and their generated artifacts may
create false anomalies. In this paper we take a different route and we propose
to address anomaly segmentation through prototype learning. Our intuition is
that anomalous pixels are those that are dissimilar to all class prototypes
known by the model. We extract class prototypes from the training data in a
lightweight manner using a cosine similarity-based classifier. Experiments on
StreetHazards show that our approach achieves the new state of the art, with a
significant margin over previous works, despite the reduced computational
overhead. Code is available at https://github.com/DarioFontanel/PAnS.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00473</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00473</id><submitter>Matthew Shardlow</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:22:36 GMT</date><size>7159kb</size></version><title>SemEval-2021 Task 1: Lexical Complexity Prediction</title><authors>Matthew Shardlow, Richard Evans, Gustavo Henrique Paetzold, Marcos
  Zampieri</authors><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the results and main findings of SemEval-2021 Task 1 -
Lexical Complexity Prediction. We provided participants with an augmented
version of the CompLex Corpus (Shardlow et al 2020). CompLex is an English
multi-domain corpus in which words and multi-word expressions (MWEs) were
annotated with respect to their complexity using a five point Likert scale.
SemEval-2021 Task 1 featured two Sub-tasks: Sub-task 1 focused on single words
and Sub-task 2 focused on MWEs. The competition attracted 198 teams in total,
of which 54 teams submitted official runs on the test data to Sub-task 1 and 37
to Sub-task 2.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00474</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00474</id><submitter>Antti Honkela</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:23:16 GMT</date><size>60kb</size><source_type>D</source_type></version><title>Gaussian Processes with Differential Privacy</title><authors>Antti Honkela</authors><categories>cs.LG cs.CR stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Gaussian processes (GPs) are non-parametric Bayesian models that are widely
used for diverse prediction tasks. Previous work in adding strong privacy
protection to GPs via differential privacy (DP) has been limited to protecting
only the privacy of the prediction targets (model outputs) but not inputs. We
break this limitation by introducing GPs with DP protection for both model
inputs and outputs. We achieve this by using sparse GP methodology and
publishing a private variational approximation on known inducing points. The
approximation covariance is adjusted to approximately account for the added
uncertainty from DP noise. The approximation can be used to compute arbitrary
predictions using standard sparse GP techniques. We propose a method for
hyperparameter learning using a private selection protocol applied to
validation set log-likelihood. Our experiments demonstrate that given
sufficient amount of data, the method can produce accurate models under strong
privacy protection.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00477</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00477</id><submitter>Antti Koskela</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:30:32 GMT</date><size>1957kb</size><source_type>D</source_type></version><title>Tight Accounting in the Shuffle Model of Differential Privacy</title><authors>Antti Koskela, Mikko A. Heikkil\&quot;a, Antti Honkela</authors><categories>cs.CR cs.LG stat.ML</categories><comments>24 pages, 10 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Shuffle model of differential privacy is a novel distributed privacy model
based on a combination of local privacy mechanisms and a trusted shuffler. It
has been shown that the additional randomisation provided by the shuffler
improves privacy bounds compared to the purely local mechanisms. Accounting
tight bounds, especially for multi-message protocols, is complicated by the
complexity brought by the shuffler. The recently proposed Fourier Accountant
for evaluating $(\varepsilon,\delta)$-differential privacy guarantees has been
shown to give tighter bounds than commonly used methods for non-adaptive
compositions of various complex mechanisms. In this paper we show how to
compute tight privacy bounds using the Fourier Accountant for multi-message
versions of several ubiquitous mechanisms in the shuffle model and demonstrate
looseness of the existing bounds in the literature.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00479</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00479</id><submitter>Syrine Krichene</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:33:53 GMT</date><size>198kb</size><source_type>D</source_type></version><title>DoT: An efficient Double Transformer for NLP tasks with tables</title><authors>Syrine Krichene, Thomas M\&quot;uller and Julian Martin Eisenschlos</authors><categories>cs.CL</categories><comments>11 pages, 4 figures, to be published in Findings of ACL-IJCNLP 2021</comments><msc-class>68-06</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformer-based approaches have been successfully used to obtain
state-of-the-art accuracy on natural language processing (NLP) tasks with
semi-structured tables. These model architectures are typically deep, resulting
in slow training and inference, especially for long inputs. To improve
efficiency while maintaining a high accuracy, we propose a new architecture,
DoT, a double transformer model, that decomposes the problem into two
sub-tasks: A shallow pruning transformer that selects the top-K tokens,
followed by a deep task-specific transformer that takes as input those K
tokens. Additionally, we modify the task-specific attention to incorporate the
pruning scores. The two transformers are jointly trained by optimizing the
task-specific loss. We run experiments on three benchmarks, including
entailment and question-answering. We show that for a small drop of accuracy,
DoT improves training and inference time by at least 50%. We also show that the
pruning transformer effectively selects relevant tokens enabling the end-to-end
model to maintain similar accuracy as slower baseline models. Finally, we
analyse the pruning and give some insight into its impact on the task model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00480</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00480</id><submitter>Xianzhang Wu</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:34:00 GMT</date><size>619kb</size><source_type>D</source_type></version><title>New Placement Delivery Array Construction for Coded Caching with
  Flexible Memory Size</title><authors>Xianzhang Wu</authors><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Coded caching is an emerging technique to alleviate the network pressure in
data transmissions. In such a scheme, each file in the data center or library
is usually divided into a number of packets to pursue a low broadcasting rate
based on the designed placements at each user's cache. However, the
implementation complexity of this scheme increases as the number of packets
increases. Therefore, it is crucial to design a scheme with a small
subpacketization, while maintaining a relatively low transmission rate. In this
paper, a placement delivery array (PDA) scheme that works with flexible memory
sizes is proposed, and then it is generalized to fit more scenarios. It is
shown that the subpacketization level can be decreased while maintaining the
same number of users, memory ratio and transmission rate.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00485</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00485</id><submitter>Natasha S Sharma</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:40:40 GMT</date><size>4663kb</size></version><title>Robust a-posteriori error estimates for weak Galerkin method for the
  convection-diffusion problem</title><authors>Natasha Sharma</authors><categories>math.NA cs.NA</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a robust a posteriori error estimator for the weak Galerkin finite
element method applied to stationary convection-diffusion equations in the
convection-dominated regime. The estimator provides global upper and lower
bounds of the error %measured in a suitable norm and is robust in the sense
that upper and lower bounds are uniformly bounded with respect to the diffusion
coefficient. Results of the numerical experiments are presented to illustrate
the performance of the error estimator.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00487</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00487</id><submitter>Yingqian Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:45:35 GMT</date><size>9345kb</size><source_type>D</source_type></version><title>Dense Nested Attention Network for Infrared Small Target Detection</title><authors>Boyang Li, Chao Xiao, Longguang Wang, Yingqian Wang, Zaiping Lin, Miao
  Li, Wei An, Yulan Guo</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-frame infrared small target (SIRST) detection aims at separating small
targets from clutter backgrounds. With the advances of deep learning, CNN-based
methods have yielded promising results in generic object detection due to their
powerful modeling capability. However, existing CNN-based methods cannot be
directly applied for infrared small targets since pooling layers in their
networks could lead to the loss of targets in deep layers. To handle this
problem, we propose a dense nested attention network (DNANet) in this paper.
Specifically, we design a dense nested interactive module (DNIM) to achieve
progressive interaction among high-level and low-level features. With the
repeated interaction in DNIM, infrared small targets in deep layers can be
maintained. Based on DNIM, we further propose a cascaded channel and spatial
attention module (CSAM) to adaptively enhance multi-level features. With our
DNANet, contextual information of small targets can be well incorporated and
fully exploited by repeated fusion and enhancement. Moreover, we develop an
infrared small target dataset (namely, NUDT-SIRST) and propose a set of
evaluation metrics to conduct comprehensive performance evaluation. Experiments
on both public and our self-developed datasets demonstrate the effectiveness of
our method. Compared to other state-of-the-art methods, our method achieves
better performance in terms of probability of detection (Pd), false-alarm rate
(Fa), and intersection of union (IoU).
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00489</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00489</id><submitter>Harold Soh</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:49:31 GMT</date><size>3344kb</size><source_type>D</source_type></version><title>Extended Tactile Perception: Vibration Sensing through Tools and Grasped
  Objects</title><authors>Tasbolat Taunyazov, Luar Shui Song, Eugene Lim, Hian Hian See, David
  Lee, Benjamin C.K. Tee, Harold Soh</authors><categories>cs.RO cs.LG</categories><comments>9 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans display the remarkable ability to sense the world through tools and
other held objects. For example, we are able to pinpoint impact locations on a
held rod and tell apart different textures using a rigid probe. In this work,
we consider how we can enable robots to have a similar capacity, i.e., to
embody tools and extend perception using standard grasped objects. We propose
that vibro-tactile sensing using dynamic tactile sensors on the robot fingers,
along with machine learning models, enables robots to decipher contact
information that is transmitted as vibrations along rigid objects. This paper
reports on extensive experiments using the BioTac micro-vibration sensor and a
new event dynamic sensor, the NUSkin, capable of multi-taxel sensing at 4~kHz.
We demonstrate that fine localization on a held rod is possible using our
approach (with errors less than 1 cm on a 20 cm rod). Next, we show that
vibro-tactile perception can lead to reasonable grasp stability prediction
during object handover, and accurate food identification using a standard fork.
We find that multi-taxel vibro-tactile sensing at sufficiently high sampling
rate (above 2 kHz) led to the best performance across the various tasks and
objects. Taken together, our results provides both evidence and guidelines for
using vibro-tactile perception to extend tactile perception, which we believe
will lead to enhanced competency with tools and better physical
human-robot-interaction.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00490</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00490</id><submitter>Yuxuan Sun</submitter><version version="v1"><date>Mon, 31 May 2021 08:55:02 GMT</date><size>1248kb</size><source_type>D</source_type></version><title>Dynamic Scheduling for Over-the-Air Federated Edge Learning with Energy
  Constraints</title><authors>Yuxuan Sun, Sheng Zhou, Zhisheng Niu, Deniz G\&quot;und\&quot;uz</authors><categories>cs.LG cs.IT math.IT</categories><comments>Submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning and wireless communication technologies are jointly
facilitating an intelligent edge, where federated edge learning (FEEL) is a
promising training framework. As wireless devices involved in FEEL are resource
limited in terms of communication bandwidth, computing power and battery
capacity, it is important to carefully schedule them to optimize the training
performance. In this work, we consider an over-the-air FEEL system with analog
gradient aggregation, and propose an energy-aware dynamic device scheduling
algorithm to optimize the training performance under energy constraints of
devices, where both communication energy for gradient aggregation and
computation energy for local training are included. The consideration of
computation energy makes dynamic scheduling challenging, as devices are
scheduled before local training, but the communication energy for over-the-air
aggregation depends on the l2-norm of local gradient, which is known after
local training. We thus incorporate estimation methods into scheduling to
predict the gradient norm. Taking the estimation error into account, we
characterize the performance gap between the proposed algorithm and its offline
counterpart. Experimental results show that, under a highly unbalanced local
data distribution, the proposed algorithm can increase the accuracy by 4.9% on
CIFAR-10 dataset compared with the myopic benchmark, while satisfying the
energy constraints.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00496</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00496</id><submitter>Lili Zhao</submitter><version version="v1"><date>Tue, 1 Jun 2021 13:59:08 GMT</date><size>3637kb</size><source_type>D</source_type></version><title>RAI-Net: Range-Adaptive LiDAR Point Cloud Frame Interpolation Network</title><authors>Lili Zhao, Zezhi Zhu, Xuhu Lin, Xuezhou Guo, Qian Yin, Wenyi Wang,
  Jianwen Chen</authors><categories>eess.IV cs.CV</categories><comments>Accepted by the IEEE International Symposium on Broadband Multimedia
  Systems and Broadcasting 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  LiDAR point cloud frame interpolation, which synthesizes the intermediate
frame between the captured frames, has emerged as an important issue for many
applications. Especially for reducing the amounts of point cloud transmission,
it is by predicting the intermediate frame based on the reference frames to
upsample data to high frame rate ones. However, due to high-dimensional and
sparse characteristics of point clouds, it is more difficult to predict the
intermediate frame for LiDAR point clouds than videos. In this paper, we
propose a novel LiDAR point cloud frame interpolation method, which exploits
range images (RIs) as an intermediate representation with CNNs to conduct the
frame interpolation process. Considering the inherited characteristics of RIs
differ from that of color images, we introduce spatially adaptive convolutions
to extract range features adaptively, while a high-efficient flow estimation
method is presented to generate optical flows. The proposed model then warps
the input frames and range features, based on the optical flows to synthesize
the interpolated frame. Extensive experiments on the KITTI dataset have clearly
demonstrated that our method consistently achieves superior frame interpolation
results with better perceptual quality to that of using state-of-the-art video
frame interpolation methods. The proposed method could be integrated into any
LiDAR point cloud compression systems for inter prediction.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00497</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00497</id><submitter>Li Su</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:00:14 GMT</date><size>45kb</size></version><title>Omnizart: A General Toolbox for Automatic Music Transcription</title><authors>Yu-Te Wu, Yin-Jyun Luo, Tsung-Ping Chen, I-Chieh Wei, Jui-Yang Hsu,
  Yi-Chin Chuang, Li Su</authors><categories>cs.SD cs.AI eess.AS</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  We present and release Omnizart, a new Python library that provides a
streamlined solution to automatic music transcription (AMT). Omnizart
encompasses modules that construct the life-cycle of deep learning-based AMT,
and is designed for ease of use with a compact command-line interface. To the
best of our knowledge, Omnizart is the first transcription toolkit which offers
models covering a wide class of instruments ranging from solo, instrument
ensembles, percussion instruments to vocal, as well as models for chord
recognition and beat/downbeat tracking, two music information retrieval (MIR)
tasks highly related to AMT.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00498</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00498</id><submitter>Saurav Samantaray</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:02:40 GMT</date><size>883kb</size><source_type>D</source_type></version><title>A Unified Asymptotic Preserving and Well-balanced Scheme for the Euler
  System with Multiscale Relaxation</title><authors>K. R. Arun, M. Krishnan, S. Samantaray</authors><categories>math.NA cs.NA</categories><msc-class>Primary 35L45, 35L60, 35L65, 35L67, Secondary 65M06, 65M08</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The design and analysis of a unified asymptotic preserving (AP) and
well-balanced scheme for the Euler Equations with gravitational and frictional
source terms is presented in this paper. The asymptotic behaviour of the Euler
system in the limit of zero Mach and Froude numbers, and large friction is
characterised by an additional scaling parameter. Depending on the values of
this parameter, the Euler system relaxes towards a hyperbolic or a parabolic
limit equation. Standard Implicit-Explicit Runge-Kutta schemes are incapable of
switching between these asymptotic regimes. We propose a time
semi-discretisation to obtain a unified scheme which is AP for the two
different limits. A further reformulation of the semi-implicit scheme can be
recast as a fully-explicit method in which the mass update contains both
hyperbolic and parabolic fluxes. A space-time fully-discrete scheme is derived
using a finite volume framework. A hydrostatic reconstruction strategy, an
upwinding of the sources at the interfaces, and a careful choice of the central
discretisation of the parabolic fluxes are used to achieve the well-balancing
property for hydrostatic steady states. Results of several numerical case
studies are presented to substantiate the theoretical claims and to verify the
robustness of the scheme.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00501</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00501</id><submitter>Fuhui Zhou</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:08:20 GMT</date><size>811kb</size><source_type>D</source_type></version><title>A Unified Cognitive Learning Framework for Adapting to Dynamic
  Environment and Tasks</title><authors>Qihui Wu, Tianchen Ruan, Fuhui Zhou, Yang Huang, Fan Xu, Shijin Zhao,
  Ya Liu, and Xuyang Huang</authors><categories>cs.AI eess.SP</categories><comments>This paper has been submitted to IEEE Wireless Communications
  Magazine(minor revision)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many machine learning frameworks have been proposed and used in wireless
communications for realizing diverse goals. However, their incapability of
adapting to the dynamic wireless environment and tasks and of self-learning
limit their extensive applications and achievable performance. Inspired by the
great flexibility and adaptation of primate behaviors due to the brain
cognitive mechanism, a unified cognitive learning (CL) framework is proposed
for the dynamic wireless environment and tasks. The mathematical framework for
our proposed CL is established. Using the public and authoritative dataset, we
demonstrate that our proposed CL framework has three advantages, namely, the
capability of adapting to the dynamic environment and tasks, the self-learning
capability and the capability of 'good money driving out bad money' by taking
modulation recognition as an example. The proposed CL framework can enrich the
current learning frameworks and widen the applications.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00502</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00502</id><submitter>Jason Bernard</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:09:18 GMT</date><size>1695kb</size></version><title>Automated Grading of Anatomical Objective Structured Practical Exams
  Using Decision Trees</title><authors>Jason Bernard, Ranil Sonnadara, Anthony N. Saraco, Josh P. Mitchell,
  Alex B. Bak, Ilana Bayer, Bruce C. Wainman</authors><categories>cs.LG</categories><comments>33 pages, 3 figures, 2 tables. Under review at Anatomical Education
  Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An Objective Structured Practical Examination (OSPE) is an effective and
robust, but resource-intensive, means of evaluating anatomical knowledge. Since
most OSPEs employ short answer or fill-in-the-blank style questions, the format
requires many people familiar with the content to mark the exams. However, the
increasing prevalence of online delivery for anatomy and physiology courses
could result in students losing the OSPE practice that they would receive in
face-to-face learning sessions. The purpose of this study was to test the
accuracy of Decision Trees (DTs) in marking OSPE questions as a potential first
step to creating an intelligent, online OSPE tutoring system. The study used
the results of the winter 2020 semester final OSPE from McMaster University's
anatomy and physiology course in the Faculty of Health Sciences (HTHSCI
2FF3/2LL3/1D06) as the data set. Ninety percent of the data set was used in a
10-fold validation algorithm to train a DT for each of the 54 questions. Each
DT was comprised of unique words that appeared in correct, student-written
answers. The remaining 10% of the data set was marked by the generated DTs.
When the answers marked by the DT were compared to the answers marked by staff
and faculty, the DT achieved an average accuracy of 94.49% across all 54
questions. This suggests that machine learning algorithms such as DTs are a
highly effective option for OSPE grading and are suitable for the development
of an intelligent, online OSPE tutoring system.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00504</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00504</id><submitter>Zafer Dogan</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:10:12 GMT</date><size>3024kb</size><source_type>D</source_type></version><title>Two-stage domain adapted training for better generalization in
  real-world image restoration and super-resolution</title><authors>Cansu Korkmaz, A.Murat Tekalp, Zafer Dogan</authors><categories>eess.IV cs.LG eess.SP</categories><comments>Accepted for publication in IEEE ICIP 2021 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that in inverse problems, end-to-end trained networks
overfit the degradation model seen in the training set, i.e., they do not
generalize to other types of degradations well. Recently, an approach to first
map images downsampled by unknown filters to bicubicly downsampled look-alike
images was proposed to successfully super-resolve such images. In this paper,
we show that any inverse problem can be formulated by first mapping the input
degraded images to an intermediate domain, and then training a second network
to form output images from these intermediate images. Furthermore, the best
intermediate domain may vary according to the task. Our experimental results
demonstrate that this two-stage domain-adapted training strategy does not only
achieve better results on a given class of unknown degradations but can also
generalize to other unseen classes of degradations better.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00506</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00506</id><submitter>Gencer Sumbul</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:11:08 GMT</date><size>874kb</size><source_type>D</source_type></version><title>A Novel Graph-Theoretic Deep Representation Learning Method for
  Multi-Label Remote Sensing Image Retrieval</title><authors>Gencer Sumbul and Beg\&quot;um Demir</authors><categories>cs.CV</categories><comments>Accepted at IEEE International Geoscience and Remote Sensing
  Symposium (IGARSS) 2021. Our code is available at
  https://git.tu-berlin.de/rsim/GT-DRL-CBIR</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a novel graph-theoretic deep representation learning
method in the framework of multi-label remote sensing (RS) image retrieval
problems. The proposed method aims to extract and exploit multi-label
co-occurrence relationships associated to each RS image in the archive. To this
end, each training image is initially represented with a graph structure that
provides region-based image representation combining both local information and
the related spatial organization. Unlike the other graph-based methods, the
proposed method contains a novel learning strategy to train a deep neural
network for automatically predicting a graph structure of each RS image in the
archive. This strategy employs a region representation learning loss function
to characterize the image content based on its multi-label co-occurrence
relationship. Experimental results show the effectiveness of the proposed
method for retrieval problems in RS compared to state-of-the-art deep
representation learning methods. The code of the proposed method is publicly
available at https://git.tu-berlin.de/rsim/GT-DRL-CBIR .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00507</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00507</id><submitter>Zheng Ye</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:11:17 GMT</date><size>6550kb</size><source_type>D</source_type></version><title>Towards Quantifiable Dialogue Coherence Evaluation</title><authors>Zheng Ye, Liucun Lu, Lishan Huang, Liang Lin, Xiaodan Liang</authors><categories>cs.CL</categories><comments>Long paper; ACL2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic dialogue coherence evaluation has attracted increasing attention
and is crucial for developing promising dialogue systems. However, existing
metrics have two major limitations: (a) they are mostly trained in a simplified
two-level setting (coherent vs. incoherent), while humans give Likert-type
multi-level coherence scores, dubbed as &quot;quantifiable&quot;; (b) their predicted
coherence scores cannot align with the actual human rating standards due to the
absence of human guidance during training. To address these limitations, we
propose Quantifiable Dialogue Coherence Evaluation (QuantiDCE), a novel
framework aiming to train a quantifiable dialogue coherence metric that can
reflect the actual human rating standards. Specifically, QuantiDCE includes two
training stages, Multi-Level Ranking (MLR) pre-training and Knowledge
Distillation (KD) fine-tuning. During MLR pre-training, a new MLR loss is
proposed for enabling the model to learn the coarse judgement of coherence
degrees. Then, during KD fine-tuning, the pretrained model is further finetuned
to learn the actual human rating standards with only very few human-annotated
data. To advocate the generalizability even with limited fine-tuning data, a
novel KD regularization is introduced to retain the knowledge learned at the
pre-training stage. Experimental results show that the model trained by
QuantiDCE presents stronger correlations with human judgements than the other
state-of-the-art metrics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00508</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00508</id><submitter>Alireza Farhadi</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:11:18 GMT</date><size>747kb</size><source_type>D</source_type></version><title>Differentially Private Densest Subgraph</title><authors>Alireza Farhadi, MohammadTaghi Hajiaghayi and Elaine Shi</authors><categories>cs.CR cs.DS cs.GT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Given a graph, the densest subgraph problem asks for a set of vertices such
that the average degree among these vertices is maximized. Densest subgraph has
numerous applications in learning, e.g., community detection in social
networks, link spam detection, correlation mining, bioinformatics, and so on.
Although there are efficient algorithms that output either exact or approximate
solutions to the densest subgraph problem, existing algorithms may violate the
privacy of the individuals in the network, e.g., leaking the
existence/non-existence of edges.
  In this paper, we study the densest subgraph problem in the framework of the
differential privacy, and we derive the first upper and lower bounds for this
problem. We show that there exists a linear-time $\epsilon$-differentially
private algorithm that finds a $2$-approximation of the densest subgraph with
an extra poly-logarithmic additive error. Our algorithm not only reports the
approximate density of the densest subgraph, but also reports the vertices that
form the dense subgraph.
  Our upper bound almost matches the famous $2$-approximation by Charikar both
in performance and in approximation ratio, but we additionally achieve
differential privacy. In comparison with Charikar's algorithm, our algorithm
has an extra poly-logarithmic additive error. We partly justify the additive
error with a new lower bound, showing that for any differentially private
algorithm that provides a constant-factor approximation, a sub-logarithmic
additive error is inherent.
  We also practically study our differentially private algorithm on real-world
graphs, and we show that in practice the algorithm finds a solution which is
very close to the optimal
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00509</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00509</id><submitter>Peng Sun</submitter><version version="v1"><date>Sat, 29 May 2021 11:50:42 GMT</date><size>323kb</size><source_type>D</source_type></version><title>Towards Efficient Compressive Data Collection in the Internet of Things</title><authors>Peng Sun, Liantao Wu and Zhi Wang</authors><categories>cs.IT eess.SP math.IT</categories><comments>6 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  It is of paramount importance to achieve efficient data collection in the
Internet of Things (IoT). Due to the inherent structural properties (e.g.,
sparsity) existing in many signals of interest, compressive sensing (CS)
technology has been extensively used for data collection in IoT to improve both
accuracy and energy efficiency. Apart from the existing works which leverage CS
as a channel coding scheme to deal with data loss during transmission, some
recent results have started to employ CS as a source coding strategy. The
frequently used projection matrices in these CS-based source coding schemes
include dense random matrices (e.g., Gaussian matrices or Bernoulli matrices)
and structured matrices (e.g., Toeplitz matrices). However, these matrices are
either difficult to be implemented on resource-constrained IoT sensor nodes or
have limited applicability. To address these issues, in this paper, we design a
novel simple and efficient projection matrix, named sparse Gaussian matrix,
which is easy and resource-saving to be implemented in practical IoT
applications. We conduct both theoretical analysis and experimental evaluation
of the designed sparse Gaussian matrix. The results demonstrate that employing
the designed projection matrix to perform CS-based source coding could
significantly save time and memory cost while ensuring satisfactory signal
recovery performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00510</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00510</id><submitter>Deepanway Ghosal</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:14:46 GMT</date><size>1529kb</size><source_type>D</source_type></version><title>CIDER: Commonsense Inference for Dialogue Explanation and Reasoning</title><authors>Deepanway Ghosal and Pengfei Hong and Siqi Shen and Navonil Majumder
  and Rada Mihalcea and Soujanya Poria</authors><categories>cs.CL cs.AI cs.LG</categories><comments>SIGDIAL 2021</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Commonsense inference to understand and explain human language is a
fundamental research problem in natural language processing. Explaining human
conversations poses a great challenge as it requires contextual understanding,
planning, inference, and several aspects of reasoning including causal,
temporal, and commonsense reasoning. In this work, we introduce CIDER -- a
manually curated dataset that contains dyadic dialogue explanations in the form
of implicit and explicit knowledge triplets inferred using contextual
commonsense inference. Extracting such rich explanations from conversations can
be conducive to improving several downstream applications. The annotated
triplets are categorized by the type of commonsense knowledge present (e.g.,
causal, conditional, temporal). We set up three different tasks conditioned on
the annotated dataset: Dialogue-level Natural Language Inference, Span
Extraction, and Multi-choice Span Selection. Baseline results obtained with
transformer-based models reveal that the tasks are difficult, paving the way
for promising future research. The dataset and the baseline implementations are
publicly available at https://github.com/declare-lab/CIDER.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00512</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00512</id><submitter>Lukas Heppe</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:16:41 GMT</date><size>6921kb</size><source_type>D</source_type></version><title>The Care Label Concept: A Certification Suite for Trustworthy and
  Resource-Aware Machine Learning</title><authors>Katharina Morik and Helena Kotthaus and Lukas Heppe and Danny Heinrich
  and Raphael Fischer and Andreas Pauly and Nico Piatkowski</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning applications have become ubiquitous. This has led to an
increased effort of making machine learning trustworthy. Explainable and fair
AI have already matured. They address knowledgeable users and application
engineers. For those who do not want to invest time into understanding the
method or the learned model, we offer care labels: easy to understand at a
glance, allowing for method or model comparisons, and, at the same time,
scientifically well-based. On one hand, this transforms descriptions as given
by, e.g., Fact Sheets or Model Cards, into a form that is well-suited for
end-users. On the other hand, care labels are the result of a certification
suite that tests whether stated guarantees hold. In this paper, we present two
experiments with our certification suite. One shows the care labels for
configurations of Markov random fields (MRFs). Based on the underlying theory
of MRFs, each choice leads to its specific rating of static properties like,
e.g., expressivity and reliability. In addition, the implementation is tested
and resource consumption is measured yielding dynamic properties. This
two-level procedure is followed by another experiment certifying deep neural
network (DNN) models. There, we draw the static properties from the literature
on a particular model and data set. At the second level, experiments are
generated that deliver measurements of robustness against certain attacks. We
illustrate this by ResNet-18 and MobileNetV3 applied to ImageNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00514</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00514</id><submitter>Lampros Gavalakis</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:17:13 GMT</date><size>23kb</size></version><title>Entropy and the Discrete Central Limit Theorem</title><authors>Lampros Gavalakis, Ioannis Kontoyiannis</authors><categories>math.PR cs.IT math.IT</categories><comments>15 pages</comments><msc-class>60F05, 94A17, 60E15</msc-class><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  A strengthened version of the central limit theorem for discrete random
variables is established, relying only on information-theoretic tools and
elementary arguments. It is shown that the relative entropy between the
standardised sum of $n$ independent and identically distributed lattice random
variables and an appropriately discretised Gaussian, vanishes as $n\to\infty$.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00515</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00515</id><submitter>Pichao Wang</submitter><version version="v1"><date>Fri, 28 May 2021 06:49:10 GMT</date><size>6266kb</size><source_type>D</source_type></version><title>KVT: k-NN Attention for Boosting Vision Transformers</title><authors>Pichao Wang and Xue Wang and Fan Wang and Ming Lin and Shuning Chang
  and Wen Xie and Hao Li and Rong Jin</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Convolutional Neural Networks (CNNs) have dominated computer vision for
years, due to its ability in capturing locality and translation invariance.
Recently, many vision transformer architectures have been proposed and they
show promising performance. A key component in vision transformers is the
fully-connected self-attention which is more powerful than CNNs in modelling
long range dependencies. However, since the current dense self-attention uses
all image patches (tokens) to compute attention matrix, it may neglect locality
of images patches and involve noisy tokens (e.g., clutter background and
occlusion), leading to a slow training process and potentially degradation of
performance. To address these problems, we propose a sparse attention scheme,
dubbed k-NN attention, for boosting vision transformers. Specifically, instead
of involving all the tokens for attention matrix calculation, we only select
the top-k similar tokens from the keys for each query to compute the attention
map. The proposed k-NN attention naturally inherits the local bias of CNNs
without introducing convolutional operations, as nearby tokens tend to be more
similar than others. In addition, the k-NN attention allows for the exploration
of long range correlation and at the same time filter out irrelevant tokens by
choosing the most similar tokens from the entire image. Despite its simplicity,
we verify, both theoretically and empirically, that $k$-NN attention is
powerful in distilling noise from input tokens and in speeding up training.
Extensive experiments are conducted by using ten different vision transformer
architectures to verify that the proposed k-NN attention can work with any
existing transformer architectures to improve its prediction performance.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00517</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00517</id><submitter>Zhou Tianze</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:22:57 GMT</date><size>5809kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 06:16:03 GMT</date><size>5809kb</size><source_type>D</source_type></version><version version="v3"><date>Thu, 3 Jun 2021 09:30:05 GMT</date><size>5810kb</size><source_type>D</source_type></version><title>Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit
  Assignment</title><authors>Tianze Zhou, Fubiao Zhang, Kun Shao, Kai Li, Wenhan Huang, Jun Luo,
  Weixun Wang, Yaodong Yang, Hangyu Mao, Bin Wang, Dong Li, Wulong Liu, Jianye
  Hao</authors><categories>cs.AI</categories><comments>12 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Extending transfer learning to cooperative multi-agent reinforcement learning
(MARL) has recently received much attention. In contrast to the single-agent
setting, the coordination indispensable in cooperative MARL constrains each
agent's policy. However, existing transfer methods focus exclusively on agent
policy and ignores coordination knowledge. We propose a new architecture that
realizes robust coordination knowledge transfer through appropriate
decomposition of the overall coordination into several coordination patterns.
We use a novel mixing network named level-adaptive QTransformer
(LA-QTransformer) to realize agent coordination that considers credit
assignment, with appropriate coordination patterns for different agents
realized by a novel level-adaptive Transformer (LA-Transformer) dedicated to
the transfer of coordination knowledge. In addition, we use a novel agent
network named Population Invariant agent with Transformer (PIT) to realize the
coordination transfer in more varieties of scenarios. Extensive experiments in
StarCraft II micro-management show that LA-QTransformer together with PIT
achieves superior performance compared with state-of-the-art baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00524</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00524</id><submitter>Marina Delianidi</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:40:28 GMT</date><size>146kb</size><source_type>D</source_type></version><title>Student Performance Prediction Using Dynamic Neural Models</title><authors>Marina Delianidi, Konstantinos Diamantaras, George Chrysogonidis,
  Vasileios Nikiforidis</authors><categories>cs.LG cs.AI</categories><comments>9 pages, 4 figures, to be published in EDM 2021: the 14th
  International Conference on Educational Data Mining, June 29 - July 2, 2021,
  Paris, France</comments><acm-class>I.2.6; K.3.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of predicting the correctness of the student's
response on the next exam question based on their previous interactions in the
course of their learning and evaluation process. We model the student
performance as a dynamic problem and compare the two major classes of dynamic
neural architectures for its solution, namely the finite-memory Time Delay
Neural Networks (TDNN) and the potentially infinite-memory Recurrent Neural
Networks (RNN). Since the next response is a function of the knowledge state of
the student and this, in turn, is a function of their previous responses and
the skills associated with the previous questions, we propose a two-part
network architecture. The first part employs a dynamic neural network (either
TDNN or RNN) to trace the student knowledge state. The second part applies on
top of the dynamic part and it is a multi-layer feed-forward network which
completes the classification task of predicting the student response based on
our estimate of the student knowledge state. Both input skills and previous
responses are encoded using different embeddings. Regarding the skill
embeddings we tried two different initialization schemes using (a) random
vectors and (b) pretrained vectors matching the textual descriptions of the
skills. Our experiments show that the performance of the RNN approach is better
compared to the TDNN approach in all datasets that we have used. Also, we show
that our RNN architecture outperforms the state-of-the-art models in four out
of five datasets. It is worth noting that the TDNN approach also outperforms
the state of the art models in four out of five datasets, although it is
slightly worse than our proposed RNN approach. Finally, contrary to our
expectations, we find that the initialization of skill embeddings using
pretrained vectors offers practically no advantage over random initialization.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00526</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00526</id><submitter>Zhenglun Kong</submitter><version version="v1"><date>Sun, 30 May 2021 16:19:11 GMT</date><size>2326kb</size><source_type>D</source_type></version><title>A Compression-Compilation Framework for On-mobile Real-time BERT
  Applications</title><authors>Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen
  Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang</authors><categories>cs.LG cs.AI</categories><comments>Accepted to IJCAI-21 Demonstrations Track. arXiv admin note:
  substantial text overlap with arXiv:2009.06823</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformer-based deep learning models have increasingly demonstrated high
accuracy on many natural language processing (NLP) tasks. In this paper, we
propose a compression-compilation co-design framework that can guarantee the
identified model to meet both resource and real-time specifications of mobile
devices. Our framework applies a compiler-aware neural architecture
optimization method (CANAO), which can generate the optimal compressed model
that balances both accuracy and latency. We are able to achieve up to 7.8x
speedup compared with TensorFlow-Lite with only minor accuracy loss. We present
two types of BERT applications on mobile devices: Question Answering (QA) and
Text Generation. Both can be executed in real-time with latency as low as 45ms.
Videos for demonstrating the framework can be found on
https://www.youtube.com/watch?v=_WIRvK_2PZI
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00528</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00528</id><submitter>Beate Sick</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:43:47 GMT</date><size>832kb</size><source_type>D</source_type></version><title>Transformation Models for Flexible Posteriors in Variational Bayes</title><authors>Sefan H\&quot;ortling, Daniel Dold, Oliver D\&quot;urr, Beate Sick</authors><categories>stat.ML cs.LG</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main challenge in Bayesian models is to determine the posterior for the
model parameters. Already, in models with only one or few parameters, the
analytical posterior can only be determined in special settings. In Bayesian
neural networks, variational inference is widely used to approximate
difficult-to-compute posteriors by variational distributions. Usually,
Gaussians are used as variational distributions (Gaussian-VI) which limits the
quality of the approximation due to their limited flexibility. Transformation
models on the other hand are flexible enough to fit any distribution. Here we
present transformation model-based variational inference (TM-VI) and
demonstrate that it allows to accurately approximate complex posteriors in
models with one parameter and also works in a mean-field fashion for
multi-parameter models like neural networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00531</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00531</id><submitter>Parvaneh Janbakhshi</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:48:08 GMT</date><size>182kb</size><source_type>D</source_type></version><title>Supervised Speech Representation Learning for Parkinson's Disease
  Classification</title><authors>Parvaneh Janbakhshi and Ina Kodrasi</authors><categories>eess.AS cs.SD</categories><comments>Submitted to ITG Conference on Speech Communication 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently proposed automatic pathological speech classification techniques use
unsupervised auto-encoders to obtain a high-level abstract representation of
speech. Since these representations are learned based on reconstructing the
input, there is no guarantee that they are robust to pathology-unrelated cues
such as speaker identity information. Further, these representations are not
necessarily discriminative for pathology detection. In this paper, we exploit
supervised auto-encoders to extract robust and discriminative speech
representations for Parkinson's disease classification. To reduce the influence
of speaker variabilities unrelated to pathology, we propose to obtain speaker
identity-invariant representations by adversarial training of an auto-encoder
and a speaker identification task. To obtain a discriminative representation,
we propose to jointly train an auto-encoder and a pathological speech
classifier. Experimental results on a Spanish database show that the proposed
supervised representation learning methods yield more robust and discriminative
representations for automatically classifying Parkinson's disease speech,
outperforming the baseline unsupervised representation learning system.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00532</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00532</id><submitter>Yuxiao Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:48:50 GMT</date><size>1190kb</size><source_type>D</source_type></version><title>Topology and Admittance Estimation: Precision Limits and Algorithms</title><authors>Yuxiao Liu, Ning Zhang, Qingchun Hou, Audun Botterud, Chongqing Kang</authors><categories>cs.IT cs.SY eess.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution grid topology and admittance information are essential for
system planning, operation, and protection. In many distribution grids, missing
or inaccurate topology and admittance data call for efficient estimation
methods. However, measurement data may be insufficient or contaminated with
large noise, which will introduce fundamental limits to the estimation
accuracy. This work explores the theoretical precision limits of the topology
and admittance estimation (TAE) problem, with different measurement devices,
noise levels, and the number of measurements. On this basis, we propose a
conservative progressive self-adaptive (CPS) algorithm to estimate the topology
and admittance. Results on IEEE 33 and 141-bus systems validate that the
proposed CPS method can approach the theoretical precision limits under various
measurement settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00534</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00534</id><submitter>Diego Rodriguez</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:51:12 GMT</date><size>2061kb</size><source_type>D</source_type></version><title>DeepWalk: Omnidirectional Bipedal Gait by Deep Reinforcement Learning</title><authors>Diego Rodriguez and Sven Behnke</authors><categories>cs.RO</categories><comments>In: Proceedings of the International Conference on Robotics and
  Automation (ICRA) 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bipedal walking is one of the most difficult but exciting challenges in
robotics. The difficulties arise from the complexity of high-dimensional
dynamics, sensing and actuation limitations combined with real-time and
computational constraints. Deep Reinforcement Learning (DRL) holds the promise
to address these issues by fully exploiting the robot dynamics with minimal
craftsmanship. In this paper, we propose a novel DRL approach that enables an
agent to learn omnidirectional locomotion for humanoid (bipedal) robots.
Notably, the locomotion behaviors are accomplished by a single control policy
(a single neural network). We achieve this by introducing a new curriculum
learning method that gradually increases the task difficulty by scheduling
target velocities. In addition, our method does not require reference motions
which facilities its application to robots with different kinematics, and
reduces the overall complexity. Finally, different strategies for sim-to-real
transfer are presented which allow us to transfer the learned policy to a real
humanoid robot.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00537</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00537</id><submitter>Longhui Wei</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:52:36 GMT</date><size>4695kb</size><source_type>D</source_type></version><title>Exploring the Diversity and Invariance in Yourself for Visual
  Pre-Training Task</title><authors>Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, Qi Tian</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, self-supervised learning methods have achieved remarkable success
in visual pre-training task. By simply pulling the different augmented views of
each image together or other novel mechanisms, they can learn much unsupervised
knowledge and significantly improve the transfer performance of pre-training
models. However, these works still cannot avoid the representation collapse
problem, i.e., they only focus on limited regions or the extracted features on
totally different regions inside each image are nearly the same. Generally,
this problem makes the pre-training models cannot sufficiently describe the
multi-grained information inside images, which further limits the upper bound
of their transfer performance. To alleviate this issue, this paper introduces a
simple but effective mechanism, called Exploring the Diversity and Invariance
in Yourself E-DIY. By simply pushing the most different regions inside each
augmented view away, E-DIY can preserve the diversity of extracted region-level
features. By pulling the most similar regions from different augmented views of
the same image together, E-DIY can ensure the robustness of region-level
features. Benefited from the above diversity and invariance exploring
mechanism, E-DIY maximally extracts the multi-grained visual information inside
each image. Extensive experiments on downstream tasks demonstrate the
superiority of our proposed approach, e.g., there are 2.1% improvements
compared with the strong baseline BYOL on COCO while fine-tuning Mask R-CNN
with the R50-C4 backbone and 1X learning schedule.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00538</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00538</id><submitter>Laurens Arp</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:52:54 GMT</date><size>249kb</size><source_type>D</source_type></version><title>Value propagation-based spatio-temporal interpolation inspired by Markov
  reward processes</title><authors>Laurens Arp, Mitra Baratchi, Holger Hoos</authors><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Given the common problem of missing data in real-world applications from
various fields, such as remote sensing, ecology and meteorology, the
interpolation of missing spatial and spatio-temporal data can be of tremendous
value. Existing methods for spatial interpolation, most notably Gaussian
processes and spatial autoregressive models, tend to suffer from (a) a
trade-off between modelling local or global spatial interaction, (b) the
assumption there is only one possible path between two points, and (c) the
assumption of homogeneity of intermediate locations between points. Addressing
these issues, we propose a value propagation method, inspired by Markov reward
processes (MRPs), as a spatial interpolation method, and introduce two variants
thereof: (i) a static discount (SD-MRP) and (ii) a data-driven weight
prediction (WP-MRP) variant. Both these interpolation variants operate locally,
while implicitly accounting for global spatial relationships in the entire
system through recursion. We evaluated our proposed methods by comparing the
mean absolute errors and running times of interpolated grid cells to those of 7
common baselines. Our analysis involved detailed experiments on two synthetic
and two real-world datasets over 44 total experimental conditions. Experimental
results show the competitive advantage of MRP interpolation on real-world data,
as the average performance of SD-MRP on real-world data under all experimental
conditions was ranked significantly higher than that of all other methods,
followed by WP-MRP. On synthetic data, we show that WP-MRP can perform better
than SD-MRP given sufficiently informative features. We further found that,
even in cases where our methods had no significant advantage over baselines
numerically, our methods preserved the spatial structure of the target grid
better than the baselines.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00541</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00541</id><submitter>Fabio De Gaspari</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:53:38 GMT</date><size>235kb</size><source_type>D</source_type></version><title>MalPhase: Fine-Grained Malware Detection Using Network Flow Data</title><authors>Michal Piskozub, Fabio De Gaspari, Frederick Barr-Smith, Luigi V.
  Mancini, Ivan Martinovic</authors><categories>cs.CR cs.LG cs.NI</categories><comments>Paper accepted for publication at ACM AsiaCCS 2021</comments><doi>10.1145/3433210.3453101</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Economic incentives encourage malware authors to constantly develop new,
increasingly complex malware to steal sensitive data or blackmail individuals
and companies into paying large ransoms. In 2017, the worldwide economic impact
of cyberattacks is estimated to be between 445 and 600 billion USD, or 0.8% of
global GDP. Traditionally, one of the approaches used to defend against malware
is network traffic analysis, which relies on network data to detect the
presence of potentially malicious software. However, to keep up with increasing
network speeds and amount of traffic, network analysis is generally limited to
work on aggregated network data, which is traditionally challenging and yields
mixed results. In this paper we present MalPhase, a system that was designed to
cope with the limitations of aggregated flows. MalPhase features a multi-phase
pipeline for malware detection, type and family classification. The use of an
extended set of network flow features and a simultaneous multi-tier
architecture facilitates a performance improvement for deep learning models,
making them able to detect malicious flows (&gt;98% F1) and categorize them to a
respective malware type (&gt;93% F1) and family (&gt;91% F1). Furthermore, the use of
robust features and denoising autoencoders allows MalPhase to perform well on
samples with varying amounts of benign traffic mixed in. Finally, MalPhase
detects unseen malware samples with performance comparable to that of known
samples, even when interlaced with benign flows to reflect realistic network
environments.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00543</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00543</id><submitter>Amrit Singh Bedi</submitter><version version="v1"><date>Sat, 29 May 2021 19:05:48 GMT</date><size>7457kb</size><source_type>D</source_type></version><title>MARL with General Utilities via Decentralized Shadow Reward Actor-Critic</title><authors>Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, and Alec Koppel</authors><categories>stat.ML cs.AI cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We posit a new mechanism for cooperation in multi-agent reinforcement
learning (MARL) based upon any nonlinear function of the team's long-term
state-action occupancy measure, i.e., a \emph{general utility}. This subsumes
the cumulative return but also allows one to incorporate risk-sensitivity,
exploration, and priors. % We derive the {\bf D}ecentralized {\bf S}hadow
Reward {\bf A}ctor-{\bf C}ritic (DSAC) in which agents alternate between policy
evaluation (critic), weighted averaging with neighbors (information mixing),
and local gradient updates for their policy parameters (actor). DSAC augments
the classic critic step by requiring agents to (i) estimate their local
occupancy measure in order to (ii) estimate the derivative of the local utility
with respect to their occupancy measure, i.e., the &quot;shadow reward&quot;. DSAC
converges to $\epsilon$-stationarity in $\mathcal{O}(1/\epsilon^{2.5})$
(Theorem \ref{theorem:final}) or faster $\mathcal{O}(1/\epsilon^{2})$
(Corollary \ref{corollary:communication}) steps with high probability,
depending on the amount of communications. We further establish the
non-existence of spurious stationary points for this problem, that is, DSAC
finds the globally optimal policy (Corollary \ref{corollary:global}).
Experiments demonstrate the merits of goals beyond the cumulative return in
cooperative MARL.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00545</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00545</id><submitter>Victor Veitch</submitter><version version="v1"><date>Mon, 31 May 2021 14:39:38 GMT</date><size>779kb</size><source_type>D</source_type></version><version version="v2"><date>Wed, 2 Jun 2021 03:11:24 GMT</date><size>779kb</size><source_type>D</source_type></version><title>Counterfactual Invariance to Spurious Correlations: Why and How to Pass
  Stress Tests</title><authors>Victor Veitch, Alexander D'Amour, Steve Yadlowsky, Jacob Eisenstein</authors><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Informally, a `spurious correlation' is the dependence of a model on some
aspect of the input data that an analyst thinks shouldn't matter. In machine
learning, these have a know-it-when-you-see-it character; e.g., changing the
gender of a sentence's subject changes a sentiment predictor's output. To check
for spurious correlations, we can `stress test' models by perturbing irrelevant
parts of input data and seeing if model predictions change. In this paper, we
study stress testing using the tools of causal inference. We introduce
\emph{counterfactual invariance} as a formalization of the requirement that
changing irrelevant parts of the input shouldn't change model predictions. We
connect counterfactual invariance to out-of-domain model performance, and
provide practical schemes for learning (approximately) counterfactual invariant
predictors (without access to counterfactual examples). It turns out that both
the means and implications of counterfactual invariance depend fundamentally on
the true underlying causal structure of the data. Distinct causal structures
require distinct regularization schemes to induce counterfactual invariance.
Similarly, counterfactual invariance implies different domain shift guarantees
depending on the underlying causal structure. This theory is supported by
empirical results on text classification.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00546</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00546</id><submitter>Joao Marques-Silva</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:57:58 GMT</date><size>32kb</size></version><title>Efficient Explanations With Relevant Sets</title><authors>Yacine Izza, Alexey Ignatiev, Nina Narodytska, Martin C. Cooper, Joao
  Marques-Silva</authors><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent work proposed $\delta$-relevant inputs (or sets) as a probabilistic
explanation for the predictions made by a classifier on a given input.
$\delta$-relevant sets are significant because they serve to relate
(model-agnostic) Anchors with (model-accurate) PI- explanations, among other
explanation approaches. Unfortunately, the computation of smallest size
$\delta$-relevant sets is complete for ${NP}^{PP}$, rendering their computation
largely infeasible in practice. This paper investigates solutions for tackling
the practical limitations of $\delta$-relevant sets. First, the paper
alternatively considers the computation of subset-minimal sets. Second, the
paper studies concrete families of classifiers, including decision trees among
others. For these cases, the paper shows that the computation of subset-minimal
$\delta$-relevant sets is in NP, and can be solved with a polynomial number of
calls to an NP oracle. The experimental evaluation compares the proposed
approach with heuristic explainers for the concrete case of the classifiers
studied in the paper, and confirms the advantage of the proposed solution over
the state of the art.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00548</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00548</id><submitter>Hehu Xie</submitter><version version="v1"><date>Tue, 1 Jun 2021 14:59:13 GMT</date><size>92kb</size><source_type>D</source_type></version><title>Enhanced Error Estimates for Augmented Subspace Method</title><authors>Haikun Dang, Yifan Wang, Hehu Xie and Chenguang Zhou</authors><categories>math.NA cs.NA</categories><comments>19 pages, 24 figures</comments><msc-class>65N30, 65N25, 65L15, 65B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, some enhanced error estimates are derived for the augmented
subspace methods which are designed for solving eigenvalue problems. We will
show that the augmented subspace methods have the second order convergence rate
which is better than the existing results. These sharper estimates provide a
new dependence of convergence rate on the coarse spaces in augmented subspace
methods. These new results are also validated by some numerical examples.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00553</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00553</id><submitter>Zaccharie Ramzi</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:07:34 GMT</date><size>2305kb</size><source_type>D</source_type></version><title>SHINE: SHaring the INverse Estimate from the forward pass for bi-level
  optimization and implicit models</title><authors>Zaccharie Ramzi, Florian Mannel, Shaojie Bai, Jean-Luc Starck,
  Philippe Ciuciu, Thomas Moreau</authors><categories>cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, implicit deep learning has emerged as a method to increase
the depth of deep neural networks. While their training is memory-efficient,
they are still significantly slower to train than their explicit counterparts.
In Deep Equilibrium Models (DEQs), the training is performed as a bi-level
problem, and its computational complexity is partially driven by the iterative
inversion of a huge Jacobian matrix. In this paper, we propose a novel strategy
to tackle this computational bottleneck from which many bi-level problems
suffer. The main idea is to use the quasi-Newton matrices from the forward pass
to efficiently approximate the inverse Jacobian matrix in the direction needed
for the gradient computation. We provide a theorem that motivates using our
method with the original forward algorithms. In addition, by modifying these
forward algorithms, we further provide theoretical guarantees that our method
asymptotically estimates the true implicit gradient. We empirically study this
approach in many settings, ranging from hyperparameter optimization to large
Multiscale DEQs applied to CIFAR and ImageNet. We show that it reduces the
computational cost of the backward pass by up to two orders of magnitude. All
this is achieved while retaining the excellent performance of the original
models in hyperparameter optimization and on CIFAR, and giving encouraging and
competitive results on ImageNet.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00554</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00554</id><submitter>Vegard Antun</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:10:18 GMT</date><size>3562kb</size><source_type>D</source_type></version><title>Recovering wavelet coefficients from binary samples using fast
  transforms</title><authors>Vegard Antun</authors><categories>math.NA cs.IT cs.NA math.IT</categories><msc-class>94A20, 94A11, 42C10, 42C40, 46C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering a signal (function) from finitely many binary or Fourier samples
is one of the core problems in modern medical imaging, and by now there exist a
plethora of methods for recovering a signal from such samples. Examples of
methods, which can utilise wavelet reconstruction, include generalised
sampling, infinite-dimensional compressive sensing, the
parameterised-background data-weak (PBDW) method etc. However, for any of these
methods to be applied in practice, accurate and fast modelling of an $N \times
M$ section of the infinite-dimensional change-of-basis matrix between the
sampling basis (Fourier or Walsh-Hadamard samples) and the wavelet
reconstruction basis is paramount. In this work, we derive an algorithm, which
bypasses the $NM$ storage requirement and the $\mathcal{O}(NM)$ computational
cost of matrix-vector multiplication with this matrix when using Walsh-Hadamard
samples and wavelet reconstruction. The proposed algorithm computes the
matrix-vector multiplication in $\mathcal{O}(N\log N)$ operations and has a
storage requirement of $\mathcal{O}(2^q)$, where $N=2^{dq} M$, (usually $q \in
\{1,2\}$) and $d=1,2$ is the dimension. As matrix-vector multiplications is the
computational bottleneck for iterative algorithms used by the mentioned
reconstruction methods, the proposed algorithm speeds up the reconstruction of
wavelet coefficients from Walsh-Hadamard samples considerably.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00557</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00557</id><submitter>David Ahmedt-Aristizabal</submitter><version version="v1"><date>Thu, 27 May 2021 13:28:24 GMT</date><size>29354kb</size><source_type>D</source_type></version><title>Towards Interpretable Attention Networks for Cervical Cancer Analysis</title><authors>Ruiqi Wang, Mohammad Ali Armin, Simon Denman, Lars Petersson, David
  Ahmedt-Aristizabal</authors><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in deep learning have enabled the development of automated
frameworks for analysing medical images and signals, including analysis of
cervical cancer. Many previous works focus on the analysis of isolated cervical
cells, or do not offer sufficient methods to explain and understand how the
proposed models reach their classification decisions on multi-cell images.
Here, we evaluate various state-of-the-art deep learning models and
attention-based frameworks for the classification of images of multiple
cervical cells. As we aim to provide interpretable deep learning models to
address this task, we also compare their explainability through the
visualization of their gradients. We demonstrate the importance of using images
that contain multiple cells over using isolated single-cell images. We show the
effectiveness of the residual channel attention model for extracting important
features from a group of cells, and demonstrate this model's efficiency for
this classification task. This work highlights the benefits of channel
attention mechanisms in analyzing multiple-cell images for potential relations
and distributions within a group of cells. It also provides interpretable
models to address the classification of cervical cells.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00559</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00559</id><submitter>Alvaro Quintanar</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:18:55 GMT</date><size>5222kb</size><source_type>D</source_type></version><title>Predicting Vehicles Trajectories in Urban Scenarios with Transformer
  Networks and Augmented Information</title><authors>A. Quintanar, D. Fern\'andez-Llorca, I. Parra, R. Izquierdo, M. A.
  Sotelo</authors><categories>cs.CV</categories><comments>This work has been accepted for publication at IEEE Intelligent
  Vehicles Symposium 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the behavior of road users is of vital importance for the
development of trajectory prediction systems. In this context, the latest
advances have focused on recurrent structures, establishing the social
interaction between the agents involved in the scene. More recently, simpler
structures have also been introduced for predicting pedestrian trajectories,
based on Transformer Networks, and using positional information. They allow the
individual modelling of each agent's trajectory separately without any complex
interaction terms. Our model exploits these simple structures by adding
augmented data (position and heading), and adapting their use to the problem of
vehicle trajectory prediction in urban scenarios in prediction horizons up to 5
seconds. In addition, a cross-performance analysis is performed between
different types of scenarios, including highways, intersections and
roundabouts, using recent datasets (inD, rounD, highD and INTERACTION). Our
model achieves state-of-the-art results and proves to be flexible and adaptable
to different types of urban contexts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00561</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00561</id><submitter>Mathijs Schuurmans</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:19:17 GMT</date><size>869kb</size><source_type>D</source_type></version><title>A General Framework for Learning-Based Distributionally Robust MPC of
  Markov Jump Systems</title><authors>Mathijs Schuurmans and Panagiotis Patrinos</authors><categories>math.OC cs.SY eess.SY</categories><comments>Submitted for review. arXiv admin note: text overlap with
  arXiv:2009.04422</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present a data-driven model predictive control (MPC) scheme for
chance-constrained Markov jump systems with unknown switching probabilities.
Using samples of the underlying Markov chain, ambiguity sets of transition
probabilities are estimated which include the true conditional probability
distributions with high probability. These sets are updated online and used to
formulate a time-varying, risk-averse optimal control problem. We prove
recursive feasibility of the resulting MPC scheme and show that the original
chance constraints remain satisfied at every time step. Furthermore, we show
that under sufficient decrease of the confidence levels, the resulting MPC
scheme renders the closed-loop system mean-square stable with respect to the
true-but-unknown distributions, while remaining less conservative than a fully
robust approach. Finally, we show that the data-driven value function converges
to its nominal counterpart as the sample size grows to infinity. We illustrate
our approach on a numerical example.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00563</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00563</id><submitter>Yang Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:20:34 GMT</date><size>16688kb</size><source_type>D</source_type></version><title>IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse</title><authors>Liangliang Shi, Yang Li, Junchi Yan</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite its success, generative adversarial networks (GANs) still suffer from
mode collapse, namely the generator can only map latent variables to a partial
set of modes of the target distribution. In this paper, we analyze and try to
regularize this issue with an independent and identically distributed (IID)
sampling perspective and emphasize that holding the IID property for generation
in target space (i.e. real data) can naturally avoid mode collapse. This is
based on the basic IID assumption for real data in machine learning. However,
though the source samples $\mathbf{z}$ obey IID, the target generation
$G(\mathbf{z})$ may not necessarily be IID. Based on this observation, we
provide a new loss to encourage the closeness between the inverse source from
generation, and a standard Gaussian distribution in the latent space, as a way
of regularizing the generation to be IID. The logic is that the inverse samples
back from target data should also be IID for source distribution. Experiments
on both synthetic and real-world data show the superiority and robustness of
our model.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00564</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00564</id><submitter>Amir Sonee Dr.</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:23:12 GMT</date><size>652kb</size><source_type>D</source_type></version><title>Wireless Federated Learning with Limited Communication and Differential
  Privacy</title><authors>Amir Sonee and Stefano Rini and Yu-Chih Huang</authors><categories>cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the role of dimensionality reduction in efficient
communication and differential privacy (DP) of the local datasets at the remote
users for over-the-air computation (AirComp)-based federated learning (FL)
model. More precisely, we consider the FL setting in which clients are prompted
to train a machine learning model by simultaneous channel-aware and limited
communications with a parameter server (PS) over a Gaussian multiple-access
channel (GMAC), so that transmissions sum coherently at the PS globally aware
of the channel coefficients. For this setting, an algorithm is proposed based
on applying federated stochastic gradient descent (FedSGD) for training the
minimum of a given loss function based on the local gradients,
Johnson-Lindenstrauss (JL) random projection for reducing the dimension of the
local updates, and artificial noise to further aid user's privacy. For this
scheme, our results show that the local DP performance is mainly improved due
to injecting noise of greater variance on each dimension while keeping the
sensitivity of the projected vectors unchanged. This is while the convergence
rate is slowed down compared to the case without dimensionality reduction. As
the performance outweighs for the slower convergence, the trade-off between
privacy and convergence is higher but is shown to lessen in high-dimensional
regime yielding almost the same trade-off with much less communication cost.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00565</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00565</id><submitter>Kris Nikov</submitter><version version="v1"><date>Wed, 26 May 2021 10:04:27 GMT</date><size>3914kb</size><source_type>D</source_type></version><title>Robust and accurate fine-grain power models for embedded systems with no
  on-chip PMU</title><authors>Kris Nikov, Marcos Martinez, Zbigniew Chamski, Kyriakos Georgiou, Jose
  Nunez-Yanez, and Kerstin Eder</authors><categories>cs.DC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a novel approach to event-based power modelling for
embedded platforms that do not have a Performance Monitoring Unit (PMU). The
method involves complementing the target hardware platform, where the physical
power data is measured, with another platform on which the CPU performance
data, that is needed for model generation, can be collected. The methodology is
used to generate accurate fine-grain power models for the the Gaisler GR712RC
dual-core LEON3 fault-tolerant SPARC processor with on-board power sensors and
no PMU. A Kintex UltraScale FPGA is used as the support platform to obtain the
required CPU performance data, by running a soft-core representation of the
dual-core LEON3 as on the GR712RC but with a PMU implementation. Both platforms
execute the same benchmark set and data collection is synchronised using
per-sample timestamps so that the power sensor data from the GR712RC board can
be matched to the PMU data from the FPGA. The synchronised samples are then
processed by the Robust Energy and Power Predictor Selection (REPPS) software
in order to generate power models. The models achieve less than 2% power
estimation error when validated on an industrial use-case and can successfully
follow program phases, which makes them suitable for runtime power profiling.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00566</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00566</id><submitter>Jie Ou</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:30:09 GMT</date><size>4745kb</size><source_type>D</source_type></version><title>Full-Resolution Encoder-Decoder Networks with Multi-Scale Feature Fusion
  for Human Pose Estimation</title><authors>Jie Ou, Mingjian Chen, Hong Wu</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  To achieve more accurate 2D human pose estimation, we extend the successful
encoder-decoder network, simple baseline network (SBN), in three ways. To
reduce the quantization errors caused by the large output stride size, two more
decoder modules are appended to the end of the simple baseline network to get
full output resolution. Then, the global context blocks (GCBs) are added to the
encoder and decoder modules to enhance them with global context features.
Furthermore, we propose a novel spatial-attention-based multi-scale feature
collection and distribution module (SA-MFCD) to fuse and distribute multi-scale
features to boost the pose estimation. Experimental results on the MS COCO
dataset indicate that our network can remarkably improve the accuracy of human
pose estimation over SBN, our network using ResNet34 as the backbone network
can even achieve the same accuracy as SBN with ResNet152, and our networks can
achieve superior results with big backbone networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00569</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00569</id><submitter>Sandip Das</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:32:21 GMT</date><size>6913kb</size></version><title>Optimal virtual PON slicing to support ultra-low latency mesh traffic
  pattern in MEC-based Cloud-RAN</title><authors>Sandip Das, Marco Ruffini</authors><categories>cs.NI</categories><comments>5 pages, 5 Figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  As progressive densification of cells, deployment of Cloud-RAN and \ac{MEC}
are coming into reality to support the ultra-low latency with high reliability
in 5G and beyond, it generates mesh traffic pattern across fronthaul network.
This led to evolution of PON architectural enhancements with virtualization in
order to support such mesh traffic pattern. However, allocation of virtual PON
slices dynamically over such mesh-PON based fronthaul transport is becoming a
research challenge. In this paper, we provide a mixed analytical-iterative
model to compute optimal virtual PON slice allocation, providing mesh access
connectivity with ultra-low end-to-end latency in next-generation MEC-based
Cloud-RAN. Our proposed method can compute optimal virtual PON slice allocation
in timescales compatible with real-time or near real-time operations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00570</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00570</id><submitter>Yongxing Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:33:45 GMT</date><size>3332kb</size><source_type>D</source_type></version><title>Robust design optimisation of continuous flow polymerase chain reaction
  thermal flow systems</title><authors>Yongxing Wang, Hazim A. Hamad, Jochen Voss and Harvey M. Thompson</authors><categories>cs.CE</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper presents an efficient methodology for the robust optimisation of
Continuous Flow Polymerase Chain Reaction (CFPCR) devices. It enables the
effects of uncertainties in device geometry, due to manufacturing tolerances,
on the competing objectives of minimising the temperature deviations within the
CFPCR thermal zones, together with minimising the pressure drop across the
device, to be explored. We first validate that our training data from conjugate
heat transfer simulations of the CFPCR thermal flow problems is noise free and
then combine a deterministic surrogate model, based on the mean of a Gaussian
Process Regression (GPR) simulator, with Polynomial Chaos Expansions (PCE) to
propagate the manufacturing uncertainties in the geometry design variables into
the optimisation outputs. The resultant probabilistic model is used to solve a
series of robust optimisation problems. The influence of the robust problem
formulation and constraints on the design conservatism of the robust optima in
comparison with the corresponding deterministic cases is explored briefly.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00571</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00571</id><submitter>Ivan Fumagalli</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:34:09 GMT</date><size>814kb</size><source_type>D</source_type></version><title>A reduced 3D-0D FSI model of the aortic valve including leaflets
  curvature</title><authors>Ivan Fumagalli</authors><categories>math.NA cs.CE cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present work, we propose a novel lumped-parameter model for the
description of the aortic valve dynamics, including elastic effects associated
to the leaflets' curvature. The introduction of a lumped-parameter model based
on momentum balance entails an easier calibration of the parameter models, that
are instead typically numerous in phenomenological-based models. This model is
coupled with 3D Navier-Stokes equations describing the blood flow, where the
valve surface is represented by a resistive method, and valve leaflets velocity
is taken into consideration. The resulting reduced fluid-structure interaction
problem has a computational cost that is comparable with the solution of a
prescribed-motion fluid dynamics problem. A SUPG-PSPG stabilized finite element
scheme is adopted for the discretization of the coupled problem, and the
computational results show the suitability of the system in representing the
leaflets motion, the blood flow in the ascending aorta, and the pressure jump
across the leaflets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00572</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00572</id><submitter>Jian-Wei Zhang</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:34:30 GMT</date><size>17363kb</size><source_type>D</source_type></version><title>Prior-Enhanced Few-Shot Segmentation with Meta-Prototypes</title><authors>Jian-Wei Zhang, Lei Lv, Yawei Luo, Hao-Zhe Feng, Yi Yang, Wei Chen</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Few-shot segmentation~(FSS) performance has been extensively promoted by
introducing episodic training and class-wise prototypes. However, the FSS
problem remains challenging due to three limitations: (1) Models are distracted
by task-unrelated information; (2) The representation ability of a single
prototype is limited; (3) Class-related prototypes ignore the prior knowledge
of base classes. We propose the Prior-Enhanced network with Meta-Prototypes to
tackle these limitations. The prior-enhanced network leverages the support and
query (pseudo-) labels in feature extraction, which guides the model to focus
on the task-related features of the foreground objects, and suppress much noise
due to the lack of supervised knowledge. Moreover, we introduce multiple
meta-prototypes to encode hierarchical features and learn class-agnostic
structural information. The hierarchical features help the model highlight the
decision boundary and focus on hard pixels, and the structural information
learned from base classes is treated as the prior knowledge for novel classes.
Experiments show that our method achieves the mean-IoU scores of 60.79% and
41.16% on PASCAL-$5^i$ and COCO-$20^i$, outperforming the state-of-the-art
method by 3.49% and 5.64% in the 5-shot setting. Moreover, comparing with
1-shot results, our method promotes 5-shot accuracy by 3.73% and 10.32% on the
above two benchmarks. The source code of our method is available at
https://github.com/Jarvis73/PEMP.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00573</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00573</id><submitter>Hanock Kwak</submitter><version version="v1"><date>Mon, 24 May 2021 03:17:05 GMT</date><size>1350kb</size></version><title>One4all User Representation for Recommender Systems in E-commerce</title><authors>Kyuyong Shin, Hanock Kwak, Kyung-Min Kim, Minkyu Kim, Young-Jin Park,
  Jisu Jeong, Seungjae Jung</authors><categories>cs.IR cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  General-purpose representation learning through large-scale pre-training has
shown promising results in the various machine learning fields. For an
e-commerce domain, the objective of general-purpose, i.e., one for all,
representations would be efficient applications for extensive downstream tasks
such as user profiling, targeting, and recommendation tasks. In this paper, we
systematically compare the generalizability of two learning strategies, i.e.,
transfer learning through the proposed model, ShopperBERT, vs. learning from
scratch. ShopperBERT learns nine pretext tasks with 79.2M parameters from 0.8B
user behaviors collected over two years to produce user embeddings. As a
result, the MLPs that employ our embedding method outperform more complex
models trained from scratch for five out of six tasks. Specifically, the
pre-trained embeddings have superiority over the task-specific supervised
features and the strong baselines, which learn the auxiliary dataset for the
cold-start problem. We also show the computational efficiency and embedding
visualization of the pre-trained features.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00574</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00574</id><submitter>Abdulmalik Alwarafy</submitter><version version="v1"><date>Tue, 25 May 2021 19:41:40 GMT</date><size>21766kb</size><source_type>D</source_type></version><title>Deep Reinforcement Learning for Radio Resource Allocation and Management
  in Next Generation Heterogeneous Wireless Networks: A Survey</title><authors>Abdulmalik Alwarafy, Mohamed Abdallah, Bekir Sait Ciftler, Ala
  Al-Fuqaha and Mounir Hamdi</authors><categories>eess.SP cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Next generation wireless networks are expected to be extremely complex due to
their massive heterogeneity in terms of the types of network architectures they
incorporate, the types and numbers of smart IoT devices they serve, and the
types of emerging applications they support. In such large-scale and
heterogeneous networks (HetNets), radio resource allocation and management
(RRAM) becomes one of the major challenges encountered during system design and
deployment. In this context, emerging Deep Reinforcement Learning (DRL)
techniques are expected to be one of the main enabling technologies to address
the RRAM in future wireless HetNets. In this paper, we conduct a systematic
in-depth, and comprehensive survey of the applications of DRL techniques in
RRAM for next generation wireless networks. Towards this, we first overview the
existing traditional RRAM methods and identify their limitations that motivate
the use of DRL techniques in RRAM. Then, we provide a comprehensive review of
the most widely used DRL algorithms to address RRAM problems, including the
value- and policy-based algorithms. The advantages, limitations, and use-cases
for each algorithm are provided. We then conduct a comprehensive and in-depth
literature review and classify existing related works based on both the radio
resources they are addressing and the type of wireless networks they are
investigating. To this end, we carefully identify the types of DRL algorithms
utilized in each related work, the elements of these algorithms, and the main
findings of each related work. Finally, we highlight important open challenges
and provide insights into several future research directions in the context of
DRL-based RRAM. This survey is intentionally designed to guide and stimulate
more research endeavors towards building efficient and fine-grained DRL-based
RRAM schemes for future wireless networks.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00576</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00576</id><submitter>Isaac Dunn</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:37:30 GMT</date><size>15086kb</size><source_type>D</source_type></version><title>Exposing Previously Undetectable Faults in Deep Neural Networks</title><authors>Isaac Dunn, Hadrien Pouget, Daniel Kroening and Tom Melham</authors><categories>cs.LG cs.CV cs.SE</categories><comments>Accepted to the ACM SIGSOFT International Symposium on Software
  Testing and Analysis (ISSTA 2021)</comments><acm-class>I.2.6; D.2.5</acm-class><doi>10.1145/3460319.3464801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing methods for testing DNNs solve the oracle problem by constraining
the raw features (e.g. image pixel values) to be within a small distance of a
dataset example for which the desired DNN output is known. But this limits the
kinds of faults these approaches are able to detect. In this paper, we
introduce a novel DNN testing method that is able to find faults in DNNs that
other methods cannot. The crux is that, by leveraging generative machine
learning, we can generate fresh test inputs that vary in their high-level
features (for images, these include object shape, location, texture, and
colour). We demonstrate that our approach is capable of detecting deliberately
injected faults as well as new faults in state-of-the-art DNNs, and that in
both cases, existing methods are unable to find these faults.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00583</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00583</id><submitter>Aitor Arjona</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:50:22 GMT</date><size>3067kb</size><source_type>D</source_type></version><title>Triggerflow: Trigger-based Orchestration of Serverless Workflows</title><authors>Aitor Arjona, Pedro Garc\'ia-L\'opez, Josep Samp\'e, Aleksander
  Slominski and Lionel Villard</authors><categories>cs.DC</categories><comments>17 pages, 17 figures, preprint submitted to Future Generation
  Computer Systems. arXiv admin note: substantial text overlap with
  arXiv:2006.08654</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  As more applications are being moved to the Cloud thanks to serverless
computing, it is increasingly necessary to support the native life cycle
execution of those applications in the data center. But existing cloud
orchestration systems either focus on short-running workflows (like IBM
Composer or Amazon Step Functions Express Workflows) or impose considerable
overheads for synchronizing massively parallel jobs (Azure Durable Functions,
Amazon Step Functions). None of them are open systems enabling extensible
interception and optimization of custom workflows. We present Triggerflow: an
extensible Trigger-based Orchestration architecture for serverless workflows.
We demonstrate that Triggerflow is a novel serverless building block capable of
constructing different reactive orchestrators (State Machines, Directed Acyclic
Graphs, Workflow as code, Federated Learning orchestrator). We also validate
that it can support high-volume event processing workloads, auto-scale on
demand with scale down to zero when not used, and transparently guarantee fault
tolerance and efficient resource usage when orchestrating long running
scientific workflows.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00588</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00588</id><submitter>Jianbiao Mei</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:56:10 GMT</date><size>559kb</size><source_type>D</source_type></version><title>TransVOS: Video Object Segmentation with Transformers</title><authors>Jianbiao Mei, Mengmeng Wang, Yeneng Lin, Yong Liu</authors><categories>cs.CV cs.AI</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Space-Time Memory Network (STM) based methods have achieved
state-of-the-art performance in semi-supervised video object segmentation
(VOS). A critical problem in this task is how to model the dependency both
among different frames and inside every frame. However, most of these methods
neglect the spatial relationships (inside each frame) and do not make full use
of the temporal relationships (among different frames). In this paper, we
propose a new transformer-based framework, termed TransVOS, introducing a
vision transformer to fully exploit and model both the temporal and spatial
relationships. Moreover, most STM-based approaches employ two disparate
encoders to extract features of two significant inputs, i.e., reference sets
(history frames with predicted masks) and query frame, respectively, increasing
the models' parameters and complexity. To slim the popular two-encoder pipeline
while keeping the effectiveness, we design a single two-path feature extractor
to encode the above two inputs in a unified way. Extensive experiments
demonstrate the superiority of our TransVOS over state-of-the-art methods on
both DAVIS and YouTube-VOS datasets. Codes will be released when it is
published.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00589</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00589</id><submitter>Bogdan Mazoure</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:58:05 GMT</date><size>2594kb</size><source_type>D</source_type></version><title>Improving Long-Term Metrics in Recommendation Systems using
  Short-Horizon Offline RL</title><authors>Bogdan Mazoure, Paul Mineiro, Pavithra Srinath, Reza Sharifi Sedeh,
  Doina Precup, Adith Swaminathan</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study session-based recommendation scenarios where we want to recommend
items to users during sequential interactions to improve their long-term
utility. Optimizing a long-term metric is challenging because the learning
signal (whether the recommendations achieved their desired goals) is delayed
and confounded by other user interactions with the system. Immediately
measurable proxies such as clicks can lead to suboptimal recommendations due to
misalignment with the long-term metric. Many works have applied episodic
reinforcement learning (RL) techniques for session-based recommendation but
these methods do not account for policy-induced drift in user intent across
sessions. We develop a new batch RL algorithm called Short Horizon Policy
Improvement (SHPI) that approximates policy-induced distribution shifts across
sessions. By varying the horizon hyper-parameter in SHPI, we recover well-known
policy improvement schemes in the RL literature. Empirical results on four
recommendation tasks show that SHPI can outperform matrix factorization,
offline bandits, and offline RL baselines. We also provide a stable and
computationally efficient implementation using weighted regression oracles.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00590</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00590</id><submitter>Jialu Liu</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:59:40 GMT</date><size>2093kb</size><source_type>D</source_type></version><title>NewsEmbed: Modeling News through Pre-trained DocumentRepresentations</title><authors>Jialu Liu, Tianqi Liu, Cong Yu</authors><categories>cs.CL cs.IR cs.LG</categories><doi>10.1145/3447548.3467392</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed's competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00591</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00591</id><submitter>Chiara Piazzola</submitter><version version="v1"><date>Tue, 1 Jun 2021 15:59:44 GMT</date><size>10051kb</size><source_type>D</source_type></version><title>Comparing Multi-Index Stochastic Collocation and Multi-Fidelity
  Stochastic Radial Basis Functions for Forward Uncertainty Quantification of
  Ship Resistance</title><authors>Chiara Piazzola, Lorenzo Tamellini, Riccardo Pellegrini, Riccardo
  Broglia, Andrea Serani, Matteo Diez</authors><categories>math.NA cs.NA</categories><comments>arXiv admin note: text overlap with arXiv:2005.07405</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a comparison of two multi-fidelity methods for the
forward uncertainty quantification of a naval engineering problem.
Specifically, we consider the problem of quantifying the uncertainty of the
hydrodynamic resistance of a roll-on/roll-off passengers ferry advancing in
calm water and subject to two operational uncertainties (ship speed and
payload). The first four statistical moments (mean, variance, skewness,
kurtosis), and the probability density function for such quantity of interest
(QoI) are computed with two multi-fidelity methods, i.e., the Multi-Index
Stochastic Collocation (MISC) method and an adaptive multi-fidelity Stochastic
Radial Basis Functions (SRBF) algorithm. The QoI is evaluated via computational
fluid dynamics simulations, which are performed with the in-house unsteady
Reynolds-Averaged Navier-Stokes (RANS) multi-grid solver $\chi$navis. The
different fidelities employed by both methods are obtained by stopping the RANS
solver at different grid levels of the multi-grid cycle. The performance of
both methods are presented and discussed: in a nutshell, the findings suggest
that, at least for the current implementations of both algorithms, MISC could
be preferred whenever a limited computational budget is available, whereas for
a larger computational budget SRBFs seem to be preferable, thanks to its
robustness to the numerical noise in the evaluations of the QoI.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00592</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00592</id><submitter>Kaiyang Zhou</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:00:08 GMT</date><size>1820kb</size><source_type>D</source_type></version><title>Semi-Supervised Domain Generalization with Stochastic StyleMatch</title><authors>Kaiyang Zhou, Chen Change Loy, Ziwei Liu</authors><categories>cs.CV cs.AI cs.LG</categories><comments>Tech report. Code available at
  https://github.com/KaiyangZhou/ssdg-benchmark</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing research on domain generalization assumes source data gathered
from multiple domains are fully annotated. However, in real-world applications,
we might have only a few labels available from each source domain due to high
annotation cost, along with abundant unlabeled data that are much easier to
obtain. In this work, we investigate semi-supervised domain generalization
(SSDG), a more realistic and practical setting. Our proposed approach,
StyleMatch, is inspired by FixMatch, a state-of-the-art semi-supervised
learning method based on pseudo-labeling, with several new ingredients tailored
to solve SSDG. Specifically, 1) to mitigate overfitting in the scarce labeled
source data while improving robustness against noisy pseudo labels, we
introduce stochastic modeling to the classifier's weights, seen as class
prototypes, with Gaussian distributions. 2) To enhance generalization under
domain shift, we upgrade FixMatch's two-view consistency learning paradigm
based on weak and strong augmentations to a multi-view version with style
augmentation as the third complementary view. To provide a comprehensive study
and evaluation, we establish two SSDG benchmarks, which cover a wide range of
strong baseline methods developed in relevant areas including domain
generalization and semi-supervised learning. Extensive experiments demonstrate
that StyleMatch achieves the best out-of-distribution generalization
performance in the low-data regime. We hope our approach and benchmarks can
pave the way for future research on data-efficient and generalizable learning
systems.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00594</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00594</id><submitter>Fang Wang</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:02:07 GMT</date><size>189kb</size><source_type>D</source_type></version><title>Gauss-Seidel Method with Oblique Direction</title><authors>Fang Wang and Weiguo Li and Wendi Bao and Zhonglu Lv</authors><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a Gauss-Seidel method with oblique direction (GSO) is proposed
for finding the least-squares solution to a system of linear equations, where
the coefficient matrix may be full rank or rank deficient and the system is
overdetermined or underdetermined. Through this method, the number of iteration
steps and running time can be reduced to a greater extent to find the
least-squares solution, especially when the columns of matrix A are close to
linear correlation. It is theoretically proved that GSO method converges to the
least-squares solution. At the same time, a randomized version--randomized
Gauss-Seidel method with oblique direction (RGSO) is established, and its
convergence is proved. Theoretical proof and numerical results show that the
GSO method and the RGSO method are more efficient than the coordinate descent
(CD) method and the randomized coordinate descent (RCD) method.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00596</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00596</id><submitter>Van-Quang Nguyen</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:06:09 GMT</date><size>24589kb</size><source_type>D</source_type></version><title>Look Wide and Interpret Twice: Improving Performance on Interactive
  Instruction-following Tasks</title><authors>Van-Quang Nguyen, Masanori Suganuma, Takayuki Okatani</authors><categories>cs.CV</categories><comments>Winner of the ALFRED Challenge at ECCV 2020. To appear in IJCAI2021.
  8 pages and supp</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  There is a growing interest in the community in making an embodied AI agent
perform a complicated task while interacting with an environment following
natural language directives. Recent studies have tackled the problem using
ALFRED, a well-designed dataset for the task, but achieved only very low
accuracy. This paper proposes a new method, which outperforms the previous
methods by a large margin. It is based on a combination of several new ideas.
One is a two-stage interpretation of the provided instructions. The method
first selects and interprets an instruction without using visual information,
yielding a tentative action sequence prediction. It then integrates the
prediction with the visual information etc., yielding the final prediction of
an action and an object. As the object's class to interact is identified in the
first stage, it can accurately select the correct object from the input image.
Moreover, our method considers multiple egocentric views of the environment and
extracts essential information by applying hierarchical attention conditioned
on the current instruction. This contributes to the accurate prediction of
actions for navigation. A preliminary version of the method won the ALFRED
Challenge 2020. The current version achieves the unseen environment's success
rate of 4.45% with a single view, which is further improved to 8.37% with
multiple views.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00598</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00598</id><submitter>Ezechukwu Nwokedi</submitter><version version="v1"><date>Fri, 28 May 2021 16:30:09 GMT</date><size>13702kb</size><source_type>D</source_type></version><title>Unsupervised detection of mouse behavioural anomalies using two-stream
  convolutional autoencoders</title><authors>Ezechukwu I Nwokedi, Rasneer S Bains, Luc Bidaut, Sara Wells, Xujiong
  Ye, James M Brown</authors><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper explores the application of unsupervised learning to detecting
anomalies in mouse video data. The two models presented in this paper are a
dual-stream, 3D convolutional autoencoder (with residual connections) and a
dual-stream, 2D convolutional autoencoder. The publicly available dataset used
here contains twelve videos of single home-caged mice alongside frame-level
annotations. Under the pretext that the autoencoder only sees normal events,
the video data was handcrafted to treat each behaviour as a pseudo-anomaly
thereby eliminating them from the others during training. The results are
presented for one conspicuous behaviour (hang) and one inconspicuous behaviour
(groom). The performance of these models is compared to a single stream
autoencoder and a supervised learning model, which are both based on the custom
CAE. Both models are also tested on the CUHK Avenue dataset were found to
perform as well as some state-of-the-art architectures.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00599</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00599</id><submitter>Michael Aupetit</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:07:50 GMT</date><size>7184kb</size><source_type>D</source_type></version><title>ClustRank: a Visual Quality Measure Trained on Perceptual Data for
  Sorting Scatterplots by Cluster Patterns</title><authors>Mostafa Abbas, Ehsan Ullah, Abdelkader Baggag, Halima Bensmail,
  Michael Sedlmair, Michael Aupetit</authors><categories>cs.HC cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Visual quality measures (VQMs) are designed to support analysts by
automatically detecting and quantifying patterns in visualizations. We propose
a new data-driven technique called ClustRank that allows to rank scatterplots
according to visible grouping patterns. Our model first encodes scatterplots in
the parametric space of a Gaussian Mixture Model, and then uses a classifier
trained on human judgment data to estimate the perceptual complexity of
grouping patterns. The numbers of initial mixture components and final combined
groups determine the rank of the scatterplot. ClustRank improves on existing
VQM techniques by mimicking human judgments on two-Gaussian cluster patterns
and gives more accuracy when ranking general cluster patterns in scatterplots.
We demonstrate its benefit by analyzing kinship data for genome-wide
association studies, a domain in which experts rely on the visual analysis of
large sets of scatterplots. We make the three benchmark datasets and the
ClustRank VQM available for practical use and further improvements.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00600</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00600</id><submitter>Anshuman Chhabra</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:07:52 GMT</date><size>3799kb</size><source_type>D</source_type></version><title>Fair Clustering Using Antidote Data</title><authors>Anshuman Chhabra, Adish Singla, Prasant Mohapatra</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering algorithms are widely utilized for many modern data science
applications. This motivates the need to make outputs of clustering algorithms
fair. Traditionally, new fair algorithmic variants to clustering algorithms are
developed for specific notions of fairness. However, depending on the
application context, different definitions of fairness might need to be
employed. As a result, new algorithms and analysis need to be proposed for each
combination of clustering algorithm and fairness definition. Additionally, each
new algorithm would need to be reimplemented for deployment in a real-world
system. Hence, we propose an alternate approach to fairness in clustering where
we augment the original dataset with a small number of data points, called
antidote data. When clustering is undertaken on this new dataset, the output is
fair, for the chosen clustering algorithm and fairness definition. We formulate
this as a general bi-level optimization problem which can accommodate any
center-based clustering algorithms and fairness notions. We then categorize
approaches for solving this bi-level optimization for different problem
settings. Extensive experiments on different clustering algorithms and fairness
notions show that our algorithms can achieve desired levels of fairness on many
real-world datasets with a very small percentage of antidote data added. We
also find that our algorithms achieve lower fairness costs and competitive
clustering performance compared to other state-of-the-art fair clustering
algorithms.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00604</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00604</id><submitter>Robert Kleinberg</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:12:08 GMT</date><size>30kb</size></version><title>Optimal Stopping with Behaviorally Biased Agents: The Role of Loss
  Aversion and Changing Reference Points</title><authors>Jon Kleinberg, Robert Kleinberg, and Sigal Oren</authors><categories>cs.GT cs.DS</categories><comments>To appear in the 2021 ACM Conference on Economics and Computation
  (EC'21)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People are often reluctant to sell a house, or shares of stock, below the
price at which they originally bought it. While this is generally not
consistent with rational utility maximization, it does reflect two strong
empirical regularities that are central to the behavioral science of human
decision-making: a tendency to evaluate outcomes relative to a reference point
determined by context (in this case the original purchase price), and the
phenomenon of loss aversion in which people are particularly prone to avoid
outcomes below the reference point. Here we explore the implications of
reference points and loss aversion in optimal stopping problems, where people
evaluate a sequence of options in one pass, either accepting the option and
stopping the search or giving up on the option forever. The best option seen so
far sets a reference point that shifts as the search progresses, and a biased
decision-maker's utility incurs an additional penalty when they accept a later
option that is below this reference point.
  We formulate and study a behaviorally well-motivated version of the optimal
stopping problem that incorporates these notions of reference dependence and
loss aversion. We obtain tight bounds on the performance of a biased agent in
this model relative to the best option obtainable in retrospect (a type of
prophet inequality for biased agents), as well as tight bounds on the ratio
between the performance of a biased agent and the performance of a rational
one. We further establish basic monotonicity results, and show an exponential
gap between the performance of a biased agent in a stopping problem with
respect to a worst-case versus a random order. As part of this, we establish
fundamental differences between optimal stopping problems for rational versus
biased agents, and these differences inform our analysis.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00606</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00606</id><submitter>Elad Wasserstein</submitter><version version="v1"><date>Sun, 30 May 2021 15:28:52 GMT</date><size>2115kb</size><source_type>D</source_type></version><title>Dynamic-Deep: ECG Task-Aware Compression</title><authors>Eli Brosh, Elad Wasserstein, Anat Bremler-Barr</authors><categories>eess.SP cs.LG</categories><comments>submitted to Globecom2021 SAC MLC</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Monitoring medical data, e.g., Electrocardiogram (ECG) signals, is a common
application of Internet of Things (IoT) devices. Compression methods are often
applied on the massive amounts of sensor data generated before sending it to
the Cloud to reduce storage and delivery costs. A lossy compression provides
high compression gain (CG) but may reduce the performance of an ECG application
(downstream task) due to information loss. Previous works on ECG monitoring
focus either on optimizing the signal reconstruction or the task's performance.
Instead, we advocate a lossy compression solution that allows configuring a
desired performance level on the downstream tasks while maintaining an
optimized CG.
  We propose Dynamic-Deep, a task-aware compression that uses convolutional
autoencoders. The compression level is dynamically selected to yield an
optimized compression without violating tasks' performance requirements. We
conduct an extensive evaluation of our approach on common ECG datasets using
two popular ECG applications, which includes heart rate (HR) arrhythmia
classification. We demonstrate that Dynamic-Deep improves HR classification
F1-score by a factor of 3 and increases CG by up to 83% compared to the
previous state-of-the-art (autoencoder-based) compressor. Additionally,
Dynamic-Deep has a 67% lower memory footprint. Analyzing Dynamic-Deep on the
Google Cloud Platform, we observe a 97% reduction in cloud costs compared to a
no compression solution.
  To the best of our knowledge, Dynamic-Deep is the first proposal to focus on
balancing the need for high performance of cloud-based downstream tasks and the
desire to achieve optimized compression in IoT ECG monitoring settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00607</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00607</id><submitter>Maria Barbero Li\~n\'an</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:18:08 GMT</date><size>45kb</size></version><title>Extended retraction maps: a seed of geometric integrators</title><authors>Mar\'ia Barbero Li\~n\'an and David Mart\'in de Diego</authors><categories>math.NA cs.NA math-ph math.MP math.SG</categories><msc-class>37M15, 65P10, 70G45, 53D22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical notion of retraction map used to approximate geodesics is
extended and rigorously defined to become a powerful tool to construct
geometric integrators. Using the geometry of the tangent and cotangent bundles,
we are able to tangently and cotangent lift such a map so that these lifts
inherit the same properties as the original one and they continue to be
extended retraction maps. In particular, the cotangent lift of this new notion
of retraction map is a natural symplectomorphism, what plays a key role for
constructing geometric integrators and symplectic methods. As a result, a wide
range of numerical methods are recovered and canonically constructed by using
different extended retraction maps, as well as some operations with Lagrangian
submanifolds.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00609</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00609</id><submitter>Pan Zhang</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:22:01 GMT</date><size>6972kb</size><source_type>D</source_type></version><title>Robust Mutual Learning for Semi-supervised Semantic Segmentation</title><authors>Pan Zhang, Bo Zhang, Ting Zhang, Dong Chen, Fang Wen</authors><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent semi-supervised learning (SSL) methods are commonly based on pseudo
labeling. Since the SSL performance is greatly influenced by the quality of
pseudo labels, mutual learning has been proposed to effectively suppress the
noises in the pseudo supervision. In this work, we propose robust mutual
learning that improves the prior approach in two aspects. First, the vanilla
mutual learners suffer from the coupling issue that models may converge to
learn homogeneous knowledge. We resolve this issue by introducing mean teachers
to generate mutual supervisions so that there is no direct interaction between
the two students. We also show that strong data augmentations, model noises and
heterogeneous network architectures are essential to alleviate the model
coupling. Second, we notice that mutual learning fails to leverage the
network's own ability for pseudo label refinement. Therefore, we introduce
self-rectification that leverages the internal knowledge and explicitly
rectifies the pseudo labels before the mutual teaching. Such self-rectification
and mutual teaching collaboratively improve the pseudo label accuracy
throughout the learning. The proposed robust mutual learning demonstrates
state-of-the-art performance on semantic segmentation in low-data regime.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00610</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00610</id><submitter>Lang He</submitter><version version="v1"><date>Thu, 27 May 2021 15:48:31 GMT</date><size>19333kb</size><source_type>D</source_type></version><title>Deep Learning for Depression Recognition with Audiovisual Cues: A Review</title><authors>Lang He, Mingyue Niu, Prayag Tiwari, Pekka Marttinen, Rui Su, Jiewei
  Jiang, Chenguang Guo, Hongyu Wang, Songtao Ding, Zhongmin Wang, Wei Dang,
  Xiaoying Pan</authors><categories>eess.SP cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the acceleration of the pace of work and life, people have to face more
and more pressure, which increases the possibility of suffering from
depression. However, many patients may fail to get a timely diagnosis due to
the serious imbalance in the doctor-patient ratio in the world. Promisingly,
physiological and psychological studies have indicated some differences in
speech and facial expression between patients with depression and healthy
individuals. Consequently, to improve current medical care, many scholars have
used deep learning to extract a representation of depression cues in audio and
video for automatic depression detection. To sort out and summarize these
works, this review introduces the databases and describes objective markers for
automatic depression estimation (ADE). Furthermore, we review the deep learning
methods for automatic depression detection to extract the representation of
depression from audio and video. Finally, this paper discusses challenges and
promising directions related to automatic diagnosing of depression using deep
learning technologies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00611</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00611</id><submitter>Andriy Temko Dr</submitter><version version="v1"><date>Fri, 28 May 2021 14:03:56 GMT</date><size>975kb</size></version><title>Deep Learning for EEG Seizure Detection in Preterm Infants</title><authors>Alison OShea, Rehan Ahmed, Gordon Lightbody, Sean Mathieson, Elena
  Pavlidis, Rhodri Lloyd, Francesco Pisani, Willian Marnane, Geraldine Boylan,
  Andriy Temko</authors><categories>eess.SP cs.AI cs.LG</categories><journal-ref>Int J Neural Syst (2021)</journal-ref><doi>10.1142/S0129065721500088</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  EEG is the gold standard for seizure detection in the newborn infant, but EEG
interpretation in the preterm group is particularly challenging; trained
experts are scarce and the task of interpreting EEG in real-time is arduous.
Preterm infants are reported to have a higher incidence of seizures compared to
term infants. Preterm EEG morphology differs from that of term infants, which
implies that seizure detection algorithms trained on term EEG may not be
appropriate. The task of developing preterm specific algorithms becomes
extra-challenging given the limited amount of annotated preterm EEG data
available. This paper explores novel deep learning (DL) architectures for the
task of neonatal seizure detection in preterm infants. The study tests and
compares several approaches to address the problem: training on data from
full-term infants; training on data from preterm infants; training on
age-specific preterm data and transfer learning. The system performance is
assessed on a large database of continuous EEG recordings of 575h in duration.
It is shown that the accuracy of a validated term-trained EEG seizure detection
algorithm, based on a support vector machine classifier, when tested on preterm
infants falls well short of the performance achieved for full-term infants. An
AUC of 88.3% was obtained when tested on preterm EEG as compared to 96.6%
obtained when tested on term EEG. When re-trained on preterm EEG, the
performance marginally increases to 89.7%. An alternative DL approach shows a
more stable trend when tested on the preterm cohort, starting with an AUC of
93.3% for the term-trained algorithm and reaching 95.0% by transfer learning
from the term model using available preterm data.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00613</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00613</id><submitter>Jian Cui</submitter><version version="v1"><date>Sun, 30 May 2021 14:36:34 GMT</date><size>3421kb</size></version><title>A Compact and Interpretable Convolutional Neural Network for
  Cross-Subject Driver Drowsiness Detection from Single-Channel EEG</title><authors>Jian Cui, Zirui Lan, Yisi Liu, Ruilin Li, Fan Li, Olga Sourina, and
  Wolfgang Mueller-Wittig</authors><categories>eess.SP cs.HC cs.LG cs.NE</categories><doi>10.1016/j.ymeth.2021.04.017</doi><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Driver drowsiness is one of main factors leading to road fatalities and
hazards in the transportation industry. Electroencephalography (EEG) has been
considered as one of the best physiological signals to detect drivers drowsy
states, since it directly measures neurophysiological activities in the brain.
However, designing a calibration-free system for driver drowsiness detection
with EEG is still a challenging task, as EEG suffers from serious mental and
physical drifts across different subjects. In this paper, we propose a compact
and interpretable Convolutional Neural Network (CNN) to discover shared EEG
features across different subjects for driver drowsiness detection. We
incorporate the Global Average Pooling (GAP) layer in the model structure,
allowing the Class Activation Map (CAM) method to be used for localizing
regions of the input signal that contribute most for classification. Results
show that the proposed model can achieve an average accuracy of 73.22% on 11
subjects for 2-class cross-subject EEG signal classification, which is higher
than conventional machine learning methods and other state-of-art deep learning
methods. It is revealed by the visualization technique that the model has
learned biologically explainable features, e.g., Alpha spindles and Theta
burst, as evidence for the drowsy state. It is also interesting to see that the
model uses artifacts that usually dominate the wakeful EEG, e.g., muscle
artifacts and sensor drifts, to recognize the alert state. The proposed model
illustrates a potential direction to use CNN models as a powerful tool to
discover shared features related to different mental states across different
subjects from EEG signals.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00614</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00614</id><submitter>Nazgol Tavabi</submitter><version version="v1"><date>Sun, 30 May 2021 00:47:19 GMT</date><size>4224kb</size><source_type>D</source_type></version><title>Pattern Discovery in Time Series with Byte Pair Encoding</title><authors>Nazgol Tavabi, Kristina Lerman</authors><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing popularity of wearable sensors has generated large quantities of
temporal physiological and activity data. Ability to analyze this data offers
new opportunities for real-time health monitoring and forecasting. However,
temporal physiological data presents many analytic challenges: the data is
noisy, contains many missing values, and each series has a different length.
Most methods proposed for time series analysis and classification do not handle
datasets with these characteristics nor do they offer interpretability and
explainability, a critical requirement in the health domain. We propose an
unsupervised method for learning representations of time series based on common
patterns identified within them. The patterns are, interpretable, variable in
length, and extracted using Byte Pair Encoding compression technique. In this
way the method can capture both long-term and short-term dependencies present
in the data. We show that this method applies to both univariate and
multivariate time series and beats state-of-the-art approaches on a real world
dataset collected from wearable sensors.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00615</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00615</id><submitter>Chenglin Li</submitter><version version="v1"><date>Mon, 31 May 2021 11:04:39 GMT</date><size>1382kb</size><source_type>D</source_type></version><title>Meta-HAR: Federated Representation Learning for Human Activity
  Recognition</title><authors>Chenglin Li, Di Niu, Bei Jiang, Xiao Zuo and Jianming Yang</authors><categories>eess.SP cs.LG</categories><doi>10.1145/3442381.3450006</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Human activity recognition (HAR) based on mobile sensors plays an important
role in ubiquitous computing. However, the rise of data regulatory constraints
precludes collecting private and labeled signal data from personal devices at
scale. Federated learning has emerged as a decentralized alternative solution
to model training, which iteratively aggregates locally updated models into a
shared global model, therefore being able to leverage decentralized, private
data without central collection. However, the effectiveness of federated
learning for HAR is affected by the fact that each user has different activity
types and even a different signal distribution for the same activity type.
Furthermore, it is uncertain if a single global model trained can generalize
well to individual users or new users with heterogeneous data. In this paper,
we propose Meta-HAR, a federated representation learning framework, in which a
signal embedding network is meta-learned in a federated manner, while the
learned signal representations are further fed into a personalized
classification network at each user for activity prediction. In order to boost
the representation ability of the embedding network, we treat the HAR problem
at each user as a different task and train the shared embedding network through
a Model-Agnostic Meta-learning framework, such that the embedding network can
generalize to any individual user. Personalization is further achieved on top
of the robustly learned representations in an adaptation procedure. We
conducted extensive experiments based on two publicly available HAR datasets as
well as a newly created HAR dataset. Results verify that Meta-HAR is effective
at maintaining high test accuracies for individual users, including new users,
and significantly outperforms several baselines, including Federated Averaging,
Reptile and even centralized learning in certain cases.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00617</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00617</id><submitter>Dong Quan Vu</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:25:26 GMT</date><size>4691kb</size><source_type>D</source_type></version><title>Colonel Blotto Games with Favoritism: Competitions with Pre-allocations
  and Asymmetric Effectiveness</title><authors>Dong Quan Vu, Patrick Loiseau</authors><categories>cs.GT</categories><comments>Full paper version of ACM EC conference paper:
  https://doi.org/10.1145/3465456.3467527</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the Colonel Blotto game with favoritism, an extension of the
famous Colonel Blotto game where the winner-determination rule is generalized
to include pre-allocations and asymmetry of the players' resources
effectiveness on each battlefield. Such favoritism is found in many classical
applications of the Colonel Blotto game. We focus on the Nash equilibrium.
First, we consider the closely related model of all-pay auctions with
favoritism and completely characterize its equilibrium. Based on this result,
we prove the existence of a set of optimal univariate distributions -- which
serve as candidate marginals for an equilibrium -- of the Colonel Blotto game
with favoritism and show an explicit construction thereof. In several
particular cases, this directly leads to an equilibrium of the Colonel Blotto
game with favoritism. In other cases, we use these optimal univariate
distributions to derive an approximate equilibrium with well-controlled
approximation error. Finally, we propose an algorithm -- based on the notion of
winding number in parametric curves -- to efficiently compute an approximation
of the proposed optimal univariate distributions with arbitrarily small error.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00619</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00619</id><submitter>Mohd Khizir Siddiqui</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:27:43 GMT</date><size>376kb</size><source_type>D</source_type></version><title>CoRank: A clustering cum graph ranking approach for extractive
  summarization</title><authors>Mohd Khizir Siddiqui and Amreen Ahmad and Om Pal and Tanvir Ahmad</authors><categories>cs.SI</categories><comments>19 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online information has increased tremendously in today's age of Internet. As
a result, the need has arose to extract relevant content from the plethora of
available information. Researchers are widely using automatic text
summarization techniques for extracting useful and relevant information from
voluminous available information, it also enables users to obtain valuable
knowledge in a limited period of time with minimal effort. The summary obtained
from the automatic text summarization often faces the issues of diversity and
information coverage. Promising results are obtained for automatic text
summarization by the introduction of new techniques based on graph ranking of
sentences, clustering, and optimization. This research work proposes CoRank, a
two-stage sentence selection model involving clustering and then ranking of
sentences. The initial stage involves clustering of sentences using a novel
clustering algorithm, and later selection of salient sentences using CoRank
algorithm. The approach aims to cover two objectives: maximum coverage and
diversity, which is achieved by the extraction of main topics and sub-topics
from the original text. The performance of the CoRank is validated on DUC2001
and DUC 2002 data sets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00623</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00623</id><submitter>Arindam Khan</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:34:15 GMT</date><size>1699kb</size><source_type>D</source_type></version><title>A 4-Approximation Algorithm for Maximum Independent Set of Rectangles</title><authors>Waldo Galvez, Arindam Khan, Mathieu Mari, Tobias Momke, Madhusudhan
  Reddy, Andreas Wiese</authors><categories>cs.CG cs.DS</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Maximum Independent Set of Rectangles(MISR) problem, where we
are given a set of axis-parallel rectangles in the plane and the goal is to
select a subset of non-overlapping rectangles of maximum cardinality. In a
recent breakthrough, Mitchell obtained the first constant-factor approximation
algorithm for MISR. His algorithm achieves an approximation ratio of 10 and it
is based on a dynamic program that intuitively recursively partitions the input
plane into special polygons called corner-clipped rectangles (CCRs).
  In this paper, we present a 4-approximation algorithm for MISR which is based
on a similar recursive partitioning scheme. However, we use a more general
class of polygons -- polygons that are horizontally or vertically convex --
which allows us to provide an arguably simpler analysis and already improve the
approximation ratio. Using a new fractional charging argument and fork-fences
to guide the partitions, we improve the approximation ratio even more to 4. We
hope that our ideas will lead to further progress towards a PTAS for MISR.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00628</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00628</id><submitter>Martin Frasch</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:40:50 GMT</date><size>409kb</size></version><title>Detection of preventable fetal distress during labor from scanned
  cardiotocogram tracings using deep learning</title><authors>Martin G. Frasch, Shadrian B. Strong, David Nilosek, Joshua Leaverton,
  Barry S. Schifrin</authors><categories>q-bio.QM cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Despite broad application during labor and delivery, there remains
considerable debate about the value of electronic fetal monitoring (EFM). EFM
includes the surveillance of the fetal heart rate (FHR) patterns in conjunction
with the maternal uterine contractions providing a wealth of data about fetal
behavior and the threat of diminished oxygenation and perfusion. Adverse
outcomes universally associate a fetal injury with the failure to timely
respond to FHR pattern information. Historically, the EFM data, stored
digitally, are available only as rasterized pdf images for contemporary or
historical discussion and examination. In reality, however, they are rarely
reviewed systematically. Using a unique archive of EFM collected over 50 years
of practice in conjunction with adverse outcomes, we present a deep learning
framework for training and detection of incipient or past fetal injury. We
report 94% accuracy in identifying early, preventable fetal injury intrapartum.
This framework is suited for automating an early warning and decision support
system for maintaining fetal well-being during the stresses of labor.
Ultimately, such a system could enable a physician to timely respond during
labor and prevent adverse outcomes. When adverse outcomes cannot be avoided,
they can provide guidance to the early neuroprotective treatment of the
newborn.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00629</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00629</id><submitter>Dario Oliveira</submitter><version version="v1"><date>Tue, 1 Jun 2021 16:45:19 GMT</date><size>3097kb</size><source_type>D</source_type></version><title>Decoupling Shape and Density for Liver Lesion Synthesis Using
  Conditional Generative Adversarial Networks</title><authors>Dario Augusto Borges Oliveira</authors><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lesion synthesis received much attention with the rise of efficient
generative models for augmenting training data, drawing lesion evolution
scenarios, or aiding expert training. The quality and diversity of synthesized
data are highly dependent on the annotated data used to train the models, which
not rarely struggle to derive very different yet realistic samples from the
training ones. That adds an inherent bias to lesion segmentation algorithms and
limits synthesizing lesion evolution scenarios efficiently. This paper presents
a method for decoupling shape and density for liver lesion synthesis, creating
a framework that allows straight-forwardly driving the synthesis. We offer
qualitative results that show the synthesis control by modifying shape and
density individually, and quantitative results that demonstrate that embedding
the density information in the generator model helps to increase lesion
segmentation performance compared to using the shape solely.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00638</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00638</id><submitter>Zhiliang Wu</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:09:47 GMT</date><size>1762kb</size><source_type>D</source_type></version><title>Quantifying Predictive Uncertainty in Medical Image Analysis with Deep
  Kernel Learning</title><authors>Zhiliang Wu, Yinchong Yang, Jindong Gu, Volker Tresp</authors><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks are increasingly being used for the analysis of medical
images. However, most works neglect the uncertainty in the model's prediction.
We propose an uncertainty-aware deep kernel learning model which permits the
estimation of the uncertainty in the prediction by a pipeline of a
Convolutional Neural Network and a sparse Gaussian Process. Furthermore, we
adapt different pre-training methods to investigate their impacts on the
proposed model. We apply our approach to Bone Age Prediction and Lesion
Localization. In most cases, the proposed model shows better performance
compared to common architectures. More importantly, our model expresses
systematically higher confidence in more accurate predictions and less
confidence in less accurate ones. Our model can also be used to detect
challenging and controversial test samples. Compared to related methods such as
Monte-Carlo Dropout, our approach derives the uncertainty information in a
purely analytical fashion and is thus computationally more efficient.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00639</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00639</id><submitter>Srikanth Raj Chetupalli</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:10:07 GMT</date><size>1633kb</size><source_type>D</source_type></version><title>Multi-modal Point-of-Care Diagnostics for COVID-19 Based On Acoustics
  and Symptoms</title><authors>Srikanth Raj Chetupalli, Prashant Krishnan, Neeraj Sharma, Ananya
  Muguli, Rohit Kumar, Viral Nanda, Lancelot Mark Pinto, Prasanta Kumar Ghosh,
  and Sriram Ganapathy</authors><categories>eess.AS cs.SD eess.SP</categories><comments>The Manuscript is submitted to IEEE-EMBS Journal of Biomedical and
  Health Informatics on June 1, 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research direction of identifying acoustic bio-markers of respiratory
diseases has received renewed interest following the onset of COVID-19
pandemic. In this paper, we design an approach to COVID-19 diagnostic using
crowd-sourced multi-modal data. The data resource, consisting of acoustic
signals like cough, breathing, and speech signals, along with the data of
symptoms, are recorded using a web-application over a period of ten months. We
investigate the use of statistical descriptors of simple time-frequency
features for acoustic signals and binary features for the presence of symptoms.
Unlike previous works, we primarily focus on the application of simple linear
classifiers like logistic regression and support vector machines for acoustic
data while decision tree models are employed on the symptoms data. We show that
a multi-modal integration of acoustics and symptoms classifiers achieves an
area-under-curve (AUC) of 92.40, a significant improvement over any individual
modality. Several ablation experiments are also provided which highlight the
acoustic and symptom dimensions that are important for the task of COVID-19
diagnostics.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00641</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00641</id><submitter>Jinlan Fu</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:11:42 GMT</date><size>10196kb</size><source_type>D</source_type></version><title>SpanNer: Named Entity Re-/Recognition as Span Prediction</title><authors>Jinlan Fu, Xuanjing Huang, Pengfei Liu</authors><categories>cs.CL</categories><comments>Accepted by ACL 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent years have seen the paradigm shift of Named Entity Recognition (NER)
systems from sequence labeling to span prediction. Despite its preliminary
effectiveness, the span prediction model's architectural bias has not been
fully understood. In this paper, we first investigate the strengths and
weaknesses when the span prediction model is used for named entity recognition
compared with the sequence labeling framework and how to further improve it,
which motivates us to make complementary advantages of systems based on
different paradigms. We then reveal that span prediction, simultaneously, can
serve as a system combiner to re-recognize named entities from different
systems' outputs. We experimentally implement 154 systems on 11 datasets,
covering three languages, comprehensive results show the effectiveness of span
prediction models that both serve as base NER systems and system combiners. We
make all code and datasets available: \url{https://github.com/neulab/spanner},
as well as an online system demo: \url{http://spanner.sh}. Our model also has
been deployed into the ExplainaBoard platform, which allows users to flexibly
perform a system combination of top-scoring systems in an interactive way:
\url{http://explainaboard.nlpedia.ai/leaderboard/task-ner/}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00643</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00643</id><submitter>Wally Melnitchouk</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:23:15 GMT</date><size>717kb</size><source_type>D</source_type></version><title>A survey of machine learning-based physics event generation</title><authors>Yasir Alanazi, N. Sato, Pawel Ambrozewicz, Astrid N. Hiller Blin, W.
  Melnitchouk, Marco Battaglieri, Tianbo Liu, Yaohang Li</authors><categories>hep-ph cs.LG nucl-ex</categories><comments>8 pages, 2 figures, paper accepted for publication in IJCAI2021</comments><report-no>JLAB-THY-21-3385</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event generators in high-energy nuclear and particle physics play an
important role in facilitating studies of particle reactions. We survey the
state-of-the-art of machine learning (ML) efforts at building physics event
generators. We review ML generative models used in ML-based event generators
and their specific challenges, and discuss various approaches of incorporating
physics into the ML model designs to overcome these challenges. Finally, we
explore some open questions related to super-resolution, fidelity, and
extrapolation for physics event generation based on ML technology.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00644</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00644</id><submitter>Anton Plietzsch</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:24:34 GMT</date><size>928kb</size><source_type>D</source_type></version><title>A normal form for grid forming power grid components</title><authors>Raphael Kogler, Anton Plietzsch, Paul Schultz, and Frank Hellmann</authors><categories>nlin.AO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future power grids will be operating a large number of heterogeneous
dynamical actors. Many ofthese will contribute to the fundamental dynamical
stability of the system. By taking a complexitytheoretic perspective we derive
a normal form for grid forming components in power grids. Thisallows analyzing
the grids systemic properties without the need for detailed technical
models.Our approach is based on the physics of the power flow in the grid on
the one hand, and on thecommon symmetry that is inherited from the control
objectives grid-forming power grid componentsare trying to achieve. We provide
a first experimental validation that this normal form can capturethe behavior
of complex grid forming inverters without any knowledge of the underlying
technology,and show that it can be used to make technology independent
statements on the stability of futuregrids.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00645</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00645</id><submitter>Giorgio Luigi Morales Luna</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:24:35 GMT</date><size>1705kb</size><source_type>D</source_type></version><title>Hyperspectral Band Selection for Multispectral Image Classification with
  Convolutional Networks</title><authors>Giorgio Morales and John Sheppard and Riley Logan and Joseph Shaw</authors><categories>eess.IV cs.CV</categories><comments>Accepted to appear in the International Joint Conference on Neural
  Networks 2021</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  In recent years, Hyperspectral Imaging (HSI) has become a powerful source for
reliable data in applications such as remote sensing, agriculture, and
biomedicine. However, hyperspectral images are highly data-dense and often
benefit from methods to reduce the number of spectral bands while retaining the
most useful information for a specific application. We propose a novel band
selection method to select a reduced set of wavelengths, obtained from an HSI
system in the context of image classification. Our approach consists of two
main steps: the first utilizes a filter-based approach to find relevant
spectral bands based on a collinearity analysis between a band and its
neighbors. This analysis helps to remove redundant bands and dramatically
reduces the search space. The second step applies a wrapper-based approach to
select bands from the reduced set based on their information entropy values,
and trains a compact Convolutional Neural Network (CNN) to evaluate the
performance of the current selection. We present classification results
obtained from our method and compare them to other feature selection methods on
two hyperspectral image datasets. Additionally, we use the original
hyperspectral data cube to simulate the process of using actual filters in a
multispectral imager. We show that our method produces more suitable results
for a multispectral sensor design.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00647</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00647</id><submitter>Laura Alessandretti</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:25:32 GMT</date><size>2939kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 16:22:52 GMT</date><size>10508kb</size><source_type>D</source_type></version><title>Mapping the NFT revolution: market trends, trade networks and visual
  features</title><authors>Matthieu Nadini, Laura Alessandretti, Flavio Di Giacinto, Mauro
  Martino, Luca Maria Aiello, Andrea Baronchelli</authors><categories>q-fin.ST cs.CY physics.soc-ph</categories><comments>Working paper, comments welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non Fungible Tokens (NFTs) are digital assets that represent objects like
art, videos, in-game items and music. They are traded online, often with
cryptocurrency, and they are generally encoded as smart contracts on a
blockchain. Media and public attention towards NFTs has exploded in 2021, when
the NFT art market has experienced record sales while celebrated new star
artists. However, little is known about the overall structure and evolution of
the NFT market. Here, we analyse data concerning 6.1 million trades of 4.7
million NFTs generating a total trading volume of 935 millions US dollars. Our
data are obtained primarily from the Ethereum and WAX blockchains and cover the
period between June 23, 2017 and April 27, 2021. First, we characterize the
statistical properties of the market. Second, we build the network of
interactions and show that traders have bursts of activity followed by inactive
periods, and typically specialize on NFTs associated to similar objects. Third,
we cluster objects associated to NFTs according to their visual features and
show that NFTs within the same category tend to be visually homogeneous.
Finally, we investigate the predictability of NFT sales. We use simple machine
learning algorithms and find that prices can be best predicted by the sale
history of the NFT collection, but also by some features describing the
properties of the associated object (e.g., visual features of digital images).
We anticipate that our analysis will be of interest to both researchers and
practitioners and will spark further research on the NFT production, adoption
and trading in different contexts.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00651</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00651</id><submitter>Jacob Zavatone-Veth</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:30:30 GMT</date><size>4441kb</size><source_type>D</source_type></version><title>Asymptotics of representation learning in finite Bayesian neural
  networks</title><authors>Jacob A. Zavatone-Veth and Abdulkadir Canatar and Cengiz Pehlevan</authors><categories>cs.LG cond-mat.dis-nn stat.ML</categories><comments>12+28 pages, 2+1 figures</comments><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  Recent works have suggested that finite Bayesian neural networks may
outperform their infinite cousins because finite networks can flexibly adapt
their internal representations. However, our theoretical understanding of how
the learned hidden layer representations of finite networks differ from the
fixed representations of infinite networks remains incomplete. Perturbative
finite-width corrections to the network prior and posterior have been studied,
but the asymptotics of learned features have not been fully characterized.
Here, we argue that the leading finite-width corrections to the average feature
kernels for any Bayesian network with linear readout and quadratic cost have a
largely universal form. We illustrate this explicitly for two classes of fully
connected networks: deep linear networks and networks with a single nonlinear
hidden layer. Our results begin to elucidate which features of data wide
Bayesian neural networks learn to represent.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00652</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00652</id><submitter>Da Ma</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:30:45 GMT</date><size>10814kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 07:14:35 GMT</date><size>10814kb</size><source_type>D</source_type></version><title>Comprehensive Validation of Automated Whole Body Skeletal Muscle,
  Adipose Tissue, and Bone Segmentation from 3D CT images for Body Composition
  Analysis: Towards Extended Body Composition</title><authors>Da Ma, Vincent Chow, Karteek Popuri, Mirza Faisal Beg</authors><categories>cs.CV q-bio.TO</categories><comments>This paper is based on concepts presented at the NIH Body Composition
  and Cancer Outcomes Research Webinar Series on December 17th, 2020 by Mirza
  Faisal Beg titled &quot;Automating Body Composition from Routinely Acquired CT
  images - towards 3D measurements&quot;. The talk is archived
  [here](https://epi.grants.cancer.gov/events/body-composition/#past)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The latest advances in computer-assisted precision medicine are making it
feasible to move from population-wide models that are useful to discover
aggregate patterns that hold for group-based analysis to patient-specific
models that can drive patient-specific decisions with regard to treatment
choices, and predictions of outcomes of treatment. Body Composition is
recognized as an important driver and risk factor for a wide variety of
diseases, as well as a predictor of individual patient-specific clinical
outcomes to treatment choices or surgical interventions. 3D CT images are
routinely acquired in the oncological worklows and deliver accurate rendering
of internal anatomy and therefore can be used opportunistically to assess the
amount of skeletal muscle and adipose tissue compartments. Powerful tools of
artificial intelligence such as deep learning are making it feasible now to
segment the entire 3D image and generate accurate measurements of all internal
anatomy. These will enable the overcoming of the severe bottleneck that existed
previously, namely, the need for manual segmentation, which was prohibitive to
scale to the hundreds of 2D axial slices that made up a 3D volumetric image.
Automated tools such as presented here will now enable harvesting whole-body
measurements from 3D CT or MRI images, leading to a new era of discovery of the
drivers of various diseases based on individual tissue, organ volume, shape,
and functional status. These measurements were hitherto unavailable thereby
limiting the field to a very small and limited subset. These discoveries and
the potential to perform individual image segmentation with high speed and
accuracy are likely to lead to the incorporation of these 3D measures into
individual specific treatment planning models related to nutrition, aging,
chemotoxicity, surgery and survival after the onset of a major disease such as
cancer.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00654</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00654</id><submitter>Babatunji Omoniwa</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:38:20 GMT</date><size>447kb</size><source_type>D</source_type></version><title>A reinforcement learning approach to improve communication performance
  and energy utilization in fog-based IoT</title><authors>Babatunji Omoniwa, Maxime Gueriau and Ivana Dusparic</authors><categories>cs.LG cs.NI eess.SP</categories><comments>Submitted and published in IEEE proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has shown the potential of using available mobile fog devices
(such as smartphones, drones, domestic and industrial robots) as relays to
minimize communication outages between sensors and destination devices, where
localized Internet-of-Things services (e.g., manufacturing process control,
health and security monitoring) are delivered. However, these mobile relays
deplete energy when they move and transmit to distant destinations. As such,
power-control mechanisms and intelligent mobility of the relay devices are
critical in improving communication performance and energy utilization. In this
paper, we propose a Q-learning-based decentralized approach where each mobile
fog relay agent (MFRA) is controlled by an autonomous agent which uses
reinforcement learning to simultaneously improve communication performance and
energy utilization. Each autonomous agent learns based on the feedback from the
destination and its own energy levels whether to remain active and forward the
message, or become passive for that transmission phase. We evaluate the
approach by comparing with the centralized approach, and observe that with
lesser number of MFRAs, our approach is able to ensure reliable delivery of
data and reduce overall energy cost by 56.76\% -- 88.03\%.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00655</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00655</id><submitter>Michael Crosscombe</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:39:26 GMT</date><size>150kb</size><source_type>D</source_type></version><title>The Impact of Network Connectivity on Collective Learning</title><authors>Michael Crosscombe and Jonathan Lawry</authors><categories>cs.MA cs.AI</categories><comments>13 pages, 5 figures. To appear at the 15th International Symposium on
  Distributed Autonomous Robotic Systems 2021. Presented at the joint
  DARS-SWARM 2021 symposium held (virtually) in Kyoto, Japan</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In decentralised autonomous systems it is the interactions between individual
agents which govern the collective behaviours of the system. These local-level
interactions are themselves often governed by an underlying network structure.
These networks are particularly important for collective learning and
decision-making whereby agents must gather evidence from their environment and
propagate this information to other agents in the system. Models for collective
behaviours may often rely upon the assumption of total connectivity between
agents to provide effective information sharing within the system, but this
assumption may be ill-advised. In this paper we investigate the impact that the
underlying network has on performance in the context of collective learning.
Through simulations we study small-world networks with varying levels of
connectivity and randomness and conclude that totally-connected networks result
in higher average error when compared to networks with less connectivity.
Furthermore, we show that networks of high regularity outperform networks with
increasing levels of random connectivity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00657</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00657</id><submitter>Madison Cooley</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:44:55 GMT</date><size>1227kb</size><source_type>D</source_type></version><title>Parameterized algorithms for identifying gene co-expression modules via
  weighted clique decomposition</title><authors>Madison Cooley, Casey S. Greene, Davis Issac, Milton Pividori, and
  Blair D. Sullivan</authors><categories>cs.DS</categories><comments>To be published in SIAM Conference on Applied and Computational
  Discrete Algorithms 2021 (ACDA21)</comments><acm-class>F.2.0</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a new combinatorial model for identifying regulatory modules in
gene co-expression data using a decomposition into weighted cliques. To capture
complex interaction effects, we generalize the previously-studied weighted edge
clique partition problem. As a first step, we restrict ourselves to the
noise-free setting, and show that the problem is fixed parameter tractable when
parameterized by the number of modules (cliques). We present two new algorithms
for finding these decompositions, using linear programming and integer
partitioning to determine the clique weights. Further, we implement these
algorithms in Python and test them on a biologically-inspired synthetic corpus
generated using real-world data from transcription factors and a latent
variable analysis of co-expression in varying cell types.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00660</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00660</id><submitter>Ilia Shumailov</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:45:52 GMT</date><size>13636kb</size><source_type>D</source_type></version><title>Markpainting: Adversarial Machine Learning meets Inpainting</title><authors>David Khachaturov, Ilia Shumailov, Yiren Zhao, Nicolas Papernot, Ross
  Anderson</authors><categories>cs.LG cs.AI cs.CR cs.CV cs.CY</categories><comments>Proceedings of the 38th International Conference on Machine Learning
  (ICML 2021)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Inpainting is a learned interpolation technique that is based on generative
modeling and used to populate masked or missing pieces in an image; it has wide
applications in picture editing and retouching. Recently, inpainting started
being used for watermark removal, raising concerns. In this paper we study how
to manipulate it using our markpainting technique. First, we show how an image
owner with access to an inpainting model can augment their image in such a way
that any attempt to edit it using that model will add arbitrary visible
information. We find that we can target multiple different models
simultaneously with our technique. This can be designed to reconstitute a
watermark if the editor had been trying to remove it. Second, we show that our
markpainting technique is transferable to models that have different
architectures or were trained on different datasets, so watermarks created
using it are difficult for adversaries to remove. Markpainting is novel and can
be used as a manipulation alarm that becomes visible in the event of
inpainting.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00661</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00661</id><submitter>Tom Zahavy</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:46:25 GMT</date><size>181kb</size><source_type>D</source_type></version><title>Reward is enough for convex MDPs</title><authors>Tom Zahavy, Brendan O'Donoghue, Guillaume Desjardins and Satinder
  Singh</authors><categories>cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximising a cumulative reward function that is Markov and stationary, i.e.,
defined over state-action pairs and independent of time, is sufficient to
capture many kinds of goals in a Markov Decision Process (MDP) based on the
Reinforcement Learning (RL) problem formulation. However, not all goals can be
captured in this manner. Specifically, it is easy to see that Convex MDPs in
which goals are expressed as convex functions of stationary distributions
cannot, in general, be formulated in this manner. In this paper, we reformulate
the convex MDP problem as a min-max game between the policy and cost (negative
reward) players using Fenchel duality and propose a meta-algorithm for solving
it. We show that the average of the policies produced by an RL agent that
maximizes the non-stationary reward produced by the cost player converges to an
optimal solution to the convex MDP. Finally, we show that the meta-algorithm
unifies several disparate branches of reinforcement learning algorithms in the
literature, such as apprenticeship learning, variational intrinsic control,
constrained MDPs, and pure exploration into a single framework.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00662</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00662</id><submitter>David Purser</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:48:24 GMT</date><size>390kb</size><source_type>D</source_type></version><title>Porous Invariants</title><authors>Engel Lefaucheux, Jo\&quot;el Ouaknine, David Purser, James Worrell</authors><categories>cs.LO</categories><comments>Full version of paper to appear at CAV 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of porous invariants for multipath (or
branching/nondeterministic) affine loops over the integers; these invariants
are not necessarily convex, and can in fact contain infinitely many 'holes'.
Nevertheless, we show that in many cases such invariants can be automatically
synthesised, and moreover can be used to settle (non-)reachability questions
for various interesting classes of affine loops and target sets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00663</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00663</id><submitter>Rushikesh Kamalapurkar</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:49:05 GMT</date><size>30kb</size></version><title>An occupation kernel approach to optimal control</title><authors>Rushikesh Kamalapurkar and Joel A. Rosenfeld</authors><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this effort, a novel operator theoretic framework is developed for
data-driven solution of optimal control problems. The developed methods focus
on the use of trajectories (i.e., time-series) as the fundamental unit of data
for the resolution of optimal control problems in dynamical systems. Trajectory
information in the dynamical systems is embedded in a reproducing kernel
Hilbert space (RKHS) through what are called occupation kernels. The occupation
kernels are tied to the dynamics of the system through the densely defined
Liouville operator. The pairing of Liouville operators and occupation kernels
allows for lifting of nonlinear finite-dimensional optimal control problems
into the space of infinite-dimensional linear programs over RKHSs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00664</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00664</id><submitter>Sharon Shoham Buchbinder</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:51:05 GMT</date><size>237kb</size></version><title>Quantifiers on Demand</title><authors>Arie Gurfinkel, Sharon Shoham and Yakir Vizel</authors><categories>cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated program verification is a difficult problem. It is undecidable even
for transition systems over Linear Integer Arithmetic (LIA). Extending the
transition system with theory of Arrays, further complicates the problem by
requiring inference and reasoning with universally quantified formulas. In this
paper, we present a new algorithm, Quic3, that extends IC3 to infer universally
quantified invariants over the combined theory of LIA and Arrays. Unlike other
approaches that use either IC3 or an SMT solver as a black box, Quic3 carefully
manages quantified generalization (to construct quantified invariants) and
quantifier instantiation (to detect convergence in the presence of
quantifiers). While Quic3 is not guaranteed to converge, it is guaranteed to
make progress by exploring longer and longer executions. We have implemented
Quic3 within the Constrained Horn Clause solver engine of Z3 and experimented
with it by applying Quic3 to verifying a variety of public benchmarks of array
manipulating C programs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00665</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00665</id><submitter>Joshua Myszewski</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:51:54 GMT</date><size>283kb</size><source_type>D</source_type></version><title>Validating GAN-BioBERT: A Methodology For Assessing Reporting Trends In
  Clinical Trials</title><authors>Joshua J Myszewski, Emily Klossowski, Patrick Meyer, Kristin Bevil,
  Lisa Klesius, Kristopher M Schroeder</authors><categories>cs.CL cs.LG stat.ML</categories><comments>6 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In the past decade, there has been much discussion about the issue of biased
reporting in clinical research. Despite this attention, there have been limited
tools developed for the systematic assessment of qualitative statements made in
clinical research, with most studies assessing qualitative statements relying
on the use of manual expert raters, which limits their size. Also, previous
attempts to develop larger scale tools, such as those using natural language
processing, were limited by both their accuracy and the number of categories
used for the classification of their findings. With these limitations in mind,
this study's goal was to develop a classification algorithm that was both
suitably accurate and finely grained to be applied on a large scale for
assessing the qualitative sentiment expressed in clinical trial abstracts.
Additionally, this study seeks to compare the performance of the proposed
algorithm, GAN-BioBERT, to previous studies as well as to expert manual rating
of clinical trial abstracts. This study develops a three-class sentiment
classification algorithm for clinical trial abstracts using a semi-supervised
natural language process model based on the Bidirectional Encoder
Representation from Transformers (BERT) model, from a series of clinical trial
abstracts annotated by a group of experts in academic medicine. Results: The
use of this algorithm was found to have a classification accuracy of 91.3%,
with a macro F1-Score of 0.92, which is a significant improvement in accuracy
when compared to previous methods and expert ratings, while also making the
sentiment classification finer grained than previous studies. The proposed
algorithm, GAN-BioBERT, is a suitable classification model for the large-scale
assessment of qualitative statements in clinical trial literature, providing an
accurate, reproducible tool for the large-scale study of clinical publication
trends.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00666</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00666</id><submitter>Yuxin Fang</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:54:09 GMT</date><size>2914kb</size><source_type>D</source_type></version><title>You Only Look at One Sequence: Rethinking Transformer in Vision through
  Object Detection</title><authors>Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui
  Wu, Jianwei Niu, Wenyu Liu</authors><categories>cs.CV cs.AI cs.LG</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can Transformer perform $2\mathrm{D}$ object-level recognition from a pure
sequence-to-sequence perspective with minimal knowledge about the $2\mathrm{D}$
spatial structure? To answer this question, we present You Only Look at One
Sequence (YOLOS), a series of object detection models based on the na\&quot;ive
Vision Transformer with the fewest possible modifications as well as inductive
biases. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset
only can already achieve competitive object detection performance on COCO,
\textit{e.g.}, YOLOS-Base directly adopted from BERT-Base can achieve $42.0$
box AP. We also discuss the impacts as well as limitations of current pre-train
schemes and model scaling strategies for Transformer in vision through object
detection. Code and model weights are available at
\url{https://github.com/hustvl/YOLOS}.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00667</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00667</id><submitter>Shayan Eskandari</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:55:36 GMT</date><size>1358kb</size><source_type>D</source_type></version><title>SoK: Oracles from the Ground Truth to Market Manipulation</title><authors>Shayan Eskandari, Mehdi Salehi, Wanyun Catherine Gu, Jeremy Clark</authors><categories>cs.CR cs.SY eess.SY</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  One fundamental limitation of blockchain-based smart contracts is that they
execute in a closed environment and only have access to the data and
functionality that is either already on the blockchain or fed into the
blockchain. Thus any interactions with the real world need to be mediated by a
bridge service, which is called an oracle. As decentralized applications
mature, oracles are playing an increasingly prominent role. With their
evolution comes more attacks, necessitating a greater attention to the trust
model of using oracles. In this SoK, we systemize the design alternatives for
oracles, showcase attacks, and discuss attack mitigation strategies.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00669</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00669</id><submitter>Tom Zahavy</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:56:13 GMT</date><size>9995kb</size><source_type>D</source_type></version><title>Discovering Diverse Nearly Optimal Policies withSuccessor Features</title><authors>Tom Zahavy, Brendan O'Donoghue, Andre Barreto, Volodymyr Mnih,
  Sebastian Flennerhag and Satinder Singh</authors><categories>cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding different solutions to the same problem is a key aspect of
intelligence associated with creativity and adaptation to novel situations. In
reinforcement learning, a set of diverse policies can be useful for
exploration, transfer, hierarchy, and robustness. We propose Diverse Successive
Policies, a method for discovering policies that are diverse in the space of
Successor Features, while assuring that they are near optimal. We formalize the
problem as a Constrained Markov Decision Process (CMDP) where the goal is to
find policies that maximize diversity, characterized by an intrinsic diversity
reward, while remaining near-optimal with respect to the extrinsic reward of
the MDP. We also analyze how recently proposed robustness and discrimination
rewards perform and find that they are sensitive to the initialization of the
procedure and may converge to sub-optimal solutions. To alleviate this, we
propose new explicit diversity rewards that aim to minimize the correlation
between the Successor Features of the policies in the set. We compare the
different diversity mechanisms in the DeepMind Control Suite and find that the
type of explicit diversity we are proposing is important to discover distinct
behavior, like for example different locomotion patterns.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00671</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00671</id><submitter>Ashvin Nair</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:58:02 GMT</date><size>1993kb</size><source_type>D</source_type></version><title>What Can I Do Here? Learning New Skills by Imagining Visual Affordances</title><authors>Alexander Khazatsky, Ashvin Nair, Daniel Jing, Sergey Levine</authors><categories>cs.RO cs.CV cs.LG</categories><comments>10 pages, 10 figures. To be presented at ICRA 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalist robot equipped with learned skills must be able to perform many
tasks in many different environments. However, zero-shot generalization to new
settings is not always possible. When the robot encounters a new environment or
object, it may need to finetune some of its previously learned skills to
accommodate this change. But crucially, previously learned behaviors and models
should still be suitable to accelerate this relearning. In this paper, we aim
to study how generative models of possible outcomes can allow a robot to learn
visual representations of affordances, so that the robot can sample potentially
possible outcomes in new situations, and then further train its policy to
achieve those outcomes. In effect, prior data is used to learn what kinds of
outcomes may be possible, such that when the robot encounters an unfamiliar
setting, it can sample potential outcomes from its model, attempt to reach
them, and thereby update both its skills and its outcome model. This approach,
visuomotor affordance learning (VAL), can be used to train goal-conditioned
policies that operate on raw image inputs, and can rapidly learn to manipulate
new objects via our proposed affordance-directed exploration scheme. We show
that VAL can utilize prior data to solve real-world tasks such drawer opening,
grasping, and placing objects in new scenes with only five minutes of online
experience in the new scene.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00672</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00672</id><submitter>Marcin Andrychowicz</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:58:08 GMT</date><size>6429kb</size><source_type>D</source_type></version><title>What Matters for Adversarial Imitation Learning?</title><authors>Manu Orsini, Anton Raichuk, L\'eonard Hussenot, Damien Vincent, Robert
  Dadashi, Sertan Girgin, Matthieu Geist, Olivier Bachem, Olivier Pietquin,
  Marcin Andrychowicz</authors><categories>cs.LG cs.AI cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial imitation learning has become a popular framework for imitation
in continuous control. Over the years, several variations of its components
were proposed to enhance the performance of the learned policies as well as the
sample complexity of the algorithm. In practice, these choices are rarely
tested all together in rigorous empirical studies. It is therefore difficult to
discuss and understand what choices, among the high-level algorithmic options
as well as low-level implementation details, matter. To tackle this issue, we
implement more than 50 of these choices in a generic adversarial imitation
learning framework and investigate their impacts in a large-scale study (&gt;500k
trained agents) with both synthetic and human-generated demonstrations. While
many of our findings confirm common practices, some of them are surprising or
even contradict prior work. In particular, our results suggest that artificial
demonstrations are not a good proxy for human data and that the very common
practice of evaluating imitation algorithms only with synthetic demonstrations
may lead to algorithms which perform poorly in the more realistic scenarios
with human demonstrations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00673</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00673</id><submitter>Xiaoyu Lin</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:58:32 GMT</date><size>23134kb</size><source_type>D</source_type></version><title>Fidelity Estimation Improves Noisy-Image Classification with Pretrained
  Networks</title><authors>Xiaoyu Lin, Deblina Bhattacharjee, Majed El Helou and Sabine
  S\&quot;usstrunk</authors><categories>cs.CV eess.IV</categories><comments>Submitted to IEEE SPL for review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image classification has significantly improved using deep learning. This is
mainly due to convolutional neural networks (CNNs) that are capable of learning
rich feature extractors from large datasets. However, most deep learning
classification methods are trained on clean images and are not robust when
handling noisy ones, even if a restoration preprocessing step is applied. While
novel methods address this problem, they rely on modified feature extractors
and thus necessitate retraining. We instead propose a method that can be
applied on a pretrained classifier. Our method exploits a fidelity map estimate
that is fused into the internal representations of the feature extractor,
thereby guiding the attention of the network and making it more robust to noisy
data. We improve the noisy-image classification (NIC) results by significantly
large margins, especially at high noise levels, and come close to the fully
retrained approaches. Furthermore, as proof of concept, we show that when using
our oracle fidelity map we even outperform the fully retrained methods, whether
trained on noisy or restored images.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00676</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00676</id><submitter>Zejiang Shen</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:59:00 GMT</date><size>2953kb</size><source_type>D</source_type></version><title>Incorporating Visual Layout Structures for Scientific Text
  Classification</title><authors>Zejiang Shen, Kyle Lo, Lucy Lu Wang, Bailey Kuehl, Daniel S. Weld,
  Doug Downey</authors><categories>cs.CL cs.CV</categories><comments>13 pages, 5 figures, 6 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Classifying the core textual components of a scientific paper-title, author,
body text, etc.-is a critical first step in automated scientific document
understanding. Previous work has shown how using elementary layout information,
i.e., each token's 2D position on the page, leads to more accurate
classification. We introduce new methods for incorporating VIsual LAyout
structures (VILA), e.g., the grouping of page texts into text lines or text
blocks, into language models to further improve performance. We show that the
I-VILA approach, which simply adds special tokens denoting boundaries between
layout structures into model inputs, can lead to +1~4.5 F1 Score improvements
in token classification tasks. Moreover, we design a hierarchical model H-VILA
that encodes these layout structures and record a up-to 70% efficiency boost
without hurting prediction accuracy. The experiments are conducted on a newly
curated evaluation suite, S2-VLUE, with a novel metric measuring VILA awareness
and a new dataset covering 19 scientific disciplines with gold annotations.
Pre-trained weights, benchmark datasets, and source code will be available at
https://github.com/allenai/VILA}{https://github.com/allenai/VILA.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00677</identifier>
 <datestamp>2021-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00677</id><submitter>Mohamed El Banani</submitter><version version="v1"><date>Tue, 1 Jun 2021 17:59:08 GMT</date><size>12137kb</size><source_type>D</source_type></version><title>Bootstrap Your Own Correspondences</title><authors>Mohamed El Banani, Justin Johnson</authors><categories>cs.CV</categories><comments>Preprint. 10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric feature extraction is a crucial component of point cloud
registration pipelines. Recent work has demonstrated how supervised learning
can be leveraged to learn better and more compact 3D features. However, those
approaches' reliance on ground-truth annotation limits their scalability. We
propose BYOC: a self-supervised approach that learns visual and geometric
features from RGB-D video without relying on ground-truth pose or
correspondence. Our key observation is that randomly-initialized CNNs readily
provide us with good correspondences; allowing us to bootstrap the learning of
both visual and geometric features. Our approach combines classic ideas from
point cloud registration with more recent representation learning approaches.
We evaluate our approach on indoor scene datasets and find that our method
outperforms traditional and learned descriptors, while being competitive with
current state-of-the-art supervised approaches.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00687</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00687</id><submitter>Nik Dennler</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:00:02 GMT</date><size>3691kb</size><source_type>D</source_type></version><title>Online Detection of Vibration Anomalies Using Balanced Spiking Neural
  Networks</title><authors>Nik Dennler, Germain Haessig, Matteo Cartiglia, Giacomo Indiveri</authors><categories>cs.NE cs.AI cs.LG cs.SD eess.AS</categories><comments>This work is presented at the 2021 IEEE AICAS</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Vibration patterns yield valuable information about the health state of a
running machine, which is commonly exploited in predictive maintenance tasks
for large industrial systems. However, the overhead, in terms of size,
complexity and power budget, required by classical methods to exploit this
information is often prohibitive for smaller-scale applications such as
autonomous cars, drones or robotics. Here we propose a neuromorphic approach to
perform vibration analysis using spiking neural networks that can be applied to
a wide range of scenarios. We present a spike-based end-to-end pipeline able to
detect system anomalies from vibration data, using building blocks that are
compatible with analog-digital neuromorphic circuits. This pipeline operates in
an online unsupervised fashion, and relies on a cochlea model, on feedback
adaptation and on a balanced spiking neural network. We show that the proposed
method achieves state-of-the-art performance or better against two publicly
available data sets. Further, we demonstrate a working proof-of-concept
implemented on an asynchronous neuromorphic processor device. This work
represents a significant step towards the design and implementation of
autonomous low-power edge-computing devices for online vibration monitoring.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00694</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00694</id><submitter>James Halverson</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:00:06 GMT</date><size>2613kb</size><source_type>D</source_type></version><title>Symmetry-via-Duality: Invariant Neural Network Densities from
  Parameter-Space Correlators</title><authors>Anindita Maiti, Keegan Stoner, James Halverson</authors><categories>cs.LG hep-th stat.ML</categories><comments>20 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Parameter-space and function-space provide two different duality frames in
which to study neural networks. We demonstrate that symmetries of network
densities may be determined via dual computations of network correlation
functions, even when the density is unknown and the network is not equivariant.
Symmetry-via-duality relies on invariance properties of the correlation
functions, which stem from the choice of network parameter distributions. Input
and output symmetries of neural network densities are determined, which recover
known Gaussian process results in the infinite width limit. The mechanism may
also be utilized to determine symmetries during training, when parameters are
correlated, as well as symmetries of the Neural Tangent Kernel. We demonstrate
that the amount of symmetry in the initialization density affects the accuracy
of networks trained on Fashion-MNIST, and that symmetry breaking helps only
when it is in the direction of ground truth.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00703</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00703</id><submitter>Sebastian Wiederrecht</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:03:12 GMT</date><size>77kb</size></version><title>Excluding a Planar Matching Minor in Bipartite Graphs</title><authors>Archontia C Giannopoulou, Stephan Kreutzer, Sebastian Wiederrecht</authors><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching minors are a specialisation of minors fit for the study of graph
with perfect matchings. The notion of matching minors has been used to give a
structural description of bipartite graphs on which the number of perfect
matchings can becomputed efficiently, based on a result of Little, by McCuaig
et al. in 1999.In this paper we generalise basic ideas from the graph minor
series by Robertson and Seymour to the setting of bipartite graphs with perfect
matchings. We introducea version of Erdos-Posa property for matching minors and
find a direct link between this property and planarity. From this, it follows
that a class of bipartite graphs withperfect matchings has bounded perfect
matching width if and only if it excludes aplanar matching minor. We also
present algorithms for bipartite graphs of bounded perfect matching width for a
matching version of the disjoint paths problem, matching minor containment, and
for counting the number of perfect matchings. From our structural results, we
obtain that recognising whether a bipartite graphGcontains afixed planar
graphHas a matching minor, and that counting the number of perfect matchings of
a bipartite graph that excludes a fixed planar graph as a matching minor are
both polynomial time solvable.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00706</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00706</id><submitter>Jeremy Kozdon</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:03:45 GMT</date><size>1070kb</size><source_type>D</source_type></version><title>A Non-stiff Summation-By-Parts Finite Difference Method for the Wave
  Equation in Second Order Form: Characteristic Boundary Conditions and
  Nonlinear Interfaces</title><authors>Jeremy E Kozdon and Brittany A Erickson and Tobias Harvey</authors><categories>math.NA cs.NA</categories><comments>31 pages, 6 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Curvilinear, multiblock summation-by-parts finite difference methods with the
simultaneous approximation term method provide a stable and accurate method for
solving the wave equation in second order form. That said, the standard method
can become arbitrarily stiff when characteristic boundary conditions and
nonlinear interface conditions are used. Here we propose a new technique that
avoids this stiffness by using characteristic variables to &quot;upwind&quot; the
boundary and interface treatment. This is done through the introduction of an
additional block boundary displacement variable. Using a unified energy, which
expresses both the standard as well as characteristic boundary and interface
treatment, we show that the resulting scheme has semidiscrete energy stability
for the anistropic wave equation. The theoretical stability results are
confirmed with numerical experiments that also demonstrate the accuracy and
robustness of the proposed scheme. The numerical results also show that the
characteristic scheme has a time step restriction based on standard wave
propagation considerations and not the boundary closure.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00707</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00707</id><submitter>Shihong Deng</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:04:19 GMT</date><size>9761kb</size><source_type>D</source_type></version><title>An Entropy Regularization Free Mechanism for Policy-based Reinforcement
  Learning</title><authors>Changnan Xiao, Haosen Shi, Jiajun Fan, Shihong Deng</authors><categories>cs.LG cs.AI</categories><comments>arXiv admin note: text overlap with arXiv:2105.03923</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Policy-based reinforcement learning methods suffer from the policy collapse
problem. We find valued-based reinforcement learning methods with
{\epsilon}-greedy mechanism are capable of enjoying three characteristics,
Closed-form Diversity, Objective-invariant Exploration and Adaptive Trade-off,
which help value-based methods avoid the policy collapse problem. However,
there does not exist a parallel mechanism for policy-based methods that
achieves all three characteristics. In this paper, we propose an entropy
regularization free mechanism that is designed for policy-based methods, which
achieves Closed-form Diversity, Objective-invariant Exploration and Adaptive
Trade-off. Our experiments show that our mechanism is super sample-efficient
for policy-based methods and boosts a policy-based baseline to a new
State-Of-The-Art on Arcade Learning Environment.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00714</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00714</id><submitter>Kishlaya Jaiswal</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:13:14 GMT</date><size>162kb</size><source_type>D</source_type></version><title>Parallel Polynomial Permanent Mod Powers of 2 and Shortest Disjoint
  Cycles</title><authors>Samir Datta and Kishlaya Jaiswal</authors><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a parallel algorithm for permanent mod 2^k of a matrix of
univariate integer polynomials. It places the problem in ParityL subset of
NC^2. This extends the techniques of [Valiant], [Braverman, Kulkarni, Roy] and
[Bj\&quot;orklund, Husfeldt], and yields a (randomized) parallel algorithm for
shortest 2-disjoint paths improving upon the recent result from (randomized)
polynomial time.
  We also recognize the disjoint paths problem as a special case of finding
disjoint cycles, and present (randomized) parallel algorithms for finding a
shortest cycle and shortest 2-disjoint cycles passing through any given fixed
number of vertices or edges.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00715</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00715</id><submitter>Dan Reznik</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:14:24 GMT</date><size>163kb</size></version><title>A Theory for Locus Ellipticity of Poncelet 3-Periodics</title><authors>Mark Helman, Dominique Laurain, Dan Reznik, Ronaldo Garcia</authors><categories>math.MG cs.CG cs.RO math.AG math.DS</categories><comments>13 pages, 5 figures, 3 tables, and 5 video links</comments><msc-class>51M04, 51N20, 51N35, 68T20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a theory as to why the locus of a triangle center over Poncelet
3-periodics in an ellipse pair is an ellipse or not. For the confocal pair
(elliptic billiard), we show that if the center can be expressed as a fixed
affine combination of barycenter, circumcenter, and mittenpunkt (which is
stationary over the confocal family), then its locus will be an ellipse. We
also provide conditions under which a particular locus will be a circle or a
segment. We also analyze locus turning number and monotonicity with respect to
vertices of the 3-periodic family. Finally we write out expressions for the
convex quartic locus of the incenter for a generic Poncelet family,
conjecturing it can only be an ellipse if the pair is confocal.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00717</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00717</id><submitter>Aymen Hamrouni</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:24:02 GMT</date><size>5596kb</size><source_type>D</source_type></version><title>Low Complexity Recruitment for Collaborative Mobile Crowdsourcing Using
  Graph Neural Networks</title><authors>Aymen Hamrouni, Hakim Ghazzai, Turki Alelyani, Yehia Massoud</authors><categories>cs.LG cs.CY cs.SI</categories><comments>16 pages, 20 figures, 2 tables. Accepted for publications in IEEE
  Internet-of-things Journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Collaborative Mobile crowdsourcing (CMCS) allows entities, e.g., local
authorities or individuals, to hire a team of workers from the crowd of
connected people, to execute complex tasks. In this paper, we investigate two
different CMCS recruitment strategies allowing task requesters to form teams of
socially connected and skilled workers: i) a platform-based strategy where the
platform exploits its own knowledge about the workers to form a team and ii) a
leader-based strategy where the platform designates a group leader that
recruits its own suitable team given its own knowledge about its Social Network
(SN) neighbors. We first formulate the recruitment as an Integer Linear Program
(ILP) that optimally forms teams according to four fuzzy-logic-based criteria:
level of expertise, social relationship strength, recruitment cost, and
recruiter's confidence level. To cope with NP-hardness, we design a novel
low-complexity CMCS recruitment approach relying on Graph Neural Networks
(GNNs), specifically graph embedding and clustering techniques, to shrink the
workers' search space and afterwards, exploiting a meta-heuristic genetic
algorithm to select appropriate workers. Simulation results applied on a
real-world dataset illustrate the performance of both proposed CMCS recruitment
approaches. It is shown that our proposed low-complexity GNN-based recruitment
algorithm achieves close performances to those of the baseline ILP with
significant computational time saving and ability to operate on large-scale
mobile crowdsourcing platforms. It is also shown that compared to the
leader-based strategy, the platform-based strategy recruits a more skilled team
but with lower SN relationships and higher cost.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00718</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00718</id><submitter>Binghui Peng</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:25:06 GMT</date><size>97kb</size></version><title>Public Good Games in Directed Networks</title><authors>Christos Papadimitriou and Binghui Peng</authors><categories>cs.GT cs.DS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Public goods games in undirected networks are generally known to have pure
Nash equilibria, which are easy to find. In contrast, we prove that, in
directed networks, a broad range of public goods games have intractable
equilibrium problems: The existence of pure Nash equilibria is NP-hard to
decide, and mixed Nash equilibria are PPAD-hard to find. We define general
utility public goods games, and prove a complexity dichotomy result for finding
pure equilibria, and a PPAD-completeness proof for mixed Nash equilibria. Even
in the divisible goods variant of the problem, where existence is easy to
prove, finding the equilibrium is PPAD-complete. Finally, when the treewidth of
the directed network is appropriately bounded, we prove that polynomial-time
algorithms are possible.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00719</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00719</id><submitter>Rui Meng</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:25:22 GMT</date><size>837kb</size><source_type>D</source_type></version><title>Collaborative Nonstationary Multivariate Gaussian Process Model</title><authors>Rui Meng, Herbie Lee, Kristofer Bouchard</authors><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, multi-output Gaussian process regression models either do not
model nonstationarity or are associated with severe computational burdens and
storage demands. Nonstationary multi-variate Gaussian process models (NMGP) use
a nonstationary covariance function with an input-dependent linear model of
coregionalisation to jointly model input-dependent correlation, scale, and
smoothness of outputs. Variational sparse approximation relies on inducing
points to enable scalable computations. Here, we take the best of both worlds:
considering an inducing variable framework on the underlying latent functions
in NMGP, we propose a novel model called the collaborative nonstationary
Gaussian process model(CNMGP). For CNMGP, we derive computationally tractable
variational bounds amenable to doubly stochastic variational inference.
Together, this allows us to model data in which outputs do not share a common
input set, with a computational complexity that is independent of the size of
the inputs and outputs. We illustrate the performance of our method on
synthetic data and three real datasets and show that our model generally
pro-vides better predictive performance than the state-of-the-art, and also
provides estimates of time-varying correlations that differ across outputs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00720</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00720</id><submitter>Arghya Datta</submitter><version version="v1"><date>Tue, 1 Jun 2021 18:26:08 GMT</date><size>1589kb</size><source_type>D</source_type></version><title>Fair-Net: A Network Architecture For Reducing Performance Disparity
  Between Identifiable Sub-Populations</title><authors>Arghya Datta, S. Joshua Swamidass</authors><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In real world datasets, particular groups are under-represented, much rarer
than others, and machine learning classifiers will often preform worse on
under-represented populations. This problem is aggravated across many domains
where datasets are class imbalanced, with a minority class far rarer than the
majority class. Naive approaches to handle under-representation and class
imbalance include training sub-population specific classifiers that handle
class imbalance or training a global classifier that overlooks sub-population
disparities and aims to achieve high overall accuracy by handling class
imbalance. In this study, we find that these approaches are vulnerable in class
imbalanced datasets with minority sub-populations. We introduced Fair-Net, a
branched multitask neural network architecture that improves both
classification accuracy and probability calibration across identifiable
sub-populations in class imbalanced datasets. Fair-Nets is a straightforward
extension to the output layer and error function of a network, so can be
incorporated in far more complex architectures. Empirical studies with three
real world benchmark datasets demonstrate that Fair-Net improves classification
and calibration performance, substantially reducing performance disparity
between gender and racial sub-populations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00727</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00727</id><submitter>Vladimir Ivanov</submitter><version version="v1"><date>Thu, 13 May 2021 11:09:12 GMT</date><size>483kb</size></version><title>Surgical navigation systems based on augmented reality technologies</title><authors>Vladimir Ivanov, Anton Krivtsov, Sergey Strelkov, Dmitry Gulyaev,
  Denis Godanyuk, Nikolay Kalakutsky, Artyom Pavlov, Marina Petropavloskaya,
  Alexander Smirnov, Andrew Yaremenko</authors><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This study considers modern surgical navigation systems based on augmented
reality technologies. Augmented reality glasses are used to construct holograms
of the patient's organs from MRI and CT data, subsequently transmitted to the
glasses. This, in addition to seeing the actual patient, the surgeon gains
visualization inside the patient's body (bones, soft tissues, blood vessels,
etc.). The solutions developed at Peter the Great St. Petersburg Polytechnic
University allow reducing the invasiveness of the procedure and preserving
healthy tissues. This also improves the navigation process, making it easier to
estimate the location and size of the tumor to be removed. We describe the
application of developed systems to different types of surgical operations
(removal of a malignant brain tumor, removal of a cyst of the cervical spine).
We consider the specifics of novel navigation systems designed for anesthesia,
for endoscopic operations. Furthermore, we discuss the construction of novel
visualization systems for ultrasound machines. Our findings indicate that the
technologies proposed show potential for telemedicine.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00728</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00728</id><submitter>Md Sadman Sakib</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:00:52 GMT</date><size>5003kb</size><source_type>D</source_type></version><title>Evaluating Recipes Generated from Functional Object-Oriented Network</title><authors>Md Sadman Sakib, Hailey Baez, David Paulius, and Yu Sun</authors><categories>cs.RO cs.CV</categories><comments>This manuscript has been accepted at Ubiquitous Robots 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The functional object-oriented network (FOON) has been introduced as a
knowledge representation, which takes the form of a graph, for symbolic task
planning. To get a sequential plan for a manipulation task, a robot can obtain
a task tree through a knowledge retrieval process from the FOON. To evaluate
the quality of an acquired task tree, we compare it with a conventional form of
task knowledge, such as recipes or manuals. We first automatically convert task
trees to recipes, and we then compare them with the human-created recipes in
the Recipe1M+ dataset via a survey. Our preliminary study finds no significant
difference between the recipes in Recipe1M+ and the recipes generated from FOON
task trees in terms of correctness, completeness, and clarity.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00730</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00730</id><submitter>Tavor Baharav</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:02:09 GMT</date><size>1090kb</size><source_type>D</source_type></version><title>Enabling Efficiency-Precision Trade-offs for Label Trees in Extreme
  Classification</title><authors>Tavor Z. Baharav, Daniel L. Jiang, Kedarnath Kolluri, Sujay Sanghavi,
  Inderjit S. Dhillon</authors><categories>cs.LG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extreme multi-label classification (XMC) aims to learn a model that can tag
data points with a subset of relevant labels from an extremely large label set.
Real world e-commerce applications like personalized recommendations and
product advertising can be formulated as XMC problems, where the objective is
to predict for a user a small subset of items from a catalog of several million
products. For such applications, a common approach is to organize these labels
into a tree, enabling training and inference times that are logarithmic in the
number of labels. While training a model once a label tree is available is well
studied, designing the structure of the tree is a difficult task that is not
yet well understood, and can dramatically impact both model latency and
statistical performance. Existing approaches to tree construction fall at an
extreme point, either optimizing exclusively for statistical performance, or
for latency. We propose an efficient information theory inspired algorithm to
construct intermediary operating points that trade off between the benefits of
both. Our algorithm enables interpolation between these objectives, which was
not previously possible. We corroborate our theoretical analysis with numerical
results, showing that on the Wiki-500K benchmark dataset our method can reduce
a proxy for expected latency by up to 28% while maintaining the same accuracy
as Parabel. On several datasets derived from e-commerce customer logs, our
modified label tree is able to improve this expected latency metric by up to
20% while maintaining the same accuracy. Finally, we discuss challenges in
realizing these latency improvements in deployed models.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00732</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00732</id><submitter>Sharon Shoham Buchbinder</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:15:34 GMT</date><size>710kb</size><source_type>D</source_type></version><title>Modular Verification of Concurrent Programs via Sequential Model
  Checking</title><authors>Dan Rasin, Orna Grumberg and Sharon Shoham</authors><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work utilizes the plethora of work on verification of sequential
programs for the purpose of verifying concurrent programs. We reduce the
verification of a concurrent program to a series of verification tasks of
sequential programs. Our approach is modular in the sense that each sequential
verification task roughly corresponds to the verification of a single thread,
with some additional information about the environment in which it operates.
Information regarding the environment is gathered during the run of the
algorithm, by need.
  While our approach is general, it specializes on concurrent programs where
the threads are structured hierarchically. The idea is to exploit the hierarchy
in order to minimize the amount of information that needs to be transferred
between threads. To that end, we verify one of the threads, considered &quot;main&quot;,
as a sequential program. Its verification process initiates queries to its
&quot;environment&quot; (which may contain multiple threads). Those queries are answered
by sequential verification, if the environment consists of a single thread, or,
otherwise, by applying the same hierarchical algorithm on the environment.
  Our technique is fully automatic, and allows us to use any off-the-shelf
sequential model checker. We implemented our technique in a tool called CoMuS
and evaluated it against established tools for concurrent verification. Our
experiments show that it works particularly well on hierarchically structured
programs.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00734</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00734</id><submitter>Michael Mahoney</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:19:49 GMT</date><size>921kb</size><source_type>D</source_type></version><title>Post-mortem on a deep learning contest: a Simpson's paradox and the
  complementary roles of scale metrics versus shape metrics</title><authors>Charles H. Martin and Michael W. Mahoney</authors><categories>cs.LG stat.ML</categories><comments>23 pages; 9 figures; 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand better the causes of good generalization performance in
state-of-the-art neural network (NN) models, we analyze of a corpus of models
that was made publicly-available for a contest to predict the generalization
accuracy of NNs. These models include a wide range of qualities and were
trained with a range of architectures and regularization hyperparameters. We
identify what amounts to a Simpson's paradox: where &quot;scale&quot; metrics (from
traditional statistical learning theory) perform well overall but perform
poorly on subpartitions of the data of a given depth, when regularization
hyperparameters are varied; and where &quot;shape&quot; metrics (from Heavy-Tailed Self
Regularization theory) perform well on subpartitions of the data, when
hyperparameters are varied for models of a given depth, but perform poorly
overall when models with varying depths are aggregated. Our results highlight
the subtly of comparing models when both architectures and hyperparameters are
varied, as well as the complementary role of implicit scale versus implicit
shape parameters in understanding NN model quality. Our results also suggest
caution when one tries to extract causal insight with a single metric applied
to aggregate data, and they highlight the need to go beyond one-size-fits-all
metrics based on upper bounds from generalization theory to describe the
performance of state-of-the-art NN models. Based on these findings, we present
two novel shape metrics, one data-independent, and the other data-dependent,
which can predict trends in the test accuracy of a series of NNs, of a fixed
architecture/depth, when varying solver hyperparameters.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00736</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00736</id><submitter>Alexander Korotin</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:21:48 GMT</date><size>1050kb</size><source_type>D</source_type></version><title>Large-Scale Wasserstein Gradient Flows</title><authors>Petr Mokrov, Alexander Korotin, Lingxiao Li, Aude Genevay, Justin
  Solomon, Evgeny Burnaev</authors><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wasserstein gradient flows provide a powerful means of understanding and
solving many diffusion equations. Specifically, Fokker-Planck equations, which
model the diffusion of probability measures, can be understood as gradient
descent over entropy functionals in Wasserstein space. This equivalence,
introduced by Jordan, Kinderlehrer and Otto, inspired the so-called JKO scheme
to approximate these diffusion processes via an implicit discretization of the
gradient flow in Wasserstein space. Solving the optimization problem associated
to each JKO step, however, presents serious computational challenges. We
introduce a scalable method to approximate Wasserstein gradient flows, targeted
to machine learning applications. Our approach relies on input-convex neural
networks (ICNNs) to discretize the JKO steps, which can be optimized by
stochastic gradient descent. Unlike previous work, our method does not require
domain discretization or particle simulation. As a result, we can sample from
the measure at each time step of the diffusion and compute its probability
density. We demonstrate our algorithm's performance by computing diffusions
following the Fokker-Planck equation and apply it to unnormalized density
sampling as well as nonlinear filtering.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00737</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00737</id><submitter>Belinda Z. Li</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:23:20 GMT</date><size>933kb</size><source_type>D</source_type></version><title>Implicit Representations of Meaning in Neural Language Models</title><authors>Belinda Z. Li, Maxwell Nye, Jacob Andreas</authors><categories>cs.CL</categories><comments>15 pages, 6 figures; accepted to ACL 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Does the effectiveness of neural language models derive entirely from
accurate modeling of surface word co-occurrence statistics, or do these models
represent and reason about the world they describe? In BART and T5 transformer
language models, we identify contextual word representations that function as
models of entities and situations as they evolve throughout a discourse. These
neural representations have functional similarities to linguistic models of
dynamic semantics: they support a linear readout of each entity's current
properties and relations, and can be manipulated with predictable effects on
language generation. Our results indicate that prediction in pretrained neural
language models is supported, at least in part, by dynamic representations of
meaning and implicit simulation of entity state, and that this behavior can be
learned with only text as training data. Code and data are available at
https://github.com/belindal/state-probes .
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00739</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00739</id><submitter>Ruben Tolosana</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:33:46 GMT</date><size>371kb</size></version><title>ICDAR 2021 Competition on On-Line Signature Verification</title><authors>Ruben Tolosana, Ruben Vera-Rodriguez, Carlos Gonzalez-Garcia, Julian
  Fierrez, Santiago Rengifo, Aythami Morales, Javier Ortega-Garcia, Juan Carlos
  Ruiz-Garcia, Sergio Romero-Tapiador, Jiajia Jiang, Songxuan Lai, Lianwen Jin,
  Yecheng Zhu, Javier Galbally, Moises Diaz, Miguel Angel Ferrer, Marta
  Gomez-Barrero, Ilya Hodashinsky, Konstantin Sarin, Artem Slezkin, Marina
  Bardamova, Mikhail Svetlakov, Mohammad Saleem, Cintia Lia Sz\&quot;ucs, Bence
  Kovari, Falk Pulsmeyer, Mohamad Wehbi, Dario Zanca, Sumaiya Ahmad, Sarthak
  Mishra and Suraiya Jabin</authors><categories>cs.CV cs.HC</categories><journal-ref>Proc. International Conference on Document Analysis and
  Recognition 2021</journal-ref><license>http://creativecommons.org/licenses/by-nc-nd/4.0/</license><abstract>  This paper describes the experimental framework and results of the ICDAR 2021
Competition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021
is to evaluate the limits of on-line signature verification systems on popular
scenarios (office/mobile) and writing inputs (stylus/finger) through
large-scale public databases. Three different tasks are considered in the
competition, simulating realistic scenarios as both random and skilled
forgeries are simultaneously considered on each task. The results obtained in
SVC 2021 prove the high potential of deep learning methods. In particular, the
best on-line signature verification system of SVC 2021 obtained Equal Error
Rate (EER) values of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3).
  SVC 2021 will be established as an on-going competition, where researchers
can easily benchmark their systems against the state of the art in an open
common platform using large-scale public databases such as DeepSignDB and
SVC2021_EvalDB, and standard experimental protocols.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00740</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00740</id><submitter>Fangwei Ye</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:36:44 GMT</date><size>23kb</size></version><title>Intermittent Private Information Retrieval with Application to Location
  Privacy</title><authors>Fangwei Ye, Salim El Rouayheb</authors><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of intermittent private information retrieval with
multiple servers, in which a user consecutively requests one of K messages from
N replicated databases such that part of requests need to be protected while
others do not need privacy. Because of the correlation between requests, the
user cannot simply ignore the privacy for the non-private requests.
  We start by studying a basic two-requests system where one request is private
and the other is non-private. We propose a scheme for any correlation structure
between two requests, which concatenates an obfuscation scheme and a standard
PIR scheme to prevent leakage when retrieving information for the non-private
request. The general problem beyond two-requests would require a specification
of the correlation structure. Motivated by the location privacy application, we
study the Markov model as the correlation structure. To be concrete, we study
the problem in the context of location privacy and we apply the basic
two-requests intermittent private information retrieval scheme as a building
block to design a location privacy protection mechanism that preserves privacy
for locations in the trace level.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00742</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00742</id><submitter>Md Saroar Jahan</submitter><version version="v1"><date>Sat, 22 May 2021 21:48:14 GMT</date><size>2611kb</size><source_type>D</source_type></version><title>A systematic review of Hate Speech automatic detection using Natural
  Language Processing</title><authors>Md Saroar Jahan, Mourad Oussalah</authors><categories>cs.CL</categories><comments>34 pages, 22 Figure, 14 Table</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the multiplication of social media platforms, which offer anonymity,
easy access and online community formation, and online debate, the issue of
hate speech detection and tracking becomes a growing challenge to society,
individual, policy-makers and researchers. Despite efforts for leveraging
automatic techniques for automatic detection and monitoring, their performances
are still far from satisfactory, which constantly calls for future research on
the issue. This paper provides a systematic review of literature in this field,
with a focus on natural language processing and deep learning technologies,
highlighting the terminology, processing pipeline, core methods employed, with
a focal point on deep learning architecture. From a methodological perspective,
we adopt PRISMA guideline of systematic review of the last 10 years literature
from ACM Digital Library and Google Scholar. In the sequel, existing surveys,
limitations, and future research directions are extensively discussed.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00745</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00745</id><submitter>Ofek Rafaeli</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:48:23 GMT</date><size>803kb</size></version><version version="v2"><date>Thu, 3 Jun 2021 11:24:28 GMT</date><size>745kb</size></version><title>Part of Speech and Universal Dependency effects on English Arabic
  Machine Translation</title><authors>Ofek Rafaeli, Omri Abend, Leshem Choshen, Dmitry Nikolaev</authors><categories>cs.CL cs.AI cs.LG</categories><comments>19 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this research paper, I will elaborate on a method to evaluate machine
translation models based on their performance on underlying syntactical
phenomena between English and Arabic languages. This method is especially
important as such &quot;neural&quot; and &quot;machine learning&quot; are hard to fine-tune and
change. Thus, finding a way to evaluate them easily and diversely would greatly
help the task of bettering them.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00746</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00746</id><submitter>Dimitri Bertsekas</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:50:22 GMT</date><size>15kb</size></version><title>On-Line Policy Iteration for Infinite Horizon Dynamic Programming</title><authors>Dimitri Bertsekas</authors><categories>math.OC cs.AI cs.SY eess.SY</categories><acm-class>I.2</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we propose an on-line policy iteration (PI) algorithm for
finite-state infinite horizon discounted dynamic programming, whereby the
policy improvement operation is done on-line, only for the states that are
encountered during operation of the system. This allows the continuous
updating/improvement of the current policy, thus resulting in a form of on-line
PI that incorporates the improved controls into the current policy as new
states and controls are generated. The algorithm converges in a finite number
of stages to a type of locally optimal policy, and suggests the possibility of
variants of PI and multiagent PI where the policy improvement is simplified.
Moreover, the algorithm can be used with on-line replanning, and is also
well-suited for on-line PI algorithms with value and policy approximations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00749</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00749</id><submitter>Ran Zmigrod</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:51:55 GMT</date><size>94kb</size><source_type>D</source_type></version><title>Higher-order Derivatives of Weighted Finite-state Machines</title><authors>Ran Zmigrod, Tim Vieira, Ryan Cotterell</authors><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Weighted finite-state machines are a fundamental building block of NLP
systems. They have withstood the test of time -- from their early use in noisy
channel models in the 1990s up to modern-day neurally parameterized conditional
random fields. This work examines the computation of higher-order derivatives
with respect to the normalization constant for weighted finite-state machines.
We provide a general algorithm for evaluating derivatives of all orders, which
has not been previously described in the literature. In the case of
second-order derivatives, our scheme runs in the optimal $\mathcal{O}(A^2 N^4)$
time where $A$ is the alphabet size and $N$ is the number of states. Our
algorithm is significantly faster than prior algorithms. Additionally, our
approach leads to a significantly faster algorithm for computing second-order
expectations, such as covariance matrices and gradients of first-order
expectations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00750</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00750</id><submitter>Sana Tonekaboni</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:53:24 GMT</date><size>2747kb</size><source_type>D</source_type></version><title>Unsupervised Representation Learning for Time Series with Temporal
  Neighborhood Coding</title><authors>Sana Tonekaboni, Danny Eytan, Anna Goldenberg</authors><categories>cs.LG stat.ML</categories><comments>Camera-ready at ICLR 2021</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time series are often complex and rich in information but sparsely labeled
and therefore challenging to model. In this paper, we propose a self-supervised
framework for learning generalizable representations for non-stationary time
series. Our approach, called Temporal Neighborhood Coding (TNC), takes
advantage of the local smoothness of a signal's generative process to define
neighborhoods in time with stationary properties. Using a debiased contrastive
objective, our framework learns time series representations by ensuring that in
the encoding space, the distribution of signals from within a neighborhood is
distinguishable from the distribution of non-neighboring signals. Our
motivation stems from the medical field, where the ability to model the dynamic
nature of time series data is especially valuable for identifying, tracking,
and predicting the underlying patients' latent states in settings where
labeling data is practically impossible. We compare our method to recently
developed unsupervised representation learning approaches and demonstrate
superior performance on clustering and classification tasks for multiple
datasets.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00753</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00753</id><submitter>Zaccharie Ramzi</submitter><version version="v1"><date>Tue, 1 Jun 2021 19:59:21 GMT</date><size>5981kb</size><source_type>D</source_type></version><title>Is good old GRAPPA dead?</title><authors>Zaccharie Ramzi, Alexandre Vignaud, Jean-Luc Starck, Philippe Ciuciu</authors><categories>eess.IV cs.LG physics.med-ph</categories><comments>Presented at ISMRM 2021</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We perform a qualitative analysis of performance of XPDNet, a
state-of-the-art deep learning approach for MRI reconstruction, compared to
GRAPPA, a classical approach. We do this in multiple settings, in particular
testing the robustness of the XPDNet to unseen settings, and show that the
XPDNet can to some degree generalize well.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00755</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00755</id><submitter>Americo Cunha Jr</submitter><version version="v1"><date>Thu, 27 May 2021 22:09:41 GMT</date><size>2597kb</size><source_type>D</source_type></version><title>Assessment of a transient homogeneous reactor through in situ adaptive
  tabulation</title><authors>Americo Cunha Jr, Luis Fernando Figueira da Silva</authors><categories>physics.flu-dyn cs.CE math.DS stat.CO</categories><msc-class>37N10</msc-class><acm-class>I.6.5</acm-class><journal-ref>Journal of the Brazilian Society of Mechanical Sciences and
  Engineering, vol. 36, pp. 377, 2014</journal-ref><doi>10.1007/s40430-013-0080-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of computational models for the numerical simulation of
chemically reacting flows operating in the turbulent regime requires the
solution of partial differential equations that represent the balance of mass,
linear momentum, chemical species, and energy. The chemical reactions of the
model may involve detailed reaction mechanisms for the description of the
physicochemical phenomena. One of the biggest challenges is the stiffness of
the numerical simulation of these models and the nonlinear nature of species
rate of reaction. This work presents a study of in situ adaptive tabulation
(ISAT) technique, focusing on the accuracy, efficiency, and memory usage in the
simulation of homogeneous stirred reactor models using simple and complex
reaction mechanisms. The combustion of carbon monoxide with oxygen and methane
with air mixtures are considered, using detailed reaction mechanisms with 4 and
53 species, 3 and 325 reactions, respectively. The results of these simulations
indicate that the developed implementation of ISAT technique has a absolute
global error smaller than 1 %. Moreover, ISAT technique provides gains, in
terms of computational time, of up to 80% when compared with the direct
integration of the full chemical kinetics. However, in terms of memory usage
the present implementation of ISAT technique is found to be excessively
demanding.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00757</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00757</id><submitter>Petar Veli\v{c}kovi\'c</submitter><version version="v1"><date>Mon, 31 May 2021 16:37:55 GMT</date><size>704kb</size><source_type>D</source_type></version><title>Neural message passing for joint paratope-epitope prediction</title><authors>Alice Del Vecchio, Andreea Deac, Pietro Li\`o and Petar
  Veli\v{c}kovi\'c</authors><categories>q-bio.QM cs.LG q-bio.BM</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Antibodies are proteins in the immune system which bind to antigens to detect
and neutralise them. The binding sites in an antibody-antigen interaction are
known as the paratope and epitope, respectively, and the prediction of these
regions is key to vaccine and synthetic antibody development. Contrary to prior
art, we argue that paratope and epitope predictors require asymmetric
treatment, and propose distinct neural message passing architectures that are
geared towards the specific aspects of paratope and epitope prediction,
respectively. We obtain significant improvements on both tasks, setting the new
state-of-the-art and recovering favourable qualitative predictions on antigens
of relevance to COVID-19.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00759</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00759</id><submitter>Ajay Pratap</submitter><version version="v1"><date>Thu, 20 May 2021 09:51:38 GMT</date><size>2527kb</size><source_type>D</source_type></version><title>Covid-19 Spread Detection and Controlling with Fog-based Infection
  Probability Evaluation Model</title><authors>Suraj Mahawar and Ajay Pratap</authors><categories>cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  COVID-19 has created a pandemic around the world, paused the path of building
the future, and still ongoing without having any long-term solution shortly.
The time taken in vaccine distribution is too slow compared to the spread of
COVID-19. Hence, it is important to aware and takes precautions on time without
delaying and waiting for long-duration after getting infected with the virus.
Currently used technology is more advanced than ever before. Almost everyone
has access to at least one mobile device with an Internet connection.
Therefore, we propose a Fog Server (FS) based system that can be used to create
awareness about the spread of COVID-19 within the surroundings of individuals
utilizing the concept of Hidden Markov Models (HMM) and Bluetooth contact
tracing, in polynomial computational time complexity. Moreover, we evaluate the
effectiveness of the proposed model through real-world data analysis on
different simulation parameter settings.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00761</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00761</id><submitter>Maciej Besta</submitter><version version="v1"><date>Wed, 26 May 2021 17:56:37 GMT</date><size>261kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 15:59:58 GMT</date><size>288kb</size><source_type>D</source_type></version><title>Motif Prediction with Graph Neural Networks</title><authors>Maciej Besta, Raphael Grob, Cesare Miglioli, Nicola Bernold, Grzegorz
  Kwasniewski, Gabriel Gjini, Raghavendra Kanakagiri, Saleh Ashkboos, Lukas
  Gianinazzi, Nikoli Dryden, Torsten Hoefler</authors><categories>cs.SI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link prediction is one of the central problems in graph mining. However,
recent studies highlight the importance of higher-order network analysis, where
complex structures called motifs are the first-class citizens. We first show
that existing link prediction schemes fail to effectively predict motifs. To
alleviate this, we establish a general motif prediction problem and we propose
several heuristics that assess the chances for a specified motif to appear. To
make the scores realistic, our heuristics consider - among others -
correlations between links, i.e., the potential impact of some arriving links
on the appearance of other links in a given motif. Finally, for highest
accuracy, we develop a graph neural network (GNN) architecture for motif
prediction. Our architecture offers vertex features and sampling schemes that
capture the rich structural properties of motifs. While our heuristics are fast
and do not need any training, GNNs ensure highest accuracy of predicting
motifs, both for dense (e.g., k-cliques) and for sparse ones (e.g., k-stars).
We consistently outperform the best available competitor by more than 10% on
average and up to 32% in area under the curve. Importantly, the advantages of
our approach over schemes based on uncorrelated link prediction increase with
the increasing motif size and complexity. We also successfully apply our
architecture for predicting more arbitrary clusters and communities,
illustrating its potential for graph mining beyond motif analysis.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00762</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00762</id><submitter>Preetam Nandy</submitter><version version="v1"><date>Sat, 29 May 2021 00:11:42 GMT</date><size>3498kb</size><source_type>D</source_type></version><title>A/B Testing for Recommender Systems in a Two-sided Marketplace</title><authors>Preetam Nandy, Divya Venugopalan, Chun Lo, Shaunak Chatterjee</authors><categories>cs.SI stat.AP stat.ME</categories><msc-class>62K99, 62G05, 62P30</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Two-sided marketplaces are standard business models of many online platforms
(e.g., Amazon, Facebook, LinkedIn), wherein the platforms have consumers,
buyers or content viewers on one side and producers, sellers or
content-creators on the other. Consumer side measurement of the impact of a
treatment variant can be done via simple online A/B testing. \textit{Producer
side measurement is more challenging because the producer experience depends on
the treatment assignment of the consumers}. Existing approaches for producer
side measurement are either based on graph cluster-based randomization or on
certain treatment propagation assumptions. The former approach results in
low-powered experiments as the producer-consumer network density increases and
the latter approach lacks a strict notion of error control. In this paper, we
propose (i) a quantification of the quality of a producer side experiment, and
(ii) a new experiment design mechanism that generates high quality experiments
based on this quantification. Our approach, called UniCoRn ({Uni}fying
{Co}unterfactual {R}a{n}kings), provides explicit control over the quality of
the experiment and its computation cost. Further, we prove that our experiment
design is optimal. Our approach is agnostic to the density of the
producer-consumer network and does not rely on any treatment propagation
assumption. Moreover, unlike the existing approaches, we do not need to know
the underlying network in advance, making this widely applicable to the
industrial setting where the underlying network is unknown and challenging to
predict a priori due to its dynamic nature. We use simulations to thoroughly
validate our approach and compare it against existing methods. We also
implement UniCoRn in an edge recommendation application that serves tens of
millions of members and billions of edge recommendations daily.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00764</identifier>
 <datestamp>2021-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00764</id><submitter>Dongyun Han</submitter><version version="v1"><date>Tue, 1 Jun 2021 20:02:29 GMT</date><size>18217kb</size><source_type>D</source_type></version><version version="v2"><date>Thu, 3 Jun 2021 03:38:43 GMT</date><size>18216kb</size><source_type>D</source_type></version><title>HisVA: A Visual Analytics System for Studying History</title><authors>Dongyun Han, Gorakh Parsad, Hwiyeon Kim, Jaekyom Shim, Oh-Sang Kwon,
  Kyung A Son, Jooyoung Lee, Isaac Cho, and Sungahn Ko</authors><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studying history involves many difficult tasks. Examples include searching
for proper data in a large event space, understanding stories of historical
events by time and space, and finding relationships among events that may not
be apparent. Instructors who extensively use well-organized and well-argued
materials (e.g., textbooks and online resources) can lead students to a narrow
perspective in understanding history and prevent spontaneous investigation of
historical events, with the students asking their own questions. In this work,
we proposed HisVA, a visual analytics system that allows the efficient
exploration of historical events from Wikipedia using three views: event, map,
and resource. HisVA provides an effective event exploration space, where users
can investigate relationships among historical events by reviewing and linking
them in terms of space and time. To evaluate our system, we present two usage
scenarios, a user study with a qualitative analysis of user exploration
strategies, and %expert feedback with in-class deployment results.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00765</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00765</id><submitter>Nou\'edyn Baspin</submitter><version version="v1"><date>Tue, 1 Jun 2021 20:03:16 GMT</date><size>885kb</size><source_type>D</source_type></version><title>Connectivity constrains quantum codes</title><authors>Nou\'edyn Baspin, Anirudh Krishna</authors><categories>quant-ph cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum low-density parity-check (LDPC) codes are an important class of
quantum error correcting codes. In such codes, each qubit only affects a
constant number of syndrome bits, and each syndrome bit only relies on some
constant number of qubits. Constructing quantum LDPC codes is challenging. It
is an open problem to understand if there exist good quantum LDPC codes, i.e.
with constant rate and relative distance. Furthermore, techniques to perform
fault-tolerant gates are poorly understood. We present a unified way to address
these problems. Our main results are a) a bound on the distance, b) a bound on
the code dimension and c) limitations on certain fault-tolerant gates that can
be applied to quantum LDPC codes. All three of these bounds are cast as a
function of the graph separator of the connectivity graph representation of the
quantum code. We find that unless the connectivity graph contains an expander,
the code is severely limited. This implies a necessary, but not sufficient,
condition to construct good codes. This is the first bound that studies the
limitations of quantum LDPC codes that does not rely on locality. As an
application, we present novel bounds on quantum LDPC codes associated with
local graphs in $D$-dimensional hyperbolic space.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00767</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00767</id><submitter>Mohammad Arani</submitter><version version="v1"><date>Fri, 28 May 2021 22:14:04 GMT</date><size>697kb</size></version><title>A Simulation-Optimization Technique for Service Level Analysis in
  Conjunction with Reorder Point Estimation and Lead-Time consideration: A Case
  Study in Sea Port</title><authors>Mohammad Arani and Saeed Abdolmaleki and Maryam Maleki and Mohsen
  Momenitabar and Xian Liu</authors><categories>eess.SY cs.SY math.OC</categories><comments>will be available https://www.springer.com/gp/book/9783030699833</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study offers a step-by-step practical procedure from the analysis of the
current status of the spare parts inventory system to advanced service-level
analysis by virtue of simulation-optimization technique for a real-world case
study associated with a seaport. The remarkable variety and immense diversity
on one hand, and extreme complexities not only in consumption patterns but in
the supply of spare parts in an international port with technically advance
port operator machinery, on the other hand, have convinced the managers to deal
with this issue in a structural framework. The huge available data require
cleaning and classification to properly process them and derive reorder point
(ROP) estimation, reorder quantity (ROQ) estimation, and associated service
level analysis. Finally, from 247000 items used in 9 years long, 1416 inventory
items are elected as a result of ABC analysis integrating with the Analytic
Hierarchy Process (AHP), which led to the main items that need to be kept under
strict inventory control. The ROPs and the pertinent quantities are simulated
by Arena software for all the main items, each of which took approximately 30
minutes run-time on a personal computer to determine near-optimal estimations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00769</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00769</id><submitter>Mike Wu</submitter><version version="v1"><date>Tue, 1 Jun 2021 20:07:16 GMT</date><size>1261kb</size><source_type>D</source_type></version><title>Improving Compositionality of Neural Networks by Decoding
  Representations to Inputs</title><authors>Mike Wu, Noah Goodman, Stefano Ermon</authors><categories>cs.LG</categories><comments>9 pages content; 2 pages appendix</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In traditional software programs, we take for granted how easy it is to debug
code by tracing program logic from variables back to input, apply unit tests
and assertion statements to block erroneous behavior, and compose programs
together. But as the programs we write grow more complex, it becomes hard to
apply traditional software to applications like computer vision or natural
language. Although deep learning programs have demonstrated strong performance
on these applications, they sacrifice many of the functionalities of
traditional software programs. In this paper, we work towards bridging the
benefits of traditional and deep learning programs by jointly training a
generative model to constrain neural network activations to &quot;decode&quot; back to
inputs. Doing so enables practitioners to probe and track information encoded
in activation(s), apply assertion-like constraints on what information is
encoded in an activation, and compose separate neural networks together in a
plug-and-play fashion. In our experiments, we demonstrate applications of
decodable representations to out-of-distribution detection, adversarial
examples, calibration, and fairness -- while matching standard neural networks
in accuracy.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00771</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00771</id><submitter>Constantinos Psomas</submitter><version version="v1"><date>Tue, 1 Jun 2021 20:11:47 GMT</date><size>71kb</size></version><title>SWIPT with Intelligent Reflecting Surfaces under Spatial Correlation</title><authors>Constantinos Psomas and Ioannis Krikidis</authors><categories>cs.IT eess.SP math.IT</categories><comments>IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surfaces (IRSs) can be beneficial to both information
and energy transfer, due to the gains achieved by their multiple elements. In
this work, we deal with the impact of spatial correlation between the IRS
elements, in the context of simultaneous wireless information and power
transfer. The performance is evaluated in terms of the average harvested energy
and the outage probability for random and equal phase shifts. Closed-form
analytical expressions for both metrics under spatial correlation are derived.
Moreover, the optimal case is considered when the elements are uncorrelated and
fully correlated. In the uncorrelated case, random and equal phase shifts
provide the same performance. However, the performance of correlated elements
attains significant gains when there are equal phase shifts. Finally, we show
that correlation is always beneficial to energy transfer, whereas it is a
degrading factor for information transfer under random and optimal
configurations.
</abstract></arXivRaw>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2106.00772</identifier>
 <datestamp>2021-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXivRaw xmlns="http://arxiv.org/OAI/arXivRaw/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXivRaw/ http://arxiv.org/OAI/arXivRaw.xsd">
 <id>2106.00772</id><submitter>Sajad Khodadadian</submitter><version version="v1"><date>Tue, 1 Jun 2021 20:11:54 GMT</date><size>64kb</size><source_type>D</source_type></version><title>Information Theoretic Measures for Fairness-aware Feature Selection</title><authors>Sajad Khodadadian, Mohamed Nafea, AmirEmad Ghassami, Negar Kiyavash</authors><categories>cs.LG cs.CY cs.IT math.IT</categories><comments>15 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Machine earning algorithms are increasingly used for consequential decision
making regarding individuals based on their relevant features. Features that
are relevant for accurate decisions may however lead to either explicit or
implicit forms of discrimination against unprivileged groups, such as those of
certain race or gender. This happens due to existing biases in the training
data, which are often replicated or even exacerbated by the learning algorithm.
Identifying and measuring these biases at the data level is a challenging
problem due to the interdependence among the features, and the decision
outcome. In this work, we develop a framework for fairness-aware feature
selection, based on information theoretic measures for the accuracy and
discriminatory impacts of features. Specifically, our goal is to design a
fairness utility score for each feature which quantifies how this feature
influences accurate as well as nondiscriminatory decisions. We first propose
information theoretic measures for the impact of different subsets of features
on the accuracy and discrimination of the model. Subsequently, we deduce the
marginal impact of each feature using Shapley value function. Our framework
depends on the joint statistics of the data rather than a particular classifier
design. We examine our proposed framework on real and synthetic data to
evaluate its performance.
</abstract></arXivRaw>
</metadata>
</record>
<resumptionToken cursor="1000" completeListSize="2583">5392151|2001</resumptionToken>
</ListRecords>
</OAI-PMH>
